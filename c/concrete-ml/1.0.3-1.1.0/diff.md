# Comparing `tmp/concrete_ml-1.0.3-py3-none-any.whl.zip` & `tmp/concrete_ml-1.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,58 +1,58 @@
-Zip file size: 178062 bytes, number of entries: 56
+Zip file size: 179089 bytes, number of entries: 56
 -rw-r--r--  2.0 unx      284 b- defN 80-Jan-01 00:00 concrete/__init__.py
 -rw-r--r--  2.0 unx       51 b- defN 80-Jan-01 00:00 concrete/ml/__init__.py
 -rw-r--r--  2.0 unx       95 b- defN 80-Jan-01 00:00 concrete/ml/common/__init__.py
 -rw-r--r--  2.0 unx     2519 b- defN 80-Jan-01 00:00 concrete/ml/common/check_inputs.py
 -rw-r--r--  2.0 unx      101 b- defN 80-Jan-01 00:00 concrete/ml/common/debugging/__init__.py
 -rw-r--r--  2.0 unx     2377 b- defN 80-Jan-01 00:00 concrete/ml/common/debugging/custom_assert.py
 -rw-r--r--  2.0 unx     1221 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/__init__.py
 -rw-r--r--  2.0 unx     8204 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/decoder.py
 -rw-r--r--  2.0 unx      601 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/dumpers.py
--rw-r--r--  2.0 unx    12166 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/encoder.py
+-rw-r--r--  2.0 unx    12167 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/encoder.py
 -rw-r--r--  2.0 unx      743 b- defN 80-Jan-01 00:00 concrete/ml/common/serialization/loaders.py
--rw-r--r--  2.0 unx    18125 b- defN 80-Jan-01 00:00 concrete/ml/common/utils.py
+-rw-r--r--  2.0 unx    18128 b- defN 80-Jan-01 00:00 concrete/ml/common/utils.py
 -rw-r--r--  2.0 unx      235 b- defN 80-Jan-01 00:00 concrete/ml/deployment/Dockerfile.server
 -rw-r--r--  2.0 unx      121 b- defN 80-Jan-01 00:00 concrete/ml/deployment/__init__.py
 -rw-r--r--  2.0 unx    17918 b- defN 80-Jan-01 00:00 concrete/ml/deployment/deploy_to_aws.py
 -rw-r--r--  2.0 unx     3800 b- defN 80-Jan-01 00:00 concrete/ml/deployment/deploy_to_docker.py
--rw-r--r--  2.0 unx    13873 b- defN 80-Jan-01 00:00 concrete/ml/deployment/fhe_client_server.py
+-rw-r--r--  2.0 unx    13773 b- defN 80-Jan-01 00:00 concrete/ml/deployment/fhe_client_server.py
 -rw-r--r--  2.0 unx     2590 b- defN 80-Jan-01 00:00 concrete/ml/deployment/server.py
 -rw-r--r--  2.0 unx       33 b- defN 80-Jan-01 00:00 concrete/ml/deployment/server_requirements.txt
 -rw-r--r--  2.0 unx     3293 b- defN 80-Jan-01 00:00 concrete/ml/deployment/utils.py
 -rw-r--r--  2.0 unx       19 b- defN 80-Jan-01 00:00 concrete/ml/onnx/__init__.py
 -rw-r--r--  2.0 unx     3472 b- defN 80-Jan-01 00:00 concrete/ml/onnx/convert.py
 -rw-r--r--  2.0 unx     9401 b- defN 80-Jan-01 00:00 concrete/ml/onnx/onnx_impl_utils.py
 -rw-r--r--  2.0 unx     9685 b- defN 80-Jan-01 00:00 concrete/ml/onnx/onnx_model_manipulations.py
 -rw-r--r--  2.0 unx    20192 b- defN 80-Jan-01 00:00 concrete/ml/onnx/onnx_utils.py
--rw-r--r--  2.0 unx    58079 b- defN 80-Jan-01 00:00 concrete/ml/onnx/ops_impl.py
+-rw-r--r--  2.0 unx    58085 b- defN 80-Jan-01 00:00 concrete/ml/onnx/ops_impl.py
 -rw-r--r--  2.0 unx      101 b- defN 80-Jan-01 00:00 concrete/ml/pytest/__init__.py
--rw-r--r--  2.0 unx    43914 b- defN 80-Jan-01 00:00 concrete/ml/pytest/torch_models.py
--rw-r--r--  2.0 unx    14823 b- defN 80-Jan-01 00:00 concrete/ml/pytest/utils.py
+-rw-r--r--  2.0 unx    45787 b- defN 80-Jan-01 00:00 concrete/ml/pytest/torch_models.py
+-rw-r--r--  2.0 unx    15760 b- defN 80-Jan-01 00:00 concrete/ml/pytest/utils.py
 -rw-r--r--  2.0 unx     1081 b- defN 80-Jan-01 00:00 concrete/ml/quantization/__init__.py
--rw-r--r--  2.0 unx    41430 b- defN 80-Jan-01 00:00 concrete/ml/quantization/base_quantized_op.py
+-rw-r--r--  2.0 unx    41439 b- defN 80-Jan-01 00:00 concrete/ml/quantization/base_quantized_op.py
 -rw-r--r--  2.0 unx    43710 b- defN 80-Jan-01 00:00 concrete/ml/quantization/post_training.py
--rw-r--r--  2.0 unx    26450 b- defN 80-Jan-01 00:00 concrete/ml/quantization/quantized_module.py
--rw-r--r--  2.0 unx    81014 b- defN 80-Jan-01 00:00 concrete/ml/quantization/quantized_ops.py
+-rw-r--r--  2.0 unx    25888 b- defN 80-Jan-01 00:00 concrete/ml/quantization/quantized_module.py
+-rw-r--r--  2.0 unx    81023 b- defN 80-Jan-01 00:00 concrete/ml/quantization/quantized_ops.py
 -rw-r--r--  2.0 unx    35671 b- defN 80-Jan-01 00:00 concrete/ml/quantization/quantizers.py
 -rw-r--r--  2.0 unx       77 b- defN 80-Jan-01 00:00 concrete/ml/search_parameters/__init__.py
 -rw-r--r--  2.0 unx    21193 b- defN 80-Jan-01 00:00 concrete/ml/search_parameters/p_error_search.py
 -rw-r--r--  2.0 unx     4679 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/__init__.py
--rw-r--r--  2.0 unx    64073 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/base.py
+-rw-r--r--  2.0 unx    64360 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/base.py
 -rw-r--r--  2.0 unx    12899 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/glm.py
 -rw-r--r--  2.0 unx    21814 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/linear_model.py
 -rw-r--r--  2.0 unx    32152 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/qnn.py
 -rw-r--r--  2.0 unx    12803 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/qnn_module.py
 -rw-r--r--  2.0 unx    11043 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/rf.py
 -rw-r--r--  2.0 unx     9155 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/svm.py
--rw-r--r--  2.0 unx     9191 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/tree.py
+-rw-r--r--  2.0 unx    10045 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/tree.py
 -rw-r--r--  2.0 unx    10923 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/tree_to_numpy.py
 -rw-r--r--  2.0 unx    18962 b- defN 80-Jan-01 00:00 concrete/ml/sklearn/xgb.py
 -rw-r--r--  2.0 unx       83 b- defN 80-Jan-01 00:00 concrete/ml/torch/__init__.py
--rw-r--r--  2.0 unx    19083 b- defN 80-Jan-01 00:00 concrete/ml/torch/compile.py
+-rw-r--r--  2.0 unx    19510 b- defN 80-Jan-01 00:00 concrete/ml/torch/compile.py
 -rw-r--r--  2.0 unx     3174 b- defN 80-Jan-01 00:00 concrete/ml/torch/numpy_module.py
 -rw-r--r--  2.0 unx      124 b- defN 80-Jan-01 00:00 concrete/ml/version.py
--rw-r--r--  2.0 unx     1546 b- defN 80-Jan-01 00:00 concrete_ml-1.0.3.dist-info/LICENSE
-?rw-r--r--  2.0 unx       88 b- defN 16-Jan-01 00:00 concrete_ml-1.0.3.dist-info/WHEEL
-?rw-r--r--  2.0 unx    11617 b- defN 16-Jan-01 00:00 concrete_ml-1.0.3.dist-info/METADATA
-?rw-r--r--  2.0 unx     5066 b- defN 16-Jan-01 00:00 concrete_ml-1.0.3.dist-info/RECORD
-56 files, 747137 bytes uncompressed, 169932 bytes compressed:  77.3%
+-rw-r--r--  2.0 unx     1546 b- defN 80-Jan-01 00:00 concrete_ml-1.1.0.dist-info/LICENSE
+?rw-r--r--  2.0 unx       88 b- defN 16-Jan-01 00:00 concrete_ml-1.1.0.dist-info/WHEEL
+?rw-r--r--  2.0 unx    12275 b- defN 16-Jan-01 00:00 concrete_ml-1.1.0.dist-info/METADATA
+?rw-r--r--  2.0 unx     5067 b- defN 16-Jan-01 00:00 concrete_ml-1.1.0.dist-info/RECORD
+56 files, 751540 bytes uncompressed, 170959 bytes compressed:  77.3%
```

## zipnote {}

```diff
@@ -150,20 +150,20 @@
 
 Filename: concrete/ml/torch/numpy_module.py
 Comment: 
 
 Filename: concrete/ml/version.py
 Comment: 
 
-Filename: concrete_ml-1.0.3.dist-info/LICENSE
+Filename: concrete_ml-1.1.0.dist-info/LICENSE
 Comment: 
 
-Filename: concrete_ml-1.0.3.dist-info/WHEEL
+Filename: concrete_ml-1.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: concrete_ml-1.0.3.dist-info/METADATA
+Filename: concrete_ml-1.1.0.dist-info/METADATA
 Comment: 
 
-Filename: concrete_ml-1.0.3.dist-info/RECORD
+Filename: concrete_ml-1.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## concrete/ml/common/serialization/encoder.py

```diff
@@ -180,15 +180,15 @@
             o (Any): The object to serialize.
 
         Returns:
             Any: The serialized object. Non-native types are returned as a dict of a specific
                 format.
 
         Raises:
-            NotImplementedError: If a fhe.Circuit, a Callable or a Generator object is given.
+            NotImplementedError: If an FHE.Circuit, a Callable or a Generator object is given.
         """
 
         # Serializing a Circuit object is currently not supported
         # FIXME: https://github.com/zama-ai/concrete-numpy-internal/issues/1841
         if isinstance(o, fhe.Circuit):
             raise NotImplementedError("Concrete Circuit object serialization is not implemented.")
```

## concrete/ml/common/utils.py

```diff
@@ -114,15 +114,15 @@
             returned in a dictionary. Only the sanitized names will work for a call to the proxy
             function.
 
     Returns:
         Tuple[Callable, Dict[str, str]]: the proxy function and the mapping of the original arg name
             to the new and sanitized arg names.
     """
-    # Some input names can be invalid arg names (eg coming from torch input.0) so sanitize them
+    # Some input names can be invalid arg names (e.g., coming from torch input.0) so sanitize them
     # to be valid Python arg names.
     orig_args_to_proxy_func_args = {
         arg_name: f"_{replace_invalid_arg_name_chars(arg_name)}"
         for arg_name in desired_functions_arg_names
     }
     proxy_func_arg_string = ", ".join(orig_args_to_proxy_func_args.values())
     proxy_func_name = replace_invalid_arg_name_chars(f"{function_to_proxy.__name__}_proxy")
```

## concrete/ml/deployment/Dockerfile.server

```diff
@@ -1,8 +1,8 @@
-FROM concrete-ml-release:latest
+FROM zamafhe/concrete-ml:latest
 WORKDIR /project
 COPY dev dev
 COPY server_requirements.txt server_requirements.txt
 COPY server.py server.py
 RUN python -m pip install -r ./server_requirements.txt
 EXPOSE 5000
 ENTRYPOINT python server.py
```

## concrete/ml/deployment/fhe_client_server.py

```diff
@@ -87,22 +87,22 @@
             serialized_evaluation_keys (bytes): the serialized evaluation keys
 
         Returns:
             bytes: the result of the model
         """
         assert_true(self.server is not None, "Model has not been loaded.")
 
-        deserialized_encrypted_quantized_data = self.server.client_specs.deserialize_public_args(
+        deserialized_encrypted_quantized_data = fhe.Value.deserialize(
             serialized_encrypted_quantized_data
         )
         deserialized_evaluation_keys = fhe.EvaluationKeys.deserialize(serialized_evaluation_keys)
         result = self.server.run(
-            deserialized_encrypted_quantized_data, deserialized_evaluation_keys
+            deserialized_encrypted_quantized_data, evaluation_keys=deserialized_evaluation_keys
         )
-        serialized_result = self.server.client_specs.serialize_public_result(result)
+        serialized_result = result.serialize()
         return serialized_result
 
 
 class FHEModelDev:
     """Dev API to save the model and then load and run the FHE circuit."""
 
     model: Any = None
@@ -315,29 +315,29 @@
         # Quantize the values
         quantized_x = self.model.quantize_input(x)
 
         # Encrypt the values
         enc_qx = self.client.encrypt(quantized_x)
 
         # Serialize the encrypted values to be sent to the server
-        serialized_enc_qx = self.client.specs.serialize_public_args(enc_qx)
+        serialized_enc_qx = enc_qx.serialize()
         return serialized_enc_qx
 
     def deserialize_decrypt(self, serialized_encrypted_quantized_result: bytes) -> numpy.ndarray:
         """Deserialize and decrypt the values.
 
         Args:
             serialized_encrypted_quantized_result (bytes): the serialized, encrypted
                 and quantized result
 
         Returns:
             numpy.ndarray: the decrypted and deserialized values
         """
         # Deserialize the encrypted values
-        deserialized_encrypted_quantized_result = self.client.specs.deserialize_public_result(
+        deserialized_encrypted_quantized_result = fhe.Value.deserialize(
             serialized_encrypted_quantized_result
         )
 
         # Decrypt the values
         deserialized_decrypted_quantized_result = self.client.decrypt(
             deserialized_encrypted_quantized_result
         )
```

## concrete/ml/onnx/ops_impl.py

```diff
@@ -125,15 +125,15 @@
     c: numpy.ndarray,
     t: numpy.ndarray,
     f: Union[numpy.ndarray, int],
 ) -> numpy.ndarray:
     """Compute the equivalent of numpy.where.
 
     This function is not mapped to any ONNX operator (as opposed to numpy_where). It is usable by
-    functions which are mapped to ONNX operators, eg numpy_div or numpy_where.
+    functions which are mapped to ONNX operators, e.g., numpy_div or numpy_where.
 
     Args:
         c (numpy.ndarray): Condition operand.
         t (numpy.ndarray): True operand.
         f (numpy.ndarray): False operand.
 
     Returns:
@@ -1627,15 +1627,15 @@
         x (numpy.ndarray): Tensor to be quantized
         scale (float): Quantizer scale
         zero_point (float): Quantizer zero-point
         bit_width (int): Number of bits of the integer representation
         rounding_mode (str): Rounding mode (default and only accepted option is "ROUND")
         signed (int): Whether this op quantizes to signed integers (default 1),
         narrow (int): Whether this op quantizes to a narrow range of integers
-            eg [-2**n_bits-1 .. 2**n_bits-1] (default 0),
+            e.g., [-2**n_bits-1 .. 2**n_bits-1] (default 0),
 
     Returns:
         result (numpy.ndarray): Tensor with float quantized values
     """
 
     assert_true(rounding_mode == "ROUND", "Only rounding quantization is supported for Brevitas")
     assert_true(signed in (1, 0), "Signed flag in Brevitas quantizer must be 0/1")
```

## concrete/ml/pytest/torch_models.py

```diff
@@ -941,15 +941,15 @@
 
         x = step(x, 0.5) * 2.0
         x = self.act(x)
         return x
 
 
 class SingleMixNet(nn.Module):
-    """Torch model that with a single conv layer that produces the output, eg a blur filter."""
+    """Torch model that with a single conv layer that produces the output, e.g., a blur filter."""
 
     mixing_layer: Union[nn.Module, nn.Sequential]
 
     def __init__(self, use_conv, use_qat, inp_size, n_bits):
         super().__init__()
 
         if use_conv:
@@ -1440,7 +1440,64 @@
         Returns:
             torch.tensor: Output of the network.
         """
         x = torch.relu(self.linear1(x))
         x = torch.relu(self.linear2(x))
         x = self.linear3(x)
         return x
+
+
+class ConcatFancyIndexing(nn.Module):
+    """Concat with fancy indexing."""
+
+    def __init__(
+        self, input_shape, hidden_shape, output_shape, n_bits: int = 4, n_blocks: int = 3
+    ) -> None:
+        """Torch Model.
+
+        Args:
+            input_shape (int):  Input size
+            output_shape (int): Output size
+            hidden_shape (int): Hidden size
+            n_bits (int):       Number of bits
+            n_blocks (int):     Number of blocks
+        """
+        super().__init__()
+
+        self.n_blocks = n_blocks
+        self.quant_1 = qnn.QuantIdentity(bit_width=n_bits, return_quant_tensor=True)
+        self.fc1 = qnn.QuantLinear(input_shape, hidden_shape, bias=False, weight_bit_width=n_bits)
+
+        self.quant_concat = qnn.QuantIdentity(bit_width=n_bits, return_quant_tensor=True)
+
+        self.quant_2 = qnn.QuantIdentity(bit_width=n_bits, return_quant_tensor=True)
+        self.fc2 = qnn.QuantLinear(
+            hidden_shape * self.n_blocks, hidden_shape, bias=True, weight_bit_width=n_bits
+        )
+
+        self.quant_3 = qnn.QuantIdentity(bit_width=n_bits, return_quant_tensor=True)
+        self.fc4 = qnn.QuantLinear(hidden_shape, output_shape, bias=True, weight_bit_width=n_bits)
+
+    def forward(self, x):
+        """Forward pass.
+
+        Args:
+            x (torch.tensor): The input of the model.
+
+        Returns:
+            torch.tensor: Output of the network.
+        """
+        x_pre = []
+
+        for i in range(self.n_blocks):
+            x_block = x[:, i, :]
+            q1_out = self.quant_1(x_block)
+            fc1_out = self.fc1(q1_out)
+            q_concat_out = self.quant_concat(fc1_out)
+
+            x_pre.append(q_concat_out)
+
+        x_pre_concat = torch.cat(x_pre, dim=1)
+        x = self.quant_2(x_pre_concat)
+        x = torch.relu(self.fc2(x))
+        x = self.fc4(self.quant_3(x))
+        return x
```

## concrete/ml/pytest/utils.py

```diff
@@ -143,46 +143,46 @@
     # To avoid to make mistakes and return empty list
     assert len(sklearn_models_and_datasets) == 28
     assert len(unique_model_classes) == 18
 
     return unique_model_classes
 
 
-def instantiate_model_generic(model_class, **parameters):
+def instantiate_model_generic(model_class, n_bits, **parameters):
     """Instantiate any Concrete ML model type.
 
     Args:
-        model_class (class): The type of the model to instantiate
-        parameters (dict): Hyper-parameters for the model instantiation
+        model_class (class): The type of the model to instantiate.
+        n_bits (int): The number of quantization to use when initializing the model. For QNNs,
+            default parameters are used based on whether `n_bits` is greater or smaller than 8.
+        parameters (dict): Hyper-parameters for the model instantiation. For QNNs, these parameters
+            will override the matching default ones.
 
     Returns:
-        model_name (str): The type of the model as a string
-        model (object): The model instance
+        model_name (str): The type of the model as a string.
+        model (object): The model instance.
     """
-
-    assert "n_bits" in parameters
-    n_bits = parameters["n_bits"]
-
     # If the model is a QNN, set the model using appropriate bit-widths
     if is_model_class_in_a_list(model_class, get_sklearn_neural_net_models()):
         extra_kwargs = {}
         if n_bits > 8:
             extra_kwargs["module__n_w_bits"] = 3
             extra_kwargs["module__n_a_bits"] = 3
             extra_kwargs["module__n_accum_bits"] = 12
         else:
             extra_kwargs["module__n_w_bits"] = 2
             extra_kwargs["module__n_a_bits"] = 2
             extra_kwargs["module__n_accum_bits"] = 7
 
+        extra_kwargs.update(parameters)
         model = model_class(**extra_kwargs)
 
     # Else, set the model using n_bits
     else:
-        model = model_class(n_bits=n_bits)
+        model = model_class(n_bits=n_bits, **parameters)
 
     # Seed the model if it handles "random_state" as a parameter
     model_params = model.get_params()
     if "random_state" in model_params:
         model_params["random_state"] = numpy.random.randint(0, 2**15)
 
         model.set_params(**model_params)
@@ -231,20 +231,31 @@
     Returns:
         Tuple[numpy.ndarray, numpy.ndarray]: The input data and the target (respectively x and y).
 
     Raises:
         TypeError: If the 'data-set' does not match any expected type.
     """
     assert n_sample >= 1, "`n_sample` must be greater than or equal to `1`"
-    n_sample = min(len(data), n_sample)
 
-    # Generates a random sample from a given 1-D array
-    random_sample = numpy.random.choice(len(data), n_sample, replace=False)
+    if isinstance(data, torch.utils.data.dataloader.DataLoader):
+        n_elements = 0
+        all_y, all_x = [], []
+        # Iterate over n batches, to apply any necessary torch transformations to the data-set
+        for x_batch, y_batch in data:
+            all_x.append(x_batch.numpy())
+            all_y.append(y_batch.numpy())
+            # Number of elements per batch
+            n_elements += y_batch.shape[0]
+            # If the number of elements within n batches is >= `n_element`, break the loop
+            # `n_sample` is reached.
+            if n_sample <= n_elements:
+                break
 
-    if (
+        x, y = numpy.concatenate(all_x), numpy.concatenate(all_y)
+    elif (
         hasattr(data, "__getitem__") and hasattr(data, "__len__") and hasattr(data, "train")
     ) or isinstance(data, torch.utils.data.dataset.Subset):
         assert targets is None, "dataset includes inputs and targets"
         splitted_dataset = list(zip(*data))
         x, y = numpy.stack(splitted_dataset[0]), numpy.array(splitted_dataset[1])
 
     elif targets is not None and is_pandas_type(data) and is_pandas_type(targets):
@@ -260,14 +271,19 @@
         y = numpy.array(targets)
     else:
         raise TypeError(
             "Only numpy arrays, torch tensors and torchvision data-sets are supported. "
             f"Got `{type(data)}` as input type and `{type(targets)}` as target type"
         )
 
+    n_sample = min(len(x), n_sample)
+
+    # Generates a random sample from a given 1-D array
+    random_sample = numpy.random.choice(len(x), n_sample, replace=False)
+
     x = x[random_sample]
     y = y[random_sample]
 
     return x, y
 
 
 def load_torch_model(
@@ -382,15 +398,15 @@
         and hasattr(object_to_serialize, "dumps")
         and hasattr(object_to_serialize, "dump_dict")
     ):
         dump_method_to_test.append(True)
 
     for use_dump_method in dump_method_to_test:
 
-        # Dump the object into a string
+        # Dump the object as a string
         if use_dump_method:
             dumped_str = object_to_serialize.dumps()
         else:
             dumped_str = dumps(object_to_serialize)
 
         # Load the object using a string
         loaded = loads(dumped_str)
@@ -402,15 +418,15 @@
         )
         assert equal_method(object_to_serialize, loaded), (
             "Loaded object (from string) is not equal to the initial one, using equal method "
             f"{equal_method}."
         )
 
         if check_str:
-            # Dump the loaded object into a string
+            # Dump the loaded object as a string
             if use_dump_method:
                 re_dumped_str = loaded.dumps()
             else:
                 re_dumped_str = dumps(loaded)
 
             # Assert that both JSON strings are equal. This will not work if some objects were
             # dumped using Skops or pickle (such as a scikit-learn model or a Type object)
```

## concrete/ml/quantization/base_quantized_op.py

```diff
@@ -78,15 +78,15 @@
     _params_that_are_onnx_inputs: Set[str] = set()
     _params_that_are_onnx_var_inputs: Set[str] = set()
     _params_that_are_required_onnx_inputs: Set[str] = set()
     _has_attr: bool
     _inputs_not_quantized: Set[str] = set()
     quantize_inputs_with_model_outputs_precision: bool = False
 
-    # The ONNX name of this op instance (eg "Conv_9", "MatMul_5" etc.)
+    # The ONNX name of this op instance (e.g., "Conv_9", "MatMul_5" etc.)
     op_instance_name: str
 
     # Determines if this op computes a tensor that is a graph output, i.e., a tensor
     # that will be decrypted and de-quantized in the clear
     produces_graph_output = False
 
     # Determines if the op produces a raw output (not quantized). This can
@@ -635,15 +635,15 @@
         # QuantizedArrays, else we return the float32 values directly.
 
         curr_input_fill_idx = 0
         for input_idx, input_ in enumerate(inputs):
             while prepared_inputs[curr_input_fill_idx] is not None:
                 curr_input_fill_idx += 1
 
-            # This is an integer scalar (eg tensor shape). This is not an encrypted
+            # This is an integer scalar (e.g., tensor shape). This is not an encrypted
             # value, it is not traced
             is_clear_value = isinstance(input_, RawOpOutput)
 
             if input_ is None:
                 # Do nothing if the input is not set, the underlying ops will handle the None
                 pass
             elif calibrate or is_clear_value:
@@ -806,15 +806,15 @@
         return output_quant_opts
 
 
 class QuantizedOpUnivariateOfEncrypted(QuantizedOp, is_utility=True):
     """An univariate operator of an encrypted value.
 
     This operation is not really operating as a quantized operation. It is useful when the
-    computations get fused into a TLU, as in eg Act(x) = x || (x + 42)).
+    computations get fused into a TLU, as in e.g., Act(x) = x || (x + 42)).
     """
 
     def __init__(
         self,
         n_bits_output: int,
         op_instance_name: str,
         int_input_names: Optional[Set[str]] = None,
```

## concrete/ml/quantization/quantized_module.py

```diff
@@ -466,27 +466,14 @@
         # Make sure that the module is compiled
         assert_true(
             self.fhe_circuit is not None,
             "The quantized module is not compiled. Please run compile(...) first before "
             "executing it in FHE.",
         )
 
-        # FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2888
-        # Check if rounding is being executed in FHE, which is not currently optimized
-        # Assert that there are rounding nodes in the circuit graph
-        rounding_nodes = self.fhe_circuit.graph.query_nodes(  # type: ignore[union-attr]
-            operation_filter="round_bit_pattern"
-        )
-
-        assert_true(
-            not rounding_nodes or simulate,
-            "Rounding is not currently optimized for execution in FHE. "
-            "Only simulation is allowed with a rounding operator.",
-        )
-
         results_cnp_circuit_list = []
         for i in range(q_x[0].shape[0]):
 
             # Extract example i from every element in the tuple q_x
             q_input = tuple(q_x[input][[i]] for input in range(len(q_x)))
 
             # For mypy
@@ -639,14 +626,15 @@
             inputset,
             configuration=configuration,
             artifacts=artifacts,
             show_mlir=show_mlir,
             p_error=p_error,
             global_p_error=global_p_error,
             verbose=verbose,
+            single_precision=False,
         )
 
         self._is_compiled = True
 
         return self.fhe_circuit
 
     def bitwidth_and_range_report(
```

## concrete/ml/quantization/quantized_ops.py

```diff
@@ -1308,25 +1308,25 @@
         assert_true(constant_inputs is not None and len(constant_inputs) >= 1)
 
 
 class QuantizedOr(QuantizedOpUnivariateOfEncrypted, QuantizedOp):
     """Or operator ||.
 
     This operation is not really working as a quantized operation. It just works when things got
-    fused, as in eg Act(x) = x || (x + 42))
+    fused, as in e.g., Act(x) = x || (x + 42))
     """
 
     _impl_for_op_named: str = "Or"
 
 
 class QuantizedDiv(QuantizedOpUnivariateOfEncrypted, QuantizedOp):
     """Div operator /.
 
     This operation is not really working as a quantized operation. It just works when things got
-    fused, as in eg Act(x) = 1000 / (x + 42))
+    fused, as in e.g., Act(x) = 1000 / (x + 42))
     """
 
     _impl_for_op_named: str = "Div"
 
 
 class QuantizedMul(QuantizedOpUnivariateOfEncrypted, QuantizedOp):
     """Multiplication operator.
@@ -1662,15 +1662,15 @@
                 bit_width (int): Number of bits of the integer representation
             input_quant_opts (Optional[QuantizationOptions]): Options for the input quantizer.
                 Default to None.
             attrs (dict):
                 rounding_mode (str): Rounding mode (default and only accepted option is "ROUND")
                 signed (int): Whether this op quantizes to signed integers (default 1),
                 narrow (int): Whether this op quantizes to a narrow range of integers
-                    eg [-2**n_bits-1 .. 2**n_bits-1] (default 0),
+                    e.g., [-2**n_bits-1 .. 2**n_bits-1] (default 0),
         """
 
         super().__init__(
             n_bits_output,
             op_instance_name,
             int_input_names,
             constant_inputs,
```

## concrete/ml/sklearn/base.py

```diff
@@ -14,14 +14,15 @@
 import brevitas.nn as qnn
 import numpy
 import onnx
 import sklearn
 import skorch.net
 import torch
 from brevitas.export.onnx.qonnx.manager import QONNXManager as BrevitasONNXManager
+from concrete.fhe import ParameterSelectionStrategy
 from concrete.fhe.compilation.artifacts import DebugArtifacts
 from concrete.fhe.compilation.circuit import Circuit
 from concrete.fhe.compilation.compiler import Compiler
 from concrete.fhe.compilation.configuration import Configuration
 from concrete.fhe.dtypes.integer import Integer
 from sklearn.base import clone
 
@@ -164,15 +165,16 @@
             and getattr(self, "sklearn_model", None) is not None
         ):
             return getattr(self.sklearn_model, attr)
 
         raise AttributeError(
             f"Attribute {attr} cannot be found in the Concrete ML {self.__class__.__name__} object "
             f"and is not a training attribute from the underlying scikit-learn "
-            f"{self.sklearn_model_class} one."
+            f"{self.sklearn_model_class} one. If the attribute is meant to represent one from that "
+            f"latter, please check that the model is properly fitted."
         )
 
     # We need to specifically call the default __setattr__ method as QNN models still inherit from
     # skorch, which provides its own __setattr__ implementation and creates a cyclic loop
     # with __getattr__. Removing this inheritance once and for all should fix the issue
     # FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/3373
     def __setattr__(self, name: str, value: Any):
@@ -545,14 +547,16 @@
             inputset,
             configuration=configuration,
             artifacts=artifacts,
             show_mlir=show_mlir,
             p_error=p_error,
             global_p_error=global_p_error,
             verbose=verbose,
+            single_precision=False,
+            parameter_selection_strategy=ParameterSelectionStrategy.MONO,
         )
 
         self._is_compiled = True
 
         assert isinstance(self.fhe_circuit, Circuit)
         return self.fhe_circuit
```

## concrete/ml/sklearn/tree.py

```diff
@@ -50,14 +50,25 @@
         self.max_features = max_features
         self.max_leaf_nodes = max_leaf_nodes
         self.class_weight = class_weight
         self.random_state = random_state
         self.min_impurity_decrease = min_impurity_decrease
         self.ccp_alpha = ccp_alpha
 
+    def __getattr__(self, attr: str):
+        # We directly expose the following methods as they are commonly used with decision trees
+        # and only represent their topological structure
+        if (
+            attr in ["get_depth", "get_n_leaves"]
+            and getattr(self, "sklearn_model", None) is not None
+        ):
+            return getattr(self.sklearn_model, attr)
+
+        return super().__getattr__(attr)
+
     def post_processing(self, y_preds: numpy.ndarray) -> numpy.ndarray:
         # Here, we want to use BaseTreeEstimatorMixin's `post-processing` method as
         # DecisionTreeClassifier models directly computes probabilities and therefore don't require
         # to apply a sigmoid or softmax in post-processing
         return BaseTreeEstimatorMixin.post_processing(self, y_preds)
 
     def dump_dict(self) -> Dict[str, Any]:
@@ -175,14 +186,25 @@
         self.min_weight_fraction_leaf = min_weight_fraction_leaf
         self.max_features = max_features
         self.max_leaf_nodes = max_leaf_nodes
         self.random_state = random_state
         self.min_impurity_decrease = min_impurity_decrease
         self.ccp_alpha = ccp_alpha
 
+    def __getattr__(self, attr: str):
+        # We directly expose the following methods as they are commonly used with decision trees
+        # and only represent their topological structure
+        if (
+            attr in ["get_depth", "get_n_leaves"]
+            and getattr(self, "sklearn_model", None) is not None
+        ):
+            return getattr(self.sklearn_model, attr)
+
+        return super().__getattr__(attr)
+
     def dump_dict(self) -> Dict[str, Any]:
         metadata: Dict[str, Any] = {}
 
         # Concrete-ML
         metadata["n_bits"] = self.n_bits
         metadata["sklearn_model"] = self.sklearn_model
         metadata["_is_fitted"] = self._is_fitted
```

## concrete/ml/torch/compile.py

```diff
@@ -6,14 +6,15 @@
 
 import numpy
 import onnx
 import torch
 from brevitas.export.onnx.qonnx.manager import QONNXManager as BrevitasONNXManager
 from brevitas.nn.quant_layer import QuantInputOutputLayer as QNNMixingLayer
 from brevitas.nn.quant_layer import QuantNonLinearActLayer as QNNUnivariateLayer
+from concrete.fhe import ParameterSelectionStrategy
 from concrete.fhe.compilation.artifacts import DebugArtifacts
 from concrete.fhe.compilation.configuration import Configuration
 
 from ..common.debugging import assert_false, assert_true
 from ..common.utils import (
     MAX_BITWIDTH_BACKWARD_COMPATIBLE,
     check_there_is_no_p_error_options_in_configuration,
@@ -110,30 +111,30 @@
     show_mlir: bool = False,
     n_bits=MAX_BITWIDTH_BACKWARD_COMPATIBLE,
     rounding_threshold_bits: Optional[int] = None,
     p_error: Optional[float] = None,
     global_p_error: Optional[float] = None,
     verbose: bool = False,
 ) -> QuantizedModule:
-    """Compile a torch module or ONNX into a FHE equivalent.
+    """Compile a torch module or ONNX into an FHE equivalent.
 
     Take a model in torch or ONNX, turn it to numpy, quantize its inputs / weights / outputs and
     finally compile it with Concrete
 
     Args:
         model (Union[torch.nn.Module, onnx.ModelProto]): the model to quantize, either in torch or
             in ONNX
         torch_inputset (Dataset): the calibration input-set, can contain either torch
             tensors or numpy.ndarray
         import_qat (bool): Flag to signal that the network being imported contains quantizers in
             in its computation graph and that Concrete ML should not re-quantize it
         configuration (Configuration): Configuration object to use during compilation
         artifacts (DebugArtifacts): Artifacts object to fill during compilation
         show_mlir (bool): if set, the MLIR produced by the converter and which is going
-            to be sent to the compiler backend is shown on the screen, eg for debugging or demo
+            to be sent to the compiler backend is shown on the screen, e.g., for debugging or demo
         n_bits: the number of bits for the quantization
         rounding_threshold_bits (int): if not None, every accumulators in the model are rounded down
             to the given bits of precision
         p_error (Optional[float]): probability of error of a single PBS
         global_p_error (Optional[float]): probability of error of the full circuit. In FHE
             simulation `global_p_error` is set to 0
         verbose (bool): whether to show compilation information
@@ -155,14 +156,21 @@
         rounding_threshold_bits=rounding_threshold_bits,
     )
 
     # Check that p_error or global_p_error is not set in both the configuration and in the direct
     # parameters
     check_there_is_no_p_error_options_in_configuration(configuration)
 
+    # If rounding is used, we force multi parameters
+    configuration = configuration if configuration is not None else Configuration()
+    if rounding_threshold_bits is not None:
+        configuration.parameter_selection_strategy = ParameterSelectionStrategy.MULTI
+    else:
+        configuration.parameter_selection_strategy = ParameterSelectionStrategy.MONO
+
     # Find the right way to set parameters for compiler, depending on the way we want to default
     p_error, global_p_error = manage_parameters_for_pbs_errors(p_error, global_p_error)
 
     quantized_module.compile(
         inputset_as_numpy_tuple,
         configuration,
         artifacts,
@@ -185,15 +193,15 @@
     show_mlir: bool = False,
     n_bits=MAX_BITWIDTH_BACKWARD_COMPATIBLE,
     rounding_threshold_bits: Optional[int] = None,
     p_error: Optional[float] = None,
     global_p_error: Optional[float] = None,
     verbose: bool = False,
 ) -> QuantizedModule:
-    """Compile a torch module into a FHE equivalent.
+    """Compile a torch module into an FHE equivalent.
 
     Take a model in torch, turn it to numpy, quantize its inputs / weights / outputs and finally
     compile it with Concrete
 
     Args:
         torch_model (torch.nn.Module): the model to quantize
         torch_inputset (Dataset): the calibration input-set, can contain either torch
@@ -201,15 +209,15 @@
         import_qat (bool): Set to True to import a network that contains quantizers and was
             trained using quantization aware training
         configuration (Configuration): Configuration object to use
             during compilation
         artifacts (DebugArtifacts): Artifacts object to fill
             during compilation
         show_mlir (bool): if set, the MLIR produced by the converter and which is going
-            to be sent to the compiler backend is shown on the screen, eg, for debugging or demo
+            to be sent to the compiler backend is shown on the screen, e.g., for debugging or demo
         n_bits: the number of bits for the quantization
         rounding_threshold_bits (int): if not None, every accumulators in the model are rounded down
             to the given bits of precision
         p_error (Optional[float]): probability of error of a single PBS
         global_p_error (Optional[float]): probability of error of the full circuit. In FHE
             simulation `global_p_error` is set to 0
         verbose (bool): whether to show compilation information
@@ -258,15 +266,15 @@
     show_mlir: bool = False,
     n_bits=MAX_BITWIDTH_BACKWARD_COMPATIBLE,
     rounding_threshold_bits: Optional[int] = None,
     p_error: Optional[float] = None,
     global_p_error: Optional[float] = None,
     verbose: bool = False,
 ) -> QuantizedModule:
-    """Compile a torch module into a FHE equivalent.
+    """Compile a torch module into an FHE equivalent.
 
     Take a model in torch, turn it to numpy, quantize its inputs / weights / outputs and finally
     compile it with Concrete-Python
 
     Args:
         onnx_model (onnx.ModelProto): the model to quantize
         torch_inputset (Dataset): the calibration input-set, can contain either torch
@@ -274,15 +282,15 @@
         import_qat (bool): Flag to signal that the network being imported contains quantizers in
             in its computation graph and that Concrete ML should not re-quantize it.
         configuration (Configuration): Configuration object to use
             during compilation
         artifacts (DebugArtifacts): Artifacts object to fill
             during compilation
         show_mlir (bool): if set, the MLIR produced by the converter and which is going
-            to be sent to the compiler backend is shown on the screen, eg, for debugging or demo
+            to be sent to the compiler backend is shown on the screen, e.g., for debugging or demo
         n_bits: the number of bits for the quantization
         rounding_threshold_bits (int): if not None, every accumulators in the model are rounded down
             to the given bits of precision
         p_error (Optional[float]): probability of error of a single PBS
         global_p_error (Optional[float]): probability of error of the full circuit. In FHE
             simulation `global_p_error` is set to 0
         verbose (bool): whether to show compilation information
@@ -345,15 +353,15 @@
             also specify a dictionary with model_inputs/model_outputs keys to override
             the 8-bit default or a single integer for both values.
         configuration (Configuration): Configuration object to use
             during compilation
         artifacts (DebugArtifacts): Artifacts object to fill
             during compilation
         show_mlir (bool): if set, the MLIR produced by the converter and which is going
-            to be sent to the compiler backend is shown on the screen, eg, for debugging or demo
+            to be sent to the compiler backend is shown on the screen, e.g., for debugging or demo
         rounding_threshold_bits (int): if not None, every accumulators in the model are rounded down
             to the given bits of precision
         p_error (Optional[float]): probability of error of a single PBS
         global_p_error (Optional[float]): probability of error of the full circuit. In FHE
             simulation `global_p_error` is set to 0
         output_onnx_file (str): temporary file to store ONNX model. If None a temporary file
             is generated
```

## concrete/ml/version.py

```diff
@@ -1,3 +1,3 @@
 """File to manage the version of the package."""
 # Auto-generated by "make set_version" do not modify
-__version__ = "1.0.3"
+__version__ = "1.1.0"
```

## Comparing `concrete_ml-1.0.3.dist-info/LICENSE` & `concrete_ml-1.1.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `concrete_ml-1.0.3.dist-info/METADATA` & `concrete_ml-1.1.0.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: concrete-ml
-Version: 1.0.3
+Version: 1.1.0
 Summary: Concrete ML is an open-source set of tools which aims to simplify the use of fully homomorphic encryption (FHE) for data scientists.
 Home-page: https://zama.ai/concrete-ml/
 License: BSD-3-Clause-Clear
 Keywords: FHE,homomorphic encryption,privacy,security
 Author: Zama
 Author-email: hello@zama.ai
 Requires-Python: >=3.8.1,<3.11
@@ -19,15 +19,15 @@
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Security
 Classifier: Topic :: Security :: Cryptography
 Classifier: Topic :: Software Development :: Compilers
 Requires-Dist: boto3 (>=1.23.5,<2.0.0)
 Requires-Dist: brevitas (==0.8.0)
-Requires-Dist: concrete-python (==1.0.0)
+Requires-Dist: concrete-python (==1.1.0-rc1)
 Requires-Dist: fastapi (>=0.93.0,<0.94.0)
 Requires-Dist: hummingbird-ml[onnx] (==0.4.8)
 Requires-Dist: numpy (==1.23.5)
 Requires-Dist: onnx (==1.13.1)
 Requires-Dist: onnxoptimizer (==0.3.10)
 Requires-Dist: onnxruntime (==1.13.1)
 Requires-Dist: protobuf (==3.20.3)
@@ -84,21 +84,21 @@
 - built-in models, which are ready-to-use FHE-friendly models with a user interface that is equivalent to their the scikit-learn and XGBoost counterparts
 - support for customs models that can use quantization aware training. These are developed by the user using PyTorch or keras/tensorflow and are imported into Concrete ML through ONNX
 
 ## Installation.
 
 Depending on your OS, Concrete ML may be installed with Docker or with pip:
 
-|               OS / HW                | Available on Docker | Available on pip |
-| :----------------------------------: | :-----------------: | :--------------: |
-|                Linux                 |         Yes         |       Yes        |
-|               Windows                |         Yes         |   Coming soon    |
-|     Windows Subsystem for Linux      |         Yes         |       Yes        |
-|            macOS (Intel)             |         Yes         |       Yes        |
-| macOS (Apple Silicon, ie M1, M2 etc) |         Yes         |       Yes        |
+|                 OS / HW                 | Available on Docker | Available on pip |
+| :-------------------------------------: | :-----------------: | :--------------: |
+|                  Linux                  |         Yes         |       Yes        |
+|                 Windows                 |         Yes         |   Coming soon    |
+|       Windows Subsystem for Linux       |         Yes         |       Yes        |
+|            macOS 11+ (Intel)            |         Yes         |       Yes        |
+| macOS 11+ (Apple Silicon: M1, M2, etc.) |         Yes         |       Yes        |
 
 Note: Concrete ML only supports Python `3.8`, `3.9` and `3.10`.
 
 Concrete ML can be installed on Kaggle ([see question on community for more details](https://community.zama.ai/t/how-do-we-use-concrete-ml-on-kaggle/332)) and on Google Colab.
 
 ### Docker
 
@@ -165,23 +165,30 @@
 
 Full, comprehensive documentation is available here: [https://docs.zama.ai/concrete-ml](https://docs.zama.ai/concrete-ml).
 
 ## Online demos and tutorials.
 
 Various tutorials are proposed for the [built-in models](docs/built-in-models/ml_examples.md) and for [deep learning](docs/deep-learning/examples.md). In addition, several complete use-cases are explored:
 
+- [Encrypted Large Language Model](use_case_examples/llm/): convert a user-defined part of a Large Language Model for encrypted text generation. Shows the trade-off between quantization and accuracy for text generation and shows how to run the model in FHE.
+
+- [Credit Scoring](use_case_examples/credit_scoring/): predicts the chance of a given loan applicant defaulting on loan repayment while keeping the user's data private. Shows how Concrete ML models easily replace their scikit-learn equivalents
+
+- [Health diagnosis](use_case_examples/disease_prediction/): based on a patient's symptoms, history and other health factors, gives
+  a diagnosis using FHE to preserve the privacy of the patient.
+
 - [MNIST](use_case_examples/mnist): a Python script and notebook showing quantization-aware training following FHE constraints. A fully-connected neural network is implemented with [Brevitas](https://github.com/Xilinx/brevitas) and is converted to FHE with Concrete ML.
 
 - [Titanic](use_case_examples/titanic/KaggleTitanic.ipynb): a notebook, which gives a solution to the [Kaggle Titanic competition](https://www.kaggle.com/c/titanic/). Implemented with XGBoost from Concrete ML, this example comes as a companion of the [Kaggle notebook](https://www.kaggle.com/code/concretemlteam/titanic-with-privacy-preserving-machine-learning), and was the subject of a blogpost in [KDnuggets](https://www.kdnuggets.com/2022/08/machine-learning-encrypted-data.html).
 
 - [Sentiment analysis with transformers](use_case_examples/sentiment_analysis_with_transformer): a gradio demo which predicts if a tweet / short message is positive, negative or neutral, with FHE of course! The [live interactive](https://huggingface.co/spaces/zama-fhe/encrypted_sentiment_analysis) demo is available on Hugging Face. This [blog post](https://huggingface.co/blog/sentiment-analysis-fhe) explains how this demo works!
 
-- [CIFAR10 FHE-friendly model with Brevitas](use_case_examples/cifar_brevitas_training): code for training from scratch a VGG-like FHE-compatible neural network using Brevitas, and a script to run the neural network in FHE. FHE simulation shows an accuracy of 88.7%, but running inference with FHE is still a work-in-progress.
+- [CIFAR10 FHE-friendly model with Brevitas](use_case_examples/cifar_brevitas_training): code for training from scratch a VGG-like FHE-compatible neural network using Brevitas, and a script to run the neural network in FHE. Execution in FHE takes ~20 minutes per image and shows an accuracy of 88.7%.
 
-- [CIFAR10 / CIFAR100 FHE-friendly models with Transfer Learning approach](use_case_examples/cifar_brevitas_finetuning): series of three notebooks, that show how to convert a pre-trained FP32 VGG11 neural network into a quantized model using Brevitas. The model is fine-tuned on the CIFAR data-sets, converted for FHE execution with Concrete ML and evaluated using FHE simulation. For CIFAR10 and CIFAR100, respectively, our simulations show an accuracy of 90.2% and 68.2%. True FHE inference is a work-in-progress.
+- [CIFAR10 / CIFAR100 FHE-friendly models with Transfer Learning approach](use_case_examples/cifar_brevitas_finetuning): series of three notebooks, that show how to convert a pre-trained FP32 VGG11 neural network into a quantized model using Brevitas. The model is fine-tuned on the CIFAR data-sets, converted for FHE execution with Concrete ML and evaluated using FHE simulation. For CIFAR10 and CIFAR100, respectively, our simulations show an accuracy of 90.2% and 68.2%.
 
 - [FHE neural network splitting for client/server deployment](use_case_examples/cifar_brevitas_with_model_splitting): we explain how to split a computationally-intensive neural network model in two parts. First, we execute the first part on the client side in the clear, and the output of this step is encrypted. Next, to complete the computation, the second part of the model is evaluated with FHE. This tutorial also shows the impact of FHE speed/accuracy trade-off on CIFAR10, limiting PBS to 8-bit, and thus achieving 62% accuracy.
 
 - [Encrypted image filtering](use_case_examples/image_filtering): finally, the live demo for our [6-min](https://6min.zama.ai) is available, in the form of a gradio application. We take encrypted images, and apply some filters (for example black-and-white, ridge detection, or your own filter).
 
 More generally, if you have built awesome projects using Concrete ML, feel free to let us know and we'll link to it!
```

### html2text {}

```diff
@@ -1,23 +1,23 @@
-Metadata-Version: 2.1 Name: concrete-ml Version: 1.0.3 Summary: Concrete ML is
+Metadata-Version: 2.1 Name: concrete-ml Version: 1.1.0 Summary: Concrete ML is
 an open-source set of tools which aims to simplify the use of fully homomorphic
 encryption (FHE) for data scientists. Home-page: https://zama.ai/concrete-ml/
 License: BSD-3-Clause-Clear Keywords: FHE,homomorphic
 encryption,privacy,security Author: Zama Author-email: hello@zama.ai Requires-
 Python: >=3.8.1,<3.11 Classifier: License :: Other/Proprietary License
 Classifier: Programming Language :: Python :: 3 Classifier: Programming
 Language :: Python :: 3.9 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.10 Classifier: Programming
 Language :: Python :: 3.8 Classifier: Programming Language :: Python :: 3.9
 Classifier: Topic :: Scientific/Engineering Classifier: Topic :: Scientific/
 Engineering :: Artificial Intelligence Classifier: Topic :: Scientific/
 Engineering :: Mathematics Classifier: Topic :: Security Classifier: Topic ::
 Security :: Cryptography Classifier: Topic :: Software Development :: Compilers
 Requires-Dist: boto3 (>=1.23.5,<2.0.0) Requires-Dist: brevitas (==0.8.0)
-Requires-Dist: concrete-python (==1.0.0) Requires-Dist: fastapi
+Requires-Dist: concrete-python (==1.1.0-rc1) Requires-Dist: fastapi
 (>=0.93.0,<0.94.0) Requires-Dist: hummingbird-ml[onnx] (==0.4.8) Requires-Dist:
 numpy (==1.23.5) Requires-Dist: onnx (==1.13.1) Requires-Dist: onnxoptimizer
 (==0.3.10) Requires-Dist: onnxruntime (==1.13.1) Requires-Dist: protobuf
 (==3.20.3) Requires-Dist: python-multipart (>=0.0.6,<0.0.7) Requires-Dist:
 scikit-learn (==1.1.3) Requires-Dist: scipy (==1.10.1) Requires-Dist:
 setuptools (==65.6.3) Requires-Dist: skops (==0.5.0) Requires-Dist: skorch
 (==0.11.0) Requires-Dist: torch (==1.13.1) Requires-Dist: tqdm
@@ -48,98 +48,106 @@
 frameworks they use, with additional options to run inferences in FHE. Concrete
 ML features: - built-in models, which are ready-to-use FHE-friendly models with
 a user interface that is equivalent to their the scikit-learn and XGBoost
 counterparts - support for customs models that can use quantization aware
 training. These are developed by the user using PyTorch or keras/tensorflow and
 are imported into Concrete ML through ONNX ## Installation. Depending on your
 OS, Concrete ML may be installed with Docker or with pip: | OS / HW | Available
-on Docker | Available on pip | | :----------------------------------: | :------
------------: | :--------------: | | Linux | Yes | Yes | | Windows | Yes |
-Coming soon | | Windows Subsystem for Linux | Yes | Yes | | macOS (Intel) | Yes
-| Yes | | macOS (Apple Silicon, ie M1, M2 etc) | Yes | Yes | Note: Concrete ML
-only supports Python `3.8`, `3.9` and `3.10`. Concrete ML can be installed on
-Kaggle ([see question on community for more details](https://community.zama.ai/
-t/how-do-we-use-concrete-ml-on-kaggle/332)) and on Google Colab. ### Docker To
-install with Docker, pull the `concrete-ml` image as follows: `docker pull
-zamafhe/concrete-ml:latest` ### Pip To install Concrete ML from PyPi, run the
-following: ``` pip install -U pip wheel setuptools pip install concrete-ml ```
-You can find more detailed installation instructions in [this part of the
-documentation](docs/getting-started/pip_installing.md) ## A simple Concrete ML
-example with scikit-learn. A simple example which is very close to scikit-learn
-is as follows, for a logistic regression : ```python from sklearn.datasets
-import make_classification from sklearn.model_selection import train_test_split
-from concrete.ml.sklearn import LogisticRegression # Lets create a synthetic
-data-set x, y = make_classification(n_samples=100, class_sep=2, n_features=30,
-random_state=42) # Split the data-set into a train and test set X_train,
-X_test, y_train, y_test = train_test_split( x, y, test_size=0.2,
-random_state=42 ) # Now we train in the clear and quantize the weights model =
-LogisticRegression(n_bits=8) model.fit(X_train, y_train) # We can simulate the
-predictions in the clear y_pred_clear = model.predict(X_test) # We then compile
-on a representative set model.compile(X_train) # Finally we run the inference
-on encrypted inputs ! y_pred_fhe = model.predict(X_test, fhe="execute") print
-("In clear :", y_pred_clear) print("In FHE :", y_pred_fhe) print(f"Similarity:
-{int((y_pred_fhe == y_pred_clear).mean()*100)}%") # Output: # In clear : [0 0 0
-0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0] # In FHE : [0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1
-1 1 0 0] # Similarity: 100% ``` This example is explained in more detail in the
-[linear model documentation](docs/built-in-models/linear.md). Concrete ML
-built-in models have APIs that are almost identical to their scikit-learn
-counterparts. It is also possible to convert PyTorch networks to FHE with the
-Concrete ML conversion APIs. Please refer to the [linear models](docs/built-in-
-models/linear.md), [tree-based models](docs/built-in-models/tree.md) and
-[neural networks](docs/built-in-models/neural-networks.md) documentation for
-more examples, showing the scikit-learn-like API of the built-in models. ##
-Documentation. Full, comprehensive documentation is available here: [https://
-docs.zama.ai/concrete-ml](https://docs.zama.ai/concrete-ml). ## Online demos
-and tutorials. Various tutorials are proposed for the [built-in models](docs/
-built-in-models/ml_examples.md) and for [deep learning](docs/deep-learning/
-examples.md). In addition, several complete use-cases are explored: - [MNIST]
-(use_case_examples/mnist): a Python script and notebook showing quantization-
-aware training following FHE constraints. A fully-connected neural network is
-implemented with [Brevitas](https://github.com/Xilinx/brevitas) and is
-converted to FHE with Concrete ML. - [Titanic](use_case_examples/titanic/
-KaggleTitanic.ipynb): a notebook, which gives a solution to the [Kaggle Titanic
-competition](https://www.kaggle.com/c/titanic/). Implemented with XGBoost from
-Concrete ML, this example comes as a companion of the [Kaggle notebook](https:/
-/www.kaggle.com/code/concretemlteam/titanic-with-privacy-preserving-machine-
-learning), and was the subject of a blogpost in [KDnuggets](https://
-www.kdnuggets.com/2022/08/machine-learning-encrypted-data.html). - [Sentiment
-analysis with transformers](use_case_examples/
-sentiment_analysis_with_transformer): a gradio demo which predicts if a tweet /
-short message is positive, negative or neutral, with FHE of course! The [live
-interactive](https://huggingface.co/spaces/zama-fhe/
+on Docker | Available on pip | | :-------------------------------------: | :---
+--------------: | :--------------: | | Linux | Yes | Yes | | Windows | Yes |
+Coming soon | | Windows Subsystem for Linux | Yes | Yes | | macOS 11+ (Intel) |
+Yes | Yes | | macOS 11+ (Apple Silicon: M1, M2, etc.) | Yes | Yes | Note:
+Concrete ML only supports Python `3.8`, `3.9` and `3.10`. Concrete ML can be
+installed on Kaggle ([see question on community for more details](https://
+community.zama.ai/t/how-do-we-use-concrete-ml-on-kaggle/332)) and on Google
+Colab. ### Docker To install with Docker, pull the `concrete-ml` image as
+follows: `docker pull zamafhe/concrete-ml:latest` ### Pip To install Concrete
+ML from PyPi, run the following: ``` pip install -U pip wheel setuptools pip
+install concrete-ml ``` You can find more detailed installation instructions in
+[this part of the documentation](docs/getting-started/pip_installing.md) ## A
+simple Concrete ML example with scikit-learn. A simple example which is very
+close to scikit-learn is as follows, for a logistic regression : ```python from
+sklearn.datasets import make_classification from sklearn.model_selection import
+train_test_split from concrete.ml.sklearn import LogisticRegression # Lets
+create a synthetic data-set x, y = make_classification(n_samples=100,
+class_sep=2, n_features=30, random_state=42) # Split the data-set into a train
+and test set X_train, X_test, y_train, y_test = train_test_split( x, y,
+test_size=0.2, random_state=42 ) # Now we train in the clear and quantize the
+weights model = LogisticRegression(n_bits=8) model.fit(X_train, y_train) # We
+can simulate the predictions in the clear y_pred_clear = model.predict(X_test)
+# We then compile on a representative set model.compile(X_train) # Finally we
+run the inference on encrypted inputs ! y_pred_fhe = model.predict(X_test,
+fhe="execute") print("In clear :", y_pred_clear) print("In FHE :", y_pred_fhe)
+print(f"Similarity: {int((y_pred_fhe == y_pred_clear).mean()*100)}%") # Output:
+# In clear : [0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0] # In FHE : [0 0 0 0 1 0
+1 0 1 1 0 0 1 0 0 1 1 1 0 0] # Similarity: 100% ``` This example is explained
+in more detail in the [linear model documentation](docs/built-in-models/
+linear.md). Concrete ML built-in models have APIs that are almost identical to
+their scikit-learn counterparts. It is also possible to convert PyTorch
+networks to FHE with the Concrete ML conversion APIs. Please refer to the
+[linear models](docs/built-in-models/linear.md), [tree-based models](docs/
+built-in-models/tree.md) and [neural networks](docs/built-in-models/neural-
+networks.md) documentation for more examples, showing the scikit-learn-like API
+of the built-in models. ## Documentation. Full, comprehensive documentation is
+available here: [https://docs.zama.ai/concrete-ml](https://docs.zama.ai/
+concrete-ml). ## Online demos and tutorials. Various tutorials are proposed for
+the [built-in models](docs/built-in-models/ml_examples.md) and for [deep
+learning](docs/deep-learning/examples.md). In addition, several complete use-
+cases are explored: - [Encrypted Large Language Model](use_case_examples/llm/):
+convert a user-defined part of a Large Language Model for encrypted text
+generation. Shows the trade-off between quantization and accuracy for text
+generation and shows how to run the model in FHE. - [Credit Scoring]
+(use_case_examples/credit_scoring/): predicts the chance of a given loan
+applicant defaulting on loan repayment while keeping the user's data private.
+Shows how Concrete ML models easily replace their scikit-learn equivalents -
+[Health diagnosis](use_case_examples/disease_prediction/): based on a patient's
+symptoms, history and other health factors, gives a diagnosis using FHE to
+preserve the privacy of the patient. - [MNIST](use_case_examples/mnist): a
+Python script and notebook showing quantization-aware training following FHE
+constraints. A fully-connected neural network is implemented with [Brevitas]
+(https://github.com/Xilinx/brevitas) and is converted to FHE with Concrete ML.
+- [Titanic](use_case_examples/titanic/KaggleTitanic.ipynb): a notebook, which
+gives a solution to the [Kaggle Titanic competition](https://www.kaggle.com/c/
+titanic/). Implemented with XGBoost from Concrete ML, this example comes as a
+companion of the [Kaggle notebook](https://www.kaggle.com/code/concretemlteam/
+titanic-with-privacy-preserving-machine-learning), and was the subject of a
+blogpost in [KDnuggets](https://www.kdnuggets.com/2022/08/machine-learning-
+encrypted-data.html). - [Sentiment analysis with transformers]
+(use_case_examples/sentiment_analysis_with_transformer): a gradio demo which
+predicts if a tweet / short message is positive, negative or neutral, with FHE
+of course! The [live interactive](https://huggingface.co/spaces/zama-fhe/
 encrypted_sentiment_analysis) demo is available on Hugging Face. This [blog
 post](https://huggingface.co/blog/sentiment-analysis-fhe) explains how this
 demo works! - [CIFAR10 FHE-friendly model with Brevitas](use_case_examples/
 cifar_brevitas_training): code for training from scratch a VGG-like FHE-
 compatible neural network using Brevitas, and a script to run the neural
-network in FHE. FHE simulation shows an accuracy of 88.7%, but running
-inference with FHE is still a work-in-progress. - [CIFAR10 / CIFAR100 FHE-
-friendly models with Transfer Learning approach](use_case_examples/
-cifar_brevitas_finetuning): series of three notebooks, that show how to convert
-a pre-trained FP32 VGG11 neural network into a quantized model using Brevitas.
-The model is fine-tuned on the CIFAR data-sets, converted for FHE execution
-with Concrete ML and evaluated using FHE simulation. For CIFAR10 and CIFAR100,
-respectively, our simulations show an accuracy of 90.2% and 68.2%. True FHE
-inference is a work-in-progress. - [FHE neural network splitting for client/
-server deployment](use_case_examples/cifar_brevitas_with_model_splitting): we
-explain how to split a computationally-intensive neural network model in two
-parts. First, we execute the first part on the client side in the clear, and
-the output of this step is encrypted. Next, to complete the computation, the
-second part of the model is evaluated with FHE. This tutorial also shows the
-impact of FHE speed/accuracy trade-off on CIFAR10, limiting PBS to 8-bit, and
-thus achieving 62% accuracy. - [Encrypted image filtering](use_case_examples/
-image_filtering): finally, the live demo for our [6-min](https://6min.zama.ai)
-is available, in the form of a gradio application. We take encrypted images,
-and apply some filters (for example black-and-white, ridge detection, or your
-own filter). More generally, if you have built awesome projects using Concrete
-ML, feel free to let us know and we'll link to it! ## Citing Concrete ML To
-cite Concrete ML, notably in academic papers, please use the following entry,
-which list authors by order of first commit: ```text @Misc{ConcreteML, title=
-{Concrete {ML}: a Privacy-Preserving Machine Learning Library using Fully
-Homomorphic Encryption for Data Scientists}, author={Arthur Meyre and Benoit
-{Chevallier-Mames} and Jordan Frery and Andrei Stoian and Roman Bredehoft and
-Luis Montero and Celia Kherfallah}, year={2022}, note={\url{https://github.com/
-zama-ai/concrete-ml}}, } ``` ## Need support? [https://user-
-images.githubusercontent.com/5758427/231115030-21195b55-2629-4c01-9809-
-be5059243999.png] ## License. This software is distributed under the BSD-3-
-Clause-Clear license. If you have any questions, please contact us at
-hello@zama.ai.
+network in FHE. Execution in FHE takes ~20 minutes per image and shows an
+accuracy of 88.7%. - [CIFAR10 / CIFAR100 FHE-friendly models with Transfer
+Learning approach](use_case_examples/cifar_brevitas_finetuning): series of
+three notebooks, that show how to convert a pre-trained FP32 VGG11 neural
+network into a quantized model using Brevitas. The model is fine-tuned on the
+CIFAR data-sets, converted for FHE execution with Concrete ML and evaluated
+using FHE simulation. For CIFAR10 and CIFAR100, respectively, our simulations
+show an accuracy of 90.2% and 68.2%. - [FHE neural network splitting for
+client/server deployment](use_case_examples/
+cifar_brevitas_with_model_splitting): we explain how to split a
+computationally-intensive neural network model in two parts. First, we execute
+the first part on the client side in the clear, and the output of this step is
+encrypted. Next, to complete the computation, the second part of the model is
+evaluated with FHE. This tutorial also shows the impact of FHE speed/accuracy
+trade-off on CIFAR10, limiting PBS to 8-bit, and thus achieving 62% accuracy. -
+[Encrypted image filtering](use_case_examples/image_filtering): finally, the
+live demo for our [6-min](https://6min.zama.ai) is available, in the form of a
+gradio application. We take encrypted images, and apply some filters (for
+example black-and-white, ridge detection, or your own filter). More generally,
+if you have built awesome projects using Concrete ML, feel free to let us know
+and we'll link to it! ## Citing Concrete ML To cite Concrete ML, notably in
+academic papers, please use the following entry, which list authors by order of
+first commit: ```text @Misc{ConcreteML, title={Concrete {ML}: a Privacy-
+Preserving Machine Learning Library using Fully Homomorphic Encryption for Data
+Scientists}, author={Arthur Meyre and Benoit {Chevallier-Mames} and Jordan
+Frery and Andrei Stoian and Roman Bredehoft and Luis Montero and Celia
+Kherfallah}, year={2022}, note={\url{https://github.com/zama-ai/concrete-ml}},
+} ``` ## Need support? [https://user-images.githubusercontent.com/5758427/
+231115030-21195b55-2629-4c01-9809-be5059243999.png] ## License. This software
+is distributed under the BSD-3-Clause-Clear license. If you have any questions,
+please contact us at hello@zama.ai.
```

## Comparing `concrete_ml-1.0.3.dist-info/RECORD` & `concrete_ml-1.1.0.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -3,54 +3,54 @@
 concrete/ml/common/__init__.py,sha256=dXaklwVfEYsMLqyH_YFOjGuxnyzoZuApIm8dKLefybw,95
 concrete/ml/common/check_inputs.py,sha256=wj_oyESYWHemVsPRBC25OQc8a2pX2j7fYGpw8lCeKUA,2519
 concrete/ml/common/debugging/__init__.py,sha256=_eh1MBBmnk2o1M4YGbH0Cbr_cEPjFOVz5wsp080HonE,101
 concrete/ml/common/debugging/custom_assert.py,sha256=H5ESt7cYnDT2PnUXvDaAvUJR2CKHwsHQ4QWtMLvcLZw,2377
 concrete/ml/common/serialization/__init__.py,sha256=SM3rIzYbRIfp7gDilx5LrrxQ7bpr0ArNkvfhoOpFxGs,1221
 concrete/ml/common/serialization/decoder.py,sha256=Vcus-zDeSA13IwzZGOBfVQy7kPSFz4uHhvR7oX4LCZ4,8204
 concrete/ml/common/serialization/dumpers.py,sha256=uXdo0YHc8WnrlI7NQ78oGdBijpD0vatjgjBEIjrSGF0,601
-concrete/ml/common/serialization/encoder.py,sha256=HJK4huhGwD4Xyooo87v70xAXLfMlzGHHb_fb2QJYxjY,12166
+concrete/ml/common/serialization/encoder.py,sha256=hNUxaKWTDs1-vFKfTOqLZF73aOAAb0Nl7SZfawOtqLs,12167
 concrete/ml/common/serialization/loaders.py,sha256=Jz10aCeuvOUIlkmKaChGgSmBR0KDsNgAmKj-UBYod6E,743
-concrete/ml/common/utils.py,sha256=rvDn2roYXJwWoU3OMJ1m72tV9N_66L-tgnzShl5zu0Y,18125
-concrete/ml/deployment/Dockerfile.server,sha256=TbSoyy195L9ttQnEf4YJ70yMuphZRHZvGep1GI4kRlM,235
+concrete/ml/common/utils.py,sha256=TsRqp1j-4udLN1fVbdXS9LksfTlJArwBxJZTK06ZDHg,18128
+concrete/ml/deployment/Dockerfile.server,sha256=ycWhDO6tWKedZSFMnDmD-TGEhdQtzsl6YXRNJqKvkr4,235
 concrete/ml/deployment/__init__.py,sha256=jgaPZMSlsJy1KF45EI92rQ7e2CKEpmLdaWcwwFEPeZ8,121
 concrete/ml/deployment/deploy_to_aws.py,sha256=P94YtL5e_r50eoNHoiklMQmlsFoRHXw9ge6Tn_7dV9c,17918
 concrete/ml/deployment/deploy_to_docker.py,sha256=c7N9XhbgBajyLiu_TvPRke5kSi6_GdmRtOOPSl-LpoE,3800
-concrete/ml/deployment/fhe_client_server.py,sha256=OAFnz7scJSIjNvgBeWI5VpRgjrJ4MT8nNFlrj0B06PQ,13873
+concrete/ml/deployment/fhe_client_server.py,sha256=pO46f-c25IQyN_2YmbT35vVZT560WbrWrMGrNYgf8XQ,13773
 concrete/ml/deployment/server.py,sha256=CB6y1v9NPq3NqOE0spzKUMNywFNmhEta8zsn5YIu42o,2590
 concrete/ml/deployment/server_requirements.txt,sha256=gyd07Mp8qZPWhuz7QI1kgYS3JbjcPbZK4cL9RDOR_x8,33
 concrete/ml/deployment/utils.py,sha256=aZFmDRUW58JHAJLK5c--UANMx1sN8C-ioz4JPcPQV-Q,3293
 concrete/ml/onnx/__init__.py,sha256=LiK0TOCAo7c5-TBk4zcO3PEQmdASN0NgLDYIYUXl464,19
 concrete/ml/onnx/convert.py,sha256=LC1YtDL_miK0QKYXzwYwLyBt1PTOXqk247BPS714EnA,3472
 concrete/ml/onnx/onnx_impl_utils.py,sha256=cQ5mfY0VCUMClOy3OGVeddISjWsdoylLu8GundXC4JY,9401
 concrete/ml/onnx/onnx_model_manipulations.py,sha256=fjy-Vqa7Cl6F-O4sft1xKa0z1LZu6X6SnrXj7UtadDQ,9685
 concrete/ml/onnx/onnx_utils.py,sha256=V39Fip97h4F85PlhiQduQPFnNizpGjyGyCHFYOHPon8,20192
-concrete/ml/onnx/ops_impl.py,sha256=Z3yj5zjyllykLmjWus6TSNvMQpPrA7fKGRFFNOYKke0,58079
+concrete/ml/onnx/ops_impl.py,sha256=rbQzlNeNePKapaypFD7m2tyD04tdpPtX1MpBcKt1RIw,58085
 concrete/ml/pytest/__init__.py,sha256=5Zk0w3T-MYPF3485ir5kZ1dP7x_VoMIreDMKnJuyBCo,101
-concrete/ml/pytest/torch_models.py,sha256=gRcaixzmf04PwLfVgGCok3uRDdwGmQpoNlnZN2QjvXY,43914
-concrete/ml/pytest/utils.py,sha256=HJF_4OB6WK8fcsQWXe3VSMCMs8CDpSfG3eJnlz2zHlw,14823
+concrete/ml/pytest/torch_models.py,sha256=jMV2D3umt-J3iOwldnGXSiNGe2TZcuYdI_oVy-T0NOg,45787
+concrete/ml/pytest/utils.py,sha256=V7hhxUb0Vf1onh4YcATC-YfnspB6610dXN5cp9oVrmU,15760
 concrete/ml/quantization/__init__.py,sha256=AMEpmLBppr9jRyHOaz9X6dND-u6urnDnkW06X_80JWQ,1081
-concrete/ml/quantization/base_quantized_op.py,sha256=uixLiZ9cz5Uy7zqMNgUKa5RKgAwZqssPU_RVHtPACBo,41430
+concrete/ml/quantization/base_quantized_op.py,sha256=p9GoVsEbBHwknENGh4G882GEmTo5qpNujw4_jYa2dfY,41439
 concrete/ml/quantization/post_training.py,sha256=mIMTmh7pLUl1RYmrji1nQzpCjyjUm9UYetMP85OZkDQ,43710
-concrete/ml/quantization/quantized_module.py,sha256=IsseO3F9uOPU3EFDKh3cQFyqcFuq36sf9I11wqt-ek8,26450
-concrete/ml/quantization/quantized_ops.py,sha256=orROqe4H0FF8vFIbMqMEW7ojmR3-HGpx2Y63NsQyAzY,81014
+concrete/ml/quantization/quantized_module.py,sha256=HoWWvkwkn3qoB8memNtkZhLKLburOHLhAq05rx7kZds,25888
+concrete/ml/quantization/quantized_ops.py,sha256=y9WMao_TimHG3YFE7aHgbiLgRZLX_h5CmJgzGZ50uZo,81023
 concrete/ml/quantization/quantizers.py,sha256=9qpikdq4EPHB0jKwpM6IqvjO3SddaOGJfNj9lkkRxAE,35671
 concrete/ml/search_parameters/__init__.py,sha256=-TGfmte3AvAn2ajLxLd-FCbru6_Ml9DiKeG7ooR819Q,77
 concrete/ml/search_parameters/p_error_search.py,sha256=SnQ1eIzHNQqIGWPbNMg4obDuN4jV0KDsPPVuCpJbkMU,21193
 concrete/ml/sklearn/__init__.py,sha256=PPR2RuegE_0-OOA9QhYyZ75lxm7rZiAWI4MqeQwRoCo,4679
-concrete/ml/sklearn/base.py,sha256=YZLdnQgAR3T1PsHaI8ssYAVXAI7KK69rd1KDGaqFtAY,64073
+concrete/ml/sklearn/base.py,sha256=GKaE2E3EUxHZraTkA3L_xrxI26ChONaRDU0V1UFQzDU,64360
 concrete/ml/sklearn/glm.py,sha256=sXbrxrSJ8_lBH6YaWEP4-5_EUbfjZyWUXNuVJ2gfsZY,12899
 concrete/ml/sklearn/linear_model.py,sha256=fIakrELdme6IQWjOr9uYHOnh4uc-Pavtxyvl2IfNHF4,21814
 concrete/ml/sklearn/qnn.py,sha256=4qkIiQK13nw7yVw8-0ZBpmEfGt-zK53BUsJaVj_Wn3k,32152
 concrete/ml/sklearn/qnn_module.py,sha256=y4LQIjDRkCq91Q6ajiNJ7IRb31eezxrrs1tfZvgGZE8,12803
 concrete/ml/sklearn/rf.py,sha256=Qe_mI_A9nEDMDjlqWqibFz_BYq4BvMVJdCAgugXfdHQ,11043
 concrete/ml/sklearn/svm.py,sha256=iHzFYX-u66PRbJjLE-0YvKvGJ4I1cJc_jLDaP4L6RXA,9155
-concrete/ml/sklearn/tree.py,sha256=4Ws9GDjv_G2oe8OGmM6ZM4fBlPcQGFG4XiJqMxavgeo,9191
+concrete/ml/sklearn/tree.py,sha256=VkN5IFXmVWJphnbggp4NSziH1m1G5bI04rUNXvyUN2I,10045
 concrete/ml/sklearn/tree_to_numpy.py,sha256=NU79gTlaSVqDbIYSNlL9Mo5kB0aQBejegy_P_iFExgQ,10923
 concrete/ml/sklearn/xgb.py,sha256=mvSwn5Kbtl_Pwe0N_2SsseShri4rAo1ByUSps2W7vV4,18962
 concrete/ml/torch/__init__.py,sha256=aUQ25-hJdirZCa20KqaVMrt2PnpnSXBCVw7QvLQ_BoQ,83
-concrete/ml/torch/compile.py,sha256=Z_Y3zYKjyquQWa9mw-9qlWH72vDI9f7d3G37ltfh3lA,19083
+concrete/ml/torch/compile.py,sha256=T8uKliYYmwZ1IIA6bg6AjeDFjG04HihTKeqW5Hl788A,19510
 concrete/ml/torch/numpy_module.py,sha256=PKJmuGL0Q7nzfXsbwz9Mr1J-w5MDGkpzRnZY86TylOI,3174
-concrete/ml/version.py,sha256=2LQo2Ai4U1G5VSXVPXYu54OfSZw7S16Et044wfBHXEA,124
-concrete_ml-1.0.3.dist-info/LICENSE,sha256=Q2TUW9iqL5JOnEcNTstSvNPYRnF-iQi24FUla8oUEwE,1546
-concrete_ml-1.0.3.dist-info/WHEEL,sha256=vxFmldFsRN_Hx10GDvsdv1wroKq8r5Lzvjp6GZ4OO8c,88
-concrete_ml-1.0.3.dist-info/METADATA,sha256=x2AK_So4XtdfuyoZ5bZ5i577_JBWZoDeJQv0uIXX0a8,11617
-concrete_ml-1.0.3.dist-info/RECORD,,
+concrete/ml/version.py,sha256=-VwCzyqnMWQEL-w31u7OLsCdj7Q3dvjWXVSzzgOX4G8,124
+concrete_ml-1.1.0.dist-info/LICENSE,sha256=Q2TUW9iqL5JOnEcNTstSvNPYRnF-iQi24FUla8oUEwE,1546
+concrete_ml-1.1.0.dist-info/WHEEL,sha256=vxFmldFsRN_Hx10GDvsdv1wroKq8r5Lzvjp6GZ4OO8c,88
+concrete_ml-1.1.0.dist-info/METADATA,sha256=fM8-Zt9LJNnFo4np5nlFznXA0hqgi8MIQud2618A7Hc,12275
+concrete_ml-1.1.0.dist-info/RECORD,,
```

