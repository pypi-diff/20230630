# Comparing `tmp/pycortexintelligence-0.0.9-py3-none-any.whl.zip` & `tmp/pycortexintelligence-1.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,16 +1,16 @@
-Zip file size: 12658 bytes, number of entries: 14
--rw-rw-rw-  2.0 fat        0 b- defN 20-Oct-08 17:59 pycortexintelligence/__init__.py
--rw-rw-rw-  2.0 fat     9232 b- defN 20-Dec-14 16:18 pycortexintelligence/functions.py
--rw-rw-rw-  2.0 fat        0 b- defN 20-Dec-08 17:30 pycortexintelligence/core/__init__.py
--rw-rw-rw-  2.0 fat      508 b- defN 20-Dec-08 17:30 pycortexintelligence/core/config.py
--rw-rw-rw-  2.0 fat     2341 b- defN 20-Dec-08 17:30 pycortexintelligence/core/funcs_env.py
--rw-rw-rw-  2.0 fat     1871 b- defN 20-Dec-08 17:30 pycortexintelligence/core/funcs_mail.py
--rw-rw-rw-  2.0 fat     7709 b- defN 20-Dec-08 17:30 pycortexintelligence/core/funcs_startproject.py
--rw-rw-rw-  2.0 fat      660 b- defN 20-Dec-14 14:37 pycortexintelligence/core/messages.py
--rw-rw-rw-  2.0 fat     1522 b- defN 20-Dec-08 17:30 pycortexintelligence-0.0.9.data/scripts/cortex.py
--rw-rw-rw-  2.0 fat     1094 b- defN 20-Dec-14 16:23 pycortexintelligence-0.0.9.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     2534 b- defN 20-Dec-14 16:23 pycortexintelligence-0.0.9.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 20-Dec-14 16:23 pycortexintelligence-0.0.9.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       21 b- defN 20-Dec-14 16:23 pycortexintelligence-0.0.9.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1303 b- defN 20-Dec-14 16:23 pycortexintelligence-0.0.9.dist-info/RECORD
-14 files, 28887 bytes uncompressed, 10430 bytes compressed:  63.9%
+Zip file size: 14760 bytes, number of entries: 14
+-rw-rw-r--  2.0 unx        0 b- defN 22-Jul-08 22:55 pycortexintelligence/__init__.py
+-rw-rw-r--  2.0 unx    12320 b- defN 23-Jun-29 14:42 pycortexintelligence/functions.py
+-rw-rw-r--  2.0 unx        0 b- defN 22-Jul-08 22:55 pycortexintelligence/core/__init__.py
+-rw-rw-r--  2.0 unx      487 b- defN 22-Jul-08 22:55 pycortexintelligence/core/config.py
+-rw-rw-r--  2.0 unx     2211 b- defN 23-May-22 18:36 pycortexintelligence/core/funcs_env.py
+-rw-rw-r--  2.0 unx     1818 b- defN 23-May-22 18:36 pycortexintelligence/core/funcs_mail.py
+-rw-rw-r--  2.0 unx     7189 b- defN 23-May-22 18:36 pycortexintelligence/core/funcs_startproject.py
+-rw-rw-r--  2.0 unx      884 b- defN 23-Jun-29 14:42 pycortexintelligence/core/messages.py
+-rwxrwxr-x  2.0 unx     1461 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.data/scripts/cortex.py
+-rw-rw-r--  2.0 unx     1073 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     5122 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       21 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1304 b- defN 23-Jun-30 12:37 pycortexintelligence-1.0.0.dist-info/RECORD
+14 files, 33982 bytes uncompressed, 12532 bytes compressed:  63.1%
```

## zipnote {}

```diff
@@ -18,26 +18,26 @@
 
 Filename: pycortexintelligence/core/funcs_startproject.py
 Comment: 
 
 Filename: pycortexintelligence/core/messages.py
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.data/scripts/cortex.py
+Filename: pycortexintelligence-1.0.0.data/scripts/cortex.py
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.dist-info/LICENSE
+Filename: pycortexintelligence-1.0.0.dist-info/LICENSE
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.dist-info/METADATA
+Filename: pycortexintelligence-1.0.0.dist-info/METADATA
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.dist-info/WHEEL
+Filename: pycortexintelligence-1.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.dist-info/top_level.txt
+Filename: pycortexintelligence-1.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: pycortexintelligence-0.0.9.dist-info/RECORD
+Filename: pycortexintelligence-1.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pycortexintelligence/functions.py

```diff
@@ -1,276 +1,347 @@
-import datetime
-
-import requests
-
-from pycortexintelligence.core.messages import *
-
-LOADMANAGER = "https://api.cortex-intelligence.com"
-
-
-def _make_url_auth(plataform_url):
-    return "https://{}/service/integration-authorization-service.login".format(plataform_url)
-
-
-def _make_download_url(plataform_url):
-    return 'https://{}/service/integration-cube-service.download?'.format(plataform_url)
-
-
-def _get_sid_bearer_token(auth_endpoint, credentials):
-    """
-    :param auth_endpoint:
-    :param credentials:
-    :return:
-    """
-    response = requests.post(auth_endpoint, json=credentials)
-    response_json = response.json()
-    return {"Authorization": "Bearer " + response_json["key"]}
-
-
-def _get_data_input(content, loadmanager, headers):
-    """
-    :param content:
-    :param loadmanager:
-    :param headers:
-    :return:
-    """
-    endpoint = loadmanager + "/datainput"
-    response = requests.post(endpoint, headers=headers, json=content)
-    data_input_id = response.json()["id"]
-    return data_input_id
-
-
-def _get_execution_id(data_input_id, content, loadmanager, headers):
-    """
-    :param data_input_id:
-    :param content:
-    :param loadmanager:
-    :param headers:
-    :return:
-    """
-    endpoint = "{}/datainput/{}/execution".format(loadmanager, data_input_id)
-    response = requests.post(endpoint, headers=headers, json=content)
-    execution_id = response.json()["executionId"]
-    return execution_id
-
-
-def _start_process(execution_id, loadmanager, headers):
-    """
-    :param execution_id:
-    :param loadmanager:
-    :param headers:
-    :return:
-    """
-    endpoint = loadmanager + "/execution/" + execution_id + "/start"
-    response = requests.put(endpoint, headers=headers)
-    return response
-
-
-def _execution_history(execution_id, loadmanager, headers):
-    """
-    :param execution_id:
-    :param loadmanager:
-    :param headers:
-    :return:
-    """
-    endpoint = loadmanager + "/execution/" + execution_id  # + '/history'
-    response = requests.get(endpoint, headers=headers)
-    return response
-
-
-def upload_local_2_cube(cubo_id, file_path, auth_endpoint, credentials,
-                        loadmanager="https://api.cortex-intelligence.com",
-                        data_format={
-                            "charset": "UTF-8",
-                            "quote": "\"",
-                            "escape": "\/\/",
-                            "delimiter": ",",
-                            "fileType": "CSV"},
-                        ):
-    """
-    :param cubo_id:
-    :param file_path:
-    :param auth_endpoint:
-    :param credentials:
-    :param loadmanager:
-    :param data_format:
-    :return:
-    """
-
-    # ================ Get Bearer Token ===================
-    headers = _get_sid_bearer_token(auth_endpoint, credentials)
-
-    # ================ Content ============================
-    content = {
-        "destinationId": cubo_id,
-        "fileProcessingTimeout": 600000,
-        "executionTimeout": 1200000,
-    }
-
-    # ================ Get Data Input Id ======================
-    data_input_id = _get_data_input(content, loadmanager, headers)
-
-    # ================ Get Execution Id =======================
-    execution_id = _get_execution_id(data_input_id, content, loadmanager, headers)
-
-    # ================ Send files =============================
-    endpoint = loadmanager + "/execution/" + execution_id + "/file"
-    response = requests.post(
-        endpoint,
-        headers=headers,
-        data=data_format,
-        files={"file": open(file_path, "rb")},
-    )
-
-    # ================ Start Data Input Process ===========================
-    _start_process(execution_id, loadmanager, headers)
-
-    return execution_id, headers
-
-
-def upload_to_cortex(**kwargs):
-    """
-    :param cubo_id:
-    :param file_path:
-    :param plataform_url:
-    :param username:
-    :param password:
-    :param data_format: data_format={
-                            "charset": "UTF-8",
-                            "quote": "\"",
-                            "escape": "\/\/",
-                            "delimiter": ",",
-                            "fileType": "CSV"
-                        }
-    :return:
-    """
-    # Read Kwargs
-    cubo_id = kwargs.get('cubo_id')
-    file_path = kwargs.get('file_path')
-    plataform_url = kwargs.get('plataform_url')
-    username = kwargs.get('username')
-    password = kwargs.get('password')
-    data_format = kwargs.get('data_format', {
-        "charset": "UTF-8",
-        "quote": "\"",
-        "escape": "\/\/",
-        "delimiter": ",",
-        "fileType": "CSV"
-    })
-
-    # Verify Kwargs
-    if cubo_id and file_path and plataform_url and username and password:
-        auth_endpoint = _make_url_auth(plataform_url)
-        credentials = {"login": str(username), "password": str(password)}
-        execution_id, headers = upload_local_2_cube(
-            cubo_id=cubo_id,
-            file_path=file_path,
-            auth_endpoint=auth_endpoint,
-            credentials=credentials,
-            data_format=data_format
-        )
-        response = _execution_history(execution_id, LOADMANAGER, headers)
-        return response
-    else:
-        raise ValueError(ERROR_ARGUMENTS_VALIDATION)
-
-
-def download_from_cortex(**kwargs):
-    """
-    :param cubo_id:
-    :param cubo_name:
-    :param plataform_url:
-    :param username:
-    :param password:
-    :param columns:
-    :param file_path:
-    :param data_format:
-    :param filters:
-    :return:
-    """
-    cubo_id = kwargs.get('cubo_id')
-    cubo_name = kwargs.get('cubo_name')
-    plataform_url = kwargs.get('plataform_url')
-    username = kwargs.get('username')
-    password = kwargs.get('password')
-    columns = kwargs.get('columns')
-    file_path = kwargs.get('file_path')
-    data_format = kwargs.get('data_format', {
-        "charset": "UTF-8",
-        "quote": "\"",
-        "escape": "\/\/",
-        "delimiter": ",",
-    })
-    filters = kwargs.get('filters', None)
-    if cubo_id and cubo_name:
-        raise ValueError(DOWNLOAD_ERROR_JUST_ID_OR_NAME)
-    if (cubo_id or cubo_name) and plataform_url and username and password and columns and file_path:
-        # Verify is a ID or Name
-        if cubo_id:
-            cube = '{"id":"' + cubo_id + '"}'
-        else:
-            cube = '{"name":"' + cubo_name + '"}'
-
-        # Columns to Download
-        columns_download = []
-        for column in columns:
-            columns_download.append({
-                "name": column,
-            })
-        columns_download = str(columns_download).replace("'", '"')
-
-        # Need to Apply Filters
-        if filters:
-            filters_download = []
-            for filter in filters:
-                column_name = filter[0]
-                value = filter[1]
-                element = {
-                    "name": column_name,
-                    "type": "SIMPLE",
-                }
-                try:
-                    value = datetime.datetime.strptime(value, "%d/%m/%Y")
-                    element["type"] = "DATE"
-                    element["rangeStart"] = value.strftime("%Y%m%d")
-                    element["rangeEnd"] = value.strftime("%Y%m%d")
-                except ValueError:
-                    try:
-                        value = value.split('-')
-                        date_start = datetime.datetime.strptime(value[0], "%d/%m/%Y")
-                        date_end = datetime.datetime.strptime(value[1], "%d/%m/%Y")
-                        element["type"] = "DATE"
-                        element["rangeStart"] = date_start.strftime("%Y%m%d")
-                        element["rangeEnd"] = date_end.strftime("%Y%m%d")
-                    except ValueError:
-                        element["value"] = value
-                filters_download.append(element)
-            filters_download = str(filters_download).replace("'", '"')
-
-        auth_endpoint = _make_url_auth(plataform_url)
-        credentials = {"login": str(username), "password": str(password)}
-        auth_post = requests.post(auth_endpoint, json=credentials)
-        headers = {
-            'x-authorization-user-id': auth_post.json()['userId'],
-            'x-authorization-token': auth_post.json()['key']
-        }
-        download_endpoint = _make_download_url(plataform_url)
-        payload = {
-            'cube': cube,
-            'charset': data_format['charset'],
-            'delimiter': data_format['delimiter'],
-            'quote': data_format['quote'],
-            'escape': data_format['escape'],
-        }
-        if filters:
-            payload['filters'] = filters_download
-        if columns_download:
-            payload['headers'] = columns_download
-
-        with requests.get(download_endpoint, stream=True, headers=headers, params=payload) as r:
-            r.raise_for_status()
-            with open(file_path, 'wb') as f:
-                for chunk in r.iter_content(chunk_size=8192):
-                    f.write(chunk)
-    else:
-        raise ValueError(ERROR_ARGUMENTS_VALIDATION)
-
+import datetime
+import json
+import logging
+from http import HTTPStatus
+from io import BufferedWriter, BytesIO
+from typing import Any, BinaryIO, Dict, List, Optional, Union
+
+import requests
+
+from pycortexintelligence.core.messages import (
+    DOWNLOAD_ERROR_JUST_ID_OR_NAME,
+    ERROR_ARGUMENTS_VALIDATION,
+)
+
+
+class ApplicationTenantFilter(logging.Filter):
+    def __init__(self, application_name, tenant):
+        self.application_name = application_name
+        self.tenant = tenant
+
+    def filter(self, record):
+        record.Application = self.application_name
+        record.tenant = self.tenant
+        return True
+
+
+class LoadExecution:
+    loadmanager_url = "https://api.cortex-intelligence.com"
+
+    def __init__(
+        self,
+        cube_id,
+        header,
+        file_processing_timeout,
+        ignore_validation_errors,
+        executor_name,
+        file_like_object,
+        data_format,
+    ):
+        self.cube_id = cube_id
+        self.header = header
+        self.file_processing_timeout = file_processing_timeout
+        self.ignore_validation_errors = ignore_validation_errors
+        self.executor_name = executor_name
+        self.file_like_object = file_like_object
+        self.data_format = data_format
+
+    def start_process(self):
+        endpoint = self.loadmanager_url + "/execution/" + self.execution_id + "/start"
+        response = requests.put(endpoint, headers=self.header)
+        response.raise_for_status()
+
+    @classmethod
+    def execution_history(cls, headers, execution_id):
+        endpoint = cls.loadmanager_url + "/execution/" + execution_id
+        response = requests.get(endpoint, headers=headers)
+        response.raise_for_status()
+        return response.json()
+
+    @classmethod
+    def check_finished(cls, headers, execution_id) -> bool:
+        history = cls.execution_history(headers, execution_id)
+        complete = history["completed"]
+        if not complete:
+            return False
+
+        if "success" not in history or history["success"] is False:
+            msg = "Error on Load execution id: {}".format(history["executionId"])
+            errors = history["errors"]
+            for error in errors:
+                msg += "\nError on file id: {}, code: {}, value: {}".format(
+                    error["fileId"], error["description"], error["value"]
+                )
+            raise Exception(msg)
+
+        return True
+
+    def send_file(self):
+        endpoint = self.loadmanager_url + "/execution/" + self.execution_id + "/file"
+        response = requests.post(
+            endpoint,
+            headers=self.header,
+            data=self.data_format,
+            files={"file": self.file_like_object},
+        )
+        response.raise_for_status()
+
+    def create_load_execution(self) -> str:
+        endpoint = f"{self.loadmanager_url}/execution"
+        content = {
+            "destinationId": self.cube_id,
+            "fileProcessingTimeout": self.file_processing_timeout,
+            "ignoreValidationErrors": self.ignore_validation_errors,
+            "name": self.executor_name,
+        }
+        response = requests.post(endpoint, headers=self.header, json=content)
+        response.raise_for_status()
+        self.execution_id = response.json()["executionId"]
+        return self.execution_id
+
+
+class PyCortex:
+    data_format = {
+        "charset": "UTF-8",
+        "quote": '"',
+        "escape": "\\",
+        "delimiter": ",",
+        "fileType": "CSV",
+        "compressed": "NONE",
+    }
+    executor_name = "LoadManager PyCortex"
+    file_processing_timeout = 300
+    ignore_validation_errors = False
+
+    @classmethod
+    def upload_to_cortex(
+        cls,
+        cube_id: str,
+        platform_url: str,
+        username: str,
+        password: str,
+        file_object: Union[str, BinaryIO],
+        is_file=True,
+        **kwargs,
+    ) -> Dict:
+        if is_file and isinstance(file_object, str):
+            file_object = open(file_object, "rb")
+
+        elif not is_file and isinstance(file_object, BytesIO):
+            file_object.seek(0)
+
+        else:
+            raise ValueError(
+                f"A combinação is_file={is_file} com o tipo {type(file_object)} do file_object não é permitida."
+            )
+
+        file_processing_timeout = int(kwargs.get("timeout", cls.file_processing_timeout))
+        ignore_validation_errors = kwargs.get("ignore_errors", cls.ignore_validation_errors)
+        executor_name = kwargs.get("executor_name", cls.executor_name)
+
+        header = cls.platform_auth(platform_url, username, password)
+
+        load_execution = LoadExecution(
+            cube_id=cube_id,
+            header=header,
+            file_processing_timeout=file_processing_timeout,
+            ignore_validation_errors=ignore_validation_errors,
+            executor_name=executor_name,
+            file_like_object=file_object,
+            data_format=cls.data_format,
+        )
+        execution_id = load_execution.create_load_execution()
+        load_execution.send_file()
+        load_execution.start_process()
+        return LoadExecution.execution_history(headers=header, execution_id=execution_id)
+
+    @staticmethod
+    def make_filter(filters: List):
+        filters_download = []
+        for filter in filters:
+            column_name = filter[0]
+            value = filter[1]
+            element = {
+                "name": column_name,
+                "type": "SIMPLE",
+            }
+            try:
+                value = datetime.datetime.strptime(value, "%d/%m/%Y")
+                element["type"] = "DATE"
+                element["rangeStart"] = value.strftime("%Y%m%d")
+                element["rangeEnd"] = value.strftime("%Y%m%d")
+            except ValueError:
+                value_temp = value
+                try:
+                    value = value.split("-")  # type: ignore
+                    date_start = datetime.datetime.strptime(value[0], "%d/%m/%Y")
+                    date_end = datetime.datetime.strptime(value[1], "%d/%m/%Y")
+                    element["type"] = "DATE"
+                    element["rangeStart"] = date_start.strftime("%Y%m%d")
+                    element["rangeEnd"] = date_end.strftime("%Y%m%d")
+                except ValueError:
+                    value = value_temp.split("|")  # type: ignore
+                    element["value"] = value
+            filters_download.append(element)
+        return json.dumps(filters_download, ensure_ascii=False)
+
+    @staticmethod
+    def platform_auth(platform_url: str, username: str, password: str, return_user_id=False):
+        if not (username and password and platform_url):
+            raise ValueError(ERROR_ARGUMENTS_VALIDATION)
+
+        credentials = {"login": username, "password": password}
+
+        auth_endpoint = f"https://{platform_url}/service/integration-authorization-service.login"
+        auth_post = requests.post(auth_endpoint, json=credentials).json()
+        if return_user_id:
+            return {
+                "x-authorization-user-id": auth_post["userId"],
+                "x-authorization-token": auth_post["key"],
+            }
+        else:
+            return {"Authorization": f"Bearer {auth_post['key']}"}
+
+    @classmethod
+    def download_from_cortex(
+        cls,
+        cube_id: str,
+        platform_url: str,
+        username: str,
+        password: str,
+        columns: List,
+        filters: List,
+        file_object: BytesIO or str,
+        cubo_name: Optional[str] = None,
+    ) -> Any:
+        if not isinstance(file_object, BytesIO):
+            file_object = open(file_object, "wb")  # type: ignore
+
+        if cube_id and cubo_name:
+            raise ValueError(DOWNLOAD_ERROR_JUST_ID_OR_NAME)
+
+        if (cube_id or cubo_name) and file_object and columns:
+            if cube_id:
+                cube = f'{{"id":"{cube_id}"}}'
+            else:
+                cube = f'{{"name":"{cubo_name}"}}'
+
+            payload = {
+                "cube": cube,
+                "charset": cls.data_format["charset"],
+                "delimiter": cls.data_format["delimiter"],
+                "quote": cls.data_format["quote"],
+                "escape": cls.data_format["escape"],
+            }
+
+            if not columns:
+                raise Exception("É NECESSÁRIO INDICAR PELO MENOS UMA COLUNA")
+
+            columns_download = json.dumps([{"name": column} for column in columns], ensure_ascii=False)
+            payload["headers"] = columns_download
+
+            filters_download = list()
+            if filters:
+                filters_download = cls.make_filter(filters)
+                payload["filters"] = filters_download
+
+            headers = cls.platform_auth(platform_url, username, password, return_user_id=True)
+            download_endpoint = cls._make_download_url(platform_url)
+
+            with requests.get(url=download_endpoint, stream=True, headers=headers, params=payload) as r:
+                content_rows = r.headers["Content-Rows"]
+                r.raise_for_status()
+                chunks_len = list()
+                for chunk in r.iter_content(chunk_size=8192):
+                    chunks_len.append(chunk)
+                    file_object.write(chunk)
+
+                file_object.flush()
+
+            if isinstance(file_object, BufferedWriter):
+                return content_rows
+
+            if isinstance(file_object, BytesIO):
+                return file_object, content_rows
+        else:
+            raise ValueError(ERROR_ARGUMENTS_VALIDATION)
+
+    @classmethod
+    def get_platform_data_credit(cls, platform_url: str, username: str, password: str, filters: Dict):
+        url = f"https://{platform_url}/controller/data-credit-control/data-credit-operation/query-exported"
+        auth_header = cls.platform_auth(platform_url, username, password)
+        response = requests.post(url, json=filters, headers=auth_header)
+        return response.json()
+
+    @classmethod
+    def delete_from_cortex(
+        cls,
+        cube_id: str,
+        platform_url: str,
+        username: str,
+        password: str,
+        filters: Optional[List] = None,
+    ):
+        auth_header = cls.platform_auth(platform_url, username, password, return_user_id=True)
+        payload = {"cube": f'{{"id": "{cube_id}"}}', "filters": list()}
+
+        if filters is None:
+            payload["filters"] = [{"name": "# Records", "type": "SIMPLE", "value": 1}]
+
+        if filters is not None:
+            payload["filters"] = cls.make_filter(filters)
+
+        delete_url = f"https://{platform_url}/service/integration-cube-service.delete"
+
+        response = requests.get(delete_url, params=payload, headers=auth_header)
+
+        if response.status_code == HTTPStatus.OK:
+            return response.status_code
+
+        if response.status_code != HTTPStatus.OK:
+            raise ValueError(f"O status code recebido, foi: {response.status_code}\n {response.content}")
+
+    @staticmethod
+    def _make_download_url(platform_url: str):
+        return f"https://{platform_url}/service/integration-cube-service.download?"
+
+
+def download_from_cortex(**kwargs) -> Any:
+    import warnings
+
+    warnings.warn(
+        "\n\nThis module will be deprecated in the next release. Please use `PyCortex.download_from_cortex`.\n\n",
+        DeprecationWarning,
+        stacklevel=2,
+    )
+    if "file_like_object" in kwargs:
+        file_object = kwargs.get("file_like_object")
+    elif "file_path" in kwargs:
+        file_object = kwargs.get("file_path")
+
+    return PyCortex.download_from_cortex(
+        cube_id=kwargs.get("cubo_id"),  # type: ignore
+        platform_url=kwargs.get("plataform_url"),  # type: ignore
+        username=kwargs.get("username"),  # type: ignore
+        password=kwargs.get("password"),  # type: ignore
+        columns=kwargs.get("columns"),  # type: ignore
+        filters=kwargs.get("filters"),  # type: ignore
+        file_object=file_object,  # type: ignore
+    )
+
+
+def upload_to_cortex(**kwargs):
+    import warnings
+
+    warnings.warn(
+        "This module is deprecated. Please use `PyCortex.upload_to_cortex`.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
+
+    return PyCortex.upload_to_cortex(
+        cube_id=kwargs["cubo_id"],
+        platform_url=kwargs["plataform_url"],
+        username=kwargs["username"],
+        password=kwargs["password"],
+        file_object=kwargs["file_path"],
+    )
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## pycortexintelligence/core/config.py

 * *Ordering differences only*

```diff
@@ -1,22 +1,22 @@
-#  Copyright (c) 2020. Cortex Intelligence.
-#  Developed by Enderson Menezes
-
-DOWNLOADED_FOLDER = 'downloaded_files/'
-OUTPUT_FOLDER = 'output/'
-LOG_FILE = 'historico.log'
-
-PARAMS_TO_CHECK = [
-    # Parametros Padrão para Envio de E-mail
-    'email_password',
-    'email_port',
-    'email_smtp',
-    'email_user',
-    'email_to_error',
-    'project_name',
-
-    # Parametros da Plataforma
-    'plataform_url',
-    'plataform_username',
-    'plataform_password',
-    'plataform_cube_id',
+#  Copyright (c) 2020. Cortex Intelligence.
+#  Developed by Enderson Menezes
+
+DOWNLOADED_FOLDER = 'downloaded_files/'
+OUTPUT_FOLDER = 'output/'
+LOG_FILE = 'historico.log'
+
+PARAMS_TO_CHECK = [
+    # Parametros Padrão para Envio de E-mail
+    'email_password',
+    'email_port',
+    'email_smtp',
+    'email_user',
+    'email_to_error',
+    'project_name',
+
+    # Parametros da Plataforma
+    'plataform_url',
+    'plataform_username',
+    'plataform_password',
+    'plataform_cube_id',
 ]
```

## pycortexintelligence/core/funcs_env.py

```diff
@@ -1,68 +1,66 @@
-#  Copyright (c) 2020. Cortex Intelligence.
-#  Developed by Enderson Menezes
-
-import os
-import shutil
-from pycortexintelligence.core.messages import *
-from pycortexintelligence.core.funcs_mail import error_message
-from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER, PARAMS_TO_CHECK, LOG_FILE
-
-FOLDERS = [OUTPUT_FOLDER, DOWNLOADED_FOLDER]
-
-FILES = [LOG_FILE]
-
-
-def __delete_file(file_path, os_params):
-    try:
-        if os.path.isfile(file_path) or os.path.islink(file_path):
-            os.unlink(file_path)
-        elif os.path.isdir(file_path):
-            shutil.rmtree(file_path)
-    except Exception as e:
-        except_text = 'Failed to delete %s. Reason: %s' % (file_path, e)
-        error_message(except_text, os_params)
-        raise 'Failed to delete %s. Reason: %s' % (file_path, e)
-
-
-def load_env_to_dict(new_params_to_check: list):
-    """
-    Verifica as variavéis que foram colocadas como obrigatórias e cria um OS_PARAMS.
-    :return: os_params um dict com variaveis de ambiente configuradas no .env
-    """
-    os_params = dict()
-    final_check = new_params_to_check + PARAMS_TO_CHECK
-    for param in final_check:
-        os_params[param] = os.getenv(param)
-    return os_params
-
-
-def verify_env(os_params: dict, new_params_to_check: list):
-    """
-    :param new_params_to_check:
-    :param os_params:
-    :return: Sem retorno, procedimento verifica se os valores do os_params bate com o que foi desenhado.
-    """
-    # Argumentos Necessários
-    final_check = new_params_to_check + PARAMS_TO_CHECK
-    for key in final_check:
-        if os_params[key] is None:
-            message_text = mail_variable_error(key)
-            error_message(message_text=message_text, os_params=os_params)
-            raise ValueError('Não conseguimos validar a chave: {}, nas variaveis de ambiente'.format(key))
-
-
-def check_dirs():
-    for folder in FOLDERS:
-        try:
-            os.stat(folder)
-        except FileNotFoundError:
-            os.mkdir(folder)
-
-
-def delete_temp_files(os_params):
-    for folder in FOLDERS:
-        for filename in os.listdir(folder):
-            file_path = os.path.join(folder, filename)
-            __delete_file(file_path, os_params)
-    for file in FILES:
-        __delete_file(file, os_params)
+#  Copyright (c) 2020. Cortex Intelligence.
+#  Developed by Enderson Menezes
+
+import os
+import shutil
+from pycortexintelligence.core.messages import *
+from pycortexintelligence.core.funcs_mail import error_message
+from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER, PARAMS_TO_CHECK, LOG_FILE
+
+FOLDERS = [OUTPUT_FOLDER, DOWNLOADED_FOLDER]
+
+FILES = [LOG_FILE]
+
+
+def __delete_file(file_path, os_params):
+    try:
+        if os.path.isfile(file_path) or os.path.islink(file_path):
+            os.unlink(file_path)
+        elif os.path.isdir(file_path):
+            shutil.rmtree(file_path)
+    except Exception as e:
+        except_text = 'Failed to delete %s. Reason: %s' % (file_path, e)
+        error_message(except_text, os_params)
+        raise 'Failed to delete %s. Reason: %s' % (file_path, e)
+
+
+def load_env_to_dict(new_params_to_check: list):
+    """
+    Verifica as variavéis que foram colocadas como obrigatórias e cria um OS_PARAMS.
+    :return: os_params um dict com variaveis de ambiente configuradas no .env
+    """
+    os_params = dict()
+    final_check = new_params_to_check + PARAMS_TO_CHECK
+    for param in final_check:
+        os_params[param] = os.getenv(param)
+    return os_params
+
+
+def verify_env(os_params: dict, new_params_to_check: list):
+    """
+    :param new_params_to_check:
+    :param os_params:
+    :return: Sem retorno, procedimento verifica se os valores do os_params bate com o que foi desenhado.
+    """
+    # Argumentos Necessários
+    final_check = new_params_to_check + PARAMS_TO_CHECK
+    for key in final_check:
+        if os_params[key] is None:
+            message_text = mail_variable_error(key)
+            error_message(message_text=message_text, os_params=os_params)
+            raise ValueError('Não conseguimos validar a chave: {}, nas variaveis de ambiente'.format(key))
+
+
+def check_dirs():
+    for folder in FOLDERS:
+        try:
+            os.stat(folder)
+        except FileNotFoundError:
+            os.mkdir(folder)
+
+
+def delete_temp_files(os_params):
+    for folder in FOLDERS:
+        for filename in os.listdir(folder):
+            file_path = os.path.join(folder, filename)
+            __delete_file(file_path, os_params)
```

## pycortexintelligence/core/funcs_mail.py

 * *Ordering differences only*

```diff
@@ -1,54 +1,54 @@
-#  Copyright (c) 2020. Cortex Intelligence.
-#  Developed by Enderson Menezes
-
-import smtplib
-import ssl
-from email.mime.multipart import MIMEMultipart
-from email.mime.text import MIMEText
-from pycortexintelligence.core import messages
-
-
-def send_email_function(server, port, user_from, password, message_text, subject, user_to):
-    """
-    :param server: Servidor SMTP para Envio de E-mails
-    :param port: Porta de Conexão SMTP
-    :param user_from: Login/Usuário Remetente
-    :param password: Senha de acesso do SMTP
-    :param message_text: Mensagem a ser enviada
-    :param subject: Assunto
-    :param user_to: Destinatário
-    :return: Não retorna nada, é um procedimento.
-    """
-    # Create a multipart message and set headers
-    message = MIMEMultipart()
-    message["From"] = user_from
-    message["To"] = user_to
-    message["Subject"] = subject
-
-    # Add body to email
-    message.attach(MIMEText(message_text, "plain"))
-
-    # Message to Text
-    text = message.as_string()
-
-    # Log in to server using secure context and send email
-    context = ssl.create_default_context()
-    with smtplib.SMTP_SSL(server, port, context=context) as server:
-        server.login(user_from, password)
-        server.sendmail(user_from, user_to, text)
-
-
-def error_message(message_text, os_params):
-    """
-    Utilize o seguinte exemplo para enviar uma mensagem de erro:
-    error_message('Tivemos problema ao enviar e-mail', OS_PARAMS)
-    """
-    send_email_function(
-        server=os_params['email_smtp'],
-        port=os_params['email_port'],
-        user_from=os_params['email_user'],
-        user_to=os_params['email_to_error'],
-        password=os_params['email_password'],
-        subject=messages.EMAIL_PROJECT_ERROR_SUBJECT.format(os_params['project_name']),
-        message_text=message_text,
+#  Copyright (c) 2020. Cortex Intelligence.
+#  Developed by Enderson Menezes
+
+import smtplib
+import ssl
+from email.mime.multipart import MIMEMultipart
+from email.mime.text import MIMEText
+from pycortexintelligence.core import messages
+
+
+def send_email_function(server, port, user_from, password, message_text, subject, user_to):
+    """
+    :param server: Servidor SMTP para Envio de E-mails
+    :param port: Porta de Conexão SMTP
+    :param user_from: Login/Usuário Remetente
+    :param password: Senha de acesso do SMTP
+    :param message_text: Mensagem a ser enviada
+    :param subject: Assunto
+    :param user_to: Destinatário
+    :return: Não retorna nada, é um procedimento.
+    """
+    # Create a multipart message and set headers
+    message = MIMEMultipart()
+    message["From"] = user_from
+    message["To"] = user_to
+    message["Subject"] = subject
+
+    # Add body to email
+    message.attach(MIMEText(message_text, "plain"))
+
+    # Message to Text
+    text = message.as_string()
+
+    # Log in to server using secure context and send email
+    context = ssl.create_default_context()
+    with smtplib.SMTP_SSL(server, port, context=context) as server:
+        server.login(user_from, password)
+        server.sendmail(user_from, user_to, text)
+
+
+def error_message(message_text, os_params):
+    """
+    Utilize o seguinte exemplo para enviar uma mensagem de erro:
+    error_message('Tivemos problema ao enviar e-mail', OS_PARAMS)
+    """
+    send_email_function(
+        server=os_params['email_smtp'],
+        port=os_params['email_port'],
+        user_from=os_params['email_user'],
+        user_to=os_params['email_to_error'],
+        password=os_params['email_password'],
+        subject=messages.EMAIL_PROJECT_ERROR_SUBJECT.format(os_params['project_name']),
+        message_text=message_text,
     )
```

## pycortexintelligence/core/funcs_startproject.py

```diff
@@ -1,379 +1,376 @@
-import os
-from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER
-
-FOLDERS = [OUTPUT_FOLDER, DOWNLOADED_FOLDER]
-FILES = [
-    'README.md',
-    '.gitignore',
-    '.dockerignore',
-    '.env',
-    'requirements.txt',
-    'Dockerfile',
-    'main.py',
-]
-
-
-def write_main_py():
-    return """from pycortexintelligence.core.funcs_env import load_env_to_dict, verify_env, delete_temp_files, check_dirs
-from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER, LOG_FILE
-from pycortexintelligence.core import messages
-import logging
-
-# Cria arquivo de LOG
-logging.basicConfig(filename=LOG_FILE, encoding='utf-8', level=logging.DEBUG, format='%(asctime)s %(message)s')
-
-# Set specific variables to project
-custom_variables = ['variable_1', 'variable_2']
-
-# Script para pegar automaticamente as variavéis de ambiente.
-OS_PARAMS = load_env_to_dict(new_params_to_check=custom_variables)
-logging.info(messages.VARIABLES_CREATED)
-
-# Valida se o OS_PARAMS está correto para esse projeto.
-verify_env(OS_PARAMS, new_params_to_check=custom_variables)
-logging.info(messages.OS_PARAMS_CORRECT)
-
-# Checa os diretórios temporários
-check_dirs()
-logging.info(messages.TEMP_DIRS)
-
-# Deleta os arquivos temporários e de output.
-delete_temp_files(os_params=OS_PARAMS)
-logging.info(messages.TEMP_DIRS_EMPTY)
-
-# TODO Define a project!
-"""
-
-
-def write_dockerfile():
-    return """FROM python:3.9-alpine
-
-# Set arguments
-# Arguments of E-mail
-ENV email_password=""
-ENV email_port=""
-ENV email_smtp=""
-ENV email_user=""
-ENV email_to_error=""
-ENV project_name=""
-
-# Arguments of Cortex
-ENV plataform_url=""
-ENV plataform_username=""
-ENV plataform_password=""
-ENV plataform_cube_id=""
-
-# Arguments of Project
-ENV variable_1=""
-ENV variable_2=""
-
-# Set environment variables
-ENV PYTHONUNBUFFERED 1
-ENV PYTHONDONTWRITEBYTECODE 1
-
-## install dependencies
-RUN set -xe \\
-    && apk add --no-cache curl \\
-    && apk --no-cache add curl gcc g++ libressl-dev libffi-dev make \\
-    && curl -sSL https://bootstrap.pypa.io/get-pip.py | python \\
-    && pip install wheel
-
-# Directory Structure
-RUN mkdir -p /code
-
-# Set work directory.
-WORKDIR /code
-
-# Copy project code.
-COPY . /code/
-
-# Install dependencies.
-RUN pip install -r requirements.txt
-
-CMD python main.py
-"""
-
-
-def write_env(project_name):
-    return """email_password=""
-email_port=""
-email_smtp=""
-email_user=""
-email_to_error=""
-project_name="{}"
-plataform_url=""
-plataform_username=""
-plataform_password=""
-plataform_cube_id=""
-variable_1=""
-variable_2=""
-""".format(project_name)
-
-
-def write_dockerignore():
-    return """### Padrão Cortex ###
-# Arquivos Temporárops e de Output
-downloaded_files/*
-output/*
-historico.log
-"""
-
-
-def write_gitignore():
-    return """# Created by https://www.toptal.com/developers/gitignore/api/python
-# Edit at https://www.toptal.com/developers/gitignore?templates=python
-
-### Padrão Cortex ###
-# Arquivos Temporárops e de Output
-downloaded_files/*
-output/*
-.env
-
-### Python ###
-# Byte-compiled / optimized / DLL files
-__pycache__/
-*.py[cod]
-*$py.class
-
-# C extensions
-*.so
-
-# Distribution / packaging
-.Python
-build/
-develop-eggs/
-dist/
-downloads/
-eggs/
-.eggs/
-lib/
-lib64/
-parts/
-sdist/
-var/
-wheels/
-pip-wheel-metadata/
-share/python-wheels/
-*.egg-info/
-.installed.cfg
-*.egg
-MANIFEST
-
-# PyInstaller
-#  Usually these files are written by a python script from a template
-#  before PyInstaller builds the exe, so as to inject date/other infos into it.
-*.manifest
-*.spec
-
-# Installer logs
-pip-log.txt
-pip-delete-this-directory.txt
-
-# Unit test / coverage reports
-htmlcov/
-.tox/
-.nox/
-.coverage
-.coverage.*
-.cache
-nosetests.xml
-coverage.xml
-*.cover
-*.py,cover
-.hypothesis/
-.pytest_cache/
-pytestdebug.log
-
-# Translations
-*.mo
-*.pot
-
-# Django stuff:
-*.log
-local_settings.py
-db.sqlite3
-db.sqlite3-journal
-
-# Flask stuff:
-instance/
-.webassets-cache
-
-# Scrapy stuff:
-.scrapy
-
-# Sphinx documentation
-docs/_build/
-doc/_build/
-
-# PyBuilder
-target/
-
-# Jupyter Notebook
-.ipynb_checkpoints
-
-# IPython
-profile_default/
-ipython_config.py
-
-# pyenv
-.python-version
-
-# pipenv
-#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
-#   However, in case of collaboration, if having platform-specific dependencies or dependencies
-#   having no cross-platform support, pipenv may install dependencies that don't work, or not
-#   install all needed dependencies.
-#Pipfile.lock
-
-# PEP 582; used by e.g. github.com/David-OConnor/pyflow
-__pypackages__/
-
-# Celery stuff
-celerybeat-schedule
-celerybeat.pid
-
-# SageMath parsed files
-*.sage.py
-
-# Environments
-#.env
-#.venv
-#env/
-#venv/
-#ENV/
-#env.bak/
-#venv.bak/
-#pythonenv*
-
-# Spyder project settings
-.spyderproject
-.spyproject
-
-# Rope project settings
-.ropeproject
-
-# mkdocs documentation
-/site
-
-# mypy
-.mypy_cache/
-.dmypy.json
-dmypy.json
-
-# Pyre type checker
-.pyre/
-
-# pytype static type analyzer
-.pytype/
-
-# profiling data
-.prof
-
-# End of https://www.toptal.com/developers/gitignore/api/python
-"""
-
-
-def write_readme_md(project_name, safe_name):
-    return """# {}
-
-**URL DO CONNECTOR:** `INSERIR URL DA TASK DENTRO DO ECS` 
-
-**CUBO:** -
-
-**FORM:** -
-
-**PERIODICIDADE:** -
-
-**CLIENTE:** -
-
-**DATA CONNECTION:** `INSERIR URL DO CLUSTER DO ECS`
-
-**DATA SOURCE:** `INSERIR URL DO ECR (Repositório GIT)`
-
-**CARGA:** `CARGA REALIZADA VIA SID (PyCortexIntelligence)`
-
-**CAMPOS ASSOCIADOS:**
-
-`-` > `-`
-
-**Descrição da Integração:**
-
-- 
-
-**Atenção**: 
- 
-- 
-
-## How to test?
-
-Create virtualenv and active it.
-
-```shell
-python -m venv {}
-source {}/bin/activate
-```
-
-With the venv activated, you need install the requirements and run the project.
-```
-({}) pip install -r requirements.txt
-({}) python main.py
-
-```
-
-## How to Build?
-
-Build the container
-```
-docker build -t {} .
-```
-
-Run the container
-```
-docker run --rm {}
-```
-""".format(
-        project_name,
-        safe_name,
-        safe_name,
-        safe_name,
-        safe_name,
-        safe_name,
-        safe_name,
-    )
-
-
-def check_create_dirs():
-    for folder in FOLDERS:
-        try:
-            os.stat(folder)
-        except FileNotFoundError:
-            os.mkdir(folder)
-
-
-def creck_create_files(project_name, safe_name):
-    for file in FILES:
-        with open(file, mode='w', encoding='utf-8') as f:
-            if file == 'README.md':
-                file_to_write = write_readme_md(project_name, safe_name)
-                print('Writing README.md file...')
-            elif file == '.gitignore':
-                file_to_write = write_gitignore()
-                print('Writing .gitignore file...')
-            elif file == '.dockerignore':
-                file_to_write = write_dockerignore()
-                print('Writing .dockerignore file...')
-            elif file == '.env':
-                file_to_write = write_env(project_name)
-                print('Writing .env file...')
-            elif file == 'requirements.txt':
-                file_to_write = ""
-                print('Writing requirements.txt file...')
-            elif file == 'Dockerfile':
-                file_to_write = write_dockerfile()
-                print('Writing Dockerfile file...')
-            elif file == 'main.py':
-                file_to_write = write_main_py()
-                print('Writing main.py file...')
-            else:
-                print('Unknown file.')
-            f.writelines(file_to_write)
+import os
+from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER
+
+FOLDERS = [OUTPUT_FOLDER, DOWNLOADED_FOLDER]
+FILES = [
+    'README.md',
+    '.gitignore',
+    '.dockerignore',
+    '.env',
+    'requirements.txt',
+    'Dockerfile',
+    'main.py',
+]
+
+
+def write_main_py():
+    return """from pycortexintelligence.core.funcs_env import load_env_to_dict, verify_env, delete_temp_files, check_dirs
+from pycortexintelligence.core.config import OUTPUT_FOLDER, DOWNLOADED_FOLDER, LOG_FILE
+from pycortexintelligence.core import messages
+
+# Set specific variables to project
+custom_variables = ['variable_1', 'variable_2']
+print(messages.CUSTOM_VARIABLES_SET)
+
+# Script para pegar automaticamente as variavéis de ambiente.
+OS_PARAMS = load_env_to_dict(new_params_to_check=custom_variables)
+print(messages.VARIABLES_CREATED)
+
+# Valida se o OS_PARAMS está correto para esse projeto.
+verify_env(OS_PARAMS, new_params_to_check=custom_variables)
+print(messages.OS_PARAMS_CORRECT)
+
+# Checa os diretórios temporários
+check_dirs()
+print(messages.TEMP_DIRS)
+
+# Deleta os arquivos temporários e de output.
+delete_temp_files(os_params=OS_PARAMS)
+print(messages.TEMP_DIRS_EMPTY)
+
+# TODO Define a project!
+"""
+
+
+def write_dockerfile():
+    return """FROM python:3.9-alpine
+
+# Set arguments
+# Arguments of E-mail
+ENV email_password=""
+ENV email_port=""
+ENV email_smtp=""
+ENV email_user=""
+ENV email_to_error=""
+ENV project_name=""
+
+# Arguments of Cortex
+ENV plataform_url=""
+ENV plataform_username=""
+ENV plataform_password=""
+ENV plataform_cube_id=""
+
+# Arguments of Project
+ENV variable_1=""
+ENV variable_2=""
+
+# Set environment variables
+ENV PYTHONUNBUFFERED 1
+ENV PYTHONDONTWRITEBYTECODE 1
+
+## install dependencies
+RUN set -xe \\
+    && apk add --no-cache curl \\
+    && apk --no-cache add curl gcc g++ libressl-dev libffi-dev make \\
+    && curl -sSL https://bootstrap.pypa.io/get-pip.py | python \\
+    && pip install wheel
+
+# Directory Structure
+RUN mkdir -p /code
+
+# Set work directory.
+WORKDIR /code
+
+# Copy project code.
+COPY . /code/
+
+# Install dependencies.
+RUN pip install -r requirements.txt
+
+CMD python main.py
+"""
+
+
+def write_env(project_name):
+    return """email_password=""
+email_port=""
+email_smtp=""
+email_user=""
+email_to_error=""
+project_name="{}"
+plataform_url=""
+plataform_username=""
+plataform_password=""
+plataform_cube_id=""
+variable_1=""
+variable_2=""
+""".format(project_name)
+
+
+def write_dockerignore():
+    return """### Padrão Cortex ###
+# Arquivos Temporárops e de Output
+downloaded_files/*
+output/*
+historico.log
+"""
+
+
+def write_gitignore():
+    return """# Created by https://www.toptal.com/developers/gitignore/api/python
+# Edit at https://www.toptal.com/developers/gitignore?templates=python
+
+### Padrão Cortex ###
+# Arquivos Temporárops e de Output
+downloaded_files/*
+output/*
+.env
+
+### Python ###
+# Byte-compiled / optimized / DLL files
+__pycache__/
+*.py[cod]
+*$py.class
+
+# C extensions
+*.so
+
+# Distribution / packaging
+.Python
+build/
+develop-eggs/
+dist/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+pip-wheel-metadata/
+share/python-wheels/
+*.egg-info/
+.installed.cfg
+*.egg
+MANIFEST
+
+# PyInstaller
+#  Usually these files are written by a python script from a template
+#  before PyInstaller builds the exe, so as to inject date/other infos into it.
+*.manifest
+*.spec
+
+# Installer logs
+pip-log.txt
+pip-delete-this-directory.txt
+
+# Unit test / coverage reports
+htmlcov/
+.tox/
+.nox/
+.coverage
+.coverage.*
+.cache
+nosetests.xml
+coverage.xml
+*.cover
+*.py,cover
+.hypothesis/
+.pytest_cache/
+pytestdebug.log
+
+# Translations
+*.mo
+*.pot
+
+# Django stuff:
+*.log
+local_settings.py
+db.sqlite3
+db.sqlite3-journal
+
+# Flask stuff:
+instance/
+.webassets-cache
+
+# Scrapy stuff:
+.scrapy
+
+# Sphinx documentation
+docs/_build/
+doc/_build/
+
+# PyBuilder
+target/
+
+# Jupyter Notebook
+.ipynb_checkpoints
+
+# IPython
+profile_default/
+ipython_config.py
+
+# pyenv
+.python-version
+
+# pipenv
+#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
+#   However, in case of collaboration, if having platform-specific dependencies or dependencies
+#   having no cross-platform support, pipenv may install dependencies that don't work, or not
+#   install all needed dependencies.
+#Pipfile.lock
+
+# PEP 582; used by e.g. github.com/David-OConnor/pyflow
+__pypackages__/
+
+# Celery stuff
+celerybeat-schedule
+celerybeat.pid
+
+# SageMath parsed files
+*.sage.py
+
+# Environments
+#.env
+#.venv
+#env/
+#venv/
+#ENV/
+#env.bak/
+#venv.bak/
+#pythonenv*
+
+# Spyder project settings
+.spyderproject
+.spyproject
+
+# Rope project settings
+.ropeproject
+
+# mkdocs documentation
+/site
+
+# mypy
+.mypy_cache/
+.dmypy.json
+dmypy.json
+
+# Pyre type checker
+.pyre/
+
+# pytype static type analyzer
+.pytype/
+
+# profiling data
+.prof
+
+# End of https://www.toptal.com/developers/gitignore/api/python
+"""
+
+
+def write_readme_md(project_name, safe_name):
+    return """# {}
+
+**URL DO CONNECTOR:** `INSERIR URL DA TASK DENTRO DO ECS` 
+
+**CUBO:** -
+
+**FORM:** -
+
+**PERIODICIDADE:** -
+
+**CLIENTE:** -
+
+**DATA CONNECTION:** `INSERIR URL DO CLUSTER DO ECS`
+
+**DATA SOURCE:** `INSERIR URL DO ECR (Repositório GIT)`
+
+**CARGA:** `CARGA REALIZADA VIA SID (PyCortexIntelligence)`
+
+**CAMPOS ASSOCIADOS:**
+
+`-` > `-`
+
+**Descrição da Integração:**
+
+- 
+
+**Atenção**: 
+ 
+- 
+
+## How to test?
+
+Create virtualenv and active it.
+
+```shell
+python -m venv {}
+source {}/bin/activate
+```
+
+With the venv activated, you need install the requirements and run the project.
+```
+({}) pip install -r requirements.txt
+({}) python main.py
+
+```
+
+## How to Build?
+
+Build the container
+```
+docker build -t {} .
+```
+
+Run the container
+```
+docker run --rm {}
+```
+""".format(
+        project_name,
+        safe_name,
+        safe_name,
+        safe_name,
+        safe_name,
+        safe_name,
+        safe_name,
+    )
+
+
+def check_create_dirs():
+    for folder in FOLDERS:
+        try:
+            os.stat(folder)
+        except FileNotFoundError:
+            os.mkdir(folder)
+
+
+def creck_create_files(project_name, safe_name):
+    for file in FILES:
+        with open(file, mode='w', encoding='utf-8') as f:
+            if file == 'README.md':
+                file_to_write = write_readme_md(project_name, safe_name)
+                print('Writing README.md file...')
+            elif file == '.gitignore':
+                file_to_write = write_gitignore()
+                print('Writing .gitignore file...')
+            elif file == '.dockerignore':
+                file_to_write = write_dockerignore()
+                print('Writing .dockerignore file...')
+            elif file == '.env':
+                file_to_write = write_env(project_name)
+                print('Writing .env file...')
+            elif file == 'requirements.txt':
+                file_to_write = ""
+                print('Writing requirements.txt file...')
+            elif file == 'Dockerfile':
+                file_to_write = write_dockerfile()
+                print('Writing Dockerfile file...')
+            elif file == 'main.py':
+                file_to_write = write_main_py()
+                print('Writing main.py file...')
+            else:
+                print('Unknown file.')
+            f.writelines(file_to_write)
```

## pycortexintelligence/core/messages.py

```diff
@@ -1,11 +1,14 @@
-VARIABLES_CREATED = 'VÁRIAVÉIS DE AMBIENTE RECUPERADAS COM SUCESSO!'
-OS_PARAMS_CORRECT = 'TUDO INDICA QUE O OS_PARAMS ESTÁ CORRETO PARA O PROJETO!'
-TEMP_DIRS = 'DIRETÓRIOS TEMPORÁRIOS CONFIGURADOS COM SUCESSO!'
-TEMP_DIRS_EMPTY = 'DIRETÓRIOS TEMPORÁRIOS RESETADOS COM SUCESSO!'
-EMAIL_PROJECT_ERROR_SUBJECT = 'Projeto: {} | Erro Encontrado'
-DOWNLOAD_ERROR_JUST_ID_OR_NAME = 'Enter only the name OR the id of the object to download!'
-ERROR_ARGUMENTS_VALIDATION = 'Error validating arguments.'
-
-
-def mail_variable_error(key):
-    return "Tivemos um erro ao verificar as varíaveis de ambiente. \n A variável {} não foi encontrada.".format(key)
+VARIABLES_CREATED = "VARIÁVEIS DE AMBIENTE RECUPERADAS COM SUCESSO!"
+OS_PARAMS_CORRECT = "TUDO INDICA QUE O OS_PARAMS ESTÁ CORRETO PARA O PROJETO!"
+TEMP_DIRS = "DIRETÓRIOS TEMPORÁRIOS CONFIGURADOS COM SUCESSO!"
+TEMP_DIRS_EMPTY = "DIRETÓRIOS TEMPORÁRIOS RESETADOS COM SUCESSO!"
+EMAIL_PROJECT_ERROR_SUBJECT = "PROJETO : {} | ERRO ENCONTRADO"
+DOWNLOAD_ERROR_JUST_ID_OR_NAME = "INSIRA APENAS O ID OU O NOME DO CUBO PARA DOWNLOAD"
+ERROR_ARGUMENTS_VALIDATION = "TIVEMOS UM ERRO AO VALIDAR OS ARGUMENTOS"
+INVALID_FILES_ERROR = "É NECESSÁRIO PASSAR UM ARQUIVO OU PONTEIRO DE ARQUIVO VÁLIDO"
+CUSTOM_VARIABLES_SET = "VARIÁVEIS DE AMBIENTE ESPECÍFICAS ENVIADAS!"
+FORMAT_TIMEOUT = "NECESSÁRIO QUE O VALOR DE TIMEOUT SEJA NÚMERICO"
+
+
+def mail_variable_error(key):
+    return "Tivemos um erro ao verificar as varíaveis de ambiente. \n A variável {} não foi encontrada.".format(key)
```

## Comparing `pycortexintelligence-0.0.9.data/scripts/cortex.py` & `pycortexintelligence-1.0.0.data/scripts/cortex.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,49 +1,49 @@
-#!/usr/bin/env python
-
-import os
-import pkg_resources
-import click
-from pycortexintelligence.core import funcs_startproject
-
-
-VERSION = pkg_resources.require("pycortexintelligence")[0].version
-
-
-@click.group()
-@click.version_option(version=VERSION, prog_name='pycortex')
-def pycortex():
-    pass
-
-
-@click.command()
-@click.option('--name', help='Start a project with this name! Like a "Project Name"')
-@click.option('--sname', help='Define a Safe Name to project like a "project_name"')
-def startproject(name, sname):
-    """
-    This script create a Cortex Default Integration Template
-    """
-    # Validate args
-    # Getting project Name
-    if name is None:
-        print('Example: Project Name')
-        name = click.prompt('Give a Project Name.', type=str)
-    if sname is None:
-        print('Example: project_name')
-        sname = click.prompt('Give a Project Safe Name.', type=str)
-        if ' ' in sname:
-            raise ValueError('Safe name, cannot have spaces!')
-
-    # Call the functions
-    print('Initializing tool...')
-    path_real = os.path.dirname(os.path.realpath(__file__))
-    path_fake = path_real.replace('/bin', "")
-    funcs_startproject.check_create_dirs()
-    funcs_startproject.creck_create_files(project_name=name, safe_name=sname)
-    print('> Files are created on "{}"'.format(path_fake))
-    print('Creating a Default Project Template for {}'.format(name))
-
-
-pycortex.add_command(startproject)
-
-if __name__ == '__main__':
+#!python
+
+import os
+import pkg_resources
+import click
+from pycortexintelligence.core import funcs_startproject
+
+
+VERSION = pkg_resources.require("pycortexintelligence")[0].version
+
+
+@click.group()
+@click.version_option(version=VERSION, prog_name='pycortex')
+def pycortex():
+    pass
+
+
+@click.command()
+@click.option('--name', help='Start a project with this name! Like a "Project Name"')
+@click.option('--sname', help='Define a Safe Name to project like a "project_name"')
+def startproject(name, sname):
+    """
+    This script create a Cortex Default Integration Template
+    """
+    # Validate args
+    # Getting project Name
+    if name is None:
+        print('Example: Project Name')
+        name = click.prompt('Give a Project Name.', type=str)
+    if sname is None:
+        print('Example: project_name')
+        sname = click.prompt('Give a Project Safe Name.', type=str)
+        if ' ' in sname:
+            raise ValueError('Safe name, cannot have spaces!')
+
+    # Call the functions
+    print('Initializing tool...')
+    path_real = os.path.dirname(os.path.realpath(__file__))
+    path_fake = path_real.replace('/bin', "")
+    funcs_startproject.check_create_dirs()
+    funcs_startproject.creck_create_files(project_name=name, safe_name=sname)
+    print('> Files are created on "{}"'.format(path_fake))
+    print('Creating a Default Project Template for {}'.format(name))
+
+
+pycortex.add_command(startproject)
+
+if __name__ == '__main__':
     pycortex()
```

## Comparing `pycortexintelligence-0.0.9.dist-info/LICENSE` & `pycortexintelligence-1.0.0.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Enderson Menezes
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Enderson Menezes
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

## Comparing `pycortexintelligence-0.0.9.dist-info/RECORD` & `pycortexintelligence-1.0.0.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 pycortexintelligence/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pycortexintelligence/functions.py,sha256=E-BB1tCNQBszj08ZIib-4xP9R143PVZmxeGORGhuDoQ,9232
+pycortexintelligence/functions.py,sha256=vhKzc3tTGGFxqiIkpTVSYd6-lyprWdE9ueb4hqeIjvw,12320
 pycortexintelligence/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pycortexintelligence/core/config.py,sha256=YbfKVpXOLC5JzJ6oqtZxLyDRPPOYt5VzRl3QP9eGXyI,508
-pycortexintelligence/core/funcs_env.py,sha256=o4kFT33ghawejrI-NY6Dm2KdWRNiR6s79Z-7DUlAYBY,2341
-pycortexintelligence/core/funcs_mail.py,sha256=9UxekQKI8CUASynJnXz58yNkDsfjE2uV4GE7TTwuFGo,1871
-pycortexintelligence/core/funcs_startproject.py,sha256=Y8Q3KGTXFUXhmqJhMug-wmGTvEdWQaO-Hj___3mrsKc,7709
-pycortexintelligence/core/messages.py,sha256=AaiMY8AzrnvpcdVfymnrEwOEmrx9WdW3lCKSwXL9ZCQ,660
-pycortexintelligence-0.0.9.data/scripts/cortex.py,sha256=CUxSYqgoJb02SnuJT3njTSIB8-7hgcKOIyQ39s7Qmjg,1522
-pycortexintelligence-0.0.9.dist-info/LICENSE,sha256=tjKZqL6NtOoD1Vqri6Uzv6V3UZaA-W8yPAtoIBP7bHE,1094
-pycortexintelligence-0.0.9.dist-info/METADATA,sha256=QRmnEo9K62cdDx4nwTIPe-YKXqiyuMB_xZpmPSpHN3g,2534
-pycortexintelligence-0.0.9.dist-info/WHEEL,sha256=S6zePDbUAjzMmpYOg2cHDxuYFWw7WiOXt6ogM6hIB5Q,92
-pycortexintelligence-0.0.9.dist-info/top_level.txt,sha256=7yAXb7mVR9f1GBrXUCSQ7rhgv71IVQrjI7X6dYrLCIM,21
-pycortexintelligence-0.0.9.dist-info/RECORD,,
+pycortexintelligence/core/config.py,sha256=CAKTpp_r7dP5cIHzltZmqQZzwzqo9U__xzHjdHtdAXs,487
+pycortexintelligence/core/funcs_env.py,sha256=I5r3kiYC9wwVWiz25NTqf2rJsqeB0_ROc__7gzm8iZ0,2211
+pycortexintelligence/core/funcs_mail.py,sha256=FFz_uxNe-etPXPB2QhmH8s18i6z3i2CXyPc-b40q2u4,1818
+pycortexintelligence/core/funcs_startproject.py,sha256=wU_RUQj8rp-2fwKcdttuFqD95-kWWErOa8GYJf9fGyo,7189
+pycortexintelligence/core/messages.py,sha256=v05j48pcjtSSdXUttSzJ3X4y-ZfASnanGtuJSqgeHoY,884
+pycortexintelligence-1.0.0.data/scripts/cortex.py,sha256=4JnCrwLKqLTdoqBiPJHRyQtq6V3iRO9M1UeCWQKqi7k,1461
+pycortexintelligence-1.0.0.dist-info/LICENSE,sha256=2bFR2oxY5CiDtRqM6078TnDiRti_ZBECF7zvqZWcRWM,1073
+pycortexintelligence-1.0.0.dist-info/METADATA,sha256=FS6NE1kXxTeK1sXR8LtTVUxUntYHLKhNo148KVoyIVQ,5122
+pycortexintelligence-1.0.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+pycortexintelligence-1.0.0.dist-info/top_level.txt,sha256=7yAXb7mVR9f1GBrXUCSQ7rhgv71IVQrjI7X6dYrLCIM,21
+pycortexintelligence-1.0.0.dist-info/RECORD,,
```

