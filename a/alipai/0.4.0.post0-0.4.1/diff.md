# Comparing `tmp/alipai-0.4.0.post0-py2.py3-none-any.whl.zip` & `tmp/alipai-0.4.1-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,83 +1,84 @@
-Zip file size: 243560 bytes, number of entries: 81
--rw-r--r--  2.0 unx       12 b- defN 23-May-18 09:03 pai/VERSION
+Zip file size: 252149 bytes, number of entries: 82
+-rw-r--r--  2.0 unx        6 b- defN 23-Jun-30 07:11 pai/VERSION
 -rw-r--r--  2.0 unx      290 b- defN 23-May-18 09:03 pai/__init__.py
--rw-r--r--  2.0 unx    37762 b- defN 23-May-18 12:05 pai/estimator.py
--rw-r--r--  2.0 unx      489 b- defN 23-May-18 09:03 pai/exception.py
--rw-r--r--  2.0 unx    12163 b- defN 23-May-18 09:03 pai/image.py
--rw-r--r--  2.0 unx    36719 b- defN 23-May-18 12:05 pai/model.py
--rw-r--r--  2.0 unx    24633 b- defN 23-May-18 09:03 pai/predictor.py
--rw-r--r--  2.0 unx    20082 b- defN 23-May-18 09:03 pai/serializers.py
--rw-r--r--  2.0 unx    14519 b- defN 23-May-18 12:05 pai/session.py
+-rw-r--r--  2.0 unx    40574 b- defN 23-Jun-30 06:33 pai/estimator.py
+-rw-r--r--  2.0 unx      489 b- defN 23-May-24 02:33 pai/exception.py
+-rw-r--r--  2.0 unx    12163 b- defN 23-Jun-20 07:36 pai/image.py
+-rw-r--r--  2.0 unx    40522 b- defN 23-Jun-16 09:21 pai/model.py
+-rw-r--r--  2.0 unx    46831 b- defN 23-Jun-16 09:21 pai/predictor.py
+-rw-r--r--  2.0 unx    20082 b- defN 23-May-19 07:10 pai/serializers.py
+-rw-r--r--  2.0 unx    14538 b- defN 23-Jun-27 08:28 pai/session.py
 -rw-r--r--  2.0 unx       39 b- defN 22-Oct-31 10:14 pai/api/__init__.py
--rw-r--r--  2.0 unx     4249 b- defN 23-May-18 09:03 pai/api/algorithm.py
--rw-r--r--  2.0 unx     7935 b- defN 23-May-18 09:03 pai/api/api_container.py
--rw-r--r--  2.0 unx     5439 b- defN 23-May-18 09:03 pai/api/base.py
--rw-r--r--  2.0 unx     4016 b- defN 23-May-18 09:03 pai/api/client_factory.py
--rw-r--r--  2.0 unx     2945 b- defN 23-May-18 09:03 pai/api/code_source.py
--rw-r--r--  2.0 unx     3755 b- defN 23-May-18 09:03 pai/api/dataset.py
--rw-r--r--  2.0 unx     1726 b- defN 23-May-18 09:03 pai/api/entity_base.py
--rw-r--r--  2.0 unx     2498 b- defN 23-May-18 09:03 pai/api/image.py
--rw-r--r--  2.0 unx     5232 b- defN 23-May-18 09:03 pai/api/job.py
--rw-r--r--  2.0 unx     6090 b- defN 23-May-18 09:03 pai/api/model.py
--rw-r--r--  2.0 unx     3426 b- defN 23-May-18 09:03 pai/api/pipeline.py
--rw-r--r--  2.0 unx     5314 b- defN 23-May-18 09:03 pai/api/pipeline_run.py
--rw-r--r--  2.0 unx     5421 b- defN 23-May-18 12:05 pai/api/service.py
--rw-r--r--  2.0 unx     5410 b- defN 23-May-18 09:03 pai/api/training_job.py
--rw-r--r--  2.0 unx     8340 b- defN 23-May-18 09:03 pai/api/workspace.py
+-rw-r--r--  2.0 unx     4249 b- defN 23-May-19 07:10 pai/api/algorithm.py
+-rw-r--r--  2.0 unx     7935 b- defN 23-Jun-30 03:18 pai/api/api_container.py
+-rw-r--r--  2.0 unx     5439 b- defN 23-Jun-29 05:41 pai/api/base.py
+-rw-r--r--  2.0 unx     4010 b- defN 23-Jun-15 12:22 pai/api/client_factory.py
+-rw-r--r--  2.0 unx     2945 b- defN 23-May-19 07:10 pai/api/code_source.py
+-rw-r--r--  2.0 unx     3755 b- defN 23-May-19 07:10 pai/api/dataset.py
+-rw-r--r--  2.0 unx     1726 b- defN 23-May-19 07:10 pai/api/entity_base.py
+-rw-r--r--  2.0 unx     2665 b- defN 23-May-31 10:09 pai/api/image.py
+-rw-r--r--  2.0 unx     5232 b- defN 23-May-19 07:10 pai/api/job.py
+-rw-r--r--  2.0 unx     6090 b- defN 23-May-19 07:10 pai/api/model.py
+-rw-r--r--  2.0 unx     3426 b- defN 23-May-19 07:10 pai/api/pipeline.py
+-rw-r--r--  2.0 unx     5314 b- defN 23-May-19 07:10 pai/api/pipeline_run.py
+-rw-r--r--  2.0 unx     5421 b- defN 23-Jun-30 03:18 pai/api/service.py
+-rw-r--r--  2.0 unx     5410 b- defN 23-May-19 07:10 pai/api/training_job.py
+-rw-r--r--  2.0 unx     8340 b- defN 23-May-19 07:10 pai/api/workspace.py
 -rw-r--r--  2.0 unx       67 b- defN 22-Oct-31 10:14 pai/common/__init__.py
--rw-r--r--  2.0 unx     1495 b- defN 23-May-18 09:03 pai/common/consts.py
--rw-r--r--  2.0 unx     4889 b- defN 23-May-18 09:03 pai/common/docker_utils.py
--rw-r--r--  2.0 unx    14998 b- defN 23-May-18 12:04 pai/common/oss_utils.py
--rw-r--r--  2.0 unx     2797 b- defN 23-May-18 09:03 pai/common/utils.py
+-rw-r--r--  2.0 unx     1565 b- defN 23-May-31 10:09 pai/common/consts.py
+-rw-r--r--  2.0 unx     6438 b- defN 23-May-31 10:09 pai/common/docker_utils.py
+-rw-r--r--  2.0 unx    12168 b- defN 23-Jun-15 12:27 pai/common/git_utils.py
+-rw-r--r--  2.0 unx    14998 b- defN 23-May-19 10:13 pai/common/oss_utils.py
+-rw-r--r--  2.0 unx     3406 b- defN 23-Jun-05 08:54 pai/common/utils.py
 -rw-r--r--  2.0 unx      710 b- defN 23-May-18 09:03 pai/common/yaml_utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-18 12:05 pai/huggingface/__init__.py
--rw-r--r--  2.0 unx     8338 b- defN 23-May-18 12:05 pai/huggingface/estimator.py
--rw-r--r--  2.0 unx    10724 b- defN 23-May-18 12:05 pai/huggingface/model.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-19 10:13 pai/huggingface/__init__.py
+-rw-r--r--  2.0 unx    10037 b- defN 23-Jun-15 12:27 pai/huggingface/estimator.py
+-rw-r--r--  2.0 unx    12791 b- defN 23-Jun-15 12:27 pai/huggingface/model.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Mar-29 11:52 pai/libs/__init__.py
--rw-r--r--  2.0 unx       21 b- defN 23-Mar-29 10:57 pai/libs/alibabacloud_aiworkspace20210204/__init__.py
--rw-r--r--  2.0 unx   241194 b- defN 23-May-18 09:03 pai/libs/alibabacloud_aiworkspace20210204/client.py
--rw-r--r--  2.0 unx   357327 b- defN 23-May-18 09:03 pai/libs/alibabacloud_aiworkspace20210204/models.py
--rw-r--r--  2.0 unx       21 b- defN 23-May-18 09:03 pai/libs/alibabacloud_eas20210701/__init__.py
--rw-r--r--  2.0 unx   188668 b- defN 23-May-18 12:05 pai/libs/alibabacloud_eas20210701/client.py
--rw-r--r--  2.0 unx   251200 b- defN 23-May-18 12:05 pai/libs/alibabacloud_eas20210701/models.py
+-rw-r--r--  2.0 unx       22 b- defN 23-May-31 10:09 pai/libs/alibabacloud_aiworkspace20210204/__init__.py
+-rw-r--r--  2.0 unx   278209 b- defN 23-May-31 10:09 pai/libs/alibabacloud_aiworkspace20210204/client.py
+-rw-r--r--  2.0 unx   400899 b- defN 23-May-31 10:09 pai/libs/alibabacloud_aiworkspace20210204/models.py
+-rw-r--r--  2.0 unx       21 b- defN 23-May-25 08:27 pai/libs/alibabacloud_eas20210701/__init__.py
+-rw-r--r--  2.0 unx   188668 b- defN 23-May-25 08:27 pai/libs/alibabacloud_eas20210701/client.py
+-rw-r--r--  2.0 unx   251200 b- defN 23-May-25 08:27 pai/libs/alibabacloud_eas20210701/models.py
 -rw-r--r--  2.0 unx       21 b- defN 23-May-18 09:03 pai/libs/alibabacloud_pai_dlc20201203/__init__.py
--rw-r--r--  2.0 unx    73033 b- defN 23-May-18 09:03 pai/libs/alibabacloud_pai_dlc20201203/client.py
+-rw-r--r--  2.0 unx    73033 b- defN 23-May-25 02:46 pai/libs/alibabacloud_pai_dlc20201203/client.py
 -rw-r--r--  2.0 unx   176083 b- defN 23-May-18 09:03 pai/libs/alibabacloud_pai_dlc20201203/models.py
 -rw-r--r--  2.0 unx       21 b- defN 23-Mar-29 11:52 pai/libs/alibabacloud_paiflow20210202/__init__.py
 -rw-r--r--  2.0 unx    76356 b- defN 23-May-18 09:03 pai/libs/alibabacloud_paiflow20210202/client.py
 -rw-r--r--  2.0 unx   116997 b- defN 23-May-18 09:03 pai/libs/alibabacloud_paiflow20210202/models.py
--rw-r--r--  2.0 unx       22 b- defN 23-May-18 09:03 pai/libs/alibabacloud_paistudio20220112/__init__.py
--rw-r--r--  2.0 unx   151599 b- defN 23-May-18 09:03 pai/libs/alibabacloud_paistudio20220112/client.py
--rw-r--r--  2.0 unx   262318 b- defN 23-May-18 09:03 pai/libs/alibabacloud_paistudio20220112/models.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-18 12:05 pai/modelscope/__init__.py
--rw-r--r--  2.0 unx     8285 b- defN 23-May-18 12:05 pai/modelscope/estimator.py
--rw-r--r--  2.0 unx    10660 b- defN 23-May-18 12:05 pai/modelscope/model.py
--rw-r--r--  2.0 unx      503 b- defN 23-May-18 09:03 pai/pipeline/__init__.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Jun-20 06:21 pai/libs/alibabacloud_paistudio20220112/__init__.py
+-rw-r--r--  2.0 unx   107153 b- defN 23-Jun-29 05:53 pai/libs/alibabacloud_paistudio20220112/client.py
+-rw-r--r--  2.0 unx   236081 b- defN 23-Jun-30 03:18 pai/libs/alibabacloud_paistudio20220112/models.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-19 10:13 pai/modelscope/__init__.py
+-rw-r--r--  2.0 unx     9985 b- defN 23-Jun-15 12:27 pai/modelscope/estimator.py
+-rw-r--r--  2.0 unx    12704 b- defN 23-Jun-15 12:27 pai/modelscope/model.py
+-rw-r--r--  2.0 unx      503 b- defN 23-May-19 07:10 pai/pipeline/__init__.py
 -rw-r--r--  2.0 unx     2463 b- defN 23-May-18 09:03 pai/pipeline/artifact.py
 -rw-r--r--  2.0 unx       81 b- defN 22-Oct-31 10:14 pai/pipeline/consts.py
 -rw-r--r--  2.0 unx    13115 b- defN 23-May-18 09:03 pai/pipeline/core.py
--rw-r--r--  2.0 unx    15710 b- defN 23-May-18 09:03 pai/pipeline/run.py
+-rw-r--r--  2.0 unx    15710 b- defN 23-May-19 07:10 pai/pipeline/run.py
 -rw-r--r--  2.0 unx    12848 b- defN 23-May-18 09:03 pai/pipeline/step.py
--rw-r--r--  2.0 unx      128 b- defN 23-May-18 09:03 pai/pipeline/component/__init__.py
+-rw-r--r--  2.0 unx      128 b- defN 23-May-19 07:10 pai/pipeline/component/__init__.py
 -rw-r--r--  2.0 unx     9801 b- defN 23-May-18 09:03 pai/pipeline/component/_base.py
 -rw-r--r--  2.0 unx     2681 b- defN 23-May-18 09:03 pai/pipeline/component/_container.py
--rw-r--r--  2.0 unx     8522 b- defN 23-May-18 09:03 pai/pipeline/component/_registered.py
+-rw-r--r--  2.0 unx     8522 b- defN 23-May-22 11:02 pai/pipeline/component/_registered.py
 -rw-r--r--  2.0 unx      667 b- defN 23-May-18 09:03 pai/pipeline/types/__init__.py
--rw-r--r--  2.0 unx    25584 b- defN 23-May-18 09:03 pai/pipeline/types/artifact.py
+-rw-r--r--  2.0 unx    25584 b- defN 23-May-19 07:10 pai/pipeline/types/artifact.py
 -rw-r--r--  2.0 unx     9725 b- defN 23-May-18 09:03 pai/pipeline/types/parameter.py
 -rw-r--r--  2.0 unx     6055 b- defN 23-May-18 09:03 pai/pipeline/types/spec.py
 -rw-r--r--  2.0 unx     4249 b- defN 23-May-18 09:03 pai/pipeline/types/variable.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-18 09:03 pai/schema/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-19 07:10 pai/schema/__init__.py
 -rw-r--r--  2.0 unx     2871 b- defN 23-May-18 09:03 pai/schema/base.py
 -rw-r--r--  2.0 unx     2857 b- defN 23-May-18 09:03 pai/schema/training_job_schema.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-18 09:03 pai/toolkit/__init__.py
--rw-r--r--  2.0 unx    16185 b- defN 23-May-18 09:03 pai/toolkit/config.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-18 09:03 pai/toolkit/helper/__init__.py
--rw-r--r--  2.0 unx     2559 b- defN 23-May-18 09:03 pai/toolkit/helper/consts.py
--rw-r--r--  2.0 unx    10835 b- defN 23-May-18 09:03 pai/toolkit/helper/utils.py
--rw-r--r--  2.0 unx    11358 b- defN 23-May-18 12:07 alipai-0.4.0.post0.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx     1225 b- defN 23-May-18 12:07 alipai-0.4.0.post0.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 23-May-18 12:07 alipai-0.4.0.post0.dist-info/WHEEL
--rw-r--r--  2.0 unx        4 b- defN 23-May-18 12:07 alipai-0.4.0.post0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6829 b- defN 23-May-18 12:07 alipai-0.4.0.post0.dist-info/RECORD
-81 files, 2343313 bytes uncompressed, 232826 bytes compressed:  90.1%
+-rw-r--r--  2.0 unx        0 b- defN 23-May-19 07:10 pai/toolkit/__init__.py
+-rw-r--r--  2.0 unx    16185 b- defN 23-May-19 07:10 pai/toolkit/config.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-19 07:10 pai/toolkit/helper/__init__.py
+-rw-r--r--  2.0 unx     2559 b- defN 23-May-19 07:10 pai/toolkit/helper/consts.py
+-rw-r--r--  2.0 unx    10835 b- defN 23-May-19 07:10 pai/toolkit/helper/utils.py
+-rw-r--r--  2.0 unx    11358 b- defN 23-Jun-30 07:12 alipai-0.4.1.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     1250 b- defN 23-Jun-30 07:12 alipai-0.4.1.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 23-Jun-30 07:12 alipai-0.4.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 23-Jun-30 07:12 alipai-0.4.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6880 b- defN 23-Jun-30 07:12 alipai-0.4.1.dist-info/RECORD
+82 files, 2404187 bytes uncompressed, 241353 bytes compressed:  90.0%
```

## zipnote {}

```diff
@@ -78,14 +78,17 @@
 
 Filename: pai/common/consts.py
 Comment: 
 
 Filename: pai/common/docker_utils.py
 Comment: 
 
+Filename: pai/common/git_utils.py
+Comment: 
+
 Filename: pai/common/oss_utils.py
 Comment: 
 
 Filename: pai/common/utils.py
 Comment: 
 
 Filename: pai/common/yaml_utils.py
@@ -222,23 +225,23 @@
 
 Filename: pai/toolkit/helper/consts.py
 Comment: 
 
 Filename: pai/toolkit/helper/utils.py
 Comment: 
 
-Filename: alipai-0.4.0.post0.dist-info/LICENSE.txt
+Filename: alipai-0.4.1.dist-info/LICENSE.txt
 Comment: 
 
-Filename: alipai-0.4.0.post0.dist-info/METADATA
+Filename: alipai-0.4.1.dist-info/METADATA
 Comment: 
 
-Filename: alipai-0.4.0.post0.dist-info/WHEEL
+Filename: alipai-0.4.1.dist-info/WHEEL
 Comment: 
 
-Filename: alipai-0.4.0.post0.dist-info/top_level.txt
+Filename: alipai-0.4.1.dist-info/top_level.txt
 Comment: 
 
-Filename: alipai-0.4.0.post0.dist-info/RECORD
+Filename: alipai-0.4.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pai/VERSION

```diff
@@ -1 +1 @@
-0.4.0.post0
+0.4.1
```

## pai/estimator.py

```diff
@@ -12,35 +12,30 @@
 from concurrent.futures import ThreadPoolExecutor
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Union
 
 import six
 
 from .api.entity_base import EntityBaseMixin
-from .common import ProviderAlibabaPAI
-from .common.consts import JobType
+from .common import ProviderAlibabaPAI, git_utils
+from .common.consts import INSTANCE_TYPE_LOCAL_GPU, JobType
 from .common.docker_utils import run_container
 from .common.oss_utils import OssUriObj, download, is_oss_uri, upload
-from .common.utils import random_str, to_plain_text
+from .common.utils import is_local_run_instance_type, random_str, to_plain_text
 from .model import InferenceSpec, Model, ResourceConfig
 from .predictor import Predictor
 from .schema.training_job_schema import TrainingJobSchema
 from .serializers import SerializerBase
 from .session import Session, config_default_session, get_default_session
 
 logger = logging.getLogger(__name__)
 
 DEFAULT_OUTPUT_MODEL_CHANNEL_NAME = "model"
 DEFAULT_CHECKPOINT_CHANNEL_NAME = "checkpoints"
 
-TRAINING_UTILS_PKG = (
-    "https://pai-sdk.oss-cn-shanghai.aliyuncs.com/training_utils/dist"
-    "/training_utils-1.0.6-py3-none-any.whl"
-)
-
 _TRAINING_JOB_URL_PATTERN = (
     "https://pai.console.aliyun.com/?regionId={region_id}"
     "&workspaceId={workspace_id}#/training/jobs/{job_id}/configs"
 )
 
 
 class Estimator(object):
@@ -75,14 +70,15 @@
     """
 
     def __init__(
         self,
         image_uri: str,
         command: str,
         source_dir: Optional[str] = None,
+        git_config: Optional[Dict[str, str]] = None,
         job_type: str = JobType.PyTorchJob,
         hyperparameters: Optional[Dict[str, Any]] = None,
         base_job_name: Optional[str] = None,
         max_run_time: Optional[int] = None,
         checkpoints_path: Optional[str] = None,
         output_path: Optional[str] = None,
         metric_definitions: Optional[List[Dict[str, str]]] = None,
@@ -100,16 +96,49 @@
             command (str): The command used to run the training job.
             source_dir (str, optional): The local source code directory used in the
                 training job. The directory will be packaged and uploaded to an OSS
                 bucket, then downloaded to the `/ml/usercode` directory in the training
                 job container. If there is a `requirements.txt` file in the source code
                 directory, the corresponding dependencies will be installed before the
                 training script runs.
+
+                If 'git_config' is provided, 'source_dir' should be a relative location
+                to a directory in the Git repo. With the following GitHub repo directory
+                structure:
+
+                .. code::
+
+                    |----- README.md
+                    |----- src
+                             |----- train.py
+                             |----- test.py
+
+                if you need 'src' directory as the source code directory, you can assign
+                source_dir='./src/'.
+            git_config (Dict[str, str]): Git configuration used to clone the repo.
+                Including ``repo``, ``branch``, ``commit``, ``username``, ``password``
+                and ``token``. The ``repo`` is required. All other fields are optional.
+                ``repo`` specifies the Git repository. If you don't provide ``branch``,
+                the default value 'master' is used. If you don't provide ``commit``, the
+                latest commit in the specified branch is used. ``username``, ``password``
+                and ``token`` are for authentication purpose.
+                For example, the following config:
+
+                .. code:: python
+
+                    git_config = {
+                        'repo': 'https://github.com/modelscope/modelscope.git',
+                        'branch': 'master',
+                        'commit': '9bfc4a9d83c4beaf8378d0a186261ffc1cd9f960'
+                    }
+
+                results in cloning the git repo specified in 'repo', then checking out
+                the 'master' branch, and checking out the specified commit.
             job_type (str): The type of job, which can be TFJob, PyTorchJob, XGBoostJob,
-             etc.
+                etc.
             hyperparameters (dict, optional): A dictionary that represents the
                 hyperparameters used in the training job. The hyperparameters will be
                 stored in the `/ml/input/config/hyperparameters.json` as a JSON
                 dictionary in the training container.
             instance_type (str): The machine instance type used to run the training job.
                 To view the supported machine instance types, please refer to the
                 document:
@@ -182,14 +211,15 @@
                         },
                     ]
 
         """
         self.image_uri = image_uri
         self.command = command
         self.source_dir = source_dir
+        self.git_config = git_config
         self.hyperparameters = hyperparameters or dict()
         self.instance_type = instance_type
         self.instance_count = instance_count
         self.job_type = job_type if job_type else JobType.PyTorchJob
         self.max_run_time = max_run_time
         self.base_job_name = base_job_name
         self.output_path = output_path
@@ -200,35 +230,37 @@
 
         self.__uploaded_source_files = None
 
         self._check_instance_type()
 
     def _prepare_for_training(self):
         """Update args before starting the training job."""
-        # TODO: used for git config
+        if self.git_config:
+            updated_args = git_utils.git_clone_repo(
+                git_config=self.git_config,
+                source_dir=self.source_dir,
+            )
+            self.source_dir = updated_args["source_dir"]
 
     def _gen_job_display_name(self, job_name=None):
         """Generate job display name."""
         if job_name:
             return job_name
         ts = datetime.now().strftime("%Y%m%d_%H%M%S")
         return "{}_{}".format(self.base_job_name or "training_job", ts)
 
     def _check(self):
         if not self.image_uri:
             raise ValueError("Please provide image_uri to create the job.")
-        if not self.entry_point:
-            raise ValueError("Please provide entry_point to create the job.")
 
     def _check_instance_type(self):
         """Check if the given instance_type is supported for training job."""
-        if (
-            self.instance_type != "local"
-            and not self.session.is_supported_training_instance(self.instance_type)
-        ):
+        if not is_local_run_instance_type(
+            self.instance_type
+        ) and not self.session.is_supported_training_instance(self.instance_type):
             raise ValueError(
                 f"Instance type {self.instance_type} not supproted. "
                 "Please provide a supported instance type to create the job."
             )
 
     def _upload_source_files(self, job_name: str) -> Optional[str]:
         """Upload local source files to OSS."""
@@ -299,21 +331,21 @@
         job_base_output_path = self._generate_job_base_output_path(job_name)
 
         # OSS URI for output channel will be mounted to directory
         # "/ml/output/{ChannelName}/" and the output OSS URI should be a "directory"
         def as_oss_dir_uri(uri: str):
             return uri if uri.endswith("/") else uri + "/"
 
-        model_path = os.path.join(
+        model_path = posixpath.join(
             job_base_output_path,
             DEFAULT_OUTPUT_MODEL_CHANNEL_NAME,
         )
         # Use checkpoints_path from user or construct a checkpoint path using
         # default output path.
-        checkpoints_path = self.checkpoints_path or os.path.join(
+        checkpoints_path = self.checkpoints_path or posixpath.join(
             job_base_output_path,
             DEFAULT_CHECKPOINT_CHANNEL_NAME,
         )
         res = [
             {
                 "Name": DEFAULT_OUTPUT_MODEL_CHANNEL_NAME,
                 "OutputUri": as_oss_dir_uri(model_path),
@@ -381,16 +413,18 @@
                 `/ml/input/data/{channel_name}` directory in the training container.
             wait (bool): Specifies whether to block until the training job is completed,
                 either succeeded, failed, or stopped. (Default True).
         """
         inputs = inputs or dict()
         self._prepare_for_training()
         job_name = self._gen_job_display_name()
-        if self.instance_type == "local":
-            training_job = self._local_run(job_name=job_name, inputs=inputs)
+        if is_local_run_instance_type(self.instance_type):
+            training_job = self._local_run(
+                job_name=job_name, inputs=inputs, instance_type=self.instance_type
+            )
         else:
             training_job = self._fit(inputs=inputs, job_name=job_name)
         self._latest_training_job = training_job
 
         if wait:
             self._latest_training_job.wait_for_completion()
 
@@ -427,18 +461,27 @@
         return training_job
 
     def _patch_default_oss_endpoint(self, uri: str):
         """Patch default OSS endpoint for Input/Output OSS data uri for TrainingJob."""
         return self.session.patch_oss_endpoint(uri)
 
     def _local_run(
-        self, job_name, inputs: Dict[str, Any] = None
+        self,
+        job_name,
+        instance_type: str,
+        inputs: Dict[str, Any] = None,
     ) -> "_LocalTrainingJob":
+        if self.instance_count > 1:
+            raise RuntimeError("Local training job only supports single instance.")
+
         training_job = _LocalTrainingJob(
-            estimator=self, inputs=inputs, job_name=job_name
+            estimator=self,
+            inputs=inputs,
+            job_name=job_name,
+            instance_type=instance_type,
         )
         training_job.run()
         return training_job
 
     def model_data(self) -> str:
         """Model data output path.
 
@@ -549,14 +592,16 @@
         return p
 
 
 _TRAINING_LAUNCH_SCRIPT_TEMPLATE = textwrap.dedent(
     """\
 #!/bin/sh
 
+env
+
 # change to working directory
 if [ -n "$PAI_WORKING_DIR" ]; then
     echo "Change to Working Directory", $PAI_WORKING_DIR
     mkdir -p $PAI_WORKING_DIR && cd $PAI_WORKING_DIR
 fi
 
 # install requirements
@@ -595,35 +640,37 @@
 class _LocalTrainingJob(object):
     """A class that represents a local training job running with docker container."""
 
     def __init__(
         self,
         estimator: Estimator,
         inputs: Dict[str, Any],
+        instance_type: str = None,
         temp_dir: str = None,
         job_name: str = None,
     ):
         self.estimator = estimator
         self.inputs = inputs
         self.tmp_dir = temp_dir or tempfile.mkdtemp()
         self.job_name = job_name
+        self.instance_type = instance_type
         logger.info("Local TrainingJob temporary directory: {}".format(self.tmp_dir))
         self._container_run = None
 
     @property
     def session(self) -> Session:
         return self.estimator.session
 
     def prepare_env(self) -> Dict[str, str]:
         """Prepare environment variables for the training job."""
 
         # Hyperparameters environment variables
         def _normalize_name(name: str) -> str:
             # replace all non-alphanumeric characters with underscore
-            return _ENV_NOT_ALLOWED_CHARS.sub("_", name)
+            return _ENV_NOT_ALLOWED_CHARS.sub("_", name).upper()
 
         env = {}
         user_args = []
         for name, value in self.estimator.hyperparameters.items():
             env[_TrainingEnv.ENV_PAI_HPS_PREFIX + _normalize_name(name)] = str(value)
             user_args.extend(["--" + name, shlex.quote(str(value))])
         env[_TrainingEnv.ENV_PAI_USER_ARGS] = shlex.join(user_args)
@@ -707,23 +754,27 @@
 
         # 4. Config output model channel
         volumes[output_model_path] = {
             "bind": posixpath.join(_TrainingJobConfig.OUTPUT_DIR, "model"),
             "mode": "rw",
         }
 
+        gpu_count = (
+            -1 if self.instance_type.strip() == INSTANCE_TYPE_LOCAL_GPU else None
+        )
         self._container_run = run_container(
             environment_variables=self.prepare_env(),
             image_uri=self.estimator.image_uri,
             entry_point=[
                 "/bin/sh",
                 posixpath.join(_TrainingJobConfig.INPUT_CONFIG_DIR, "launch.sh"),
             ],
             volumes=volumes,
             working_dir=_TrainingJobConfig.WORKING_DIR,
+            gpu_count=gpu_count,
         )
 
     def prepare_input_config(self, input_config_path):
         """Prepare input config for TrainingJob, such as hyperparameters.json,
         trainingjob.json."""
         with open(os.path.join(input_config_path, "hyperparameters.json"), "w") as f:
             hps = self.estimator.hyperparameters or dict()
@@ -915,20 +966,31 @@
         finally:
             job_logger.stop()
             future.result()
 
         self._on_job_completed()
 
     def _on_job_completed(self):
+        # print an empty line to separate the training job logs and the following logs
+        print()
         if self.status == TrainingJobStatus.Succeed:
+            print(
+                f"Training job ({self.training_job_id}) succeeded, you can check the"
+                f" logs/metrics/output in  the console:\n{self.console_uri}"
+            )
             return
         elif self.status in TrainingJobStatus.failed_status():
+            print(
+                f"Training job ({self.training_job_id}) failed, please check the logs"
+                f" in the console: \n{self.console_uri}"
+            )
             raise RuntimeError(
-                f"TrainingJob failed: training_job_id={self.training_job_id} "
-                f"reason_code={self.reason_code} status={self.status} "
+                f"TrainingJob failed: name={self.training_job_name}, "
+                f"training_job_id={self.training_job_id}, "
+                f"reason_code={self.reason_code}, status={self.status}, "
                 f"reason_message={self.reason_message}",
             )
 
     def _reload(self):
         """Reload the training job from the PAI Service,"""
         self.session.training_job_api.refresh_entity(self.training_job_id, self)
```

## pai/model.py

```diff
@@ -10,20 +10,21 @@
 import textwrap
 import time
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import requests
 from addict import Dict as AttrDict
 
-from .common.consts import ModelFormat
+from .common import git_utils
+from .common.consts import INSTANCE_TYPE_LOCAL_GPU, ModelFormat
 from .common.docker_utils import ContainerRun, run_container
 from .common.oss_utils import OssUriObj, download, is_oss_uri, upload
-from .common.utils import random_str, to_plain_text
+from .common.utils import is_local_run_instance_type, random_str, to_plain_text
 from .image import ImageInfo
-from .predictor import LocalPredictor, Predictor
+from .predictor import AsyncPredictor, LocalPredictor, Predictor, ServiceType
 from .serializers import SerializerBase
 from .session import Session, config_default_session
 
 DEFAULT_SERVICE_PORT = 8000
 
 
 logger = logging.getLogger(__name__)
@@ -69,16 +70,16 @@
         self.cpu = cpu
         self.memory = memory
         self.gpu = gpu
         self.gpu_memory = gpu_memory
 
     def __repr__(self):
         return (
-            f"<ResourceConfig:cpu={self.cpu} memory={self.memory}MB gpu={self.gpu or 0}"
-            f" gpu_memory={self.gpu_memory or 0}GB>"
+            f"ResourceConfig(cpu={self.cpu}, memory={self.memory}MB, gpu={self.gpu or 0},"
+            f" gpu_memory={self.gpu_memory or 0}GB)"
         )
 
     def __str__(self):
         return self.__repr__()
 
     def to_dict(self):
         """Transform the ResourceConfig instance to a dictionary.
@@ -335,14 +336,15 @@
 
 
 @config_default_session
 def container_serving_spec(
     command: str,
     image_uri: Union[str, ImageInfo],
     source_dir: Optional[str] = None,
+    git_config: Optional[Dict[str, Any]] = None,
     port: int = DEFAULT_SERVICE_PORT,
     environment_variables: Optional[Dict[str, str]] = None,
     requirements: Optional[List[str]] = None,
     requirements_path: Optional[str] = None,
     health_check: Optional[Dict[str, Any]] = None,
     session: Optional[Session] = None,
 ) -> InferenceSpec:
@@ -369,16 +371,47 @@
     Args:
         command (str): The command used to launch the Model server.
         source_dir (str): A relative path or an absolute path to the source code
             directory used to load model and launch the HTTP server, it will be
             uploaded to the OSS bucket and mounted to the container. If there is a
             ``requirements.txt`` file under the directory, it will be installed before
             the prediction server started.
-        image_uri (Union[str, ImageInfo]): The Docker image used to run the prediction
-            service.
+
+            If 'git_config' is provided, 'source_dir' should be a relative location
+            to a directory in the Git repo. With the following GitHub repo directory
+            structure:
+
+            .. code::
+
+                |----- README.md
+                |----- src
+                            |----- train.py
+                            |----- test.py
+
+            if you need 'src' directory as the source code directory, you can assign
+            source_dir='./src/'.
+        git_config (Dict[str, str]): Git configuration used to clone the repo.
+            Including ``repo``, ``branch``, ``commit``, ``username``, ``password`` and
+            ``token``. The ``repo`` is required. All other fields are optional. ``repo``
+            specifies the Git repository. If you don't provide ``branch``, the default
+            value 'master' is used. If you don't provide ``commit``, the latest commit
+            in the specified branch is used. ``username``, ``password`` and ``token``
+            are for authentication purpose. For example, the following config:
+
+            .. code:: python
+
+                git_config = {
+                    'repo': 'https://github.com/modelscope/modelscope.git',
+                    'branch': 'master',
+                    'commit': '9bfc4a9d83c4beaf8378d0a186261ffc1cd9f960'
+                }
+
+            results in cloning the repo specified in 'repo', then checking out the
+            'master' branch, and checking out the specified commit.
+        image_uri (str): The Docker image used to run the prediction service.
         port (int): Expose port of the server in container, the prediction request
             will be forward to the port. The environment variable ``LISTENING_PORT``
             in the container will be set to this value.
         environment_variables (Dict[str, str], optional): Dictionary of environment
             variable key-value pairs to set on the running container.
         requirements (List[str], optional): A list of Python package dependency, it
             will be installed before the serving container run.
@@ -389,14 +422,21 @@
             HTTP server.
         session (Session, optional): A PAI session instance used for communicating
             with PAI service.
 
     Returns:
         :class:`pai.model.InferenceSpec`: An InferenceSpec instance.
     """
+    if git_config:
+        updated_args = git_utils.git_clone_repo(
+            git_config=git_config,
+            source_dir=source_dir,
+        )
+        source_dir = updated_args["source_dir"]
+
     if port and int(port) in _ModelServiceConfig.NOT_ALLOWED_PORTS:
         raise ValueError(
             "Port {} is reserved by PAI, it is not allowed to configure"
             " as serving port: port={}".format(
                 ", ".join([str(p) for p in _ModelServiceConfig.NOT_ALLOWED_PORTS]), port
             )
         )
@@ -549,14 +589,16 @@
         if not model_data and "model_data" in inference_spec:
             model_data = inference_spec.model_data
         self.model_data = model_data
         self.inference_spec = inference_spec
         self.session = session
 
     def _download_model_data(self, target_dir):
+        if not self.model_data:
+            return
         logger.info(f"Prepare model data to local directory: {target_dir}")
         if self.model_data.startswith("oss://"):
             oss_uri = OssUriObj(self.model_data)
             oss_bucket = self.session.get_oss_bucket(oss_uri.bucket_name)
             download(
                 oss_path=oss_uri.object_key,
                 local_path=target_dir,
@@ -597,36 +639,39 @@
         return upload_model_data
 
     def _get_inference_spec(self):
         return self.inference_spec
 
     def deploy(
         self,
-        service_name: Optional[str] = None,
+        service_name: str,
         instance_count: Optional[int] = 1,
         instance_type: Optional[str] = None,
         resource_config: Optional[Union[Dict[str, int], ResourceConfig]] = None,
         resource_id: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
+        service_type: Optional[str] = None,
         wait: bool = True,
         serializer: Optional["SerializerBase"] = None,
         **kwargs,
     ):
         """Deploy a prediction service with the model."""
-        if instance_type == "local":
+        if is_local_run_instance_type(instance_type):
             return self._deploy_local(
+                instance_type=instance_type,
                 serializer=serializer,
                 wait=wait,
             )
         else:
             return self._deploy(
                 service_name=service_name,
                 instance_count=instance_count,
                 instance_type=instance_type,
                 resource_config=resource_config,
+                service_type=service_type,
                 resource_id=resource_id,
                 options=options,
                 wait=wait,
                 serializer=serializer,
             )
 
     def _generate_service_name(self):
@@ -636,14 +681,15 @@
     def _deploy(
         self,
         service_name: str = None,
         instance_count: int = 1,
         instance_type: str = None,
         resource_config: Union[Dict[str, int], ResourceConfig] = None,
         resource_id: str = None,
+        service_type: str = None,
         options: Dict[str, Any] = None,
         wait: bool = True,
         serializer: "SerializerBase" = None,
     ):
         """Create a prediction service."""
         if not service_name:
             service_name = self._generate_service_name()
@@ -654,44 +700,67 @@
 
         self.model_data = self._upload_model_data()
 
         config = self._build_service_config(
             service_name=service_name,
             instance_count=instance_count,
             instance_type=instance_type,
+            service_type=service_type,
             resource_config=resource_config,
             resource_id=resource_id,
             options=options,
         )
-
-        self._service_name = self.session.service_api.create(config=config)
-
-        predictor = Predictor(
-            service_name=service_name,
-            session=self.session,
-            serializer=serializer,
-        )
+        service_name = self.session.service_api.create(config=config)
+        self._wait_service_visible(service_name)
+        if service_type == ServiceType.Async:
+            predictor = AsyncPredictor(
+                service_name=service_name,
+                session=self.session,
+                serializer=serializer,
+            )
+        else:
+            predictor = Predictor(
+                service_name=service_name,
+                session=self.session,
+                serializer=serializer,
+            )
         print(
             "View the service detail by accessing the console URI: \n{}".format(
                 predictor.console_uri
             )
         )
         if wait:
             predictor.wait_for_ready()
             time.sleep(5)
 
         return predictor
 
+    def _wait_service_visible(self, service_name, attempts=3, interval=2):
+        """Wait for the service to be visible in DescribeService API.
+
+        hack:
+        https://aone.alibaba-inc.com/v2/project/1134421/bug#viewIdentifier=5dfb195e2e2b84f6b2f24718&openWorkitemIdentifier=50192431
+
+        """
+        while attempts > 0:
+            obj = self.session.service_api.get(service_name)
+            if "ServiceUid" in obj:
+                return
+            attempts -= 1
+            time.sleep(interval)
+        logger.warning("DescribeService API failed to get the Service object.")
+
     def _build_service_config(
         self,
         service_name: str = None,
         instance_count: int = None,
         instance_type: str = None,
         resource_config: Union[ResourceConfig, Dict[str, Any]] = None,
         resource_id: str = None,
+        service_type: str = None,
         options: Dict[str, Any] = None,
     ) -> Dict[str, Any]:
         """Build a service config dictionary used to create a PAI EAS service."""
 
         resource_config = (
             ResourceConfig(**resource_config)
             if resource_config and isinstance(resource_config, dict)
@@ -721,14 +790,19 @@
                 inference_spec.add_option("model_path", model_path_uri)
             else:
                 inference_spec.mount(
                     self.model_data,
                     mount_path=_ModelServiceConfig.MODEL_PATH,
                 )
 
+        if service_type:
+            inference_spec.add_option("metadata.type", service_type)
+            if inference_spec.is_container_serving():
+                inference_spec.add_option("metadata.rpc.proxy_path", "/")
+
         if service_name:
             inference_spec.add_option("name", service_name)
 
         if instance_count:
             inference_spec.add_option("metadata.instance", instance_count)
 
         if instance_type:
@@ -754,14 +828,15 @@
         if options:
             inference_spec.merge_options(options=options)
 
         return inference_spec.to_dict()
 
     def _deploy_local(
         self,
+        instance_type: str,
         serializer: SerializerBase = None,
         wait: bool = True,
     ) -> LocalPredictor:
         """Deploy the model in local using docker."""
 
         if not self.inference_spec.is_container_serving():
             raise RuntimeError(
@@ -811,39 +886,51 @@
             item["name"]: item["value"] for item in container_spec.get("env", [])
         }
 
         # build local launch script
         requirements_list = container_spec.get("prepare", dict()).get(
             "pythonRequirements", []
         )
+        requirements_path = container_spec.get("prepare", dict()).get(
+            "pythonRequirementsPath", None
+        )
+
+        # build command to install requirements
         if requirements_list:
             install_requirements = shlex.join(
                 ["python", "-m", "pip", "install"] + requirements_list
             )
+        elif requirements_path:
+            install_requirements = shlex.join(
+                ["python", "-m", "pip", "install", "-r", requirements_path]
+            )
         else:
             install_requirements = ""
+
         user_scripts = container_spec.get("script", "")
         launch_script = textwrap.dedent(
             f"""\
             set -e
             {install_requirements}
             {user_scripts}
             """
         )
 
+        gpu_count = -1 if instance_type == INSTANCE_TYPE_LOCAL_GPU else None
         container_run = run_container(
             image_uri=container_spec["image"],
             port=container_spec.get("port"),
             environment_variables=env_vars,
             entry_point=[
                 "/bin/sh",
                 "-c",
                 launch_script,
             ],
             volumes=volumes,
+            gpu_count=gpu_count,
         )
         predictor = LocalPredictor(
             container_id=container_run.container.id,
             port=container_run.port,
             serializer=serializer,
         )
 
@@ -945,19 +1032,20 @@
             model_data,
             inference_spec,
             session=session,
         )
 
     def deploy(
         self,
-        service_name: Optional[str] = None,
+        service_name: str,
         instance_count: Optional[int] = 1,
         instance_type: Optional[str] = None,
         resource_config: Optional[Union[Dict[str, int], ResourceConfig]] = None,
         resource_id: Optional[str] = None,
+        service_type: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
         wait: bool = True,
         serializer: Optional["SerializerBase"] = None,
         **kwargs,
     ):
         """Deploy an online prediction service.
 
@@ -992,30 +1080,31 @@
                 ``dedicated resource group``.
 
                 * If `resource_id` is not specified, the service is deployed
                     to public resource group.
                 * If the service deployed in a dedicated resource group, provide
                     the parameter as the ID of the resource group. Example:
                     "eas-r-6dbzve8ip0xnzte5rp".
-
+            service_type (str, optional): The type of the service.
             options (Dict[str, Any], optional): Advanced deploy parameters used
                 to create the online prediction service.
             wait (bool): Whether the call should wait until the online prediction
                 service is ready (Default True).
             serializer (:class:`pai.predictor.serializers.BaseSerializer`, optional): A
                 serializer object used to serialize the prediction request and
                 deserialize the prediction response.
         Returns:
-            :class:`pai.predictor.Predictor` : A PAI ``Predictor`` instance used for
-                making prediction to the prediction service.
+            A ``PredictorBase`` instance used for making prediction to the prediction
+            service.
         """
         return super(Model, self).deploy(
             service_name=service_name,
             instance_count=instance_count,
             instance_type=instance_type,
             resource_config=resource_config,
             resource_id=resource_id,
             options=options,
             wait=wait,
             serializer=serializer,
+            service_type=service_type,
             **kwargs,
         )
```

## pai/predictor.py

```diff
@@ -1,22 +1,27 @@
+import asyncio
+import base64
+import functools
 import json
 import logging
 import posixpath
 import time
 from abc import ABC, abstractmethod
+from concurrent.futures import Future, ThreadPoolExecutor
 from io import IOBase
-from typing import Any, Dict, List, Optional, Tuple, Union
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+from urllib.parse import urlencode
 
+import aiohttp
 import docker
 import requests
 
-from . import __version__
 from .common.consts import FrameworkTypes
 from .common.docker_utils import ContainerRun
-from .common.utils import default_user_agent
+from .common.utils import http_user_agent
 from .exception import PredictionException
 from .serializers import (
     JsonSerializer,
     PyTorchSerializer,
     SerializerBase,
     TensorFlowSerializer,
 )
@@ -25,14 +30,18 @@
 logger = logging.getLogger(__name__)
 
 _PAI_SERVICE_CONSOLE_URI_PATTERN = (
     "https://pai.console.aliyun.com/?regionId={region_id}#"
     "/eas/serviceDetail/{service_name}/detail"
 )
 
+_QUEUE_SERVICE_REQUEST_ID_HEADER = "X-Eas-Queueservice-Request-Id"
+_QUEUE_SERVICE_SINK_PATH = "sink"
+_DEFAULT_ASYNC_WORKER_COUNT = 30
+
 
 class ServiceStatus(object):
     """All EAS inference service status."""
 
     Running = "Running"
     Waiting = "Waiting"
     Scaling = "Scaling"
@@ -55,22 +64,24 @@
     # Public Internet Endpoint
     INTERNET = "INTERNET"
 
     # VPC Endpoint
     INTRANET = "INTRANET"
 
 
-def _default_user_agent():
-    return f"PAI-Python-SDK/{__version__}"
+class ServiceType(object):
+
+    Standard = "Standard"
+    Async = "Async"
 
 
 class PredictorBase(ABC):
     @abstractmethod
-    def predict(self, data: Any) -> Any:
-        """Perform inference on the provided data and return a prediction."""
+    def predict(self, *args, **kwargs) -> Any:
+        """Perform inference on the provided data and return prediction result."""
 
     @abstractmethod
     def raw_predict(
         self,
         data: Any = None,
         path: Optional[str] = None,
         headers: Optional[Dict[str, str]] = None,
@@ -102,110 +113,64 @@
         Returns:
             Dict[str, Any]: The json-encoded content of a response.
 
         """
         return json.loads(self.content)
 
 
-class Predictor(PredictorBase):
-    """Predictor is responsible for making prediction to an online service.
-
-    The `predictor.predict` method sends the input data to the online prediction service
-    and returns the prediction result. The serializer object of the predictor is
-    responsible for data transformation when the `predict` method is invoked. The input
-    data is serialized using the `serializer.serialize` method before it is sent, and
-    the response is deserialized using the `serializer.deserialize` method before the
-    prediction result returns.
-
-    Examples::
-
-        # Initialize a predictor object from an existing service using PyTorch
-        # processor.
-        torch_predictor = Predictor(service_name="example_torch_service")
-        result = torch_predictor.predict(numpy.asarray([[22,33,44], [19,22,33]]))
-        assert isinstance(result, numpy.ndarray)
-
-    """
-
+class _ServicePredictorMixin(object):
     @config_default_session
     def __init__(
         self,
         service_name: str,
+        session: Optional[Session] = None,
         endpoint_type: str = EndpointType.INTERNET,
         serializer: Optional[SerializerBase] = None,
-        session: Optional[Session] = None,
     ):
-        """Construct a `Predictor` object using an existing prediction service.
-
-        Args:
-            service_name (str): Name of the existing prediction service.
-            endpoint_type (str): Selects the endpoint used by the predictor, which
-                should be one of `INTERNET` or `INTRANET`. The `INTERNET` endpoint type
-                means that the predictor calls the service over a public endpoint, while
-                the `INTRANET` endpoint type is over a VPC endpoint.
-            serializer (SerializerBase, optional): A serializer object that transforms
-                the input Python object for data transmission and deserialize the
-                response data to Python object.
-            session (Session, optional): A PAI session object used for communicating
-                with PAI service.
-        """
+        self.service_name = service_name
         self.session = session
-
-        self._service_name = service_name
-        self._endpoint_type = endpoint_type
         self._service_api_object = self.describe_service()
-        self._serializer = serializer or self._get_default_serializer()
-        self._check()
+        self.endpoint_type = endpoint_type
+        self.serializer = serializer or self._get_default_serializer()
 
-    @property
-    def service_name(self):
-        return self._service_name
+    def __repr__(self):
+        return "{}(service_name={}, endpoint_type={})".format(
+            type(self).__name__,
+            self.service_name,
+            self.endpoint_type,
+        )
 
-    @property
-    def endpoint_type(self):
-        return self._endpoint_type
+    def refresh(self):
+        self._service_api_object = self.describe_service()
 
     @property
-    def serializer(self):
-        return self._serializer
+    def endpoint(self):
+        if self.endpoint_type == EndpointType.INTRANET:
+            return self._service_api_object["IntranetEndpoint"]
+        else:
+            return self._service_api_object["InternetEndpoint"]
 
     @property
     def service_status(self):
         """Returns the status of the service."""
-        return self.describe_service()["Status"]
+        return self._service_api_object["Status"]
+
+    @property
+    def access_token(self):
+        """Access token of the service."""
+        return self._service_api_object["AccessToken"]
 
     @property
     def console_uri(self):
         """Returns the console URI of the service."""
         return _PAI_SERVICE_CONSOLE_URI_PATTERN.format(
             region_id=self.session.region_id,
             service_name=self.service_name,
         )
 
-    def _check(self):
-        """Check parameters for the predictor"""
-        if self._endpoint_type.upper() not in [
-            EndpointType.INTERNET,
-            EndpointType.INTRANET,
-        ]:
-            raise ValueError(
-                "Parameter 'endpoint_type' for the predictor should be one of"
-                " 'INTERNET' or 'INTRANET'."
-            )
-
-    def _post_init_serializer(self):
-        """Post-initialize the serializer by invoking serializer.inspect_from_service"""
-        if not hasattr(self._serializer, "__post_init_serializer_flag") and hasattr(
-            self._serializer, "inspect_from_service"
-        ):
-            self._serializer.inspect_from_service(
-                self.service_name, session=self.session
-            )
-            setattr(self._serializer, "__post_init_serializer_flag", 1)
-
     def _get_default_serializer(self):
         """Get default serializer for the predictor by inspecting the service config."""
         from pai.model import _BuiltinProcessor
 
         service_config = json.loads(self._service_api_object["ServiceConfig"])
         processor_code = service_config.get("processor")
 
@@ -223,123 +188,23 @@
             serializer = TensorFlowSerializer()
             return serializer
         elif processor_code.startswith(FrameworkTypes.PyTorch.lower()):
             return PyTorchSerializer()
         else:
             return JsonSerializer()
 
-    def predict(self, data):
-        """Make a prediction with the online prediction service.
-
-        The serializer object for the predictor is responsible for data transformation
-        when the 'predict' method is invoked. The input data is serialized using the
-        `serializer.serialize` method before it is sent, and the response is
-        deserialized using the `serializer.deserialize` method before the prediction
-        result returns.
-
-        Args:
-            data: The input data for the prediction. It will be serialized using the
-                serializer of the predictor before transmitted to the prediction
-                service.
-
-        Returns:
-            object: Prediction result.
-
-        Raises:
-            PredictionException: Raise if status code of the prediction response does
-                not equal 200.
-        """
-        self._post_init_serializer()
-
-        data = self._serializer.serialize(data)
-        res = self.raw_predict(
-            data=data,
-        )
-        return self._serializer.deserialize(res.content)
-
-    def _build_url(self, path: Optional[str] = None) -> str:
-        if self.endpoint_type.upper() == EndpointType.INTERNET:
-            url = self._service_api_object["InternetEndpoint"]
-        else:
-            url = self._service_api_object["IntranetEndpoint"]
-        if path:
-            if path.startswith("/"):
-                path = path[1:]
-            url = posixpath.join(url, path)
-        return url
-
-    def _build_headers(self, headers: Dict[str, str]) -> Dict[str, str]:
-        headers = headers or dict()
-        access_token = self._service_api_object["AccessToken"]
-        headers["Authorization"] = access_token
-        if "User-Agent" not in headers:
-            headers["User-Agent"] = default_user_agent()
-        return headers
-
-    def raw_predict(
-        self,
-        data: Any = None,
-        path: Optional[str] = None,
-        headers: Optional[Dict[str, str]] = None,
-        method: str = "POST",
-        timeout: Optional[Union[float, Tuple[float, float]]] = None,
-        **kwargs,
-    ) -> RawResponse:
-        """Make a prediction with the online prediction service.
-
-        Args:
-            data (Any): Input data to be sent to the prediction service. If it is a
-                file-like object, bytes, or string, it will be sent as the request body.
-                Otherwise, it will be treated as a JSON serializable object and sent as
-                JSON.
-            path (str, optional): Path for the request to be sent to. If it is provided,
-                it will be appended to the endpoint URL (Default None).
-            headers (dict, optional): Request headers.
-            method (str, optional): Request method, default to 'POST'.
-            timeout(float, tuple(float, float), optional): Timeout setting for the
-                request (Default 10).
-        Returns:
-            RawResponse: Prediction response from the service.
-
-        Raises:
-            PredictionException: Raise if status code of the prediction response does
-                not equal 2xx.
-        """
-        url = self._build_url(path)
-        headers = self._build_headers(headers)
-        if isinstance(data, (IOBase, bytes, str)):
-            # if data is a file-like object, bytes, or string, it will be sent as
-            # request body
-            json_data, data = None, data
-        else:
-            # otherwise, it will be treated as a JSON serializable object and sent as
-            # JSON.
-            json_data, data = data, None
-
-        if "stream" in kwargs:
-            kwargs.pop("stream")
-            logger.warning("Predictor.raw_predict does not support 'stream' parameter.")
-
-        resp = requests.request(
-            url=url,
-            json=json_data,
-            data=data,
-            headers=headers,
-            method=method,
-            timeout=timeout,
-            **kwargs,
-        )
-        resp = RawResponse(
-            status_code=resp.status_code,
-            content=resp.content,
-            headers=dict(resp.headers),
-        )
-        if resp.status_code // 100 != 2:
-            raise PredictionException(resp.status_code, resp.content)
-        return resp
+    def _post_init_serializer(self):
+        """Post-initialize the serializer by invoking serializer.inspect_from_service"""
+        if not hasattr(self.serializer, "__post_init_serializer_flag") and hasattr(
+            self.serializer, "inspect_from_service"
+        ):
+            self.serializer.inspect_from_service(
+                self.service_name, session=self.session
+            )
+            setattr(self.serializer, "__post_init_serializer_flag", 1)
 
     def inspect_model_signature_def(self):
         """Get SignatureDef of the serving model.
 
         .. note::
 
             Only the service using the TensorFlow processor supports getting the
@@ -380,14 +245,15 @@
             unexpected_status.remove(status)
             type(self)._wait_for_status(
                 service_name=self.service_name,
                 status=status,
                 unexpected_status=unexpected_status,
                 session=self.session,
             )
+        self.refresh()
 
     def stop_service(self, wait=True):
         """Stop the running service."""
         self.session.service_api.stop(name=self.service_name)
         if wait:
             status = ServiceStatus.Stopped
             unexpected_status = ServiceStatus.completed_status()
@@ -396,34 +262,35 @@
 
             type(self)._wait_for_status(
                 service_name=self.service_name,
                 status=status,
                 unexpected_status=unexpected_status,
                 session=self.session,
             )
+        self.refresh()
 
     def delete_service(self):
         """Delete the service."""
-        self.session.service_api.delete(name=self._service_name)
+        self.session.service_api.delete(name=self.service_name)
 
     def wait_for_ready(self):
         """Wait until the service enter running status."""
-
         logger.info(
             "Service waiting for ready: service_name={}".format(self.service_name)
         )
         unexpected_status = ServiceStatus.completed_status()
         unexpected_status.remove(ServiceStatus.Running)
 
         type(self)._wait_for_status(
             service_name=self.service_name,
             status=ServiceStatus.Running,
             unexpected_status=unexpected_status,
             session=self.session,
         )
+        self.refresh()
 
     @classmethod
     @config_default_session
     def _wait_for_status(
         cls,
         service_name: str,
         status: str,
@@ -495,28 +362,28 @@
     def deploy(
         cls,
         config: Dict[str, Any],
         session: Optional[Session] = None,
         endpoint_type: str = EndpointType.INTERNET,
         serializer: Optional[SerializerBase] = None,
         wait: bool = True,
-    ):
+    ) -> PredictorBase:
         """Deploy an online prediction service using given configuration.
 
         Args:
             config (Dict[str, Any]): A dictionary of service configuration.
             session (:class:`pai.session.Session`, optional): An optional
                 session object. If not provided, a default session will be used.
             serializer: An optional serializer object. If not provided, a
                 default serializer will be used.
             endpoint_type: The type of endpoint to use.
             wait: Whether to wait for the service to be ready before returning.
 
         Returns:
-            :class:`pai.predictor.Predictor`: A Predictor object for the deployed
+            :class:`pai.predictor.PredictorBase`: A Predictor object for the deployed
                 online prediction service.
 
         """
         name = session.service_api.create(config=config)
 
         if wait:
             # Wait until the service is ready
@@ -525,20 +392,758 @@
             Predictor._wait_for_status(
                 service_name=name,
                 status=ServiceStatus.Running,
                 unexpected_status=unexpected_status,
                 session=session,
             )
 
-        p = Predictor(
-            service_name=name,
+        service_api_obj = session.service_api.get(name)
+
+        if service_api_obj["ServiceType"] == ServiceType.Async:
+            p = AsyncPredictor(
+                service_name=name,
+                endpoint_type=endpoint_type,
+                serializer=serializer,
+            )
+        else:
+            p = Predictor(
+                service_name=name,
+                endpoint_type=endpoint_type,
+                serializer=serializer,
+            )
+
+        return p
+
+    def _build_url(
+        self, path: Optional[str] = None, params: Dict[str, str] = None
+    ) -> str:
+        url = self.endpoint
+        if path:
+            if path.startswith("/"):
+                path = path[1:]
+            url = posixpath.join(url, path)
+
+        # Add params to URL
+        url = url + "?" + urlencode(params) if params else url
+        return url
+
+    def _build_headers(self, headers: Dict[str, str] = None) -> Dict[str, str]:
+        headers = headers or dict()
+        headers["Authorization"] = self.access_token
+        headers["User-Agent"] = http_user_agent(headers.get("User-Agent"))
+        return headers
+
+    def _handle_input(self, data):
+        return self.serializer.serialize(data) if self.serializer else data
+
+    def _handle_output(self, content: bytes):
+        return self.serializer.deserialize(content) if self.serializer else content
+
+    def _handle_raw_input(self, data):
+        if isinstance(data, (IOBase, bytes, str)):
+            # if data is a file-like object, bytes, or string, it will be sent as
+            # request body
+            json_data, data = None, data
+        else:
+            # otherwise, it will be treated as a JSON serializable object and sent as
+            # JSON.
+            json_data, data = data, None
+
+        return json_data, data
+
+    def _handle_raw_output(self, status_code: int, headers: dict, content: bytes):
+        return RawResponse(status_code, headers, content)
+
+    def _send_request(
+        self,
+        data=None,
+        path=None,
+        method="POST",
+        json=None,
+        headers=None,
+        params=None,
+        **kwargs,
+    ):
+        url = self._build_url(path)
+        resp = requests.request(
+            url=url,
+            json=json,
+            data=data,
+            headers=self._build_headers(headers),
+            method=method,
+            params=params,
+            **kwargs,
+        )
+        return resp
+
+    async def _send_request_async(
+        self,
+        data=None,
+        path=None,
+        method="POST",
+        json=None,
+        headers=None,
+        params=None,
+        **kwargs,
+    ):
+        url = self._build_url(path=path, params=params)
+        headers = self._build_headers(headers)
+        async with aiohttp.ClientSession() as session:
+            return await session.request(
+                method=method,
+                url=url,
+                headers=headers,
+                data=data,
+                json=json,
+                **kwargs,
+            )
+
+
+class Predictor(PredictorBase, _ServicePredictorMixin):
+    """Predictor is responsible for making prediction to an online service.
+
+    The `predictor.predict` method sends the input data to the online prediction service
+    and returns the prediction result. The serializer object of the predictor is
+    responsible for data transformation when the `predict` method is invoked. The input
+    data is serialized using the `serializer.serialize` method before it is sent, and
+    the response is deserialized using the `serializer.deserialize` method before the
+    prediction result returns.
+
+    Examples::
+
+        # Initialize a predictor object from an existing service using PyTorch
+        # processor.
+        torch_predictor = Predictor(service_name="example_torch_service")
+        result = torch_predictor.predict(numpy.asarray([[22,33,44], [19,22,33]]))
+        assert isinstance(result, numpy.ndarray)
+
+    """
+
+    @config_default_session
+    def __init__(
+        self,
+        service_name: str,
+        endpoint_type: str = EndpointType.INTERNET,
+        serializer: Optional[SerializerBase] = None,
+        session: Optional[Session] = None,
+    ):
+        """Construct a `Predictor` object using an existing prediction service.
+
+        Args:
+            service_name (str): Name of the existing prediction service.
+            endpoint_type (str): Selects the endpoint used by the predictor, which
+                should be one of `INTERNET` or `INTRANET`. The `INTERNET` endpoint type
+                means that the predictor calls the service over a public endpoint, while
+                the `INTRANET` endpoint type is over a VPC endpoint.
+            serializer (SerializerBase, optional): A serializer object that transforms
+                the input Python object for data transmission and deserialize the
+                response data to Python object.
+            session (Session, optional): A PAI session object used for communicating
+                with PAI service.
+        """
+        super(Predictor, self).__init__(
+            service_name=service_name,
+            session=session,
             endpoint_type=endpoint_type,
             serializer=serializer,
         )
-        return p
+        self._check()
+
+    def _check(self):
+        config = json.loads(self._service_api_object["ServiceConfig"])
+        if config.get("metadata", {}).get("type") == ServiceType.Async:
+            logger.warning(
+                "Predictor is not recommended to make prediction to a async"
+                " prediction service."
+            )
+
+    def predict(self, data):
+        """Make a prediction with the online prediction service.
+
+        The serializer object for the predictor is responsible for data transformation
+        when the 'predict' method is invoked. The input data is serialized using the
+        `serializer.serialize` method before it is sent, and the response is
+        deserialized using the `serializer.deserialize` method before the prediction
+        result returns.
+
+        Args:
+            data: The input data for the prediction. It will be serialized using the
+                serializer of the predictor before transmitted to the prediction
+                service.
+
+        Returns:
+            object: Prediction result.
+
+        Raises:
+            PredictionException: Raise if status code of the prediction response does
+                not equal 2xx.
+        """
+        self._post_init_serializer()
+        data = self._handle_input(data)
+        resp = self._send_request(
+            data,
+        )
+        if resp.status_code // 100 != 2:
+            raise PredictionException(resp.status_code, resp.content)
+        return self._handle_output(
+            resp.content,
+        )
+
+    def raw_predict(
+        self,
+        data: Any = None,
+        path: Optional[str] = None,
+        headers: Optional[Dict[str, str]] = None,
+        method: str = "POST",
+        timeout: Optional[Union[float, Tuple[float, float]]] = None,
+        **kwargs,
+    ) -> RawResponse:
+        """Make a prediction with the online prediction service.
+
+        Args:
+            data (Any): Input data to be sent to the prediction service. If it is a
+                file-like object, bytes, or string, it will be sent as the request body.
+                Otherwise, it will be treated as a JSON serializable object and sent as
+                JSON.
+            path (str, optional): Path for the request to be sent to. If it is provided,
+                it will be appended to the endpoint URL (Default None).
+            headers (dict, optional): Request headers.
+            method (str, optional): Request method, default to 'POST'.
+            timeout(float, tuple(float, float), optional): Timeout setting for the
+                request (Default 10).
+            **kwargs: Additional keyword arguments for the request.
+        Returns:
+            RawResponse: Prediction response from the service.
+
+        Raises:
+            PredictionException: Raise if status code of the prediction response does
+                not equal 2xx.
+        """
+        json_data, data = self._handle_raw_input(data)
+        resp = self._send_request(
+            data=data,
+            json=json_data,
+            method=method,
+            path=path,
+            headers=headers,
+            timeout=timeout,
+            **kwargs,
+        )
+        if resp.status_code // 100 != 2:
+            raise PredictionException(resp.status_code, resp.content)
+
+        resp = RawResponse(
+            status_code=resp.status_code,
+            content=resp.content,
+            headers=dict(resp.headers),
+        )
+        return resp
+
+
+class WaitConfig(object):
+    """WaitConfig is used to set polling configurations for waiting for asynchronous
+    requests to complete."""
+
+    def __init__(self, max_attempts: int = 0, interval: int = 5):
+        if interval <= 0:
+            raise ValueError("interval must be positive integer.")
+        self.max_attempts = max_attempts
+        self.interval = interval
+
+
+class AsyncTask(object):
+    """AsyncTask is a wrapper class for `concurrent.futures.Future` object that represents
+    a prediction call submitted to an async prediction service.
+    """
+
+    def __init__(
+        self,
+        future: Future,
+    ):
+        self.future = future
+        super(AsyncTask, self).__init__()
+
+    def result(self, timeout: Optional[float] = None):
+        """
+        Returns the prediction result of the call.
+
+        Args:
+            timeout (float, optional): Timeout setting  (Default None).
+
+        Returns:
+            The result of the prediction call.
+
+        """
+        return self.future.result(timeout=timeout)
+
+    def done(self):
+        return self.future.done()
+
+    def exception(self, timeout: Optional[float] = None) -> Optional[Exception]:
+        return self.future.exception()
+
+    def running(self):
+        return self.future.running()
+
+    def cancel(self):
+        return self.future.cancel()
+
+    def cancelled(self):
+        return self.future.cancelled()
+
+
+class AsyncPredictor(PredictorBase, _ServicePredictorMixin):
+    """A class that facilitates making predictions to asynchronous prediction service.
+
+    Examples::
+
+        # Initialize an AsyncPredictor object using the name of a running service.
+        async_predictor = AsyncPredictor(service_name="example_service")
+
+        # Make a prediction with the service and get the prediction result.
+        resp = async_predictor.predict(data="YourPredictionData")
+        result = resp.wait()
+
+        # Make a prediction with async API.
+        import asyncio
+        result = asyncio.run(async_predictor.predict_async(data="YourPredictionData"))
+
+    """
+
+    @config_default_session
+    def __init__(
+        self,
+        service_name: str,
+        max_workers: Optional[int] = None,
+        endpoint_type: str = EndpointType.INTERNET,
+        serializer: Optional[SerializerBase] = None,
+        session: Optional[Session] = None,
+    ):
+        """Construct a `AsyncPredictor` object using an existing async prediction service.
+
+        Args:
+            service_name (str): Name of the existing prediction service.
+            max_workers (int): The maximum number of threads that can be used to
+                execute the given prediction calls.
+            endpoint_type (str): Selects the endpoint used by the predictor, which
+                should be one of `INTERNET` or `INTRANET`. The `INTERNET` endpoint type
+                means that the predictor calls the service over a public endpoint, while
+                the `INTRANET` endpoint type is over a VPC endpoint.
+            serializer (SerializerBase, optional): A serializer object that transforms
+                the input Python object for data transmission and deserialize the
+                response data to Python object.
+            session (Session, optional): A PAI session object used for communicating
+                with PAI service.
+        """
+
+        super(AsyncPredictor, self).__init__(
+            service_name=service_name,
+            session=session,
+            endpoint_type=endpoint_type,
+            serializer=serializer,
+        )
+        self._max_workers = max_workers
+        self.executor = ThreadPoolExecutor(max_workers=self._max_workers)
+        self._check()
+
+    @property
+    def max_workers(self):
+        return self._max_workers
+
+    @max_workers.setter
+    def max_workers(self, n: int):
+        if hasattr(self, "executor"):
+            logger.info("Waiting for all submitted tasks in the queue to complete...")
+            self.executor.shutdown()
+        self._max_workers = n
+        self.executor = ThreadPoolExecutor(max_workers=self._max_workers)
+
+    def __del__(self):
+        """wait for all pending tasks to complete before exit."""
+        if hasattr(self, "executor"):
+            logger.info("Waiting for all pending tasks to complete...")
+            self.executor.shutdown()
+
+    def _check(self):
+        config = json.loads(self._service_api_object["ServiceConfig"])
+        if config.get("metadata", {}).get("type") != ServiceType.Async:
+            logger.warning(
+                "AsyncPredictor is not recommended to make prediction to a standard "
+                " prediction service."
+            )
+
+    def _get_result(
+        self, request_id: str
+    ) -> Optional[Tuple[int, Dict[str, str], bytes]]:
+        resp = self._send_request(
+            method="GET",
+            path=_QUEUE_SERVICE_SINK_PATH,
+            params={
+                "requestId": request_id,
+                # _raw_ is false because we want to get the encapsulated prediction
+                # result in response body.
+                "_raw_": "false",
+            },
+        )
+        logger.debug(
+            "Poll prediction result: request_id=%s status_code=%s, content=%s",
+            request_id,
+            resp.status_code,
+            resp.content,
+        )
+        if resp.status_code == 204:
+            # Status code 204 means could not find prediction response for the specific
+            # request id.
+            return
+
+        # Raise exception if status code is not 2xx.
+        if resp.status_code // 100 != 2:
+            raise RuntimeError(
+                "Pulling prediction result failed: status_code={} content={}".format(
+                    resp.status_code, resp.content.decode("utf-8")
+                )
+            )
+        return self._parse_encapsulated_response(resp.json()[0])
+
+    def _parse_encapsulated_response(self, data) -> Tuple[int, Dict[str, str], bytes]:
+        tags = data["tags"]
+        # If the status code from prediction service is not 200, a tag with
+        # key 'lastCode' will be added to the tags in response.
+        status_code = int(tags.get("lastCode", 200))
+        data = base64.b64decode(data["data"])
+        # currently, headers are not supported in async prediction service.
+        headers = dict()
+        return status_code, headers, data
+
+    async def _get_result_async(
+        self, request_id: str
+    ) -> Optional[Tuple[int, Dict[str, str], bytes]]:
+        resp = await self._send_request_async(
+            method="GET",
+            path=_QUEUE_SERVICE_SINK_PATH,
+            params={
+                "requestId": request_id,
+                # _raw_ is false because we want to get the encapsulated prediction
+                # result in response body.
+                "_raw_": "false",
+            },
+        )
+        status_code = resp.status
+        content = await resp.read()
+        logger.debug(
+            "Get prediction result: request_id=%s status_code=%s, content=%s",
+            request_id,
+            status_code,
+            content,
+        )
+        if status_code == 204:
+            # Status code 204 means could not find prediction response for the specific
+            # request id.
+            return
+        if status_code // 100 != 2:
+            raise RuntimeError(
+                "Pulling prediction result failed: status_code={} content={}".format(
+                    status_code, content.decode("utf-8")
+                )
+            )
+        data = (await resp.json())[0]
+        return self._parse_encapsulated_response(data)
+
+    def _poll_result(
+        self, request_id: str, wait_config: WaitConfig
+    ) -> Tuple[int, Dict[str, str], bytes]:
+        # if max_attempts is negative or zero, then wait forever
+        attempts = -1 if wait_config.max_attempts <= 0 else wait_config.max_attempts
+        while attempts != 0:
+            attempts -= 1
+            result = self._get_result(request_id=request_id)
+            if not result:
+                time.sleep(wait_config.interval)
+                continue
+            status_code, headers, content = result
+            # check real prediction response
+            if status_code // 100 != 2:
+                raise PredictionException(
+                    code=status_code,
+                    message=f"Prediction failed: status_code={status_code}"
+                    f" content={content.decode()}",
+                )
+            return status_code, headers, content
+
+        # Polling prediction result timeout.
+        raise RuntimeError(
+            f"Polling prediction result timeout: request_id={request_id}, "
+            f"total_time={wait_config.max_attempts * wait_config.interval}"
+        )
+
+    async def _poll_result_async(
+        self, request_id, wait_config: WaitConfig
+    ) -> Tuple[int, Dict[str, str], bytes]:
+        # if max_attempts is negative or zero, then wait forever
+        attempts = -1 if wait_config.max_attempts <= 0 else wait_config.max_attempts
+        while attempts != 0:
+            attempts -= 1
+            result = await self._get_result_async(request_id)
+            if not result:
+                await asyncio.sleep(wait_config.interval)
+                continue
+            status_code, headers, content = result
+            # check real prediction response
+            if status_code // 100 != 2:
+                raise PredictionException(
+                    f"Prediction failed: status_code={status_code} content={content.decode()}"
+                )
+            return status_code, headers, content
+
+        # Polling prediction result timeout.
+        raise RuntimeError(
+            f"Polling prediction result timeout: request_id={request_id}, "
+            f"total_time={wait_config.max_attempts * wait_config.interval}"
+        )
+
+    def _get_request_id(self, resp: requests.models.Response) -> str:
+        if resp.status_code // 100 != 2:
+            raise RuntimeError(
+                f"Send prediction request failed. status_code={resp.status_code} "
+                f"message={resp.text}"
+            )
+
+        if _QUEUE_SERVICE_REQUEST_ID_HEADER not in resp.headers:
+            logger.error(
+                f"Send prediction request failed. Missing request id."
+                f" status_code={resp.status_code} content={resp.text}"
+            )
+            raise RuntimeError("Missing request id in response header.")
+
+        request_id = resp.headers[_QUEUE_SERVICE_REQUEST_ID_HEADER]
+        logger.debug(
+            f"Send prediction request successfully. request_id={request_id}"
+            f" status_code={resp.status_code}",
+        )
+        return request_id
+
+    async def _get_request_id_async(self, resp: aiohttp.ClientResponse) -> str:
+        content = await resp.read()
+        if resp.status != 200:
+            raise RuntimeError(
+                "Send request to async prediction service failed: status_code={} "
+                "content={}".format(resp.status, content.decode("utf-8"))
+            )
+
+        if _QUEUE_SERVICE_REQUEST_ID_HEADER not in resp.headers:
+            logger.error(
+                f"Send prediction request failed. Missing request id."
+                f" status_code={resp.status} content={content.decode()}"
+            )
+            raise RuntimeError("Missing request id in response header.")
+        request_id = resp.headers[_QUEUE_SERVICE_REQUEST_ID_HEADER]
+        logger.debug(
+            f"Send prediction request successfully. request_id={request_id}"
+            f" status_code={resp.status}",
+        )
+        return request_id
+
+    def _predict_fn(
+        self,
+        data,
+    ):
+        """Make a prediction with the async prediction service."""
+        # serialize input data
+        data = self._handle_input(data)
+        resp = self._send_request(data=data)
+        request_id = self._get_request_id(resp)
+        logger.debug("Async prediction RequestId: ", request_id)
+        # poll prediction result
+        status, headers, content = self._poll_result(
+            request_id=request_id, wait_config=WaitConfig()
+        )
+
+        return self._handle_output(content)
+
+    def _wrap_callback_fn(self, cb: Callable):
+        """Wrap the callback function to handle the prediction result."""
+
+        @functools.wraps(cb)
+        def _(future: Future):
+            return cb(future.result())
+
+        return _
+
+    def predict(
+        self,
+        data,
+        callback: Optional[Union[Callable, List[Callable]]] = None,
+    ):
+        """Make a prediction with the async prediction service.
+
+        The input data is serialized using the `serializer.serialize` method before it
+        is sent, and the response body is deserialized using the
+        `serializer.deserialize` method the prediction result returns.
+
+        Args:
+            data: The input data for the prediction. It will be serialized using the
+                serializer of the predictor before transmitted to the prediction
+                service.
+            callback (Union[Callable, List[Callable]], optional): A Callback function,
+                or a list of callback functions used to process the prediction result.
+
+        Returns:
+            AsyncTask: The task object that can be used to retrieve the prediction
+                result.
+        """
+        self._post_init_serializer()
+        future = self.executor.submit(self._predict_fn, data)
+
+        if isinstance(callback, Callable):
+            callback = [callback]
+
+        if callback:
+            for cb in callback:
+                future.add_done_callback(self._wrap_callback_fn(cb))
+
+        return AsyncTask(future=future)
+
+    async def predict_async(self, data, wait_config: WaitConfig = WaitConfig()):
+        """Make a prediction with the async prediction service.
+
+        The serializer object for the predictor is responsible for data transformation
+        when the 'predict' method is invoked. The input data is serialized using the
+        `serializer.serialize` method before it is sent, and the response is
+        deserialized using the `serializer.deserialize` method before the prediction
+        result returns.
+
+        Args:
+            data: The input data for the prediction. It will be serialized using the
+                serializer of the predictor before transmitted to the prediction
+                service.
+            wait_config (WaitConfig): A config object that controls the behavior of
+                polling the prediction result.
+
+        Returns:
+            Prediction result.
+
+        """
+        self._post_init_serializer()
+        data = self._handle_input(data)
+        resp = await self._send_request_async(data=data)
+        request_id = await self._get_request_id_async(resp)
+
+        status_code, headers, content = await self._poll_result_async(
+            request_id=request_id, wait_config=wait_config
+        )
+        return self._handle_output(content)
+
+    def _raw_predict_fn(self, data, method, path, headers, **kwargs):
+        json_data, data = self._handle_raw_input(data)
+        resp = self._send_request(
+            path=path,
+            json=json_data,
+            data=data,
+            headers=self._build_headers(headers),
+            method=method,
+            **kwargs,
+        )
+        request_id = self._get_request_id(resp)
+        status, headers, content = self._poll_result(
+            request_id, wait_config=WaitConfig()
+        )
+        return RawResponse(status, headers, content)
+
+    def raw_predict(
+        self,
+        data: Any = None,
+        callback: Optional[Union[Callable, List[Callable], None]] = None,
+        method: str = "POST",
+        path: Optional[str] = None,
+        headers: Optional[Dict[str, str]] = None,
+        **kwargs,
+    ) -> AsyncTask:
+        """Make a prediction with the online prediction service.
+
+        Args:
+            data (Any): Input data to be sent to the prediction service. If it is a
+                file-like object, bytes, or string, it will be sent as the request body.
+                Otherwise, it will be treated as a JSON serializable object and sent as
+                JSON.
+            callback (Union[Callable, List[Callable]], optional): A Callback function,
+                or a list of callback functions used to process the prediction result.
+            path (str, optional): Path for the request to be sent to. If it is provided,
+                it will be appended to the endpoint URL (Default None).
+            headers (dict, optional): Request headers.
+            method (str, optional): Request method, default to 'POST'.
+            **kwargs: Additional keyword arguments for the request.
+        Returns:
+            AsyncTask: The task object that can be used to retrieve the prediction
+                result.
+
+        Examples:
+
+            from pai.predictor import AsyncPredictor, AsyncTask
+
+            predictor = AsyncPredictor()
+            task: AsyncTask = predictor.raw_predict(data="YourPredictionData")
+            print(task.result())
+
+        """
+
+        future = self.executor.submit(
+            self._raw_predict_fn, data, method, path, headers, **kwargs
+        )
+        cbs = [callback] if isinstance(callback, Callable) else callback
+        if cbs:
+            for cb in cbs:
+                future.add_done_callback(self._wrap_callback_fn(cb))
+
+        return AsyncTask(future=future)
+
+    async def raw_predict_async(
+        self,
+        data,
+        wait_config: WaitConfig = WaitConfig(),
+        method: str = "POST",
+        headers: Optional[Dict[str, str]] = None,
+        path: Optional[str] = None,
+        **kwargs,
+    ) -> RawResponse:
+        """Make a prediction with the online prediction service.
+
+        Args:
+            data (Any): Input data to be sent to the prediction service. If it is a
+                file-like object, bytes, or string, it will be sent as the request body.
+                Otherwise, it will be treated as a JSON serializable object and sent as
+                JSON.
+            wait_config (WaitConfig): A config object that controls the behavior of
+                polling the prediction result.
+            path (str, optional): Path for the request to be sent to. If it is provided,
+                it will be appended to the endpoint URL (Default None).
+            headers (dict, optional): Request headers.
+            method (str, optional): Request method, default to 'POST'.
+            **kwargs: Additional keyword arguments for the request.
+        Returns:
+            RawResponse: Prediction result.
+
+        """
+        if self.service_status not in ServiceStatus.completed_status():
+            self.wait_for_ready()
+        json_data, data = self._handle_raw_input(data)
+
+        resp = await self._send_request_async(
+            data=data,
+            method=method,
+            json=json_data,
+            path=path,
+            headers=headers,
+            **kwargs,
+        )
+        request_id = await self._get_request_id_async(resp)
+        # Polling the prediction result.
+        status_code, headers, content = await self._poll_result_async(
+            request_id=request_id, wait_config=wait_config
+        )
+        return self._handle_raw_output(status_code, headers, content)
 
 
 class LocalPredictor(PredictorBase):
     """Perform prediction to a local service running with docker."""
 
     def __init__(
         self,
@@ -577,28 +1182,27 @@
         """
         request_data = self.serializer.serialize(data=data)
         response = requests.post(
             url="http://127.0.0.1:{port}/".format(port=self._container_run.port),
             data=request_data,
         )
 
-        if response.status_code != 200:
+        if response.status_code // 100 != 2:
             raise PredictionException(
                 code=response.status_code,
                 message=response.content,
             )
 
         return self.serializer.deserialize(response.content)
 
     def _build_headers(
         self, headers: Optional[Dict[str, str]] = None
     ) -> Dict[str, str]:
         headers = headers or dict()
-        if "User-Agent" not in headers:
-            headers["User-Agent"] = _default_user_agent()
+        headers["User-Agent"] = http_user_agent(headers.get("User-Agent"))
         return headers
 
     def _build_url(self, path: Optional[str] = None):
         url = "http://127.0.0.1:{}".format(self.port)
         if path:
             if path.startswith("/"):
                 path = path[1:]
```

## pai/session.py

```diff
@@ -1,13 +1,14 @@
 from __future__ import absolute_import
 
 import functools
 import json
 import logging
 import os.path
+import posixpath
 import typing
 from datetime import datetime
 from typing import Callable, Optional
 
 import oss2
 
 from .api.api_container import ResourceAPIsContainerMixin
@@ -372,15 +373,15 @@
             dir_name (str, optional): The directory name of the resource.
 
         Returns:
             str: A OSS storage path.
 
         """
         dir_name = dir_name or datetime.now().strftime("%Y%m%d_%H%M%S_%f")
-        storage_path = os.path.join("pai", category, dir_name).strip()
+        storage_path = posixpath.join("pai", category, dir_name).strip()
 
         if not storage_path.endswith("/"):
             storage_path += "/"
         return storage_path
 
     def is_supported_training_instance(self, instance_type: str) -> bool:
         instance_generator = make_list_resource_iterator(self.job_api.list_ecs_specs)
```

## pai/api/client_factory.py

```diff
@@ -3,15 +3,15 @@
 import logging
 import os
 
 from alibabacloud_tea_openapi.models import Config
 
 import pai
 from pai.api.base import PAIServiceName
-from pai.common.utils import default_user_agent
+from pai.common.utils import http_user_agent
 from pai.libs.alibabacloud_aiworkspace20210204.client import Client as WorkspaceClient
 from pai.libs.alibabacloud_eas20210701.client import Client as EasClient
 from pai.libs.alibabacloud_pai_dlc20201203.client import Client as DlcClient
 from pai.libs.alibabacloud_paiflow20210202.client import Client as FlowClient
 from pai.libs.alibabacloud_paistudio20220112.client import Client as TrainingClient
 
 _logger = logging.getLogger(__name__)
@@ -74,15 +74,15 @@
             security_token=security_token,
             endpoint=cls.get_endpoint(
                 service_name=service_name,
                 region_id=region_id,
                 endpoint=endpoint,
             ),
             signature_algorithm="v2",
-            user_agent=default_user_agent(),
+            user_agent=http_user_agent(),
             **kwargs,
         )
         client = cls.ClientClsByServiceName.get(service_name)(config)
         return client
 
     @classmethod
     def get_endpoint(cls, service_name: str, region_id: str, endpoint: str = None):
```

## pai/api/image.py

```diff
@@ -40,40 +40,44 @@
 
     _list_method = "list_images_with_options"
     _create_method = "create_image_with_options"
     _delete_method = "add_image_with_options"
 
     def list(
         self,
-        name=None,
-        creator_id=None,
-        verbose=False,
         labels: Union[Dict[str, Any], List[str]] = ImageLabel.UNOFFICIAL_LABEL,
-        sort_by=None,
-        order="DESC",
-        page_number=1,
-        page_size=50,
+        name: str = None,
+        order: str = "DESC",
+        page_number: int = 1,
+        page_size: int = 50,
+        parent_user_id: str = None,
+        query: str = None,
+        sort_by: str = None,
+        user_id: str = None,
+        verbose: bool = False,
         **kwargs,
     ) -> PaginatedResult:
         """List image resources."""
         workspace_id = kwargs.pop("workspace_id", None)
         if isinstance(labels, dict):
             labels = ",".join(["{}={}".format(k, v) for k, v in labels.items()])
         elif isinstance(labels, list):
             labels = ",".join([item for item in labels])
 
         req = ListImagesRequest(
             labels=labels,
             name=name,
-            operator_create=creator_id,
-            sort_by=sort_by,
             order=order,
-            verbose=verbose,
-            page_size=page_size,
             page_number=page_number,
+            page_size=page_size,
+            parent_user_id=parent_user_id,
+            query=query,
+            sort_by=sort_by,
+            user_id=user_id,
+            verbose=verbose,
             workspace_id=workspace_id,
         )
 
         return self._list(request=req)
 
     def _list(self, request) -> PaginatedResult:
         resp: ListImagesResponseBody = self._do_request(
```

## pai/common/consts.py

```diff
@@ -64,7 +64,11 @@
     PyTorch = "PyTorch"
     TFLite = "TFLite"
     Keras = "Keras"
     Caffe = "Caffe"
     Blade = "Blade"
     Alink = "Alink"
     TensorFlow = "TensorFlow"
+
+
+INSTANCE_TYPE_LOCAL = "local"
+INSTANCE_TYPE_LOCAL_GPU = "local_gpu"
```

## pai/common/docker_utils.py

```diff
@@ -2,15 +2,14 @@
 import logging
 import subprocess
 import time
 from random import randint
 from typing import Any, Dict, List, Optional, Union
 
 import docker
-import requests
 
 logger = logging.getLogger(__name__)
 
 
 def _run_command(command: List[str], input: Optional[str] = None):
     with subprocess.Popen(
         command,
@@ -102,62 +101,91 @@
     def watch(self):
         """Watch container log and wait for container to exit."""
         log_iter = self.container.logs(
             stream=True,
             follow=True,
         )
         for log in log_iter:
-            logger.info(log)
+            print(log.decode())
         self.container.reload()
         exit_code = self.container.attrs["State"]["ExitCode"]
         if exit_code != 0:
             raise RuntimeError(
                 "Container run exited failed: exit_code={}".format(exit_code)
             )
 
 
 def run_container(
     image_uri: str,
-    container_name: str = None,
-    port: int = None,
-    environment_variables: Dict[str, str] = None,
-    command: Union[List[str], str] = None,
-    entry_point: Union[List[str], str] = None,
-    volumes: Union[Dict[str, Any], List[str]] = None,
-    working_dir: str = None,
+    container_name: Optional[str] = None,
+    port: Optional[int] = None,
+    environment_variables: Optional[Dict[str, str]] = None,
+    command: Optional[Union[List[str], str]] = None,
+    entry_point: Optional[Union[List[str], str]] = None,
+    volumes: Optional[Dict[str, Any]] = None,
+    working_dir: Optional[str] = None,
+    gpu_count: Optional[int] = None,
+    gpu_device_ids: Optional[List[str]] = None,
+    gpu_capabilities: Optional[List[List[str]]] = None,
 ) -> ContainerRun:
     """Run a container in local.
 
     Args:
         image_uri (str):  A docker image uri.
-        container_name (str): Name of the container.
-        port (int): The port to expose.
-        environment_variables (Dict[str, str]): Environment variables to set in the
-            container.
-        command (Union[List[str], str]): Command to run the container.
-        entry_point (Union[List[str], str]): Entry point to run the container.
-        volumes (Union[Dict[str, Any], List[str]]): Volumes to mount in the container.
-        working_dir (str): Working directory in the container.
+        container_name (str, optional): Name of the container.
+        port (int, optional): The port to expose.
+        environment_variables (Dict[str, str], optional): Environment variables to set
+            in the container.
+        command (Union[List[str], str], optional): Command to run the container.
+        entry_point (Union[List[str], str], optional): Entry point to run the container.
+        volumes (Dict[str, Any], optional): Volumes to mount in the container.
+        working_dir (str, optional): Working directory in the container.
+        gpu_count (int, optional): Number of GPU devices to request. Set to -1 to
+            request all available devices.
+            To use GPU, set either ``gpu_count`` or ``gpu_device_ids``.
+        gpu_device_ids (List[str], optional): List of strings for GPU device IDs,
+            corresponding to `NVIDIA_VISIBLE_DEVICES` in the NVIDIA Runtime.
+            To use GPU, set either ``gpu_count`` or ``gpu_device_ids``.
+        gpu_capabilities (List[List[str]], optional): This parameter corresponds to
+            `NVIDIA_DRIVER_CAPABILITIES` in the NVIDIA Runtime. The default value is
+             ``[["compute", "utility"]]`` if ``gpu_device_ids`` or ``gpu_count`` is set.
+             Available capabilities for the NVIDIA driver can be found in
+            https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html#driver-capabilities.
 
     Returns:
         ContainerRun: A ContainerRun object.
 
     """
     client = docker.from_env()
     # use a random host port.
     host_port = randint(49152, 65535)
+
+    if gpu_count or gpu_device_ids or gpu_capabilities:
+        if not gpu_capabilities:
+            gpu_capabilities = [["compute", "utility"]]
+        device_requests = [
+            docker.types.DeviceRequest(
+                count=gpu_count,
+                device_ids=gpu_device_ids,
+                capabilities=gpu_capabilities,
+            )
+        ]
+    else:
+        device_requests = []
+
     container = client.containers.run(
         name=container_name,
         entrypoint=entry_point,
         image=image_uri,
         command=command,
         environment=environment_variables,
         ports={port: host_port} if port else None,
         volumes=volumes,
         working_dir=working_dir,
         detach=True,
+        device_requests=device_requests,
     )
     container_run = ContainerRun(
         container=container,
         port=host_port,
     )
     return container_run
```

## pai/common/utils.py

```diff
@@ -1,17 +1,19 @@
 from __future__ import absolute_import
 
 import random
 import re
 import string
-from typing import Callable
+import sys
+from typing import Callable, Dict, Optional, Union
 
 import six
 
 from .. import __version__
+from .consts import INSTANCE_TYPE_LOCAL, INSTANCE_TYPE_LOCAL_GPU
 
 DEFAULT_PLAIN_TEXT_ALLOW_CHARACTERS = string.ascii_letters + string.digits + "_"
 
 
 def iter_with_limit(iterator, limit):
     if not isinstance(limit, six.integer_types) or limit <= 0:
         raise ValueError("'limit' should be positive integer")
@@ -89,22 +91,35 @@
 def to_plain_text(
     input_str: str, allowed_characters=DEFAULT_PLAIN_TEXT_ALLOW_CHARACTERS, repl_ch="_"
 ):
     """Replace characters in input_str if it is not in allowed_characters."""
     return "".join([c if c in allowed_characters else repl_ch for c in input_str])
 
 
-def default_user_agent() -> str:
-    """Generate default User-Agent that represents current client."""
-    return "PAI-Python-SDK/{}".format(__version__)
+def http_user_agent(user_agent: Optional[Union[Dict, str]] = None) -> str:
+    """Generate HTTP User-Agent that represents current client."""
+    ua = f"pai-python-sdk/{__version__}; python/{sys.version.split()[0]}"
+    if isinstance(user_agent, dict):
+        ua += "; " + "; ".join(f"{k}/{v}" for k, v in user_agent.items())
+    elif isinstance(user_agent, str):
+        ua += "; " + user_agent
+    return ua
 
 
 def is_notebook() -> bool:
     """Return True if current environment is notebook."""
     try:
         shell = get_ipython().__class__.__name__
         for parent_cls in shell.__mro__:
             if parent_cls.__name__ == "ZMQInteractiveShell":
                 return True
         return False
     except NameError:
         return False
+
+
+def is_local_run_instance_type(instance_type: str) -> bool:
+    """Return True if instance_type is local run instance type."""
+    return instance_type and instance_type.strip() in [
+        INSTANCE_TYPE_LOCAL_GPU,
+        INSTANCE_TYPE_LOCAL,
+    ]
```

## pai/huggingface/estimator.py

```diff
@@ -29,14 +29,15 @@
 
     """
 
     def __init__(
         self,
         command: str,
         source_dir: Optional[str] = None,
+        git_config: Optional[Dict[str, str]] = None,
         image_uri: Optional[str] = None,
         transformers_version: Optional[str] = None,
         hyperparameters: Optional[Dict[str, Any]] = None,
         base_job_name: Optional[str] = None,
         checkpoints_path: Optional[str] = None,
         output_path: Optional[str] = None,
         instance_type: str = "ecs.c6.xlarge",
@@ -50,14 +51,47 @@
             command (str): The command used to run the training job.
             source_dir (str, optional): The local source code directory used in the
                 training job. The directory will be packaged and uploaded to an OSS
                 bucket, then downloaded to the `/ml/usercode` directory in the training
                 job container. If there is a `requirements.txt` file in the source code
                 directory, the corresponding dependencies will be installed before the
                 training script runs.
+
+                If 'git_config' is provided, 'source_dir' should be a relative location
+                to a directory in the Git repo. With the following GitHub repo directory
+                structure:
+
+                .. code::
+
+                    |----- README.md
+                    |----- src
+                             |----- train.py
+                             |----- test.py
+
+                if you need 'src' directory as the source code directory, you can assign
+                source_dir='./src/'.
+            git_config (Dict[str, str]): Git configuration used to clone the repo.
+                Including ``repo``, ``branch``, ``commit``, ``username``, ``password``
+                and ``token``. The ``repo`` is required. All other fields are optional.
+                ``repo`` specifies the Git repository. If you don't provide ``branch``,
+                the default value 'master' is used. If you don't provide ``commit``, the
+                latest commit in the specified branch is used. ``username``, ``password``
+                and ``token`` are for authentication purpose.
+                For example, the following config:
+
+                .. code:: python
+
+                    git_config = {
+                        'repo': 'https://github.com/huggingface/transformers.git',
+                        'branch': 'main',
+                        'commit': '5ba0c332b6bef130ab6dcb734230849c903839f7'
+                    }
+
+                results in cloning the git repo specified in 'repo', then checking out
+                the 'main' branch, and checking out the specified commit.
             image_uri (str, optional): If specified, the estimator will use this image
                 in the training job, instead of selecting the appropriate PAI official
                 image based on transformers_version. It can be an image provided by PAI
                 or a user customized image. To view the images provided by PAI, please
                 refer to the document:
                 https://help.aliyun.com/document_detail/202834.htm.
 
@@ -133,14 +167,15 @@
         self.image_uri = image_uri
         self.transformers_version = transformers_version
 
         super(HuggingFaceEstimator, self).__init__(
             image_uri=self.image_uri,
             command=command,
             source_dir=source_dir,
+            git_config=git_config,
             hyperparameters=hyperparameters,
             base_job_name=base_job_name,
             checkpoints_path=checkpoints_path,
             output_path=output_path,
             instance_type=instance_type,
             instance_count=instance_count,
             session=session,
```

## pai/huggingface/model.py

```diff
@@ -52,14 +52,15 @@
     def __init__(
         self,
         model_data: Optional[str] = None,
         image_uri: Optional[str] = None,
         transformers_version: Optional[str] = None,
         command: Optional[str] = None,
         source_dir: Optional[str] = None,
+        git_config: Optional[Dict[str, str]] = None,
         port: int = DEFAULT_SERVICE_PORT,
         environment_variables: Optional[Dict[str, str]] = None,
         requirements: Optional[List[str]] = None,
         requirements_path: Optional[str] = None,
         health_check: Optional[Dict[str, Any]] = None,
         session: Optional[Session] = None,
         **kwargs,
@@ -76,28 +77,63 @@
 
                 If ``transformers_version`` is ``None``, then ``image_uri`` is required.
                 If also ``None``, then a ``ValueError`` will be raised.
             transformers_version (str, optional): Transformers version you want to use for
                 executing your model serving code. Defaults to ``None``. Required unless
                 ``image_uri`` is provided.
             command (str): The command used to launch the Model server.
-            source_dir (str, optional): Local path to the source code directory to be
-                uploaded and used for the model server.
+            source_dir (str, optional): A relative path or an absolute path to the source
+                code directory used to load model and launch the Model server, it will be
+                uploaded to the OSS bucket and mounted to the container. If there is a
+                ``requirements.txt`` file under the directory, it will be installed before
+                the prediction server started.
+
+                If 'git_config' is provided, 'source_dir' should be a relative location
+                to a directory in the Git repo. With the following GitHub repo directory
+                structure:
+
+                .. code::
+
+                    |----- README.md
+                    |----- src
+                                |----- train.py
+                                |----- test.py
+
+                if you need 'src' directory as the source code directory, you can assign
+                source_dir='./src/'.
+            git_config (Dict[str, str]): Git configuration used to clone the repo.
+                Including ``repo``, ``branch``, ``commit``, ``username``, ``password`` and
+                ``token``. The ``repo`` is required. All other fields are optional. ``repo``
+                specifies the Git repository. If you don't provide ``branch``, the default
+                value 'master' is used. If you don't provide ``commit``, the latest commit
+                in the specified branch is used. ``username``, ``password`` and ``token``
+                are for authentication purpose. For example, the following config:
+
+                .. code:: python
+
+                    git_config = {
+                        'repo': 'https://github.com/huggingface/transformers.git',
+                        'branch': 'main',
+                        'commit': '5ba0c332b6bef130ab6dcb734230849c903839f7'
+                    }
+
+                results in cloning the repo specified in 'repo', then checking out the
+                'main' branch, and checking out the specified commit.
             port (int, optional): Expose port of the server in container, the prediction
                 request will be forward to the port. The environment variable ``LISTENING_PORT``
                 in the container will be set to this value.
             environment_variables (Dict[str, str], optional): Dictionary of environment
                 variable key-value pairs to set on the running container.
             requirements (List[str], optional): A list of Python package dependency, it
                 will be installed before the serving container run.
             requirements_path (str, optional): A absolute path to the requirements.txt in
                 the container.
             health_check (Dict[str, Any], optional): The health check configuration. If it
                 not set, A TCP readiness probe will be used to check the health of the
-                HTTP server.
+                Model server.
             session (:class:`pai.session.Session`, optional): A pai session object
                 manages interactions with PAI REST API.
 
             **kwargs: Additional kwargs passed to the :class:`~pai.model.ModelBase` constructor.
 
         .. tip::
 
@@ -109,14 +145,15 @@
         )
 
         self.model_data = model_data
         self.image_uri = image_uri
         self.transformers_version = transformers_version
         self.command = command
         self.source_dir = source_dir
+        self.git_config = git_config
         self.port = port
         self.environment_variables = environment_variables
         self.requirements = requirements
         self.requirements_path = requirements_path
         self.health_check = health_check
         self.session = session
         inference_spec = dict()
@@ -135,16 +172,17 @@
                 "transformers_version, and image_uri are both None. "
                 "Specify either transformers_version or image_uri."
             )
 
     def serving_image_uri(self, instance_type: str) -> str:
         """Return the Docker image to use for serving.
 
-        The deploy() method, that does the model deployment, calls this method to
-        find the image to use for the inference service.
+        The :meth:`pai.huggingface.model.HuggingFaceModel.deploy` method, that does the
+        model deployment, calls this method to find the image to use for the inference
+        service.
 
         Returns:
             str: The URI of the Docker image.
         """
         if self.image_uri:
             return self.image_uri
 
@@ -159,22 +197,23 @@
             framework_version=framework_version,
             accelerator_type=accelerator_type,
             image_scope=ImageScope.INFERENCE,
         ).image_uri
 
     def deploy(
         self,
-        service_name: Optional[str] = None,
+        service_name: str,
         instance_type: Optional[str] = None,
         instance_count: Optional[int] = 1,
         resource_config: Optional[Union[Dict[str, int], ResourceConfig]] = None,
         resource_id: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
         wait: bool = True,
         serializer: Optional["SerializerBase"] = None,
+        **kwargs,
     ):
         """Deploy an online prediction service.
 
         Args:
             service_name (str, optional): Name for the online prediction service. The name
                 must be unique in a region.
             instance_type (str, optional): Type of the machine instance, for example,
@@ -224,14 +263,15 @@
 
         self.image_uri = self.serving_image_uri(instance_type=instance_type)
         self.inference_spec = container_serving_spec(
             command=self.command,
             image_uri=self.image_uri,
             port=self.port,
             source_dir=self.source_dir,
+            git_config=self.git_config,
             environment_variables=self.environment_variables,
             requirements=self.requirements,
             requirements_path=self.requirements_path,
             health_check=self.health_check,
             session=self.session,
         )
         return super(HuggingFaceModel, self).deploy(
@@ -239,8 +279,9 @@
             instance_type=instance_type,
             instance_count=instance_count,
             resource_config=resource_config,
             resource_id=resource_id,
             options=options,
             wait=wait,
             serializer=serializer,
+            **kwargs,
         )
```

## pai/libs/alibabacloud_aiworkspace20210204/__init__.py

```diff
@@ -1 +1 @@
-__version__ = '1.0.0'
+__version__ = '1.2.10'
```

## pai/libs/alibabacloud_aiworkspace20210204/client.py

```diff
@@ -7,24 +7,22 @@
 from alibabacloud_tea_openapi import models as open_api_models
 from alibabacloud_tea_util.client import Client as UtilClient
 from alibabacloud_endpoint_util.client import Client as EndpointUtilClient
 # from alibabacloud_aiworkspace20210204 import models as aiwork_space_20210204_models
 from alibabacloud_tea_util import models as util_models
 from alibabacloud_openapi_util.client import Client as OpenApiUtilClient
 
-# hack
 from pai.libs.alibabacloud_aiworkspace20210204 import models as aiwork_space_20210204_models
 
-
 class Client(OpenApiClient):
     """
     *\
     """
     def __init__(
-        self,
+        self, 
         config: open_api_models.Config,
     ):
         super().__init__(config)
         self._endpoint_rule = ''
         self.check_config(config)
         self._endpoint = self.get_endpoint('aiworkspace', self._region_id, self._endpoint_rule, self._network, self._suffix, self._endpoint_map, self._endpoint)
 
@@ -40,30 +38,14 @@
     ) -> str:
         if not UtilClient.empty(endpoint):
             return endpoint
         if not UtilClient.is_unset(endpoint_map) and not UtilClient.empty(endpoint_map.get(region_id)):
             return endpoint_map.get(region_id)
         return EndpointUtilClient.get_endpoint_rules(product_id, region_id, endpoint_rule, network, suffix)
 
-    def add_image(
-        self,
-        request: aiwork_space_20210204_models.AddImageRequest,
-    ) -> aiwork_space_20210204_models.AddImageResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.add_image_with_options(request, headers, runtime)
-
-    async def add_image_async(
-        self,
-        request: aiwork_space_20210204_models.AddImageRequest,
-    ) -> aiwork_space_20210204_models.AddImageResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.add_image_with_options_async(request, headers, runtime)
-
     def add_image_with_options(
         self,
         request: aiwork_space_20210204_models.AddImageRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddImageResponse:
         UtilClient.validate_model(request)
@@ -136,53 +118,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.AddImageResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def add_image_labels(
+    def add_image(
         self,
-        image_id: str,
-        request: aiwork_space_20210204_models.AddImageLabelsRequest,
-    ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
+        request: aiwork_space_20210204_models.AddImageRequest,
+    ) -> aiwork_space_20210204_models.AddImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.add_image_labels_with_options(image_id, request, headers, runtime)
+        return self.add_image_with_options(request, headers, runtime)
 
-    async def add_image_labels_async(
+    async def add_image_async(
         self,
-        image_id: str,
-        request: aiwork_space_20210204_models.AddImageLabelsRequest,
-    ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
+        request: aiwork_space_20210204_models.AddImageRequest,
+    ) -> aiwork_space_20210204_models.AddImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.add_image_labels_with_options_async(image_id, request, headers, runtime)
+        return await self.add_image_with_options_async(request, headers, runtime)
 
     def add_image_labels_with_options(
         self,
         image_id: str,
         request: aiwork_space_20210204_models.AddImageLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
         UtilClient.validate_model(request)
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='AddImageLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/labels',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -194,77 +173,71 @@
         self,
         image_id: str,
         request: aiwork_space_20210204_models.AddImageLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
         UtilClient.validate_model(request)
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='AddImageLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/labels',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.AddImageLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def add_member_role(
+    def add_image_labels(
         self,
-        workspace_id: str,
-        member_id: str,
-        role_name: str,
-    ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
+        image_id: str,
+        request: aiwork_space_20210204_models.AddImageLabelsRequest,
+    ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.add_member_role_with_options(workspace_id, member_id, role_name, headers, runtime)
+        return self.add_image_labels_with_options(image_id, request, headers, runtime)
 
-    async def add_member_role_async(
+    async def add_image_labels_async(
         self,
-        workspace_id: str,
-        member_id: str,
-        role_name: str,
-    ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
+        image_id: str,
+        request: aiwork_space_20210204_models.AddImageLabelsRequest,
+    ) -> aiwork_space_20210204_models.AddImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.add_member_role_with_options_async(workspace_id, member_id, role_name, headers, runtime)
+        return await self.add_image_labels_with_options_async(image_id, request, headers, runtime)
 
     def add_member_role_with_options(
         self,
         workspace_id: str,
         member_id: str,
         role_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        member_id = OpenApiUtilClient.get_encode_param(member_id)
-        role_name = OpenApiUtilClient.get_encode_param(role_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='AddMemberRole',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members/{member_id}/roles/{role_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members/{OpenApiUtilClient.get_encode_param(member_id)}/roles/{OpenApiUtilClient.get_encode_param(role_name)}',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -276,83 +249,68 @@
         self,
         workspace_id: str,
         member_id: str,
         role_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        member_id = OpenApiUtilClient.get_encode_param(member_id)
-        role_name = OpenApiUtilClient.get_encode_param(role_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='AddMemberRole',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members/{member_id}/roles/{role_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members/{OpenApiUtilClient.get_encode_param(member_id)}/roles/{OpenApiUtilClient.get_encode_param(role_name)}',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.AddMemberRoleResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def add_workspace_quota(
+    def add_member_role(
         self,
         workspace_id: str,
-        quota_id: str,
-        request: aiwork_space_20210204_models.AddWorkspaceQuotaRequest,
-    ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
+        member_id: str,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.add_workspace_quota_with_options(workspace_id, quota_id, request, headers, runtime)
+        return self.add_member_role_with_options(workspace_id, member_id, role_name, headers, runtime)
 
-    async def add_workspace_quota_async(
+    async def add_member_role_async(
         self,
         workspace_id: str,
-        quota_id: str,
-        request: aiwork_space_20210204_models.AddWorkspaceQuotaRequest,
-    ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
+        member_id: str,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.AddMemberRoleResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.add_workspace_quota_with_options_async(workspace_id, quota_id, request, headers, runtime)
+        return await self.add_member_role_with_options_async(workspace_id, member_id, role_name, headers, runtime)
 
     def add_workspace_quota_with_options(
         self,
         workspace_id: str,
         quota_id: str,
-        request: aiwork_space_20210204_models.AddWorkspaceQuotaRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
-        UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        quota_id = OpenApiUtilClient.get_encode_param(quota_id)
-        body = {}
-        if not UtilClient.is_unset(request.mode):
-            body['Mode'] = request.mode
-        if not UtilClient.is_unset(request.product_code):
-            body['ProductCode'] = request.product_code
-        if not UtilClient.is_unset(request.quota_type):
-            body['QuotaType'] = request.quota_type
         req = open_api_models.OpenApiRequest(
-            headers=headers,
-            body=OpenApiUtilClient.parse_to_map(body)
+            headers=headers
         )
         params = open_api_models.Params(
             action='AddWorkspaceQuota',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/[WorkspaceId]/quotas/[QuotaId]',
+            pathname=f'/api/v1/workspaces/%5BWorkspaceId%5D/quotas/%5BQuotaId%5D',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -360,63 +318,119 @@
             self.call_api(params, req, runtime)
         )
 
     async def add_workspace_quota_with_options_async(
         self,
         workspace_id: str,
         quota_id: str,
-        request: aiwork_space_20210204_models.AddWorkspaceQuotaRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
-        UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        quota_id = OpenApiUtilClient.get_encode_param(quota_id)
-        body = {}
-        if not UtilClient.is_unset(request.mode):
-            body['Mode'] = request.mode
-        if not UtilClient.is_unset(request.product_code):
-            body['ProductCode'] = request.product_code
-        if not UtilClient.is_unset(request.quota_type):
-            body['QuotaType'] = request.quota_type
         req = open_api_models.OpenApiRequest(
-            headers=headers,
-            body=OpenApiUtilClient.parse_to_map(body)
+            headers=headers
         )
         params = open_api_models.Params(
             action='AddWorkspaceQuota',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/[WorkspaceId]/quotas/[QuotaId]',
+            pathname=f'/api/v1/workspaces/%5BWorkspaceId%5D/quotas/%5BQuotaId%5D',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.AddWorkspaceQuotaResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_code_source(
+    def add_workspace_quota(
         self,
-        request: aiwork_space_20210204_models.CreateCodeSourceRequest,
-    ) -> aiwork_space_20210204_models.CreateCodeSourceResponse:
+        workspace_id: str,
+        quota_id: str,
+    ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_code_source_with_options(request, headers, runtime)
+        return self.add_workspace_quota_with_options(workspace_id, quota_id, headers, runtime)
 
-    async def create_code_source_async(
+    async def add_workspace_quota_async(
         self,
-        request: aiwork_space_20210204_models.CreateCodeSourceRequest,
-    ) -> aiwork_space_20210204_models.CreateCodeSourceResponse:
+        workspace_id: str,
+        quota_id: str,
+    ) -> aiwork_space_20210204_models.AddWorkspaceQuotaResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_code_source_with_options_async(request, headers, runtime)
+        return await self.add_workspace_quota_with_options_async(workspace_id, quota_id, headers, runtime)
+
+    def assume_service_identity_role_with_options(
+        self,
+        role_name: str,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse:
+        req = open_api_models.OpenApiRequest(
+            headers=headers
+        )
+        params = open_api_models.Params(
+            action='AssumeServiceIdentityRole',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/serviceidentityroles/{OpenApiUtilClient.get_encode_param(role_name)}/assume',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def assume_service_identity_role_with_options_async(
+        self,
+        role_name: str,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse:
+        req = open_api_models.OpenApiRequest(
+            headers=headers
+        )
+        params = open_api_models.Params(
+            action='AssumeServiceIdentityRole',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/serviceidentityroles/{OpenApiUtilClient.get_encode_param(role_name)}/assume',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def assume_service_identity_role(
+        self,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.assume_service_identity_role_with_options(role_name, headers, runtime)
+
+    async def assume_service_identity_role_async(
+        self,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.AssumeServiceIdentityRoleResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.assume_service_identity_role_with_options_async(role_name, headers, runtime)
 
     def create_code_source_with_options(
         self,
         request: aiwork_space_20210204_models.CreateCodeSourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateCodeSourceResponse:
@@ -502,29 +516,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateCodeSourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_dataset(
+    def create_code_source(
         self,
-        request: aiwork_space_20210204_models.CreateDatasetRequest,
-    ) -> aiwork_space_20210204_models.CreateDatasetResponse:
+        request: aiwork_space_20210204_models.CreateCodeSourceRequest,
+    ) -> aiwork_space_20210204_models.CreateCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_dataset_with_options(request, headers, runtime)
+        return self.create_code_source_with_options(request, headers, runtime)
 
-    async def create_dataset_async(
+    async def create_code_source_async(
         self,
-        request: aiwork_space_20210204_models.CreateDatasetRequest,
-    ) -> aiwork_space_20210204_models.CreateDatasetResponse:
+        request: aiwork_space_20210204_models.CreateCodeSourceRequest,
+    ) -> aiwork_space_20210204_models.CreateCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_dataset_with_options_async(request, headers, runtime)
+        return await self.create_code_source_with_options_async(request, headers, runtime)
 
     def create_dataset_with_options(
         self,
         request: aiwork_space_20210204_models.CreateDatasetRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateDatasetResponse:
@@ -542,14 +556,16 @@
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
         if not UtilClient.is_unset(request.property):
             body['Property'] = request.property
+        if not UtilClient.is_unset(request.provider_type):
+            body['ProviderType'] = request.provider_type
         if not UtilClient.is_unset(request.source_id):
             body['SourceId'] = request.source_id
         if not UtilClient.is_unset(request.source_type):
             body['SourceType'] = request.source_type
         if not UtilClient.is_unset(request.uri):
             body['Uri'] = request.uri
         if not UtilClient.is_unset(request.workspace_id):
@@ -594,14 +610,16 @@
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
         if not UtilClient.is_unset(request.property):
             body['Property'] = request.property
+        if not UtilClient.is_unset(request.provider_type):
+            body['ProviderType'] = request.provider_type
         if not UtilClient.is_unset(request.source_id):
             body['SourceId'] = request.source_id
         if not UtilClient.is_unset(request.source_type):
             body['SourceType'] = request.source_type
         if not UtilClient.is_unset(request.uri):
             body['Uri'] = request.uri
         if not UtilClient.is_unset(request.workspace_id):
@@ -622,53 +640,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateDatasetResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_dataset_labels(
+    def create_dataset(
         self,
-        dataset_id: str,
-        request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
+        request: aiwork_space_20210204_models.CreateDatasetRequest,
+    ) -> aiwork_space_20210204_models.CreateDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_dataset_labels_with_options(dataset_id, request, headers, runtime)
+        return self.create_dataset_with_options(request, headers, runtime)
 
-    async def create_dataset_labels_async(
+    async def create_dataset_async(
         self,
-        dataset_id: str,
-        request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
+        request: aiwork_space_20210204_models.CreateDatasetRequest,
+    ) -> aiwork_space_20210204_models.CreateDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_dataset_labels_with_options_async(dataset_id, request, headers, runtime)
+        return await self.create_dataset_with_options_async(request, headers, runtime)
 
     def create_dataset_labels_with_options(
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateDatasetLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/labels',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -680,62 +695,65 @@
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateDatasetLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/labels',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateDatasetLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_default_workspace(
+    def create_dataset_labels(
         self,
-        request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_default_workspace_with_options(request, headers, runtime)
+        return self.create_dataset_labels_with_options(dataset_id, request, headers, runtime)
 
-    async def create_default_workspace_async(
+    async def create_dataset_labels_async(
         self,
-        request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.CreateDatasetLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateDatasetLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_default_workspace_with_options_async(request, headers, runtime)
+        return await self.create_dataset_labels_with_options_async(dataset_id, request, headers, runtime)
 
     def create_default_workspace_with_options(
         self,
         request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
         UtilClient.validate_model(request)
         body = {}
+        if not UtilClient.is_unset(request.add_all_ram_users):
+            body['AddAllRamUsers'] = request.add_all_ram_users
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.env_types):
             body['EnvTypes'] = request.env_types
         if not UtilClient.is_unset(request.resources):
             body['Resources'] = request.resources
         req = open_api_models.OpenApiRequest(
@@ -762,14 +780,16 @@
         self,
         request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
         UtilClient.validate_model(request)
         body = {}
+        if not UtilClient.is_unset(request.add_all_ram_users):
+            body['AddAllRamUsers'] = request.add_all_ram_users
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.env_types):
             body['EnvTypes'] = request.env_types
         if not UtilClient.is_unset(request.resources):
             body['Resources'] = request.resources
         req = open_api_models.OpenApiRequest(
@@ -788,53 +808,134 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateDefaultWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_member(
+    def create_default_workspace(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.CreateMemberRequest,
-    ) -> aiwork_space_20210204_models.CreateMemberResponse:
+        request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_member_with_options(workspace_id, request, headers, runtime)
+        return self.create_default_workspace_with_options(request, headers, runtime)
 
-    async def create_member_async(
+    async def create_default_workspace_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.CreateMemberRequest,
-    ) -> aiwork_space_20210204_models.CreateMemberResponse:
+        request: aiwork_space_20210204_models.CreateDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.CreateDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_member_with_options_async(workspace_id, request, headers, runtime)
+        return await self.create_default_workspace_with_options_async(request, headers, runtime)
+
+    def create_ding_talk_robot_message_with_options(
+        self,
+        request: aiwork_space_20210204_models.CreateDingTalkRobotMessageRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.access_token):
+            body['AccessToken'] = request.access_token
+        if not UtilClient.is_unset(request.message):
+            body['Message'] = request.message
+        if not UtilClient.is_unset(request.secret):
+            body['Secret'] = request.secret
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateDingTalkRobotMessage',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/dingtalkrobotmessages',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def create_ding_talk_robot_message_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.CreateDingTalkRobotMessageRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.access_token):
+            body['AccessToken'] = request.access_token
+        if not UtilClient.is_unset(request.message):
+            body['Message'] = request.message
+        if not UtilClient.is_unset(request.secret):
+            body['Secret'] = request.secret
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateDingTalkRobotMessage',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/dingtalkrobotmessages',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def create_ding_talk_robot_message(
+        self,
+        request: aiwork_space_20210204_models.CreateDingTalkRobotMessageRequest,
+    ) -> aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.create_ding_talk_robot_message_with_options(request, headers, runtime)
+
+    async def create_ding_talk_robot_message_async(
+        self,
+        request: aiwork_space_20210204_models.CreateDingTalkRobotMessageRequest,
+    ) -> aiwork_space_20210204_models.CreateDingTalkRobotMessageResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.create_ding_talk_robot_message_with_options_async(request, headers, runtime)
 
     def create_member_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.CreateMemberRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateMemberResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.members):
             body['Members'] = request.members
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateMember',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -846,70 +947,79 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.CreateMemberRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateMemberResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.members):
             body['Members'] = request.members
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateMember',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateMemberResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_model(
+    def create_member(
         self,
-        request: aiwork_space_20210204_models.CreateModelRequest,
-    ) -> aiwork_space_20210204_models.CreateModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.CreateMemberRequest,
+    ) -> aiwork_space_20210204_models.CreateMemberResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_model_with_options(request, headers, runtime)
+        return self.create_member_with_options(workspace_id, request, headers, runtime)
 
-    async def create_model_async(
+    async def create_member_async(
         self,
-        request: aiwork_space_20210204_models.CreateModelRequest,
-    ) -> aiwork_space_20210204_models.CreateModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.CreateMemberRequest,
+    ) -> aiwork_space_20210204_models.CreateMemberResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_model_with_options_async(request, headers, runtime)
+        return await self.create_member_with_options_async(workspace_id, request, headers, runtime)
 
     def create_model_with_options(
         self,
         request: aiwork_space_20210204_models.CreateModelRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.accessibility):
             body['Accessibility'] = request.accessibility
+        if not UtilClient.is_unset(request.domain):
+            body['Domain'] = request.domain
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.model_description):
             body['ModelDescription'] = request.model_description
+        if not UtilClient.is_unset(request.model_doc):
+            body['ModelDoc'] = request.model_doc
         if not UtilClient.is_unset(request.model_name):
             body['ModelName'] = request.model_name
+        if not UtilClient.is_unset(request.origin):
+            body['Origin'] = request.origin
+        if not UtilClient.is_unset(request.task):
+            body['Task'] = request.task
         if not UtilClient.is_unset(request.workspace_id):
             body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -934,20 +1044,28 @@
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.accessibility):
             body['Accessibility'] = request.accessibility
+        if not UtilClient.is_unset(request.domain):
+            body['Domain'] = request.domain
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.model_description):
             body['ModelDescription'] = request.model_description
+        if not UtilClient.is_unset(request.model_doc):
+            body['ModelDoc'] = request.model_doc
         if not UtilClient.is_unset(request.model_name):
             body['ModelName'] = request.model_name
+        if not UtilClient.is_unset(request.origin):
+            body['Origin'] = request.origin
+        if not UtilClient.is_unset(request.task):
+            body['Task'] = request.task
         if not UtilClient.is_unset(request.workspace_id):
             body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -962,53 +1080,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateModelResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_model_labels(
+    def create_model(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.CreateModelLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
+        request: aiwork_space_20210204_models.CreateModelRequest,
+    ) -> aiwork_space_20210204_models.CreateModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_model_labels_with_options(model_id, request, headers, runtime)
+        return self.create_model_with_options(request, headers, runtime)
 
-    async def create_model_labels_async(
+    async def create_model_async(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.CreateModelLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
+        request: aiwork_space_20210204_models.CreateModelRequest,
+    ) -> aiwork_space_20210204_models.CreateModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_model_labels_with_options_async(model_id, request, headers, runtime)
+        return await self.create_model_with_options_async(request, headers, runtime)
 
     def create_model_labels_with_options(
         self,
         model_id: str,
         request: aiwork_space_20210204_models.CreateModelLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1020,91 +1135,183 @@
         self,
         model_id: str,
         request: aiwork_space_20210204_models.CreateModelLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateModelLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_model_version(
+    def create_model_labels(
         self,
         model_id: str,
-        request: aiwork_space_20210204_models.CreateModelVersionRequest,
-    ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
+        request: aiwork_space_20210204_models.CreateModelLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_model_version_with_options(model_id, request, headers, runtime)
+        return self.create_model_labels_with_options(model_id, request, headers, runtime)
 
-    async def create_model_version_async(
+    async def create_model_labels_async(
         self,
         model_id: str,
-        request: aiwork_space_20210204_models.CreateModelVersionRequest,
-    ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
+        request: aiwork_space_20210204_models.CreateModelLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateModelLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_model_version_with_options_async(model_id, request, headers, runtime)
+        return await self.create_model_labels_with_options_async(model_id, request, headers, runtime)
+
+    def create_model_release_with_options(
+        self,
+        model_id: str,
+        request: aiwork_space_20210204_models.CreateModelReleaseRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateModelReleaseResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.target_model_origin):
+            body['TargetModelOrigin'] = request.target_model_origin
+        if not UtilClient.is_unset(request.target_model_provider):
+            body['TargetModelProvider'] = request.target_model_provider
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateModelRelease',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/release',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateModelReleaseResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def create_model_release_with_options_async(
+        self,
+        model_id: str,
+        request: aiwork_space_20210204_models.CreateModelReleaseRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateModelReleaseResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.target_model_origin):
+            body['TargetModelOrigin'] = request.target_model_origin
+        if not UtilClient.is_unset(request.target_model_provider):
+            body['TargetModelProvider'] = request.target_model_provider
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateModelRelease',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/release',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateModelReleaseResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def create_model_release(
+        self,
+        model_id: str,
+        request: aiwork_space_20210204_models.CreateModelReleaseRequest,
+    ) -> aiwork_space_20210204_models.CreateModelReleaseResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.create_model_release_with_options(model_id, request, headers, runtime)
+
+    async def create_model_release_async(
+        self,
+        model_id: str,
+        request: aiwork_space_20210204_models.CreateModelReleaseRequest,
+    ) -> aiwork_space_20210204_models.CreateModelReleaseResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.create_model_release_with_options_async(model_id, request, headers, runtime)
 
     def create_model_version_with_options(
         self,
         model_id: str,
         request: aiwork_space_20210204_models.CreateModelVersionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
+        if not UtilClient.is_unset(request.approval_status):
+            body['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.format_type):
             body['FormatType'] = request.format_type
         if not UtilClient.is_unset(request.framework_type):
             body['FrameworkType'] = request.framework_type
         if not UtilClient.is_unset(request.inference_spec):
             body['InferenceSpec'] = request.inference_spec
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
+        if not UtilClient.is_unset(request.metrics):
+            body['Metrics'] = request.metrics
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
+        if not UtilClient.is_unset(request.source_id):
+            body['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            body['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.training_spec):
+            body['TrainingSpec'] = request.training_spec
         if not UtilClient.is_unset(request.uri):
             body['Uri'] = request.uri
         if not UtilClient.is_unset(request.version_description):
             body['VersionDescription'] = request.version_description
         if not UtilClient.is_unset(request.version_name):
             body['VersionName'] = request.version_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1116,95 +1323,100 @@
         self,
         model_id: str,
         request: aiwork_space_20210204_models.CreateModelVersionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
+        if not UtilClient.is_unset(request.approval_status):
+            body['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.format_type):
             body['FormatType'] = request.format_type
         if not UtilClient.is_unset(request.framework_type):
             body['FrameworkType'] = request.framework_type
         if not UtilClient.is_unset(request.inference_spec):
             body['InferenceSpec'] = request.inference_spec
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
+        if not UtilClient.is_unset(request.metrics):
+            body['Metrics'] = request.metrics
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
+        if not UtilClient.is_unset(request.source_id):
+            body['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            body['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.training_spec):
+            body['TrainingSpec'] = request.training_spec
         if not UtilClient.is_unset(request.uri):
             body['Uri'] = request.uri
         if not UtilClient.is_unset(request.version_description):
             body['VersionDescription'] = request.version_description
         if not UtilClient.is_unset(request.version_name):
             body['VersionName'] = request.version_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateModelVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_model_version_labels(
+    def create_model_version(
         self,
         model_id: str,
-        version_name: str,
-        request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
+        request: aiwork_space_20210204_models.CreateModelVersionRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_model_version_labels_with_options(model_id, version_name, request, headers, runtime)
+        return self.create_model_version_with_options(model_id, request, headers, runtime)
 
-    async def create_model_version_labels_async(
+    async def create_model_version_async(
         self,
         model_id: str,
-        version_name: str,
-        request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
-    ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
+        request: aiwork_space_20210204_models.CreateModelVersionRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_model_version_labels_with_options_async(model_id, version_name, request, headers, runtime)
+        return await self.create_model_version_with_options_async(model_id, request, headers, runtime)
 
     def create_model_version_labels_with_options(
         self,
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelVersionLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1217,54 +1429,144 @@
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         body = {}
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateModelVersionLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/labels',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateModelVersionLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_product_orders(
+    def create_model_version_labels(
         self,
-        request: aiwork_space_20210204_models.CreateProductOrdersRequest,
-    ) -> aiwork_space_20210204_models.CreateProductOrdersResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_product_orders_with_options(request, headers, runtime)
+        return self.create_model_version_labels_with_options(model_id, version_name, request, headers, runtime)
 
-    async def create_product_orders_async(
+    async def create_model_version_labels_async(
         self,
-        request: aiwork_space_20210204_models.CreateProductOrdersRequest,
-    ) -> aiwork_space_20210204_models.CreateProductOrdersResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionLabelsRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_product_orders_with_options_async(request, headers, runtime)
+        return await self.create_model_version_labels_with_options_async(model_id, version_name, request, headers, runtime)
+
+    def create_model_version_release_with_options(
+        self,
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionReleaseRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateModelVersionReleaseResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.target_model_origin):
+            body['TargetModelOrigin'] = request.target_model_origin
+        if not UtilClient.is_unset(request.target_model_provider):
+            body['TargetModelProvider'] = request.target_model_provider
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateModelVersionRelease',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/release',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateModelVersionReleaseResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def create_model_version_release_with_options_async(
+        self,
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionReleaseRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateModelVersionReleaseResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.target_model_origin):
+            body['TargetModelOrigin'] = request.target_model_origin
+        if not UtilClient.is_unset(request.target_model_provider):
+            body['TargetModelProvider'] = request.target_model_provider
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateModelVersionRelease',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/release',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateModelVersionReleaseResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def create_model_version_release(
+        self,
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionReleaseRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionReleaseResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.create_model_version_release_with_options(model_id, version_name, request, headers, runtime)
+
+    async def create_model_version_release_async(
+        self,
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.CreateModelVersionReleaseRequest,
+    ) -> aiwork_space_20210204_models.CreateModelVersionReleaseResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.create_model_version_release_with_options_async(model_id, version_name, request, headers, runtime)
 
     def create_product_orders_with_options(
         self,
         request: aiwork_space_20210204_models.CreateProductOrdersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateProductOrdersResponse:
@@ -1322,23 +1624,105 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateProductOrdersResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_user(self) -> aiwork_space_20210204_models.CreateUserResponse:
+    def create_product_orders(
+        self,
+        request: aiwork_space_20210204_models.CreateProductOrdersRequest,
+    ) -> aiwork_space_20210204_models.CreateProductOrdersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_user_with_options(headers, runtime)
+        return self.create_product_orders_with_options(request, headers, runtime)
 
-    async def create_user_async(self) -> aiwork_space_20210204_models.CreateUserResponse:
+    async def create_product_orders_async(
+        self,
+        request: aiwork_space_20210204_models.CreateProductOrdersRequest,
+    ) -> aiwork_space_20210204_models.CreateProductOrdersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_user_with_options_async(headers, runtime)
+        return await self.create_product_orders_with_options_async(request, headers, runtime)
+
+    def create_service_identity_role_with_options(
+        self,
+        request: aiwork_space_20210204_models.CreateServiceIdentityRoleRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateServiceIdentityRoleResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.role_name):
+            body['RoleName'] = request.role_name
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateServiceIdentityRole',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/serviceidentityroles',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateServiceIdentityRoleResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def create_service_identity_role_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.CreateServiceIdentityRoleRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.CreateServiceIdentityRoleResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.role_name):
+            body['RoleName'] = request.role_name
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='CreateServiceIdentityRole',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/serviceidentityroles',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.CreateServiceIdentityRoleResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def create_service_identity_role(
+        self,
+        request: aiwork_space_20210204_models.CreateServiceIdentityRoleRequest,
+    ) -> aiwork_space_20210204_models.CreateServiceIdentityRoleResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.create_service_identity_role_with_options(request, headers, runtime)
+
+    async def create_service_identity_role_async(
+        self,
+        request: aiwork_space_20210204_models.CreateServiceIdentityRoleRequest,
+    ) -> aiwork_space_20210204_models.CreateServiceIdentityRoleResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.create_service_identity_role_with_options_async(request, headers, runtime)
 
     def create_user_with_options(
         self,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateUserResponse:
         req = open_api_models.OpenApiRequest(
@@ -1380,29 +1764,23 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateUserResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_workspace(
-        self,
-        request: aiwork_space_20210204_models.CreateWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.CreateWorkspaceResponse:
+    def create_user(self) -> aiwork_space_20210204_models.CreateUserResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_workspace_with_options(request, headers, runtime)
+        return self.create_user_with_options(headers, runtime)
 
-    async def create_workspace_async(
-        self,
-        request: aiwork_space_20210204_models.CreateWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.CreateWorkspaceResponse:
+    async def create_user_async(self) -> aiwork_space_20210204_models.CreateUserResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_workspace_with_options_async(request, headers, runtime)
+        return await self.create_user_with_options_async(headers, runtime)
 
     def create_workspace_with_options(
         self,
         request: aiwork_space_20210204_models.CreateWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateWorkspaceResponse:
@@ -1468,53 +1846,52 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_workspace_resource(
+    def create_workspace(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
+        request: aiwork_space_20210204_models.CreateWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.CreateWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_workspace_resource_with_options(workspace_id, request, headers, runtime)
+        return self.create_workspace_with_options(request, headers, runtime)
 
-    async def create_workspace_resource_async(
+    async def create_workspace_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
+        request: aiwork_space_20210204_models.CreateWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.CreateWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_workspace_resource_with_options_async(workspace_id, request, headers, runtime)
+        return await self.create_workspace_with_options_async(request, headers, runtime)
 
     def create_workspace_resource_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
+        if not UtilClient.is_unset(request.option):
+            body['Option'] = request.option
         if not UtilClient.is_unset(request.resources):
             body['Resources'] = request.resources
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1526,69 +1903,71 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
+        if not UtilClient.is_unset(request.option):
+            body['Option'] = request.option
         if not UtilClient.is_unset(request.resources):
             body['Resources'] = request.resources
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='CreateWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='POST',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.CreateWorkspaceResourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_code_source(
+    def create_workspace_resource(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_code_source_with_options(code_source_id, headers, runtime)
+        return self.create_workspace_resource_with_options(workspace_id, request, headers, runtime)
 
-    async def delete_code_source_async(
+    async def create_workspace_resource_async(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.CreateWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.CreateWorkspaceResourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_code_source_with_options_async(code_source_id, headers, runtime)
+        return await self.create_workspace_resource_with_options_async(workspace_id, request, headers, runtime)
 
     def delete_code_source_with_options(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1598,69 +1977,64 @@
 
     async def delete_code_source_with_options_async(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteCodeSourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_config(
+    def delete_code_source(
         self,
-        workspace_id: str,
-        config_key: str,
-    ) -> aiwork_space_20210204_models.DeleteConfigResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_config_with_options(workspace_id, config_key, headers, runtime)
+        return self.delete_code_source_with_options(code_source_id, headers, runtime)
 
-    async def delete_config_async(
+    async def delete_code_source_async(
         self,
-        workspace_id: str,
-        config_key: str,
-    ) -> aiwork_space_20210204_models.DeleteConfigResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.DeleteCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_config_with_options_async(workspace_id, config_key, headers, runtime)
+        return await self.delete_code_source_with_options_async(code_source_id, headers, runtime)
 
     def delete_config_with_options(
         self,
         workspace_id: str,
         config_key: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteConfigResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        config_key = OpenApiUtilClient.get_encode_param(config_key)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteConfig',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs/{config_key}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs/{OpenApiUtilClient.get_encode_param(config_key)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1671,66 +2045,65 @@
     async def delete_config_with_options_async(
         self,
         workspace_id: str,
         config_key: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteConfigResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        config_key = OpenApiUtilClient.get_encode_param(config_key)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteConfig',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs/{config_key}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs/{OpenApiUtilClient.get_encode_param(config_key)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteConfigResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_dataset(
+    def delete_config(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
+        workspace_id: str,
+        config_key: str,
+    ) -> aiwork_space_20210204_models.DeleteConfigResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_dataset_with_options(dataset_id, headers, runtime)
+        return self.delete_config_with_options(workspace_id, config_key, headers, runtime)
 
-    async def delete_dataset_async(
+    async def delete_config_async(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
+        workspace_id: str,
+        config_key: str,
+    ) -> aiwork_space_20210204_models.DeleteConfigResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_dataset_with_options_async(dataset_id, headers, runtime)
+        return await self.delete_config_with_options_async(workspace_id, config_key, headers, runtime)
 
     def delete_dataset_with_options(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1740,73 +2113,71 @@
 
     async def delete_dataset_with_options_async(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteDatasetResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_dataset_labels(
+    def delete_dataset(
         self,
         dataset_id: str,
-        request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_dataset_labels_with_options(dataset_id, request, headers, runtime)
+        return self.delete_dataset_with_options(dataset_id, headers, runtime)
 
-    async def delete_dataset_labels_async(
+    async def delete_dataset_async(
         self,
         dataset_id: str,
-        request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_dataset_labels_with_options_async(dataset_id, request, headers, runtime)
+        return await self.delete_dataset_with_options_async(dataset_id, headers, runtime)
 
     def delete_dataset_labels_with_options(
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteDatasetLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/labels',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1818,77 +2189,77 @@
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteDatasetLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/labels',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteDatasetLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_members(
+    def delete_dataset_labels(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.DeleteMembersRequest,
-    ) -> aiwork_space_20210204_models.DeleteMembersResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_members_with_options(workspace_id, request, headers, runtime)
+        return self.delete_dataset_labels_with_options(dataset_id, request, headers, runtime)
 
-    async def delete_members_async(
+    async def delete_dataset_labels_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.DeleteMembersRequest,
-    ) -> aiwork_space_20210204_models.DeleteMembersResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.DeleteDatasetLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteDatasetLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_members_with_options_async(workspace_id, request, headers, runtime)
+        return await self.delete_dataset_labels_with_options_async(dataset_id, request, headers, runtime)
 
     def delete_members_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.DeleteMembersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteMembersResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.member_ids):
             query['MemberIds'] = request.member_ids
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteMembers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1900,69 +2271,69 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.DeleteMembersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteMembersResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.member_ids):
             query['MemberIds'] = request.member_ids
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteMembers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteMembersResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_model(
+    def delete_members(
         self,
-        model_id: str,
-    ) -> aiwork_space_20210204_models.DeleteModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.DeleteMembersRequest,
+    ) -> aiwork_space_20210204_models.DeleteMembersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_model_with_options(model_id, headers, runtime)
+        return self.delete_members_with_options(workspace_id, request, headers, runtime)
 
-    async def delete_model_async(
+    async def delete_members_async(
         self,
-        model_id: str,
-    ) -> aiwork_space_20210204_models.DeleteModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.DeleteMembersRequest,
+    ) -> aiwork_space_20210204_models.DeleteMembersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_model_with_options_async(model_id, headers, runtime)
+        return await self.delete_members_with_options_async(workspace_id, request, headers, runtime)
 
     def delete_model_with_options(
         self,
         model_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -1972,73 +2343,151 @@
 
     async def delete_model_with_options_async(
         self,
         model_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteModelResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_model_labels(
+    def delete_model(
         self,
         model_id: str,
-        request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_model_labels_with_options(model_id, request, headers, runtime)
+        return self.delete_model_with_options(model_id, headers, runtime)
 
-    async def delete_model_labels_async(
+    async def delete_model_async(
         self,
         model_id: str,
-        request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_model_labels_with_options_async(model_id, request, headers, runtime)
+        return await self.delete_model_with_options_async(model_id, headers, runtime)
+
+    def delete_model_domain_with_options(
+        self,
+        model_domain_id: str,
+        request: aiwork_space_20210204_models.DeleteModelDomainRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.DeleteModelDomainResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.model_task_ids):
+            query['ModelTaskIds'] = request.model_task_ids
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='DeleteModelDomain',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains/{OpenApiUtilClient.get_encode_param(model_domain_id)}',
+            method='DELETE',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.DeleteModelDomainResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def delete_model_domain_with_options_async(
+        self,
+        model_domain_id: str,
+        request: aiwork_space_20210204_models.DeleteModelDomainRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.DeleteModelDomainResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.model_task_ids):
+            query['ModelTaskIds'] = request.model_task_ids
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='DeleteModelDomain',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains/{OpenApiUtilClient.get_encode_param(model_domain_id)}',
+            method='DELETE',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.DeleteModelDomainResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def delete_model_domain(
+        self,
+        model_domain_id: str,
+        request: aiwork_space_20210204_models.DeleteModelDomainRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelDomainResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.delete_model_domain_with_options(model_domain_id, request, headers, runtime)
+
+    async def delete_model_domain_async(
+        self,
+        model_domain_id: str,
+        request: aiwork_space_20210204_models.DeleteModelDomainRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelDomainResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.delete_model_domain_with_options_async(model_domain_id, request, headers, runtime)
 
     def delete_model_labels_with_options(
         self,
         model_id: str,
         request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteModelLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2050,73 +2499,72 @@
         self,
         model_id: str,
         request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteModelLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteModelLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_model_version(
+    def delete_model_labels(
         self,
         model_id: str,
-        version_name: str,
-    ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
+        request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_model_version_with_options(model_id, version_name, headers, runtime)
+        return self.delete_model_labels_with_options(model_id, request, headers, runtime)
 
-    async def delete_model_version_async(
+    async def delete_model_labels_async(
         self,
         model_id: str,
-        version_name: str,
-    ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
+        request: aiwork_space_20210204_models.DeleteModelLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_model_version_with_options_async(model_id, version_name, headers, runtime)
+        return await self.delete_model_labels_with_options_async(model_id, request, headers, runtime)
 
     def delete_model_version_with_options(
         self,
         model_id: str,
         version_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2127,78 +2575,74 @@
     async def delete_model_version_with_options_async(
         self,
         model_id: str,
         version_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteModelVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_model_version_labels(
+    def delete_model_version(
         self,
         model_id: str,
         version_name: str,
-        request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_model_version_labels_with_options(model_id, version_name, request, headers, runtime)
+        return self.delete_model_version_with_options(model_id, version_name, headers, runtime)
 
-    async def delete_model_version_labels_async(
+    async def delete_model_version_async(
         self,
         model_id: str,
         version_name: str,
-        request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
-    ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
+    ) -> aiwork_space_20210204_models.DeleteModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_model_version_labels_with_options_async(model_id, version_name, request, headers, runtime)
+        return await self.delete_model_version_with_options_async(model_id, version_name, headers, runtime)
 
     def delete_model_version_labels_with_options(
         self,
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteModelVersionLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2211,70 +2655,73 @@
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         query = {}
         if not UtilClient.is_unset(request.keys):
             query['Keys'] = request.keys
+        if not UtilClient.is_unset(request.label_keys):
+            query['LabelKeys'] = request.label_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteModelVersionLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}/labels',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}/labels',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteModelVersionLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_workspace(
+    def delete_model_version_labels(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_workspace_with_options(workspace_id, headers, runtime)
+        return self.delete_model_version_labels_with_options(model_id, version_name, request, headers, runtime)
 
-    async def delete_workspace_async(
+    async def delete_model_version_labels_async(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.DeleteModelVersionLabelsRequest,
+    ) -> aiwork_space_20210204_models.DeleteModelVersionLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_workspace_with_options_async(workspace_id, headers, runtime)
+        return await self.delete_model_version_labels_with_options_async(model_id, version_name, request, headers, runtime)
 
     def delete_workspace_with_options(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2284,153 +2731,155 @@
 
     async def delete_workspace_with_options_async(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='DeleteWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_workspace_resource(
+    def delete_workspace(
         self,
-        resource_group_name: str,
         workspace_id: str,
-        request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
+    ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_workspace_resource_with_options(resource_group_name, workspace_id, request, headers, runtime)
+        return self.delete_workspace_with_options(workspace_id, headers, runtime)
 
-    async def delete_workspace_resource_async(
+    async def delete_workspace_async(
         self,
-        resource_group_name: str,
         workspace_id: str,
-        request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
+    ) -> aiwork_space_20210204_models.DeleteWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_workspace_resource_with_options_async(resource_group_name, workspace_id, request, headers, runtime)
+        return await self.delete_workspace_with_options_async(workspace_id, headers, runtime)
 
     def delete_workspace_resource_with_options(
         self,
-        resource_group_name: str,
         workspace_id: str,
         request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        resource_group_name = OpenApiUtilClient.get_encode_param(resource_group_name)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
+        if not UtilClient.is_unset(request.group_name):
+            query['GroupName'] = request.group_name
+        if not UtilClient.is_unset(request.option):
+            query['Option'] = request.option
         if not UtilClient.is_unset(request.product_type):
             query['ProductType'] = request.product_type
+        if not UtilClient.is_unset(request.resource_type):
+            query['ResourceType'] = request.resource_type
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources/{resource_group_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteWorkspaceResourceResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def delete_workspace_resource_with_options_async(
         self,
-        resource_group_name: str,
         workspace_id: str,
         request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        resource_group_name = OpenApiUtilClient.get_encode_param(resource_group_name)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
+        if not UtilClient.is_unset(request.group_name):
+            query['GroupName'] = request.group_name
+        if not UtilClient.is_unset(request.option):
+            query['Option'] = request.option
         if not UtilClient.is_unset(request.product_type):
             query['ProductType'] = request.product_type
+        if not UtilClient.is_unset(request.resource_type):
+            query['ResourceType'] = request.resource_type
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='DeleteWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources/{resource_group_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.DeleteWorkspaceResourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_code_source(
+    def delete_workspace_resource(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_code_source_with_options(code_source_id, headers, runtime)
+        return self.delete_workspace_resource_with_options(workspace_id, request, headers, runtime)
 
-    async def get_code_source_async(
+    async def delete_workspace_resource_async(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.DeleteWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.DeleteWorkspaceResourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_code_source_with_options_async(code_source_id, headers, runtime)
+        return await self.delete_workspace_resource_with_options_async(workspace_id, request, headers, runtime)
 
     def get_code_source_with_options(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2440,49 +2889,48 @@
 
     async def get_code_source_with_options_async(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetCodeSourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_code_sources_statistics(
+    def get_code_source(
         self,
-        request: aiwork_space_20210204_models.GetCodeSourcesStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_code_sources_statistics_with_options(request, headers, runtime)
+        return self.get_code_source_with_options(code_source_id, headers, runtime)
 
-    async def get_code_sources_statistics_async(
+    async def get_code_source_async(
         self,
-        request: aiwork_space_20210204_models.GetCodeSourcesStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.GetCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_code_sources_statistics_with_options_async(request, headers, runtime)
+        return await self.get_code_source_with_options_async(code_source_id, headers, runtime)
 
     def get_code_sources_statistics_with_options(
         self,
         request: aiwork_space_20210204_models.GetCodeSourcesStatisticsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse:
@@ -2536,45 +2984,44 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_dataset(
+    def get_code_sources_statistics(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.GetDatasetResponse:
+        request: aiwork_space_20210204_models.GetCodeSourcesStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_dataset_with_options(dataset_id, headers, runtime)
+        return self.get_code_sources_statistics_with_options(request, headers, runtime)
 
-    async def get_dataset_async(
+    async def get_code_sources_statistics_async(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.GetDatasetResponse:
+        request: aiwork_space_20210204_models.GetCodeSourcesStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetCodeSourcesStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_dataset_with_options_async(dataset_id, headers, runtime)
+        return await self.get_code_sources_statistics_with_options_async(request, headers, runtime)
 
     def get_dataset_with_options(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2584,49 +3031,48 @@
 
     async def get_dataset_with_options_async(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetDatasetResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_datasets_statistics(
+    def get_dataset(
         self,
-        request: aiwork_space_20210204_models.GetDatasetsStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetDatasetsStatisticsResponse:
+        dataset_id: str,
+    ) -> aiwork_space_20210204_models.GetDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_datasets_statistics_with_options(request, headers, runtime)
+        return self.get_dataset_with_options(dataset_id, headers, runtime)
 
-    async def get_datasets_statistics_async(
+    async def get_dataset_async(
         self,
-        request: aiwork_space_20210204_models.GetDatasetsStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetDatasetsStatisticsResponse:
+        dataset_id: str,
+    ) -> aiwork_space_20210204_models.GetDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_datasets_statistics_with_options_async(request, headers, runtime)
+        return await self.get_dataset_with_options_async(dataset_id, headers, runtime)
 
     def get_datasets_statistics_with_options(
         self,
         request: aiwork_space_20210204_models.GetDatasetsStatisticsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetDatasetsStatisticsResponse:
@@ -2680,29 +3126,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetDatasetsStatisticsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_default_workspace(
+    def get_datasets_statistics(
         self,
-        request: aiwork_space_20210204_models.GetDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.GetDefaultWorkspaceResponse:
+        request: aiwork_space_20210204_models.GetDatasetsStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetDatasetsStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_default_workspace_with_options(request, headers, runtime)
+        return self.get_datasets_statistics_with_options(request, headers, runtime)
 
-    async def get_default_workspace_async(
+    async def get_datasets_statistics_async(
         self,
-        request: aiwork_space_20210204_models.GetDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.GetDefaultWorkspaceResponse:
+        request: aiwork_space_20210204_models.GetDatasetsStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetDatasetsStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_default_workspace_with_options_async(request, headers, runtime)
+        return await self.get_datasets_statistics_with_options_async(request, headers, runtime)
 
     def get_default_workspace_with_options(
         self,
         request: aiwork_space_20210204_models.GetDefaultWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetDefaultWorkspaceResponse:
@@ -2756,53 +3202,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetDefaultWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_image(
+    def get_default_workspace(
         self,
-        image_id: str,
-        request: aiwork_space_20210204_models.GetImageRequest,
-    ) -> aiwork_space_20210204_models.GetImageResponse:
+        request: aiwork_space_20210204_models.GetDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.GetDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_image_with_options(image_id, request, headers, runtime)
+        return self.get_default_workspace_with_options(request, headers, runtime)
 
-    async def get_image_async(
+    async def get_default_workspace_async(
         self,
-        image_id: str,
-        request: aiwork_space_20210204_models.GetImageRequest,
-    ) -> aiwork_space_20210204_models.GetImageResponse:
+        request: aiwork_space_20210204_models.GetDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.GetDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_image_with_options_async(image_id, request, headers, runtime)
+        return await self.get_default_workspace_with_options_async(request, headers, runtime)
 
     def get_image_with_options(
         self,
         image_id: str,
         request: aiwork_space_20210204_models.GetImageRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetImageResponse:
         UtilClient.validate_model(request)
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         query = {}
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2814,53 +3257,54 @@
         self,
         image_id: str,
         request: aiwork_space_20210204_models.GetImageRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetImageResponse:
         UtilClient.validate_model(request)
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         query = {}
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetImageResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_images_statistics(
+    def get_image(
         self,
-        request: aiwork_space_20210204_models.GetImagesStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetImagesStatisticsResponse:
+        image_id: str,
+        request: aiwork_space_20210204_models.GetImageRequest,
+    ) -> aiwork_space_20210204_models.GetImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_images_statistics_with_options(request, headers, runtime)
+        return self.get_image_with_options(image_id, request, headers, runtime)
 
-    async def get_images_statistics_async(
+    async def get_image_async(
         self,
-        request: aiwork_space_20210204_models.GetImagesStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetImagesStatisticsResponse:
+        image_id: str,
+        request: aiwork_space_20210204_models.GetImageRequest,
+    ) -> aiwork_space_20210204_models.GetImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_images_statistics_with_options_async(request, headers, runtime)
+        return await self.get_image_with_options_async(image_id, request, headers, runtime)
 
     def get_images_statistics_with_options(
         self,
         request: aiwork_space_20210204_models.GetImagesStatisticsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetImagesStatisticsResponse:
@@ -2914,53 +3358,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetImagesStatisticsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_member(
+    def get_images_statistics(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.GetMemberRequest,
-    ) -> aiwork_space_20210204_models.GetMemberResponse:
+        request: aiwork_space_20210204_models.GetImagesStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetImagesStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_member_with_options(workspace_id, request, headers, runtime)
+        return self.get_images_statistics_with_options(request, headers, runtime)
 
-    async def get_member_async(
+    async def get_images_statistics_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.GetMemberRequest,
-    ) -> aiwork_space_20210204_models.GetMemberResponse:
+        request: aiwork_space_20210204_models.GetImagesStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetImagesStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_member_with_options_async(workspace_id, request, headers, runtime)
+        return await self.get_images_statistics_with_options_async(request, headers, runtime)
 
     def get_member_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.GetMemberRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetMemberResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.user_id):
             query['UserId'] = request.user_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetMember',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/member',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/member',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -2972,69 +3413,69 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.GetMemberRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetMemberResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.user_id):
             query['UserId'] = request.user_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetMember',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/member',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/member',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetMemberResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_model(
+    def get_member(
         self,
-        model_id: str,
-    ) -> aiwork_space_20210204_models.GetModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.GetMemberRequest,
+    ) -> aiwork_space_20210204_models.GetMemberResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_model_with_options(model_id, headers, runtime)
+        return self.get_member_with_options(workspace_id, request, headers, runtime)
 
-    async def get_model_async(
+    async def get_member_async(
         self,
-        model_id: str,
-    ) -> aiwork_space_20210204_models.GetModelResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.GetMemberRequest,
+    ) -> aiwork_space_20210204_models.GetMemberResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_model_with_options_async(model_id, headers, runtime)
+        return await self.get_member_with_options_async(workspace_id, request, headers, runtime)
 
     def get_model_with_options(
         self,
         model_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetModelResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -3044,69 +3485,64 @@
 
     async def get_model_with_options_async(
         self,
         model_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetModelResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetModelResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_model_version(
+    def get_model(
         self,
         model_id: str,
-        version_name: str,
-    ) -> aiwork_space_20210204_models.GetModelVersionResponse:
+    ) -> aiwork_space_20210204_models.GetModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_model_version_with_options(model_id, version_name, headers, runtime)
+        return self.get_model_with_options(model_id, headers, runtime)
 
-    async def get_model_version_async(
+    async def get_model_async(
         self,
         model_id: str,
-        version_name: str,
-    ) -> aiwork_space_20210204_models.GetModelVersionResponse:
+    ) -> aiwork_space_20210204_models.GetModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_model_version_with_options_async(model_id, version_name, headers, runtime)
+        return await self.get_model_with_options_async(model_id, headers, runtime)
 
     def get_model_version_with_options(
         self,
         model_id: str,
         version_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetModelVersionResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -3117,80 +3553,74 @@
     async def get_model_version_with_options_async(
         self,
         model_id: str,
         version_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetModelVersionResponse:
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='GetModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetModelVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_permission(
+    def get_model_version(
         self,
-        workspace_id: str,
-        permission_code: str,
-        request: aiwork_space_20210204_models.GetPermissionRequest,
-    ) -> aiwork_space_20210204_models.GetPermissionResponse:
+        model_id: str,
+        version_name: str,
+    ) -> aiwork_space_20210204_models.GetModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_permission_with_options(workspace_id, permission_code, request, headers, runtime)
+        return self.get_model_version_with_options(model_id, version_name, headers, runtime)
 
-    async def get_permission_async(
+    async def get_model_version_async(
         self,
-        workspace_id: str,
-        permission_code: str,
-        request: aiwork_space_20210204_models.GetPermissionRequest,
-    ) -> aiwork_space_20210204_models.GetPermissionResponse:
+        model_id: str,
+        version_name: str,
+    ) -> aiwork_space_20210204_models.GetModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_permission_with_options_async(workspace_id, permission_code, request, headers, runtime)
+        return await self.get_model_version_with_options_async(model_id, version_name, headers, runtime)
 
     def get_permission_with_options(
         self,
         workspace_id: str,
         permission_code: str,
         request: aiwork_space_20210204_models.GetPermissionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetPermissionResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        permission_code = OpenApiUtilClient.get_encode_param(permission_code)
         query = {}
         if not UtilClient.is_unset(request.accessibility):
             query['Accessibility'] = request.accessibility
         if not UtilClient.is_unset(request.creator):
             query['Creator'] = request.creator
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetPermission',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/permissions/{permission_code}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/permissions/{OpenApiUtilClient.get_encode_param(permission_code)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -3203,56 +3633,58 @@
         workspace_id: str,
         permission_code: str,
         request: aiwork_space_20210204_models.GetPermissionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetPermissionResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        permission_code = OpenApiUtilClient.get_encode_param(permission_code)
         query = {}
         if not UtilClient.is_unset(request.accessibility):
             query['Accessibility'] = request.accessibility
         if not UtilClient.is_unset(request.creator):
             query['Creator'] = request.creator
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetPermission',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/permissions/{permission_code}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/permissions/{OpenApiUtilClient.get_encode_param(permission_code)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetPermissionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_role_statistics(
+    def get_permission(
         self,
-        request: aiwork_space_20210204_models.GetRoleStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetRoleStatisticsResponse:
+        workspace_id: str,
+        permission_code: str,
+        request: aiwork_space_20210204_models.GetPermissionRequest,
+    ) -> aiwork_space_20210204_models.GetPermissionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_role_statistics_with_options(request, headers, runtime)
+        return self.get_permission_with_options(workspace_id, permission_code, request, headers, runtime)
 
-    async def get_role_statistics_async(
+    async def get_permission_async(
         self,
-        request: aiwork_space_20210204_models.GetRoleStatisticsRequest,
-    ) -> aiwork_space_20210204_models.GetRoleStatisticsResponse:
+        workspace_id: str,
+        permission_code: str,
+        request: aiwork_space_20210204_models.GetPermissionRequest,
+    ) -> aiwork_space_20210204_models.GetPermissionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_role_statistics_with_options_async(request, headers, runtime)
+        return await self.get_permission_with_options_async(workspace_id, permission_code, request, headers, runtime)
 
     def get_role_statistics_with_options(
         self,
         request: aiwork_space_20210204_models.GetRoleStatisticsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetRoleStatisticsResponse:
@@ -3306,53 +3738,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetRoleStatisticsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_workspace(
+    def get_role_statistics(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.GetWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
+        request: aiwork_space_20210204_models.GetRoleStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetRoleStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_workspace_with_options(workspace_id, request, headers, runtime)
+        return self.get_role_statistics_with_options(request, headers, runtime)
 
-    async def get_workspace_async(
+    async def get_role_statistics_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.GetWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
+        request: aiwork_space_20210204_models.GetRoleStatisticsRequest,
+    ) -> aiwork_space_20210204_models.GetRoleStatisticsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_workspace_with_options_async(workspace_id, request, headers, runtime)
+        return await self.get_role_statistics_with_options_async(request, headers, runtime)
 
     def get_workspace_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.GetWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -3364,53 +3793,54 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.GetWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.GetWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_code_sources(
+    def get_workspace(
         self,
-        request: aiwork_space_20210204_models.ListCodeSourcesRequest,
-    ) -> aiwork_space_20210204_models.ListCodeSourcesResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.GetWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_code_sources_with_options(request, headers, runtime)
+        return self.get_workspace_with_options(workspace_id, request, headers, runtime)
 
-    async def list_code_sources_async(
+    async def get_workspace_async(
         self,
-        request: aiwork_space_20210204_models.ListCodeSourcesRequest,
-    ) -> aiwork_space_20210204_models.ListCodeSourcesResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.GetWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.GetWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_code_sources_with_options_async(request, headers, runtime)
+        return await self.get_workspace_with_options_async(workspace_id, request, headers, runtime)
 
     def list_code_sources_with_options(
         self,
         request: aiwork_space_20210204_models.ListCodeSourcesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListCodeSourcesResponse:
@@ -3484,53 +3914,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListCodeSourcesResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_configs(
+    def list_code_sources(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListConfigsRequest,
-    ) -> aiwork_space_20210204_models.ListConfigsResponse:
+        request: aiwork_space_20210204_models.ListCodeSourcesRequest,
+    ) -> aiwork_space_20210204_models.ListCodeSourcesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_configs_with_options(workspace_id, request, headers, runtime)
+        return self.list_code_sources_with_options(request, headers, runtime)
 
-    async def list_configs_async(
+    async def list_code_sources_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListConfigsRequest,
-    ) -> aiwork_space_20210204_models.ListConfigsResponse:
+        request: aiwork_space_20210204_models.ListCodeSourcesRequest,
+    ) -> aiwork_space_20210204_models.ListCodeSourcesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_configs_with_options_async(workspace_id, request, headers, runtime)
+        return await self.list_code_sources_with_options_async(request, headers, runtime)
 
     def list_configs_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListConfigsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListConfigsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.config_keys):
             query['ConfigKeys'] = request.config_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListConfigs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -3542,80 +3969,85 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListConfigsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListConfigsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.config_keys):
             query['ConfigKeys'] = request.config_keys
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListConfigs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListConfigsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_datasets(
+    def list_configs(
         self,
-        request: aiwork_space_20210204_models.ListDatasetsRequest,
-    ) -> aiwork_space_20210204_models.ListDatasetsResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.ListConfigsRequest,
+    ) -> aiwork_space_20210204_models.ListConfigsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_datasets_with_options(request, headers, runtime)
+        return self.list_configs_with_options(workspace_id, request, headers, runtime)
 
-    async def list_datasets_async(
+    async def list_configs_async(
         self,
-        request: aiwork_space_20210204_models.ListDatasetsRequest,
-    ) -> aiwork_space_20210204_models.ListDatasetsResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.ListConfigsRequest,
+    ) -> aiwork_space_20210204_models.ListConfigsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_datasets_with_options_async(request, headers, runtime)
+        return await self.list_configs_with_options_async(workspace_id, request, headers, runtime)
 
     def list_datasets_with_options(
         self,
         request: aiwork_space_20210204_models.ListDatasetsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListDatasetsResponse:
         UtilClient.validate_model(request)
         query = {}
         if not UtilClient.is_unset(request.data_source_types):
             query['DataSourceTypes'] = request.data_source_types
         if not UtilClient.is_unset(request.data_types):
             query['DataTypes'] = request.data_types
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
         if not UtilClient.is_unset(request.label_keys):
             query['LabelKeys'] = request.label_keys
         if not UtilClient.is_unset(request.label_values):
             query['LabelValues'] = request.label_values
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.properties):
             query['Properties'] = request.properties
+        if not UtilClient.is_unset(request.source_id):
+            query['SourceId'] = request.source_id
         if not UtilClient.is_unset(request.source_types):
             query['SourceTypes'] = request.source_types
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -3644,28 +4076,32 @@
     ) -> aiwork_space_20210204_models.ListDatasetsResponse:
         UtilClient.validate_model(request)
         query = {}
         if not UtilClient.is_unset(request.data_source_types):
             query['DataSourceTypes'] = request.data_source_types
         if not UtilClient.is_unset(request.data_types):
             query['DataTypes'] = request.data_types
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
         if not UtilClient.is_unset(request.label_keys):
             query['LabelKeys'] = request.label_keys
         if not UtilClient.is_unset(request.label_values):
             query['LabelValues'] = request.label_values
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.properties):
             query['Properties'] = request.properties
+        if not UtilClient.is_unset(request.source_id):
+            query['SourceId'] = request.source_id
         if not UtilClient.is_unset(request.source_types):
             query['SourceTypes'] = request.source_types
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -3682,29 +4118,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListDatasetsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_features(
+    def list_datasets(
         self,
-        request: aiwork_space_20210204_models.ListFeaturesRequest,
-    ) -> aiwork_space_20210204_models.ListFeaturesResponse:
+        request: aiwork_space_20210204_models.ListDatasetsRequest,
+    ) -> aiwork_space_20210204_models.ListDatasetsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_features_with_options(request, headers, runtime)
+        return self.list_datasets_with_options(request, headers, runtime)
 
-    async def list_features_async(
+    async def list_datasets_async(
         self,
-        request: aiwork_space_20210204_models.ListFeaturesRequest,
-    ) -> aiwork_space_20210204_models.ListFeaturesResponse:
+        request: aiwork_space_20210204_models.ListDatasetsRequest,
+    ) -> aiwork_space_20210204_models.ListDatasetsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_features_with_options_async(request, headers, runtime)
+        return await self.list_datasets_with_options_async(request, headers, runtime)
 
     def list_features_with_options(
         self,
         request: aiwork_space_20210204_models.ListFeaturesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListFeaturesResponse:
@@ -3758,37 +4194,35 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListFeaturesResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_global_permissions(
+    def list_features(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
+        request: aiwork_space_20210204_models.ListFeaturesRequest,
+    ) -> aiwork_space_20210204_models.ListFeaturesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_global_permissions_with_options(workspace_id, headers, runtime)
+        return self.list_features_with_options(request, headers, runtime)
 
-    async def list_global_permissions_async(
+    async def list_features_async(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
+        request: aiwork_space_20210204_models.ListFeaturesRequest,
+    ) -> aiwork_space_20210204_models.ListFeaturesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_global_permissions_with_options_async(workspace_id, headers, runtime)
+        return await self.list_features_with_options_async(request, headers, runtime)
 
     def list_global_permissions_with_options(
         self,
-        workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListGlobalPermissions',
             version='2021-02-04',
             protocol='HTTPS',
@@ -3802,19 +4236,17 @@
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListGlobalPermissionsResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def list_global_permissions_with_options_async(
         self,
-        workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListGlobalPermissions',
             version='2021-02-04',
             protocol='HTTPS',
@@ -3826,29 +4258,23 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListGlobalPermissionsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_image_labels(
-        self,
-        request: aiwork_space_20210204_models.ListImageLabelsRequest,
-    ) -> aiwork_space_20210204_models.ListImageLabelsResponse:
+    def list_global_permissions(self) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_image_labels_with_options(request, headers, runtime)
+        return self.list_global_permissions_with_options(headers, runtime)
 
-    async def list_image_labels_async(
-        self,
-        request: aiwork_space_20210204_models.ListImageLabelsRequest,
-    ) -> aiwork_space_20210204_models.ListImageLabelsResponse:
+    async def list_global_permissions_async(self) -> aiwork_space_20210204_models.ListGlobalPermissionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_image_labels_with_options_async(request, headers, runtime)
+        return await self.list_global_permissions_with_options_async(headers, runtime)
 
     def list_image_labels_with_options(
         self,
         request: aiwork_space_20210204_models.ListImageLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListImageLabelsResponse:
@@ -3918,52 +4344,56 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListImageLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_images(
+    def list_image_labels(
         self,
-        request: aiwork_space_20210204_models.ListImagesRequest,
-    ) -> aiwork_space_20210204_models.ListImagesResponse:
+        request: aiwork_space_20210204_models.ListImageLabelsRequest,
+    ) -> aiwork_space_20210204_models.ListImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_images_with_options(request, headers, runtime)
+        return self.list_image_labels_with_options(request, headers, runtime)
 
-    async def list_images_async(
+    async def list_image_labels_async(
         self,
-        request: aiwork_space_20210204_models.ListImagesRequest,
-    ) -> aiwork_space_20210204_models.ListImagesResponse:
+        request: aiwork_space_20210204_models.ListImageLabelsRequest,
+    ) -> aiwork_space_20210204_models.ListImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_images_with_options_async(request, headers, runtime)
+        return await self.list_image_labels_with_options_async(request, headers, runtime)
 
     def list_images_with_options(
         self,
         request: aiwork_space_20210204_models.ListImagesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListImagesResponse:
         UtilClient.validate_model(request)
         query = {}
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
-        if not UtilClient.is_unset(request.operator_create):
-            query['OperatorCreate'] = request.operator_create
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.parent_user_id):
+            query['ParentUserId'] = request.parent_user_id
+        if not UtilClient.is_unset(request.query):
+            query['Query'] = request.query
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.user_id):
+            query['UserId'] = request.user_id
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -3992,24 +4422,28 @@
     ) -> aiwork_space_20210204_models.ListImagesResponse:
         UtilClient.validate_model(request)
         query = {}
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
-        if not UtilClient.is_unset(request.operator_create):
-            query['OperatorCreate'] = request.operator_create
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.parent_user_id):
+            query['ParentUserId'] = request.parent_user_id
+        if not UtilClient.is_unset(request.query):
+            query['Query'] = request.query
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.user_id):
+            query['UserId'] = request.user_id
         if not UtilClient.is_unset(request.verbose):
             query['Verbose'] = request.verbose
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -4026,41 +4460,38 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListImagesResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_members(
+    def list_images(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListMembersRequest,
-    ) -> aiwork_space_20210204_models.ListMembersResponse:
+        request: aiwork_space_20210204_models.ListImagesRequest,
+    ) -> aiwork_space_20210204_models.ListImagesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_members_with_options(workspace_id, request, headers, runtime)
+        return self.list_images_with_options(request, headers, runtime)
 
-    async def list_members_async(
+    async def list_images_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListMembersRequest,
-    ) -> aiwork_space_20210204_models.ListMembersResponse:
+        request: aiwork_space_20210204_models.ListImagesRequest,
+    ) -> aiwork_space_20210204_models.ListImagesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_members_with_options_async(workspace_id, request, headers, runtime)
+        return await self.list_images_with_options_async(request, headers, runtime)
 
     def list_members_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListMembersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListMembersResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.member_name):
             query['MemberName'] = request.member_name
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
@@ -4070,15 +4501,15 @@
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListMembers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -4090,15 +4521,14 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListMembersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListMembersResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.member_name):
             query['MemberName'] = request.member_name
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
@@ -4108,79 +4538,164 @@
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListMembers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListMembersResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_model_versions(
+    def list_members(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.ListModelVersionsRequest,
-    ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.ListMembersRequest,
+    ) -> aiwork_space_20210204_models.ListMembersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_model_versions_with_options(model_id, request, headers, runtime)
+        return self.list_members_with_options(workspace_id, request, headers, runtime)
 
-    async def list_model_versions_async(
+    async def list_members_async(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.ListModelVersionsRequest,
-    ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.ListMembersRequest,
+    ) -> aiwork_space_20210204_models.ListMembersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_model_versions_with_options_async(model_id, request, headers, runtime)
+        return await self.list_members_with_options_async(workspace_id, request, headers, runtime)
+
+    def list_model_domains_with_options(
+        self,
+        request: aiwork_space_20210204_models.ListModelDomainsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.ListModelDomainsResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.model_domain_ids):
+            query['ModelDomainIds'] = request.model_domain_ids
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='ListModelDomains',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains',
+            method='GET',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.ListModelDomainsResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def list_model_domains_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.ListModelDomainsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.ListModelDomainsResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.model_domain_ids):
+            query['ModelDomainIds'] = request.model_domain_ids
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='ListModelDomains',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains',
+            method='GET',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.ListModelDomainsResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def list_model_domains(
+        self,
+        request: aiwork_space_20210204_models.ListModelDomainsRequest,
+    ) -> aiwork_space_20210204_models.ListModelDomainsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.list_model_domains_with_options(request, headers, runtime)
+
+    async def list_model_domains_async(
+        self,
+        request: aiwork_space_20210204_models.ListModelDomainsRequest,
+    ) -> aiwork_space_20210204_models.ListModelDomainsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.list_model_domains_with_options_async(request, headers, runtime)
 
     def list_model_versions_with_options(
         self,
         model_id: str,
         request: aiwork_space_20210204_models.ListModelVersionsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         query = {}
+        if not UtilClient.is_unset(request.approval_status):
+            query['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.format_type):
             query['FormatType'] = request.format_type
         if not UtilClient.is_unset(request.framework_type):
             query['FrameworkType'] = request.framework_type
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
+        if not UtilClient.is_unset(request.label_string):
+            query['LabelString'] = request.label_string
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.versionl_name):
-            query['VersionlName'] = request.versionl_name
+        if not UtilClient.is_unset(request.source_id):
+            query['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            query['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.version_name):
+            query['VersionName'] = request.version_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListModelVersions',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -4192,88 +4707,113 @@
         self,
         model_id: str,
         request: aiwork_space_20210204_models.ListModelVersionsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         query = {}
+        if not UtilClient.is_unset(request.approval_status):
+            query['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.format_type):
             query['FormatType'] = request.format_type
         if not UtilClient.is_unset(request.framework_type):
             query['FrameworkType'] = request.framework_type
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
+        if not UtilClient.is_unset(request.label_string):
+            query['LabelString'] = request.label_string
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.versionl_name):
-            query['VersionlName'] = request.versionl_name
+        if not UtilClient.is_unset(request.source_id):
+            query['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            query['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.version_name):
+            query['VersionName'] = request.version_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListModelVersions',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListModelVersionsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_models(
+    def list_model_versions(
         self,
-        request: aiwork_space_20210204_models.ListModelsRequest,
-    ) -> aiwork_space_20210204_models.ListModelsResponse:
+        model_id: str,
+        request: aiwork_space_20210204_models.ListModelVersionsRequest,
+    ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_models_with_options(request, headers, runtime)
+        return self.list_model_versions_with_options(model_id, request, headers, runtime)
 
-    async def list_models_async(
+    async def list_model_versions_async(
         self,
-        request: aiwork_space_20210204_models.ListModelsRequest,
-    ) -> aiwork_space_20210204_models.ListModelsResponse:
+        model_id: str,
+        request: aiwork_space_20210204_models.ListModelVersionsRequest,
+    ) -> aiwork_space_20210204_models.ListModelVersionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_models_with_options_async(request, headers, runtime)
+        return await self.list_model_versions_with_options_async(model_id, request, headers, runtime)
 
     def list_models_with_options(
         self,
         request: aiwork_space_20210204_models.ListModelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListModelsResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.domain):
+            query['Domain'] = request.domain
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
+        if not UtilClient.is_unset(request.label_string):
+            query['LabelString'] = request.label_string
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.model_name):
             query['ModelName'] = request.model_name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
+        if not UtilClient.is_unset(request.origin):
+            query['Origin'] = request.origin
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.provider):
+            query['Provider'] = request.provider
+        if not UtilClient.is_unset(request.query):
+            query['Query'] = request.query
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.task):
+            query['Task'] = request.task
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
@@ -4296,26 +4836,40 @@
         self,
         request: aiwork_space_20210204_models.ListModelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListModelsResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.domain):
+            query['Domain'] = request.domain
+        if not UtilClient.is_unset(request.label):
+            query['Label'] = request.label
+        if not UtilClient.is_unset(request.label_string):
+            query['LabelString'] = request.label_string
         if not UtilClient.is_unset(request.labels):
             query['Labels'] = request.labels
         if not UtilClient.is_unset(request.model_name):
             query['ModelName'] = request.model_name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
+        if not UtilClient.is_unset(request.origin):
+            query['Origin'] = request.origin
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.provider):
+            query['Provider'] = request.provider
+        if not UtilClient.is_unset(request.query):
+            query['Query'] = request.query
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.task):
+            query['Task'] = request.task
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
@@ -4330,41 +4884,118 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListModelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_operation_logs(
+    def list_models(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListOperationLogsRequest,
-    ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
+        request: aiwork_space_20210204_models.ListModelsRequest,
+    ) -> aiwork_space_20210204_models.ListModelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_operation_logs_with_options(workspace_id, request, headers, runtime)
+        return self.list_models_with_options(request, headers, runtime)
 
-    async def list_operation_logs_async(
+    async def list_models_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.ListOperationLogsRequest,
-    ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
+        request: aiwork_space_20210204_models.ListModelsRequest,
+    ) -> aiwork_space_20210204_models.ListModelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_operation_logs_with_options_async(workspace_id, request, headers, runtime)
+        return await self.list_models_with_options_async(request, headers, runtime)
+
+    def list_module_configs_with_options(
+        self,
+        request: aiwork_space_20210204_models.ListModuleConfigsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.ListModuleConfigsResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.module_codes):
+            query['ModuleCodes'] = request.module_codes
+        if not UtilClient.is_unset(request.region):
+            query['Region'] = request.region
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='ListModuleConfigs',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/moduleconfigs',
+            method='GET',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.ListModuleConfigsResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def list_module_configs_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.ListModuleConfigsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.ListModuleConfigsResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.module_codes):
+            query['ModuleCodes'] = request.module_codes
+        if not UtilClient.is_unset(request.region):
+            query['Region'] = request.region
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
+        )
+        params = open_api_models.Params(
+            action='ListModuleConfigs',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/moduleconfigs',
+            method='GET',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.ListModuleConfigsResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def list_module_configs(
+        self,
+        request: aiwork_space_20210204_models.ListModuleConfigsRequest,
+    ) -> aiwork_space_20210204_models.ListModuleConfigsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.list_module_configs_with_options(request, headers, runtime)
+
+    async def list_module_configs_async(
+        self,
+        request: aiwork_space_20210204_models.ListModuleConfigsRequest,
+    ) -> aiwork_space_20210204_models.ListModuleConfigsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.list_module_configs_with_options_async(request, headers, runtime)
 
     def list_operation_logs_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListOperationLogsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.entity_status):
             query['EntityStatus'] = request.entity_status
         if not UtilClient.is_unset(request.entity_types):
             query['EntityTypes'] = request.entity_types
         if not UtilClient.is_unset(request.operation_status):
             query['OperationStatus'] = request.operation_status
@@ -4382,15 +5013,15 @@
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListOperationLogs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/logs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/logs',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -4402,15 +5033,14 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.ListOperationLogsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         query = {}
         if not UtilClient.is_unset(request.entity_status):
             query['EntityStatus'] = request.entity_status
         if not UtilClient.is_unset(request.entity_types):
             query['EntityTypes'] = request.entity_types
         if not UtilClient.is_unset(request.operation_status):
             query['OperationStatus'] = request.operation_status
@@ -4428,57 +5058,58 @@
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListOperationLogs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/logs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/logs',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListOperationLogsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_permissions(
+    def list_operation_logs(
         self,
         workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListPermissionsResponse:
+        request: aiwork_space_20210204_models.ListOperationLogsRequest,
+    ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_permissions_with_options(workspace_id, headers, runtime)
+        return self.list_operation_logs_with_options(workspace_id, request, headers, runtime)
 
-    async def list_permissions_async(
+    async def list_operation_logs_async(
         self,
         workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListPermissionsResponse:
+        request: aiwork_space_20210204_models.ListOperationLogsRequest,
+    ) -> aiwork_space_20210204_models.ListOperationLogsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_permissions_with_options_async(workspace_id, headers, runtime)
+        return await self.list_operation_logs_with_options_async(workspace_id, request, headers, runtime)
 
     def list_permissions_with_options(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListPermissionsResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListPermissions',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/permissions',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/permissions',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -4488,49 +5119,48 @@
 
     async def list_permissions_with_options_async(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListPermissionsResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListPermissions',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/permissions',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/permissions',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListPermissionsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_product_authorizations(
+    def list_permissions(
         self,
-        request: aiwork_space_20210204_models.ListProductAuthorizationsRequest,
-    ) -> aiwork_space_20210204_models.ListProductAuthorizationsResponse:
+        workspace_id: str,
+    ) -> aiwork_space_20210204_models.ListPermissionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_product_authorizations_with_options(request, headers, runtime)
+        return self.list_permissions_with_options(workspace_id, headers, runtime)
 
-    async def list_product_authorizations_async(
+    async def list_permissions_async(
         self,
-        request: aiwork_space_20210204_models.ListProductAuthorizationsRequest,
-    ) -> aiwork_space_20210204_models.ListProductAuthorizationsResponse:
+        workspace_id: str,
+    ) -> aiwork_space_20210204_models.ListPermissionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_product_authorizations_with_options_async(request, headers, runtime)
+        return await self.list_permissions_with_options_async(workspace_id, headers, runtime)
 
     def list_product_authorizations_with_options(
         self,
         request: aiwork_space_20210204_models.ListProductAuthorizationsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListProductAuthorizationsResponse:
@@ -4584,29 +5214,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListProductAuthorizationsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_products(
+    def list_product_authorizations(
         self,
-        request: aiwork_space_20210204_models.ListProductsRequest,
-    ) -> aiwork_space_20210204_models.ListProductsResponse:
+        request: aiwork_space_20210204_models.ListProductAuthorizationsRequest,
+    ) -> aiwork_space_20210204_models.ListProductAuthorizationsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_products_with_options(request, headers, runtime)
+        return self.list_product_authorizations_with_options(request, headers, runtime)
 
-    async def list_products_async(
+    async def list_product_authorizations_async(
         self,
-        request: aiwork_space_20210204_models.ListProductsRequest,
-    ) -> aiwork_space_20210204_models.ListProductsResponse:
+        request: aiwork_space_20210204_models.ListProductAuthorizationsRequest,
+    ) -> aiwork_space_20210204_models.ListProductAuthorizationsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_products_with_options_async(request, headers, runtime)
+        return await self.list_product_authorizations_with_options_async(request, headers, runtime)
 
     def list_products_with_options(
         self,
         request: aiwork_space_20210204_models.ListProductsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListProductsResponse:
@@ -4668,29 +5298,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListProductsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_quotas(
+    def list_products(
         self,
-        request: aiwork_space_20210204_models.ListQuotasRequest,
-    ) -> aiwork_space_20210204_models.ListQuotasResponse:
+        request: aiwork_space_20210204_models.ListProductsRequest,
+    ) -> aiwork_space_20210204_models.ListProductsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_quotas_with_options(request, headers, runtime)
+        return self.list_products_with_options(request, headers, runtime)
 
-    async def list_quotas_async(
+    async def list_products_async(
         self,
-        request: aiwork_space_20210204_models.ListQuotasRequest,
-    ) -> aiwork_space_20210204_models.ListQuotasResponse:
+        request: aiwork_space_20210204_models.ListProductsRequest,
+    ) -> aiwork_space_20210204_models.ListProductsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_quotas_with_options_async(request, headers, runtime)
+        return await self.list_products_with_options_async(request, headers, runtime)
 
     def list_quotas_with_options(
         self,
         request: aiwork_space_20210204_models.ListQuotasRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListQuotasResponse:
@@ -4744,54 +5374,56 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListQuotasResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_resources(
+    def list_quotas(
         self,
-        request: aiwork_space_20210204_models.ListResourcesRequest,
-    ) -> aiwork_space_20210204_models.ListResourcesResponse:
+        request: aiwork_space_20210204_models.ListQuotasRequest,
+    ) -> aiwork_space_20210204_models.ListQuotasResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_resources_with_options(request, headers, runtime)
+        return self.list_quotas_with_options(request, headers, runtime)
 
-    async def list_resources_async(
+    async def list_quotas_async(
         self,
-        request: aiwork_space_20210204_models.ListResourcesRequest,
-    ) -> aiwork_space_20210204_models.ListResourcesResponse:
+        request: aiwork_space_20210204_models.ListQuotasRequest,
+    ) -> aiwork_space_20210204_models.ListQuotasResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_resources_with_options_async(request, headers, runtime)
+        return await self.list_quotas_with_options_async(request, headers, runtime)
 
     def list_resources_with_options(
         self,
         request: aiwork_space_20210204_models.ListResourcesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListResourcesResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.group_name):
+            query['GroupName'] = request.group_name
         if not UtilClient.is_unset(request.option):
             query['Option'] = request.option
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.product_types):
             query['ProductTypes'] = request.product_types
-        if not UtilClient.is_unset(request.resource_group_name):
-            query['ResourceGroupName'] = request.resource_group_name
         if not UtilClient.is_unset(request.resource_name):
             query['ResourceName'] = request.resource_name
+        if not UtilClient.is_unset(request.resource_types):
+            query['ResourceTypes'] = request.resource_types
+        if not UtilClient.is_unset(request.verbose):
+            query['Verbose'] = request.verbose
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
-        if not UtilClient.is_unset(request.workspace_ids):
-            query['WorkspaceIds'] = request.workspace_ids
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListResources',
             version='2021-02-04',
@@ -4812,30 +5444,32 @@
         self,
         request: aiwork_space_20210204_models.ListResourcesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListResourcesResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.group_name):
+            query['GroupName'] = request.group_name
         if not UtilClient.is_unset(request.option):
             query['Option'] = request.option
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.product_types):
             query['ProductTypes'] = request.product_types
-        if not UtilClient.is_unset(request.resource_group_name):
-            query['ResourceGroupName'] = request.resource_group_name
         if not UtilClient.is_unset(request.resource_name):
             query['ResourceName'] = request.resource_name
+        if not UtilClient.is_unset(request.resource_types):
+            query['ResourceTypes'] = request.resource_types
+        if not UtilClient.is_unset(request.verbose):
+            query['Verbose'] = request.verbose
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
-        if not UtilClient.is_unset(request.workspace_ids):
-            query['WorkspaceIds'] = request.workspace_ids
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='ListResources',
             version='2021-02-04',
@@ -4848,29 +5482,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListResourcesResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_users(
+    def list_resources(
         self,
-        request: aiwork_space_20210204_models.ListUsersRequest,
-    ) -> aiwork_space_20210204_models.ListUsersResponse:
+        request: aiwork_space_20210204_models.ListResourcesRequest,
+    ) -> aiwork_space_20210204_models.ListResourcesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_users_with_options(request, headers, runtime)
+        return self.list_resources_with_options(request, headers, runtime)
 
-    async def list_users_async(
+    async def list_resources_async(
         self,
-        request: aiwork_space_20210204_models.ListUsersRequest,
-    ) -> aiwork_space_20210204_models.ListUsersResponse:
+        request: aiwork_space_20210204_models.ListResourcesRequest,
+    ) -> aiwork_space_20210204_models.ListResourcesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_users_with_options_async(request, headers, runtime)
+        return await self.list_resources_with_options_async(request, headers, runtime)
 
     def list_users_with_options(
         self,
         request: aiwork_space_20210204_models.ListUsersRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListUsersResponse:
@@ -4940,45 +5574,44 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListUsersResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_workspace_users(
+    def list_users(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
+        request: aiwork_space_20210204_models.ListUsersRequest,
+    ) -> aiwork_space_20210204_models.ListUsersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_workspace_users_with_options(workspace_id, headers, runtime)
+        return self.list_users_with_options(request, headers, runtime)
 
-    async def list_workspace_users_async(
+    async def list_users_async(
         self,
-        workspace_id: str,
-    ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
+        request: aiwork_space_20210204_models.ListUsersRequest,
+    ) -> aiwork_space_20210204_models.ListUsersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_workspace_users_with_options_async(workspace_id, headers, runtime)
+        return await self.list_users_with_options_async(request, headers, runtime)
 
     def list_workspace_users_with_options(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListWorkspaceUsers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/users',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/users',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -4988,49 +5621,48 @@
 
     async def list_workspace_users_with_options_async(
         self,
         workspace_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='ListWorkspaceUsers',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/users',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/users',
             method='GET',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListWorkspaceUsersResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_workspaces(
+    def list_workspace_users(
         self,
-        request: aiwork_space_20210204_models.ListWorkspacesRequest,
-    ) -> aiwork_space_20210204_models.ListWorkspacesResponse:
+        workspace_id: str,
+    ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_workspaces_with_options(request, headers, runtime)
+        return self.list_workspace_users_with_options(workspace_id, headers, runtime)
 
-    async def list_workspaces_async(
+    async def list_workspace_users_async(
         self,
-        request: aiwork_space_20210204_models.ListWorkspacesRequest,
-    ) -> aiwork_space_20210204_models.ListWorkspacesResponse:
+        workspace_id: str,
+    ) -> aiwork_space_20210204_models.ListWorkspaceUsersResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_workspaces_with_options_async(request, headers, runtime)
+        return await self.list_workspace_users_with_options_async(workspace_id, headers, runtime)
 
     def list_workspaces_with_options(
         self,
         request: aiwork_space_20210204_models.ListWorkspacesRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.ListWorkspacesResponse:
@@ -5124,45 +5756,136 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.ListWorkspacesResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def publish_code_source(
+    def list_workspaces(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
+        request: aiwork_space_20210204_models.ListWorkspacesRequest,
+    ) -> aiwork_space_20210204_models.ListWorkspacesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.publish_code_source_with_options(code_source_id, headers, runtime)
+        return self.list_workspaces_with_options(request, headers, runtime)
 
-    async def publish_code_source_async(
+    async def list_workspaces_async(
         self,
-        code_source_id: str,
-    ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
+        request: aiwork_space_20210204_models.ListWorkspacesRequest,
+    ) -> aiwork_space_20210204_models.ListWorkspacesResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.publish_code_source_with_options_async(code_source_id, headers, runtime)
+        return await self.list_workspaces_with_options_async(request, headers, runtime)
+
+    def migrate_datasets_with_options(
+        self,
+        request: aiwork_space_20210204_models.MigrateDatasetsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.MigrateDatasetsResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.count):
+            body['Count'] = request.count
+        if not UtilClient.is_unset(request.dataset_id):
+            body['DatasetId'] = request.dataset_id
+        if not UtilClient.is_unset(request.if_force):
+            body['IfForce'] = request.if_force
+        if not UtilClient.is_unset(request.owner_id):
+            body['OwnerId'] = request.owner_id
+        if not UtilClient.is_unset(request.workspace_id):
+            body['WorkspaceId'] = request.workspace_id
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='MigrateDatasets',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/datasets/migrate',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.MigrateDatasetsResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def migrate_datasets_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.MigrateDatasetsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.MigrateDatasetsResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.count):
+            body['Count'] = request.count
+        if not UtilClient.is_unset(request.dataset_id):
+            body['DatasetId'] = request.dataset_id
+        if not UtilClient.is_unset(request.if_force):
+            body['IfForce'] = request.if_force
+        if not UtilClient.is_unset(request.owner_id):
+            body['OwnerId'] = request.owner_id
+        if not UtilClient.is_unset(request.workspace_id):
+            body['WorkspaceId'] = request.workspace_id
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='MigrateDatasets',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/datasets/migrate',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.MigrateDatasetsResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def migrate_datasets(
+        self,
+        request: aiwork_space_20210204_models.MigrateDatasetsRequest,
+    ) -> aiwork_space_20210204_models.MigrateDatasetsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.migrate_datasets_with_options(request, headers, runtime)
+
+    async def migrate_datasets_async(
+        self,
+        request: aiwork_space_20210204_models.MigrateDatasetsRequest,
+    ) -> aiwork_space_20210204_models.MigrateDatasetsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.migrate_datasets_with_options_async(request, headers, runtime)
 
     def publish_code_source_with_options(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}/publish',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5172,65 +5895,63 @@
 
     async def publish_code_source_with_options_async(
         self,
         code_source_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
-        code_source_id = OpenApiUtilClient.get_encode_param(code_source_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishCodeSource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/codesources/{code_source_id}/publish',
+            pathname=f'/api/v1/codesources/{OpenApiUtilClient.get_encode_param(code_source_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.PublishCodeSourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def publish_dataset(
+    def publish_code_source(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.PublishDatasetResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.publish_dataset_with_options(dataset_id, headers, runtime)
+        return self.publish_code_source_with_options(code_source_id, headers, runtime)
 
-    async def publish_dataset_async(
+    async def publish_code_source_async(
         self,
-        dataset_id: str,
-    ) -> aiwork_space_20210204_models.PublishDatasetResponse:
+        code_source_id: str,
+    ) -> aiwork_space_20210204_models.PublishCodeSourceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.publish_dataset_with_options_async(dataset_id, headers, runtime)
+        return await self.publish_code_source_with_options_async(code_source_id, headers, runtime)
 
     def publish_dataset_with_options(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/publish',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5240,65 +5961,63 @@
 
     async def publish_dataset_with_options_async(
         self,
         dataset_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishDatasetResponse:
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}/publish',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.PublishDatasetResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def publish_image(
+    def publish_dataset(
         self,
-        image_id: str,
-    ) -> aiwork_space_20210204_models.PublishImageResponse:
+        dataset_id: str,
+    ) -> aiwork_space_20210204_models.PublishDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.publish_image_with_options(image_id, headers, runtime)
+        return self.publish_dataset_with_options(dataset_id, headers, runtime)
 
-    async def publish_image_async(
+    async def publish_dataset_async(
         self,
-        image_id: str,
-    ) -> aiwork_space_20210204_models.PublishImageResponse:
+        dataset_id: str,
+    ) -> aiwork_space_20210204_models.PublishDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.publish_image_with_options_async(image_id, headers, runtime)
+        return await self.publish_dataset_with_options_async(dataset_id, headers, runtime)
 
     def publish_image_with_options(
         self,
         image_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishImageResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/publish',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5308,65 +6027,63 @@
 
     async def publish_image_with_options_async(
         self,
         image_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.PublishImageResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='PublishImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/publish',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/publish',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.PublishImageResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def remove_image(
+    def publish_image(
         self,
         image_id: str,
-    ) -> aiwork_space_20210204_models.RemoveImageResponse:
+    ) -> aiwork_space_20210204_models.PublishImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.remove_image_with_options(image_id, headers, runtime)
+        return self.publish_image_with_options(image_id, headers, runtime)
 
-    async def remove_image_async(
+    async def publish_image_async(
         self,
         image_id: str,
-    ) -> aiwork_space_20210204_models.RemoveImageResponse:
+    ) -> aiwork_space_20210204_models.PublishImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.remove_image_with_options_async(image_id, headers, runtime)
+        return await self.publish_image_with_options_async(image_id, headers, runtime)
 
     def remove_image_with_options(
         self,
         image_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveImageResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5376,147 +6093,135 @@
 
     async def remove_image_with_options_async(
         self,
         image_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveImageResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveImage',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.RemoveImageResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def remove_image_labels(
+    def remove_image(
         self,
         image_id: str,
-        label_key: str,
-    ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
+    ) -> aiwork_space_20210204_models.RemoveImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.remove_image_labels_with_options(image_id, label_key, headers, runtime)
+        return self.remove_image_with_options(image_id, headers, runtime)
 
-    async def remove_image_labels_async(
+    async def remove_image_async(
         self,
         image_id: str,
-        label_key: str,
-    ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
+    ) -> aiwork_space_20210204_models.RemoveImageResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.remove_image_labels_with_options_async(image_id, label_key, headers, runtime)
+        return await self.remove_image_with_options_async(image_id, headers, runtime)
 
     def remove_image_labels_with_options(
         self,
         image_id: str,
-        label_key: str,
+        label_keys: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
-        label_key = OpenApiUtilClient.get_encode_param(label_key)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveImageLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/labels/{label_key}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/labels/{OpenApiUtilClient.get_encode_param(label_keys)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.RemoveImageLabelsResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def remove_image_labels_with_options_async(
         self,
         image_id: str,
-        label_key: str,
+        label_keys: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
-        image_id = OpenApiUtilClient.get_encode_param(image_id)
-        label_key = OpenApiUtilClient.get_encode_param(label_key)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveImageLabels',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/images/{image_id}/labels/{label_key}',
+            pathname=f'/api/v1/images/{OpenApiUtilClient.get_encode_param(image_id)}/labels/{OpenApiUtilClient.get_encode_param(label_keys)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.RemoveImageLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def remove_member_role(
+    def remove_image_labels(
         self,
-        workspace_id: str,
-        member_id: str,
-        role_name: str,
-    ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
+        image_id: str,
+        label_keys: str,
+    ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.remove_member_role_with_options(workspace_id, member_id, role_name, headers, runtime)
+        return self.remove_image_labels_with_options(image_id, label_keys, headers, runtime)
 
-    async def remove_member_role_async(
+    async def remove_image_labels_async(
         self,
-        workspace_id: str,
-        member_id: str,
-        role_name: str,
-    ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
+        image_id: str,
+        label_keys: str,
+    ) -> aiwork_space_20210204_models.RemoveImageLabelsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.remove_member_role_with_options_async(workspace_id, member_id, role_name, headers, runtime)
+        return await self.remove_image_labels_with_options_async(image_id, label_keys, headers, runtime)
 
     def remove_member_role_with_options(
         self,
         workspace_id: str,
         member_id: str,
         role_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        member_id = OpenApiUtilClient.get_encode_param(member_id)
-        role_name = OpenApiUtilClient.get_encode_param(role_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveMemberRole',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members/{member_id}/roles/{role_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members/{OpenApiUtilClient.get_encode_param(member_id)}/roles/{OpenApiUtilClient.get_encode_param(role_name)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5528,71 +6233,68 @@
         self,
         workspace_id: str,
         member_id: str,
         role_name: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        member_id = OpenApiUtilClient.get_encode_param(member_id)
-        role_name = OpenApiUtilClient.get_encode_param(role_name)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveMemberRole',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/members/{member_id}/roles/{role_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/members/{OpenApiUtilClient.get_encode_param(member_id)}/roles/{OpenApiUtilClient.get_encode_param(role_name)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.RemoveMemberRoleResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def remove_workspace_quota(
+    def remove_member_role(
         self,
         workspace_id: str,
-        quota_id: str,
-    ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
+        member_id: str,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.remove_workspace_quota_with_options(workspace_id, quota_id, headers, runtime)
+        return self.remove_member_role_with_options(workspace_id, member_id, role_name, headers, runtime)
 
-    async def remove_workspace_quota_async(
+    async def remove_member_role_async(
         self,
         workspace_id: str,
-        quota_id: str,
-    ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
+        member_id: str,
+        role_name: str,
+    ) -> aiwork_space_20210204_models.RemoveMemberRoleResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.remove_workspace_quota_with_options_async(workspace_id, quota_id, headers, runtime)
+        return await self.remove_member_role_with_options_async(workspace_id, member_id, role_name, headers, runtime)
 
     def remove_workspace_quota_with_options(
         self,
         workspace_id: str,
         quota_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        quota_id = OpenApiUtilClient.get_encode_param(quota_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveWorkspaceQuota',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/quotas/{quota_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/quotas/{OpenApiUtilClient.get_encode_param(quota_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5603,74 +6305,129 @@
     async def remove_workspace_quota_with_options_async(
         self,
         workspace_id: str,
         quota_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        quota_id = OpenApiUtilClient.get_encode_param(quota_id)
         req = open_api_models.OpenApiRequest(
             headers=headers
         )
         params = open_api_models.Params(
             action='RemoveWorkspaceQuota',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/quotas/{quota_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/quotas/{OpenApiUtilClient.get_encode_param(quota_id)}',
             method='DELETE',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_configs(
+    def remove_workspace_quota(
         self,
         workspace_id: str,
-        request: aiwork_space_20210204_models.UpdateConfigsRequest,
-    ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
+        quota_id: str,
+    ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_configs_with_options(workspace_id, request, headers, runtime)
+        return self.remove_workspace_quota_with_options(workspace_id, quota_id, headers, runtime)
 
-    async def update_configs_async(
+    async def remove_workspace_quota_async(
         self,
         workspace_id: str,
-        request: aiwork_space_20210204_models.UpdateConfigsRequest,
-    ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
+        quota_id: str,
+    ) -> aiwork_space_20210204_models.RemoveWorkspaceQuotaResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_configs_with_options_async(workspace_id, request, headers, runtime)
+        return await self.remove_workspace_quota_with_options_async(workspace_id, quota_id, headers, runtime)
+
+    def sync_users_with_options(
+        self,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.SyncUsersResponse:
+        req = open_api_models.OpenApiRequest(
+            headers=headers
+        )
+        params = open_api_models.Params(
+            action='SyncUsers',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/users/action/sync',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.SyncUsersResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def sync_users_with_options_async(
+        self,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.SyncUsersResponse:
+        req = open_api_models.OpenApiRequest(
+            headers=headers
+        )
+        params = open_api_models.Params(
+            action='SyncUsers',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/users/action/sync',
+            method='POST',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.SyncUsersResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def sync_users(self) -> aiwork_space_20210204_models.SyncUsersResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.sync_users_with_options(headers, runtime)
+
+    async def sync_users_async(self) -> aiwork_space_20210204_models.SyncUsersResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.sync_users_with_options_async(headers, runtime)
 
     def update_configs_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.UpdateConfigsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.configs):
             body['Configs'] = request.configs
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateConfigs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5682,65 +6439,63 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.UpdateConfigsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.configs):
             body['Configs'] = request.configs
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateConfigs',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/configs',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/configs',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateConfigsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_dataset(
+    def update_configs(
         self,
-        dataset_id: str,
-        request: aiwork_space_20210204_models.UpdateDatasetRequest,
-    ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.UpdateConfigsRequest,
+    ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_dataset_with_options(dataset_id, request, headers, runtime)
+        return self.update_configs_with_options(workspace_id, request, headers, runtime)
 
-    async def update_dataset_async(
+    async def update_configs_async(
         self,
-        dataset_id: str,
-        request: aiwork_space_20210204_models.UpdateDatasetRequest,
-    ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
+        workspace_id: str,
+        request: aiwork_space_20210204_models.UpdateConfigsRequest,
+    ) -> aiwork_space_20210204_models.UpdateConfigsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_dataset_with_options_async(dataset_id, request, headers, runtime)
+        return await self.update_configs_with_options_async(workspace_id, request, headers, runtime)
 
     def update_dataset_with_options(
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.UpdateDatasetRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         body = {}
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
@@ -5748,15 +6503,15 @@
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5768,15 +6523,14 @@
         self,
         dataset_id: str,
         request: aiwork_space_20210204_models.UpdateDatasetRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
         UtilClient.validate_model(request)
-        dataset_id = OpenApiUtilClient.get_encode_param(dataset_id)
         body = {}
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
@@ -5784,52 +6538,54 @@
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateDataset',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/datasets/{dataset_id}',
+            pathname=f'/api/v1/datasets/{OpenApiUtilClient.get_encode_param(dataset_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateDatasetResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_default_workspace(
+    def update_dataset(
         self,
-        request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.UpdateDatasetRequest,
+    ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_default_workspace_with_options(request, headers, runtime)
+        return self.update_dataset_with_options(dataset_id, request, headers, runtime)
 
-    async def update_default_workspace_async(
+    async def update_dataset_async(
         self,
-        request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
+        dataset_id: str,
+        request: aiwork_space_20210204_models.UpdateDatasetRequest,
+    ) -> aiwork_space_20210204_models.UpdateDatasetResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_default_workspace_with_options_async(request, headers, runtime)
+        return await self.update_dataset_with_options_async(dataset_id, request, headers, runtime)
 
     def update_default_workspace_with_options(
         self,
         request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
         UtilClient.validate_model(request)
         body = {}
-        if not UtilClient.is_unset(request.default_workspace_id):
-            body['DefaultWorkspaceId'] = request.default_workspace_id
+        if not UtilClient.is_unset(request.workspace_id):
+            body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateDefaultWorkspace',
             version='2021-02-04',
@@ -5850,16 +6606,16 @@
         self,
         request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
         UtilClient.validate_model(request)
         body = {}
-        if not UtilClient.is_unset(request.default_workspace_id):
-            body['DefaultWorkspaceId'] = request.default_workspace_id
+        if not UtilClient.is_unset(request.workspace_id):
+            body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateDefaultWorkspace',
             version='2021-02-04',
@@ -5872,57 +6628,62 @@
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_model(
+    def update_default_workspace(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.UpdateModelRequest,
-    ) -> aiwork_space_20210204_models.UpdateModelResponse:
+        request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_model_with_options(model_id, request, headers, runtime)
+        return self.update_default_workspace_with_options(request, headers, runtime)
 
-    async def update_model_async(
+    async def update_default_workspace_async(
         self,
-        model_id: str,
-        request: aiwork_space_20210204_models.UpdateModelRequest,
-    ) -> aiwork_space_20210204_models.UpdateModelResponse:
+        request: aiwork_space_20210204_models.UpdateDefaultWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.UpdateDefaultWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_model_with_options_async(model_id, request, headers, runtime)
+        return await self.update_default_workspace_with_options_async(request, headers, runtime)
 
     def update_model_with_options(
         self,
         model_id: str,
         request: aiwork_space_20210204_models.UpdateModelRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateModelResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
         if not UtilClient.is_unset(request.accessibility):
             body['Accessibility'] = request.accessibility
+        if not UtilClient.is_unset(request.domain):
+            body['Domain'] = request.domain
         if not UtilClient.is_unset(request.model_description):
             body['ModelDescription'] = request.model_description
+        if not UtilClient.is_unset(request.model_doc):
+            body['ModelDoc'] = request.model_doc
         if not UtilClient.is_unset(request.model_name):
             body['ModelName'] = request.model_name
+        if not UtilClient.is_unset(request.origin):
+            body['Origin'] = request.origin
+        if not UtilClient.is_unset(request.task):
+            body['Task'] = request.task
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -5934,89 +6695,178 @@
         self,
         model_id: str,
         request: aiwork_space_20210204_models.UpdateModelRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateModelResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
         body = {}
         if not UtilClient.is_unset(request.accessibility):
             body['Accessibility'] = request.accessibility
+        if not UtilClient.is_unset(request.domain):
+            body['Domain'] = request.domain
         if not UtilClient.is_unset(request.model_description):
             body['ModelDescription'] = request.model_description
+        if not UtilClient.is_unset(request.model_doc):
+            body['ModelDoc'] = request.model_doc
         if not UtilClient.is_unset(request.model_name):
             body['ModelName'] = request.model_name
+        if not UtilClient.is_unset(request.origin):
+            body['Origin'] = request.origin
+        if not UtilClient.is_unset(request.task):
+            body['Task'] = request.task
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateModel',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateModelResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_model_version(
+    def update_model(
         self,
         model_id: str,
-        version_name: str,
-        request: aiwork_space_20210204_models.UpdateModelVersionRequest,
-    ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
+        request: aiwork_space_20210204_models.UpdateModelRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_model_version_with_options(model_id, version_name, request, headers, runtime)
+        return self.update_model_with_options(model_id, request, headers, runtime)
 
-    async def update_model_version_async(
+    async def update_model_async(
         self,
         model_id: str,
-        version_name: str,
-        request: aiwork_space_20210204_models.UpdateModelVersionRequest,
-    ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
+        request: aiwork_space_20210204_models.UpdateModelRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_model_version_with_options_async(model_id, version_name, request, headers, runtime)
+        return await self.update_model_with_options_async(model_id, request, headers, runtime)
+
+    def update_model_domains_with_options(
+        self,
+        request: aiwork_space_20210204_models.UpdateModelDomainsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.UpdateModelDomainsResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.model_domains):
+            body['ModelDomains'] = request.model_domains
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='UpdateModelDomains',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.UpdateModelDomainsResponse(),
+            self.call_api(params, req, runtime)
+        )
+
+    async def update_model_domains_with_options_async(
+        self,
+        request: aiwork_space_20210204_models.UpdateModelDomainsRequest,
+        headers: Dict[str, str],
+        runtime: util_models.RuntimeOptions,
+    ) -> aiwork_space_20210204_models.UpdateModelDomainsResponse:
+        UtilClient.validate_model(request)
+        body = {}
+        if not UtilClient.is_unset(request.model_domains):
+            body['ModelDomains'] = request.model_domains
+        req = open_api_models.OpenApiRequest(
+            headers=headers,
+            body=OpenApiUtilClient.parse_to_map(body)
+        )
+        params = open_api_models.Params(
+            action='UpdateModelDomains',
+            version='2021-02-04',
+            protocol='HTTPS',
+            pathname=f'/api/v1/modeldomains',
+            method='PUT',
+            auth_type='AK',
+            style='ROA',
+            req_body_type='json',
+            body_type='json'
+        )
+        return TeaCore.from_map(
+            aiwork_space_20210204_models.UpdateModelDomainsResponse(),
+            await self.call_api_async(params, req, runtime)
+        )
+
+    def update_model_domains(
+        self,
+        request: aiwork_space_20210204_models.UpdateModelDomainsRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelDomainsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.update_model_domains_with_options(request, headers, runtime)
+
+    async def update_model_domains_async(
+        self,
+        request: aiwork_space_20210204_models.UpdateModelDomainsRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelDomainsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.update_model_domains_with_options_async(request, headers, runtime)
 
     def update_model_version_with_options(
         self,
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.UpdateModelVersionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         body = {}
+        if not UtilClient.is_unset(request.approval_status):
+            body['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.inference_spec):
             body['InferenceSpec'] = request.inference_spec
+        if not UtilClient.is_unset(request.metrics):
+            body['Metrics'] = request.metrics
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
+        if not UtilClient.is_unset(request.source_id):
+            body['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            body['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.training_spec):
+            body['TrainingSpec'] = request.training_spec
         if not UtilClient.is_unset(request.version_description):
             body['VersionDescription'] = request.version_description
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -6029,84 +6879,93 @@
         model_id: str,
         version_name: str,
         request: aiwork_space_20210204_models.UpdateModelVersionRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
         UtilClient.validate_model(request)
-        model_id = OpenApiUtilClient.get_encode_param(model_id)
-        version_name = OpenApiUtilClient.get_encode_param(version_name)
         body = {}
+        if not UtilClient.is_unset(request.approval_status):
+            body['ApprovalStatus'] = request.approval_status
         if not UtilClient.is_unset(request.inference_spec):
             body['InferenceSpec'] = request.inference_spec
+        if not UtilClient.is_unset(request.metrics):
+            body['Metrics'] = request.metrics
         if not UtilClient.is_unset(request.options):
             body['Options'] = request.options
+        if not UtilClient.is_unset(request.source_id):
+            body['SourceId'] = request.source_id
+        if not UtilClient.is_unset(request.source_type):
+            body['SourceType'] = request.source_type
+        if not UtilClient.is_unset(request.training_spec):
+            body['TrainingSpec'] = request.training_spec
         if not UtilClient.is_unset(request.version_description):
             body['VersionDescription'] = request.version_description
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateModelVersion',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/models/{model_id}/versions/{version_name}',
+            pathname=f'/api/v1/models/{OpenApiUtilClient.get_encode_param(model_id)}/versions/{OpenApiUtilClient.get_encode_param(version_name)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateModelVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_workspace(
+    def update_model_version(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.UpdateModelVersionRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_workspace_with_options(workspace_id, request, headers, runtime)
+        return self.update_model_version_with_options(model_id, version_name, request, headers, runtime)
 
-    async def update_workspace_async(
+    async def update_model_version_async(
         self,
-        workspace_id: str,
-        request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
-    ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
+        model_id: str,
+        version_name: str,
+        request: aiwork_space_20210204_models.UpdateModelVersionRequest,
+    ) -> aiwork_space_20210204_models.UpdateModelVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_workspace_with_options_async(workspace_id, request, headers, runtime)
+        return await self.update_model_version_with_options_async(model_id, version_name, request, headers, runtime)
 
     def update_workspace_with_options(
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.display_name):
             body['DisplayName'] = request.display_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
@@ -6118,124 +6977,141 @@
         self,
         workspace_id: str,
         request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
         body = {}
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.display_name):
             body['DisplayName'] = request.display_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateWorkspace',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateWorkspaceResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_workspace_resource(
+    def update_workspace(
         self,
         workspace_id: str,
-        resource_group_name: str,
-        request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
+        request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_workspace_resource_with_options(workspace_id, resource_group_name, request, headers, runtime)
+        return self.update_workspace_with_options(workspace_id, request, headers, runtime)
 
-    async def update_workspace_resource_async(
+    async def update_workspace_async(
         self,
         workspace_id: str,
-        resource_group_name: str,
-        request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
-    ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
+        request: aiwork_space_20210204_models.UpdateWorkspaceRequest,
+    ) -> aiwork_space_20210204_models.UpdateWorkspaceResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_workspace_resource_with_options_async(workspace_id, resource_group_name, request, headers, runtime)
+        return await self.update_workspace_with_options_async(workspace_id, request, headers, runtime)
 
     def update_workspace_resource_with_options(
         self,
         workspace_id: str,
-        resource_group_name: str,
         request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        resource_group_name = OpenApiUtilClient.get_encode_param(resource_group_name)
         body = {}
+        if not UtilClient.is_unset(request.group_name):
+            body['GroupName'] = request.group_name
         if not UtilClient.is_unset(request.is_default):
             body['IsDefault'] = request.is_default
         if not UtilClient.is_unset(request.product_type):
             body['ProductType'] = request.product_type
+        if not UtilClient.is_unset(request.resource_type):
+            body['ResourceType'] = request.resource_type
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources/{resource_group_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateWorkspaceResourceResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def update_workspace_resource_with_options_async(
         self,
         workspace_id: str,
-        resource_group_name: str,
         request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
         UtilClient.validate_model(request)
-        workspace_id = OpenApiUtilClient.get_encode_param(workspace_id)
-        resource_group_name = OpenApiUtilClient.get_encode_param(resource_group_name)
         body = {}
+        if not UtilClient.is_unset(request.group_name):
+            body['GroupName'] = request.group_name
         if not UtilClient.is_unset(request.is_default):
             body['IsDefault'] = request.is_default
         if not UtilClient.is_unset(request.product_type):
             body['ProductType'] = request.product_type
+        if not UtilClient.is_unset(request.resource_type):
+            body['ResourceType'] = request.resource_type
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateWorkspaceResource',
             version='2021-02-04',
             protocol='HTTPS',
-            pathname=f'/api/v1/workspaces/{workspace_id}/resources/{resource_group_name}',
+            pathname=f'/api/v1/workspaces/{OpenApiUtilClient.get_encode_param(workspace_id)}/resources',
             method='PUT',
             auth_type='AK',
             style='ROA',
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             aiwork_space_20210204_models.UpdateWorkspaceResourceResponse(),
             await self.call_api_async(params, req, runtime)
         )
+
+    def update_workspace_resource(
+        self,
+        workspace_id: str,
+        request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.update_workspace_resource_with_options(workspace_id, request, headers, runtime)
+
+    async def update_workspace_resource_async(
+        self,
+        workspace_id: str,
+        request: aiwork_space_20210204_models.UpdateWorkspaceResourceRequest,
+    ) -> aiwork_space_20210204_models.UpdateWorkspaceResourceResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.update_workspace_resource_with_options_async(workspace_id, request, headers, runtime)
```

## pai/libs/alibabacloud_aiworkspace20210204/models.py

```diff
@@ -18,41 +18,27 @@
         display_name: str = None,
         gmt_create_time: str = None,
         gmt_modify_time: str = None,
         mount_path: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
-        # 表示代码是否是工作空间下公开的,可选值PRIVATE,PUBLIC
         self.accessibility = accessibility
-        # 代码分支
         self.code_branch = code_branch
-        # 代码Commit ID
         self.code_commit = code_commit
-        # 代码仓库地址
         self.code_repo = code_repo
-        # 访问代码仓库所用的AccessToken
         self.code_repo_access_token = code_repo_access_token
-        # 访问代码仓库的用户名
         self.code_repo_user_name = code_repo_user_name
-        # 代码源ID
         self.code_source_id = code_source_id
-        # 代码源详细描述
         self.description = description
-        # 代码源配置的名字
         self.display_name = display_name
-        # 创建时间
         self.gmt_create_time = gmt_create_time
-        # 修改时间
         self.gmt_modify_time = gmt_modify_time
-        # 代码Mount路径
         self.mount_path = mount_path
-        # 代码源配置的用户ID
         self.user_id = user_id
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -119,23 +105,21 @@
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
-class DatasetLabel(TeaModel):
+class Label(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # Key
         self.key = key
-        # Value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -164,58 +148,43 @@
         accessibility: str = None,
         data_source_type: str = None,
         data_type: str = None,
         dataset_id: str = None,
         description: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
-        labels: List[DatasetLabel] = None,
+        labels: List[Label] = None,
         name: str = None,
         options: str = None,
         owner_id: str = None,
         property: str = None,
+        provider_type: str = None,
         source_id: str = None,
         source_type: str = None,
         uri: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
-        # Accessibility
         self.accessibility = accessibility
-        # DataSourceType
         self.data_source_type = data_source_type
-        # DataType
         self.data_type = data_type
-        # Dataset Id
         self.dataset_id = dataset_id
-        # Description
         self.description = description
-        # GmtCreateTime
         self.gmt_create_time = gmt_create_time
-        # GmtModifiedTime
         self.gmt_modified_time = gmt_modified_time
-        # Labels
         self.labels = labels
-        # Name
         self.name = name
-        # Options
         self.options = options
-        # Owner Id
         self.owner_id = owner_id
-        # Property
         self.property = property
-        # SourceId
+        self.provider_type = provider_type
         self.source_id = source_id
-        # SourceType
         self.source_type = source_type
-        # Uri
         self.uri = uri
-        # User Id
         self.user_id = user_id
-        # WorkspaceId
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -248,14 +217,16 @@
             result['Name'] = self.name
         if self.options is not None:
             result['Options'] = self.options
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
         if self.property is not None:
             result['Property'] = self.property
+        if self.provider_type is not None:
+            result['ProviderType'] = self.provider_type
         if self.source_id is not None:
             result['SourceId'] = self.source_id
         if self.source_type is not None:
             result['SourceType'] = self.source_type
         if self.uri is not None:
             result['Uri'] = self.uri
         if self.user_id is not None:
@@ -279,46 +250,46 @@
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
-                temp_model = DatasetLabel()
+                temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Options') is not None:
             self.options = m.get('Options')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
         if m.get('Property') is not None:
             self.property = m.get('Property')
+        if m.get('ProviderType') is not None:
+            self.provider_type = m.get('ProviderType')
         if m.get('SourceId') is not None:
             self.source_id = m.get('SourceId')
         if m.get('SourceType') is not None:
             self.source_type = m.get('SourceType')
         if m.get('Uri') is not None:
             self.uri = m.get('Uri')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
-class Label(TeaModel):
+class DatasetLabel(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # 标签的key
         self.key = key
-        # 标签的value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -340,94 +311,104 @@
             self.value = m.get('Value')
         return self
 
 
 class ModelVersion(TeaModel):
     def __init__(
         self,
+        approval_status: str = None,
         format_type: str = None,
         framework_type: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         inference_spec: Dict[str, Any] = None,
         labels: List[Label] = None,
+        metrics: Dict[str, Any] = None,
         options: str = None,
         owner_id: str = None,
+        source_id: str = None,
+        source_type: str = None,
+        training_spec: Dict[str, Any] = None,
         uri: str = None,
         user_id: str = None,
         version_description: str = None,
         version_name: str = None,
     ):
-        # 模型格式
+        self.approval_status = approval_status
         self.format_type = format_type
-        # 模型框架
         self.framework_type = framework_type
-        # 创建时间
         self.gmt_create_time = gmt_create_time
-        # 最后更新时间
         self.gmt_modified_time = gmt_modified_time
-        # 下游配置
         self.inference_spec = inference_spec
-        # 标签列表
         self.labels = labels
-        # 扩展字段
+        self.metrics = metrics
         self.options = options
-        # 云账号ID
         self.owner_id = owner_id
-        # 版本的URI
+        self.source_id = source_id
+        self.source_type = source_type
+        self.training_spec = training_spec
         self.uri = uri
-        # 创建模型版本的用户ID
         self.user_id = user_id
-        # 版本的描述
         self.version_description = version_description
-        # 版本名，模型下唯一
         self.version_name = version_name
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.approval_status is not None:
+            result['ApprovalStatus'] = self.approval_status
         if self.format_type is not None:
             result['FormatType'] = self.format_type
         if self.framework_type is not None:
             result['FrameworkType'] = self.framework_type
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.inference_spec is not None:
             result['InferenceSpec'] = self.inference_spec
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
+        if self.metrics is not None:
+            result['Metrics'] = self.metrics
         if self.options is not None:
             result['Options'] = self.options
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
+        if self.source_type is not None:
+            result['SourceType'] = self.source_type
+        if self.training_spec is not None:
+            result['TrainingSpec'] = self.training_spec
         if self.uri is not None:
             result['Uri'] = self.uri
         if self.user_id is not None:
             result['UserId'] = self.user_id
         if self.version_description is not None:
             result['VersionDescription'] = self.version_description
         if self.version_name is not None:
             result['VersionName'] = self.version_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ApprovalStatus') is not None:
+            self.approval_status = m.get('ApprovalStatus')
         if m.get('FormatType') is not None:
             self.format_type = m.get('FormatType')
         if m.get('FrameworkType') is not None:
             self.framework_type = m.get('FrameworkType')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
@@ -435,18 +416,26 @@
         if m.get('InferenceSpec') is not None:
             self.inference_spec = m.get('InferenceSpec')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
+        if m.get('Metrics') is not None:
+            self.metrics = m.get('Metrics')
         if m.get('Options') is not None:
             self.options = m.get('Options')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
+        if m.get('SourceType') is not None:
+            self.source_type = m.get('SourceType')
+        if m.get('TrainingSpec') is not None:
+            self.training_spec = m.get('TrainingSpec')
         if m.get('Uri') is not None:
             self.uri = m.get('Uri')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('VersionDescription') is not None:
             self.version_description = m.get('VersionDescription')
         if m.get('VersionName') is not None:
@@ -454,46 +443,45 @@
         return self
 
 
 class Model(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
+        domain: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         labels: List[Label] = None,
         latest_version: ModelVersion = None,
         model_description: str = None,
+        model_doc: str = None,
         model_id: str = None,
         model_name: str = None,
+        origin: str = None,
         owner_id: str = None,
+        provider: str = None,
+        task: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
-        # 可见性
         self.accessibility = accessibility
-        # 创建时间
+        self.domain = domain
         self.gmt_create_time = gmt_create_time
-        # 最后更新时间
         self.gmt_modified_time = gmt_modified_time
-        # 标签列表
         self.labels = labels
-        # 最新版本
         self.latest_version = latest_version
-        # 模型的描述
         self.model_description = model_description
-        # 模型ID
+        self.model_doc = model_doc
         self.model_id = model_id
-        # 模型名字
         self.model_name = model_name
-        # 云账号ID
+        self.origin = origin
         self.owner_id = owner_id
-        # 创建模型的用户ID
+        self.provider = provider
+        self.task = task
         self.user_id = user_id
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -504,78 +492,123 @@
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.accessibility is not None:
             result['Accessibility'] = self.accessibility
+        if self.domain is not None:
+            result['Domain'] = self.domain
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         if self.latest_version is not None:
             result['LatestVersion'] = self.latest_version.to_map()
         if self.model_description is not None:
             result['ModelDescription'] = self.model_description
+        if self.model_doc is not None:
+            result['ModelDoc'] = self.model_doc
         if self.model_id is not None:
             result['ModelId'] = self.model_id
         if self.model_name is not None:
             result['ModelName'] = self.model_name
+        if self.origin is not None:
+            result['Origin'] = self.origin
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
+        if self.provider is not None:
+            result['Provider'] = self.provider
+        if self.task is not None:
+            result['Task'] = self.task
         if self.user_id is not None:
             result['UserId'] = self.user_id
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
             self.accessibility = m.get('Accessibility')
+        if m.get('Domain') is not None:
+            self.domain = m.get('Domain')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('LatestVersion') is not None:
             temp_model = ModelVersion()
             self.latest_version = temp_model.from_map(m['LatestVersion'])
         if m.get('ModelDescription') is not None:
             self.model_description = m.get('ModelDescription')
+        if m.get('ModelDoc') is not None:
+            self.model_doc = m.get('ModelDoc')
         if m.get('ModelId') is not None:
             self.model_id = m.get('ModelId')
         if m.get('ModelName') is not None:
             self.model_name = m.get('ModelName')
+        if m.get('Origin') is not None:
+            self.origin = m.get('Origin')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
+        if m.get('Provider') is not None:
+            self.provider = m.get('Provider')
+        if m.get('Task') is not None:
+            self.task = m.get('Task')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
+class ResourcesExecutorValue(TeaModel):
+    def __init__(
+        self,
+        owner_id: str = None,
+    ):
+        self.owner_id = owner_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.owner_id is not None:
+            result['OwnerId'] = self.owner_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('OwnerId') is not None:
+            self.owner_id = m.get('OwnerId')
+        return self
+
+
 class AddImageRequestLabels(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # Key
         self.key = key
-        # Value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -604,25 +637,19 @@
         accessibility: str = None,
         description: str = None,
         image_uri: str = None,
         labels: List[AddImageRequestLabels] = None,
         name: str = None,
         workspace_id: str = None,
     ):
-        # 可见性 Public 公有 Private 私有
         self.accessibility = accessibility
-        # 镜像描述
         self.description = description
-        # 镜像地址
         self.image_uri = image_uri
-        # 镜像标签，是个数组
         self.labels = labels
-        # 镜像名称
         self.name = name
-        # 工作空间id
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -671,40 +698,38 @@
 
 class AddImageResponseBody(TeaModel):
     def __init__(
         self,
         image_id: str = None,
         request_id: str = None,
     ):
-        # 镜像 id
         self.image_id = image_id
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.image_id is not None:
             result['ImageId'] = self.image_id
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('ImageId') is not None:
             self.image_id = m.get('ImageId')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class AddImageResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -750,17 +775,15 @@
 
 class AddImageLabelsRequestLabels(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # Key
         self.key = key
-        # Value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -784,15 +807,14 @@
 
 
 class AddImageLabelsRequest(TeaModel):
     def __init__(
         self,
         labels: List[AddImageLabelsRequestLabels] = None,
     ):
-        # 标签
         self.labels = labels
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -820,34 +842,33 @@
 
 
 class AddImageLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class AddImageLabelsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -892,15 +913,14 @@
 
 
 class AddMemberRoleResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -959,90 +979,136 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = AddMemberRoleResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class AddWorkspaceQuotaRequest(TeaModel):
+class AddWorkspaceQuotaResponseBody(TeaModel):
     def __init__(
         self,
-        mode: str = None,
-        product_code: str = None,
-        quota_type: str = None,
+        request_id: str = None,
     ):
-        # 模式  isolate 预付费  share 后付费  develop 开发模式
-        self.mode = mode
-        # 产品代码
-        self.product_code = product_code
-        # 产品类型，  支持PAI，MaxCompute，
-        self.quota_type = quota_type
+        self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
-        if self.mode is not None:
-            result['Mode'] = self.mode
-        if self.product_code is not None:
-            result['ProductCode'] = self.product_code
-        if self.quota_type is not None:
-            result['QuotaType'] = self.quota_type
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('Mode') is not None:
-            self.mode = m.get('Mode')
-        if m.get('ProductCode') is not None:
-            self.product_code = m.get('ProductCode')
-        if m.get('QuotaType') is not None:
-            self.quota_type = m.get('QuotaType')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
-class AddWorkspaceQuotaResponseBody(TeaModel):
+class AddWorkspaceQuotaResponse(TeaModel):
     def __init__(
         self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: AddWorkspaceQuotaResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = AddWorkspaceQuotaResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
+class AssumeServiceIdentityRoleResponseBody(TeaModel):
+    def __init__(
+        self,
+        access_key_id: str = None,
+        access_key_secret: str = None,
         request_id: str = None,
+        security_token: str = None,
     ):
-        # 请求 id
+        self.access_key_id = access_key_id
+        self.access_key_secret = access_key_secret
         self.request_id = request_id
+        self.security_token = security_token
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.access_key_id is not None:
+            result['AccessKeyId'] = self.access_key_id
+        if self.access_key_secret is not None:
+            result['AccessKeySecret'] = self.access_key_secret
         if self.request_id is not None:
             result['RequestId'] = self.request_id
+        if self.security_token is not None:
+            result['SecurityToken'] = self.security_token
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('AccessKeyId') is not None:
+            self.access_key_id = m.get('AccessKeyId')
+        if m.get('AccessKeySecret') is not None:
+            self.access_key_secret = m.get('AccessKeySecret')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
+        if m.get('SecurityToken') is not None:
+            self.security_token = m.get('SecurityToken')
         return self
 
 
-class AddWorkspaceQuotaResponse(TeaModel):
+class AssumeServiceIdentityRoleResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
         status_code: int = None,
-        body: AddWorkspaceQuotaResponseBody = None,
+        body: AssumeServiceIdentityRoleResponseBody = None,
     ):
         self.headers = headers
         self.status_code = status_code
         self.body = body
 
     def validate(self):
         self.validate_required(self.headers, 'headers')
@@ -1068,15 +1134,15 @@
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('headers') is not None:
             self.headers = m.get('headers')
         if m.get('statusCode') is not None:
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
-            temp_model = AddWorkspaceQuotaResponseBody()
+            temp_model = AssumeServiceIdentityRoleResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class CreateCodeSourceRequest(TeaModel):
     def __init__(
         self,
@@ -1086,31 +1152,22 @@
         code_repo_access_token: str = None,
         code_repo_user_name: str = None,
         description: str = None,
         display_name: str = None,
         mount_path: str = None,
         workspace_id: str = None,
     ):
-        # 代码是否是本工作空间内公开的，可选值PRIVATE、PUBLIC
         self.accessibility = accessibility
-        # 代码分支
         self.code_branch = code_branch
-        # 代码仓库地址
         self.code_repo = code_repo
-        # 代码仓库访问Token
         self.code_repo_access_token = code_repo_access_token
-        # 代码仓库的用户名
         self.code_repo_user_name = code_repo_user_name
-        # 代码源详细描述
         self.description = description
-        # 代码源配置名称
         self.display_name = display_name
-        # 代码本地挂载目录，默认挂载到/root/code/下
         self.mount_path = mount_path
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1163,17 +1220,15 @@
 
 class CreateCodeSourceResponseBody(TeaModel):
     def __init__(
         self,
         code_source_id: str = None,
         request_id: str = None,
     ):
-        # 创建的代码源配置的ID
         self.code_source_id = code_source_id
-        # 请求ID
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1243,46 +1298,36 @@
 class CreateDatasetRequest(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
         data_source_type: str = None,
         data_type: str = None,
         description: str = None,
-        labels: List[DatasetLabel] = None,
+        labels: List[Label] = None,
         name: str = None,
         options: str = None,
         property: str = None,
+        provider_type: str = None,
         source_id: str = None,
         source_type: str = None,
         uri: str = None,
         workspace_id: str = None,
     ):
-        # Accessibility
         self.accessibility = accessibility
-        # DataSourceType
         self.data_source_type = data_source_type
-        # DataType
         self.data_type = data_type
-        # Description
         self.description = description
-        # Labels
         self.labels = labels
-        # Name
         self.name = name
-        # Options
         self.options = options
-        # Property
         self.property = property
-        # SourceId
+        self.provider_type = provider_type
         self.source_id = source_id
-        # SourceType
         self.source_type = source_type
-        # Uri
         self.uri = uri
-        # WorkspaceId
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -1307,14 +1352,16 @@
                 result['Labels'].append(k.to_map() if k else None)
         if self.name is not None:
             result['Name'] = self.name
         if self.options is not None:
             result['Options'] = self.options
         if self.property is not None:
             result['Property'] = self.property
+        if self.provider_type is not None:
+            result['ProviderType'] = self.provider_type
         if self.source_id is not None:
             result['SourceId'] = self.source_id
         if self.source_type is not None:
             result['SourceType'] = self.source_type
         if self.uri is not None:
             result['Uri'] = self.uri
         if self.workspace_id is not None:
@@ -1330,22 +1377,24 @@
         if m.get('DataType') is not None:
             self.data_type = m.get('DataType')
         if m.get('Description') is not None:
             self.description = m.get('Description')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
-                temp_model = DatasetLabel()
+                temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Options') is not None:
             self.options = m.get('Options')
         if m.get('Property') is not None:
             self.property = m.get('Property')
+        if m.get('ProviderType') is not None:
+            self.provider_type = m.get('ProviderType')
         if m.get('SourceId') is not None:
             self.source_id = m.get('SourceId')
         if m.get('SourceType') is not None:
             self.source_type = m.get('SourceType')
         if m.get('Uri') is not None:
             self.uri = m.get('Uri')
         if m.get('WorkspaceId') is not None:
@@ -1356,15 +1405,14 @@
 class CreateDatasetResponseBody(TeaModel):
     def __init__(
         self,
         dataset_id: str = None,
         request_id: str = None,
     ):
         self.dataset_id = dataset_id
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1430,15 +1478,15 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class CreateDatasetLabelsRequest(TeaModel):
     def __init__(
         self,
-        labels: List[DatasetLabel] = None,
+        labels: List[Label] = None,
     ):
         self.labels = labels
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
@@ -1457,25 +1505,24 @@
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
-                temp_model = DatasetLabel()
+                temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         return self
 
 
 class CreateDatasetLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1538,76 +1585,84 @@
         return self
 
 
 class CreateDefaultWorkspaceRequestResources(TeaModel):
     def __init__(
         self,
         product_type: str = None,
+        resource_type: str = None,
     ):
-        # 产品类型
         self.product_type = product_type
+        self.resource_type = resource_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.product_type is not None:
             result['ProductType'] = self.product_type
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('ProductType') is not None:
             self.product_type = m.get('ProductType')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         return self
 
 
 class CreateDefaultWorkspaceRequest(TeaModel):
     def __init__(
         self,
+        add_all_ram_users: bool = None,
         description: str = None,
         env_types: List[str] = None,
         resources: List[CreateDefaultWorkspaceRequestResources] = None,
     ):
-        # 描述，最多80个字符
+        self.add_all_ram_users = add_all_ram_users
         self.description = description
-        # 环境列表
         self.env_types = env_types
-        # 资源
         self.resources = resources
 
     def validate(self):
         if self.resources:
             for k in self.resources:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.add_all_ram_users is not None:
+            result['AddAllRamUsers'] = self.add_all_ram_users
         if self.description is not None:
             result['Description'] = self.description
         if self.env_types is not None:
             result['EnvTypes'] = self.env_types
         result['Resources'] = []
         if self.resources is not None:
             for k in self.resources:
                 result['Resources'].append(k.to_map() if k else None)
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('AddAllRamUsers') is not None:
+            self.add_all_ram_users = m.get('AddAllRamUsers')
         if m.get('Description') is not None:
             self.description = m.get('Description')
         if m.get('EnvTypes') is not None:
             self.env_types = m.get('EnvTypes')
         self.resources = []
         if m.get('Resources') is not None:
             for k in m.get('Resources'):
@@ -1618,17 +1673,15 @@
 
 class CreateDefaultWorkspaceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         workspace_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 工作空间 id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1691,23 +1744,131 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateDefaultWorkspaceResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class CreateDingTalkRobotMessageRequest(TeaModel):
+    def __init__(
+        self,
+        access_token: str = None,
+        message: str = None,
+        secret: str = None,
+    ):
+        self.access_token = access_token
+        self.message = message
+        self.secret = secret
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.access_token is not None:
+            result['AccessToken'] = self.access_token
+        if self.message is not None:
+            result['Message'] = self.message
+        if self.secret is not None:
+            result['Secret'] = self.secret
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('AccessToken') is not None:
+            self.access_token = m.get('AccessToken')
+        if m.get('Message') is not None:
+            self.message = m.get('Message')
+        if m.get('Secret') is not None:
+            self.secret = m.get('Secret')
+        return self
+
+
+class CreateDingTalkRobotMessageResponseBody(TeaModel):
+    def __init__(
+        self,
+        request_id: str = None,
+    ):
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class CreateDingTalkRobotMessageResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: CreateDingTalkRobotMessageResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = CreateDingTalkRobotMessageResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class CreateMemberRequestMembers(TeaModel):
     def __init__(
         self,
         roles: List[str] = None,
         user_id: str = None,
     ):
-        # 角色列表
         self.roles = roles
-        # 用户 id
         self.user_id = user_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1731,15 +1892,14 @@
 
 
 class CreateMemberRequest(TeaModel):
     def __init__(
         self,
         members: List[CreateMemberRequestMembers] = None,
     ):
-        # 用户列表
         self.members = members
 
     def validate(self):
         if self.members:
             for k in self.members:
                 if k:
                     k.validate()
@@ -1770,21 +1930,17 @@
     def __init__(
         self,
         display_name: str = None,
         member_id: str = None,
         roles: List[str] = None,
         user_id: str = None,
     ):
-        # 成员显示名
         self.display_name = display_name
-        # 成员 id
         self.member_id = member_id
-        # 角色列表
         self.roles = roles
-        # 用户 id
         self.user_id = user_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1817,17 +1973,15 @@
 
 class CreateMemberResponseBody(TeaModel):
     def __init__(
         self,
         members: List[CreateMemberResponseBodyMembers] = None,
         request_id: str = None,
     ):
-        # 成员列表
         self.members = members
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         if self.members:
             for k in self.members:
                 if k:
                     k.validate()
@@ -1902,28 +2056,31 @@
         return self
 
 
 class CreateModelRequest(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
+        domain: str = None,
         labels: List[Label] = None,
         model_description: str = None,
+        model_doc: str = None,
         model_name: str = None,
+        origin: str = None,
+        task: str = None,
         workspace_id: str = None,
     ):
-        # Accessibility
         self.accessibility = accessibility
-        # Labels
+        self.domain = domain
         self.labels = labels
-        # ModelDescription
         self.model_description = model_description
-        # ModelName
+        self.model_doc = model_doc
         self.model_name = model_name
-        # WorkspaceId
+        self.origin = origin
+        self.task = task
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -1932,52 +2089,67 @@
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.accessibility is not None:
             result['Accessibility'] = self.accessibility
+        if self.domain is not None:
+            result['Domain'] = self.domain
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         if self.model_description is not None:
             result['ModelDescription'] = self.model_description
+        if self.model_doc is not None:
+            result['ModelDoc'] = self.model_doc
         if self.model_name is not None:
             result['ModelName'] = self.model_name
+        if self.origin is not None:
+            result['Origin'] = self.origin
+        if self.task is not None:
+            result['Task'] = self.task
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
             self.accessibility = m.get('Accessibility')
+        if m.get('Domain') is not None:
+            self.domain = m.get('Domain')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('ModelDescription') is not None:
             self.model_description = m.get('ModelDescription')
+        if m.get('ModelDoc') is not None:
+            self.model_doc = m.get('ModelDoc')
         if m.get('ModelName') is not None:
             self.model_name = m.get('ModelName')
+        if m.get('Origin') is not None:
+            self.origin = m.get('Origin')
+        if m.get('Task') is not None:
+            self.task = m.get('Task')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class CreateModelResponseBody(TeaModel):
     def __init__(
         self,
         model_id: str = None,
         request_id: str = None,
     ):
         self.model_id = model_id
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2080,15 +2252,14 @@
 
 
 class CreateModelLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2147,90 +2318,222 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateModelLabelsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class CreateModelReleaseRequest(TeaModel):
+    def __init__(
+        self,
+        target_model_origin: str = None,
+        target_model_provider: str = None,
+    ):
+        self.target_model_origin = target_model_origin
+        self.target_model_provider = target_model_provider
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.target_model_origin is not None:
+            result['TargetModelOrigin'] = self.target_model_origin
+        if self.target_model_provider is not None:
+            result['TargetModelProvider'] = self.target_model_provider
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('TargetModelOrigin') is not None:
+            self.target_model_origin = m.get('TargetModelOrigin')
+        if m.get('TargetModelProvider') is not None:
+            self.target_model_provider = m.get('TargetModelProvider')
+        return self
+
+
+class CreateModelReleaseResponseBody(TeaModel):
+    def __init__(
+        self,
+        model_id: str = None,
+        request_id: str = None,
+    ):
+        self.model_id = model_id
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_id is not None:
+            result['ModelId'] = self.model_id
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelId') is not None:
+            self.model_id = m.get('ModelId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class CreateModelReleaseResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: CreateModelReleaseResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = CreateModelReleaseResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class CreateModelVersionRequest(TeaModel):
     def __init__(
         self,
+        approval_status: str = None,
         format_type: str = None,
         framework_type: str = None,
         inference_spec: Dict[str, Any] = None,
         labels: List[Label] = None,
+        metrics: Dict[str, Any] = None,
         options: str = None,
+        source_id: str = None,
+        source_type: str = None,
+        training_spec: Dict[str, Any] = None,
         uri: str = None,
         version_description: str = None,
         version_name: str = None,
     ):
-        # 模型类型
+        self.approval_status = approval_status
         self.format_type = format_type
-        # 模型框架
         self.framework_type = framework_type
-        # 描述如何应用于下游的推理应用
         self.inference_spec = inference_spec
-        # 标签
         self.labels = labels
-        # 扩展字段
+        self.metrics = metrics
         self.options = options
-        # 版本Uri
+        self.source_id = source_id
+        self.source_type = source_type
+        self.training_spec = training_spec
         self.uri = uri
-        # 版本描述
         self.version_description = version_description
-        # 模型版本，模型下唯一。
         self.version_name = version_name
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.approval_status is not None:
+            result['ApprovalStatus'] = self.approval_status
         if self.format_type is not None:
             result['FormatType'] = self.format_type
         if self.framework_type is not None:
             result['FrameworkType'] = self.framework_type
         if self.inference_spec is not None:
             result['InferenceSpec'] = self.inference_spec
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
+        if self.metrics is not None:
+            result['Metrics'] = self.metrics
         if self.options is not None:
             result['Options'] = self.options
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
+        if self.source_type is not None:
+            result['SourceType'] = self.source_type
+        if self.training_spec is not None:
+            result['TrainingSpec'] = self.training_spec
         if self.uri is not None:
             result['Uri'] = self.uri
         if self.version_description is not None:
             result['VersionDescription'] = self.version_description
         if self.version_name is not None:
             result['VersionName'] = self.version_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ApprovalStatus') is not None:
+            self.approval_status = m.get('ApprovalStatus')
         if m.get('FormatType') is not None:
             self.format_type = m.get('FormatType')
         if m.get('FrameworkType') is not None:
             self.framework_type = m.get('FrameworkType')
         if m.get('InferenceSpec') is not None:
             self.inference_spec = m.get('InferenceSpec')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
+        if m.get('Metrics') is not None:
+            self.metrics = m.get('Metrics')
         if m.get('Options') is not None:
             self.options = m.get('Options')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
+        if m.get('SourceType') is not None:
+            self.source_type = m.get('SourceType')
+        if m.get('TrainingSpec') is not None:
+            self.training_spec = m.get('TrainingSpec')
         if m.get('Uri') is not None:
             self.uri = m.get('Uri')
         if m.get('VersionDescription') is not None:
             self.version_description = m.get('VersionDescription')
         if m.get('VersionName') is not None:
             self.version_name = m.get('VersionName')
         return self
@@ -2238,17 +2541,15 @@
 
 class CreateModelVersionResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         version_name: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
-        # 模型名称
         self.version_name = version_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2316,15 +2617,14 @@
 
 
 class CreateModelVersionLabelsRequest(TeaModel):
     def __init__(
         self,
         labels: List[Label] = None,
     ):
-        # 版本标签
         self.labels = labels
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -2352,15 +2652,14 @@
 
 
 class CreateModelVersionLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2419,26 +2718,139 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateModelVersionLabelsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class CreateModelVersionReleaseRequest(TeaModel):
+    def __init__(
+        self,
+        target_model_origin: str = None,
+        target_model_provider: str = None,
+    ):
+        self.target_model_origin = target_model_origin
+        self.target_model_provider = target_model_provider
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.target_model_origin is not None:
+            result['TargetModelOrigin'] = self.target_model_origin
+        if self.target_model_provider is not None:
+            result['TargetModelProvider'] = self.target_model_provider
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('TargetModelOrigin') is not None:
+            self.target_model_origin = m.get('TargetModelOrigin')
+        if m.get('TargetModelProvider') is not None:
+            self.target_model_provider = m.get('TargetModelProvider')
+        return self
+
+
+class CreateModelVersionReleaseResponseBody(TeaModel):
+    def __init__(
+        self,
+        model_id: str = None,
+        request_id: str = None,
+        version_name: str = None,
+    ):
+        self.model_id = model_id
+        self.request_id = request_id
+        self.version_name = version_name
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_id is not None:
+            result['ModelId'] = self.model_id
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        if self.version_name is not None:
+            result['VersionName'] = self.version_name
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelId') is not None:
+            self.model_id = m.get('ModelId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        if m.get('VersionName') is not None:
+            self.version_name = m.get('VersionName')
+        return self
+
+
+class CreateModelVersionReleaseResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: CreateModelVersionReleaseResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = CreateModelVersionReleaseResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class CreateProductOrdersRequestProductsInstanceProperties(TeaModel):
     def __init__(
         self,
         code: str = None,
         name: str = None,
         value: str = None,
     ):
-        # 代号
         self.code = code
-        # 名
         self.name = name
-        # 值
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2472,27 +2884,20 @@
         charge_type: str = None,
         duration: int = None,
         instance_properties: List[CreateProductOrdersRequestProductsInstanceProperties] = None,
         order_type: str = None,
         pricing_cycle: str = None,
         product_code: str = None,
     ):
-        # 是否自动续费
         self.auto_renew = auto_renew
-        # 付费类型
         self.charge_type = charge_type
-        # 购买时长,与pricingCycle配合使用
         self.duration = duration
-        # 实例属性信息
         self.instance_properties = instance_properties
-        # 订单类型
         self.order_type = order_type
-        # 计价单位
         self.pricing_cycle = pricing_cycle
-        # 产品code
         self.product_code = product_code
 
     def validate(self):
         if self.instance_properties:
             for k in self.instance_properties:
                 if k:
                     k.validate()
@@ -2545,17 +2950,15 @@
 
 class CreateProductOrdersRequest(TeaModel):
     def __init__(
         self,
         auto_pay: bool = None,
         products: CreateProductOrdersRequestProducts = None,
     ):
-        # 是否自动购买所有产品
         self.auto_pay = auto_pay
-        # 逗号分隔的产品
         self.products = products
 
     def validate(self):
         if self.products:
             self.products.validate()
 
     def to_map(self):
@@ -2584,21 +2987,17 @@
     def __init__(
         self,
         buy_product_request_id: str = None,
         message: str = None,
         order_id: str = None,
         request_id: str = None,
     ):
-        # 产品购买请求id
         self.buy_product_request_id = buy_product_request_id
-        # 消息
         self.message = message
-        # 订单id
         self.order_id = order_id
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2609,27 +3008,27 @@
         if self.buy_product_request_id is not None:
             result['BuyProductRequestId'] = self.buy_product_request_id
         if self.message is not None:
             result['Message'] = self.message
         if self.order_id is not None:
             result['OrderId'] = self.order_id
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('BuyProductRequestId') is not None:
             self.buy_product_request_id = m.get('BuyProductRequestId')
         if m.get('Message') is not None:
             self.message = m.get('Message')
         if m.get('OrderId') is not None:
             self.order_id = m.get('OrderId')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class CreateProductOrdersResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -2669,23 +3068,119 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateProductOrdersResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class CreateServiceIdentityRoleRequest(TeaModel):
+    def __init__(
+        self,
+        role_name: str = None,
+    ):
+        self.role_name = role_name
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.role_name is not None:
+            result['RoleName'] = self.role_name
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RoleName') is not None:
+            self.role_name = m.get('RoleName')
+        return self
+
+
+class CreateServiceIdentityRoleResponseBody(TeaModel):
+    def __init__(
+        self,
+        request_id: str = None,
+    ):
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class CreateServiceIdentityRoleResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: CreateServiceIdentityRoleResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = CreateServiceIdentityRoleResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class CreateUserResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         user_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 用户 id
         self.user_id = user_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2756,21 +3251,17 @@
     def __init__(
         self,
         description: str = None,
         display_name: str = None,
         env_types: List[str] = None,
         workspace_name: str = None,
     ):
-        # 描述，最多80个字符
         self.description = description
-        # 显示名称
         self.display_name = display_name
-        # 环境列表
         self.env_types = env_types
-        # 名字 3-23 个字符, 需要字母开头，只能包含字母下划线和数字，region内唯一
         self.workspace_name = workspace_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2803,17 +3294,15 @@
 
 class CreateWorkspaceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         workspace_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 工作空间 id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -2879,100 +3368,59 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class CreateWorkspaceResourceRequestResourcesQuotas(TeaModel):
     def __init__(
         self,
-        card_type: str = None,
-        mode: str = None,
-        name: str = None,
-        product_code: str = None,
-        quota_type: str = None,
-        spec: str = None,
+        id: str = None,
     ):
-        # 卡类型，支持cpu、gpu
-        self.card_type = card_type
-        # 模式 isolate 预付费 share 后付费 develop 开发模式
-        self.mode = mode
-        # 配额名称
-        self.name = name
-        # 商品 code
-        self.product_code = product_code
-        # 产品类型， 支持PAI，MaxCompute
-        self.quota_type = quota_type
-        # 规格描述
-        self.spec = spec
+        self.id = id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
-        if self.card_type is not None:
-            result['CardType'] = self.card_type
-        if self.mode is not None:
-            result['Mode'] = self.mode
-        if self.name is not None:
-            result['Name'] = self.name
-        if self.product_code is not None:
-            result['ProductCode'] = self.product_code
-        if self.quota_type is not None:
-            result['QuotaType'] = self.quota_type
-        if self.spec is not None:
-            result['Spec'] = self.spec
+        if self.id is not None:
+            result['Id'] = self.id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('CardType') is not None:
-            self.card_type = m.get('CardType')
-        if m.get('Mode') is not None:
-            self.mode = m.get('Mode')
-        if m.get('Name') is not None:
-            self.name = m.get('Name')
-        if m.get('ProductCode') is not None:
-            self.product_code = m.get('ProductCode')
-        if m.get('QuotaType') is not None:
-            self.quota_type = m.get('QuotaType')
-        if m.get('Spec') is not None:
-            self.spec = m.get('Spec')
+        if m.get('Id') is not None:
+            self.id = m.get('Id')
         return self
 
 
 class CreateWorkspaceResourceRequestResources(TeaModel):
     def __init__(
         self,
         env_type: str = None,
         group_name: str = None,
         is_default: bool = None,
         name: str = None,
         product_type: str = None,
         quotas: List[CreateWorkspaceResourceRequestResourcesQuotas] = None,
-        spec: str = None,
+        resource_type: str = None,
+        spec: Dict[str, Any] = None,
         workspace_id: str = None,
     ):
-        # 环境， 支持dev（开发）、prod（生产）
         self.env_type = env_type
-        # 分组名，主账户内唯一 一个 GroupName 下可能有一个 dev 资源和一个 prod 资源
         self.group_name = group_name
-        # 是否默认资源 每个类型都有一个默认的资源
         self.is_default = is_default
-        # 资源名 长度需要在3到27个字符 region内唯一
         self.name = name
-        # 产品类型， 支持PAI，MaxCompute
         self.product_type = product_type
         self.quotas = quotas
-        # 对于MaxCompute是个json，有如下key： Endpoint Project
+        self.resource_type = resource_type
         self.spec = spec
-        # 所属的工作空间 id
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.quotas:
             for k in self.quotas:
                 if k:
                     k.validate()
@@ -2993,14 +3441,16 @@
             result['Name'] = self.name
         if self.product_type is not None:
             result['ProductType'] = self.product_type
         result['Quotas'] = []
         if self.quotas is not None:
             for k in self.quotas:
                 result['Quotas'].append(k.to_map() if k else None)
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         if self.spec is not None:
             result['Spec'] = self.spec
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
@@ -3016,63 +3466,69 @@
         if m.get('ProductType') is not None:
             self.product_type = m.get('ProductType')
         self.quotas = []
         if m.get('Quotas') is not None:
             for k in m.get('Quotas'):
                 temp_model = CreateWorkspaceResourceRequestResourcesQuotas()
                 self.quotas.append(temp_model.from_map(k))
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         if m.get('Spec') is not None:
             self.spec = m.get('Spec')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class CreateWorkspaceResourceRequest(TeaModel):
     def __init__(
         self,
+        option: str = None,
         resources: List[CreateWorkspaceResourceRequestResources] = None,
     ):
-        # 资源列表
+        self.option = option
         self.resources = resources
 
     def validate(self):
         if self.resources:
             for k in self.resources:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.option is not None:
+            result['Option'] = self.option
         result['Resources'] = []
         if self.resources is not None:
             for k in self.resources:
                 result['Resources'].append(k.to_map() if k else None)
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('Option') is not None:
+            self.option = m.get('Option')
         self.resources = []
         if m.get('Resources') is not None:
             for k in m.get('Resources'):
                 temp_model = CreateWorkspaceResourceRequestResources()
                 self.resources.append(temp_model.from_map(k))
         return self
 
 
 class CreateWorkspaceResourceResponseBodyResources(TeaModel):
     def __init__(
         self,
         id: str = None,
     ):
-        # 资源Id
         self.id = id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3094,19 +3550,16 @@
 class CreateWorkspaceResourceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         resources: List[CreateWorkspaceResourceResponseBodyResources] = None,
         total_count: int = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 资源集合
         self.resources = resources
-        # 总数
         self.total_count = total_count
 
     def validate(self):
         if self.resources:
             for k in self.resources:
                 if k:
                     k.validate()
@@ -3187,15 +3640,14 @@
 
 class DeleteCodeSourceResponseBody(TeaModel):
     def __init__(
         self,
         code_source_id: str = None,
         request_id: str = None,
     ):
-        # 被删除的代码源配置ID
         self.code_source_id = code_source_id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
@@ -3264,15 +3716,14 @@
 
 
 class DeleteConfigResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3336,15 +3787,14 @@
 
 
 class DeleteDatasetResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3407,43 +3857,48 @@
         return self
 
 
 class DeleteDatasetLabelsRequest(TeaModel):
     def __init__(
         self,
         keys: str = None,
+        label_keys: str = None,
     ):
         self.keys = keys
+        self.label_keys = label_keys
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.keys is not None:
             result['Keys'] = self.keys
+        if self.label_keys is not None:
+            result['LabelKeys'] = self.label_keys
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Keys') is not None:
             self.keys = m.get('Keys')
+        if m.get('LabelKeys') is not None:
+            self.label_keys = m.get('LabelKeys')
         return self
 
 
 class DeleteDatasetLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3507,15 +3962,14 @@
 
 
 class DeleteMembersRequest(TeaModel):
     def __init__(
         self,
         member_ids: str = None,
     ):
-        # 需要删除的成员 Id 列表，以逗号分隔
         self.member_ids = member_ids
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3535,15 +3989,14 @@
 
 
 class DeleteMembersResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3607,15 +4060,14 @@
 
 
 class DeleteModelResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3674,48 +4126,150 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = DeleteModelResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class DeleteModelDomainRequest(TeaModel):
+    def __init__(
+        self,
+        model_task_ids: str = None,
+    ):
+        self.model_task_ids = model_task_ids
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_task_ids is not None:
+            result['ModelTaskIds'] = self.model_task_ids
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelTaskIds') is not None:
+            self.model_task_ids = m.get('ModelTaskIds')
+        return self
+
+
+class DeleteModelDomainResponseBody(TeaModel):
+    def __init__(
+        self,
+        request_id: str = None,
+    ):
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class DeleteModelDomainResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: DeleteModelDomainResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = DeleteModelDomainResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class DeleteModelLabelsRequest(TeaModel):
     def __init__(
         self,
         keys: str = None,
+        label_keys: str = None,
     ):
-        # 需要删除的标签Keys
         self.keys = keys
+        self.label_keys = label_keys
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.keys is not None:
             result['Keys'] = self.keys
+        if self.label_keys is not None:
+            result['LabelKeys'] = self.label_keys
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Keys') is not None:
             self.keys = m.get('Keys')
+        if m.get('LabelKeys') is not None:
+            self.label_keys = m.get('LabelKeys')
         return self
 
 
 class DeleteModelLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3779,15 +4333,14 @@
 
 
 class DeleteModelVersionResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3850,44 +4403,48 @@
         return self
 
 
 class DeleteModelVersionLabelsRequest(TeaModel):
     def __init__(
         self,
         keys: str = None,
+        label_keys: str = None,
     ):
-        # 版本标签Keys
         self.keys = keys
+        self.label_keys = label_keys
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.keys is not None:
             result['Keys'] = self.keys
+        if self.label_keys is not None:
+            result['LabelKeys'] = self.label_keys
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Keys') is not None:
             self.keys = m.get('Keys')
+        if m.get('LabelKeys') is not None:
+            self.label_keys = m.get('LabelKeys')
         return self
 
 
 class DeleteModelVersionLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -3951,34 +4508,33 @@
 
 
 class DeleteWorkspaceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class DeleteWorkspaceResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -4021,63 +4577,80 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class DeleteWorkspaceResourceRequest(TeaModel):
     def __init__(
         self,
+        group_name: str = None,
+        option: str = None,
         product_type: str = None,
+        resource_type: str = None,
     ):
+        self.group_name = group_name
+        self.option = option
         self.product_type = product_type
+        self.resource_type = resource_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.group_name is not None:
+            result['GroupName'] = self.group_name
+        if self.option is not None:
+            result['Option'] = self.option
         if self.product_type is not None:
             result['ProductType'] = self.product_type
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('GroupName') is not None:
+            self.group_name = m.get('GroupName')
+        if m.get('Option') is not None:
+            self.option = m.get('Option')
         if m.get('ProductType') is not None:
             self.product_type = m.get('ProductType')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         return self
 
 
 class DeleteWorkspaceResourceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class DeleteWorkspaceResourceResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -4136,43 +4709,28 @@
         gmt_create_time: str = None,
         gmt_modify_time: str = None,
         mount_path: str = None,
         request_id: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
-        # 代码是否是本工作空间内公开的，可选值PRIVATE、PUBLIC
         self.accessibility = accessibility
-        # 代码仓库分支
         self.code_branch = code_branch
-        # 代码Commit
         self.code_commit = code_commit
-        # 代码仓库地址
         self.code_repo = code_repo
-        # 访问代码仓库的token
         self.code_repo_access_token = code_repo_access_token
-        # 代码仓库的用户名
         self.code_repo_user_name = code_repo_user_name
-        # 代码源配置ID
         self.code_source_id = code_source_id
-        # 详细描述
         self.description = description
-        # 代码源配置名字
         self.display_name = display_name
-        # 创建时间
         self.gmt_create_time = gmt_create_time
-        # 修改时间
         self.gmt_modify_time = gmt_modify_time
-        # 代码本地挂载目录，默认挂载到/root/code/下
         self.mount_path = mount_path
-        # 请求ID
         self.request_id = request_id
-        # 代码配置源的创建者ID
         self.user_id = user_id
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4292,15 +4850,14 @@
 
 
 class GetCodeSourcesStatisticsRequest(TeaModel):
     def __init__(
         self,
         workspace_id: str = None,
     ):
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4321,17 +4878,15 @@
 
 class GetCodeSourcesStatisticsResponseBody(TeaModel):
     def __init__(
         self,
         count: int = None,
         request_id: str = None,
     ):
-        # 此用户可以查看的代码的数目
         self.count = count
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4404,19 +4959,20 @@
         accessibility: str = None,
         data_source_type: str = None,
         data_type: str = None,
         dataset_id: str = None,
         description: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
-        labels: List[DatasetLabel] = None,
+        labels: List[Label] = None,
         name: str = None,
         options: str = None,
         owner_id: str = None,
         property: str = None,
+        provider_type: str = None,
         request_id: str = None,
         source_id: str = None,
         source_type: str = None,
         uri: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
@@ -4428,15 +4984,15 @@
         self.gmt_create_time = gmt_create_time
         self.gmt_modified_time = gmt_modified_time
         self.labels = labels
         self.name = name
         self.options = options
         self.owner_id = owner_id
         self.property = property
-        # Id of the request
+        self.provider_type = provider_type
         self.request_id = request_id
         self.source_id = source_id
         self.source_type = source_type
         self.uri = uri
         self.user_id = user_id
         self.workspace_id = workspace_id
 
@@ -4474,14 +5030,16 @@
             result['Name'] = self.name
         if self.options is not None:
             result['Options'] = self.options
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
         if self.property is not None:
             result['Property'] = self.property
+        if self.provider_type is not None:
+            result['ProviderType'] = self.provider_type
         if self.request_id is not None:
             result['RequestId'] = self.request_id
         if self.source_id is not None:
             result['SourceId'] = self.source_id
         if self.source_type is not None:
             result['SourceType'] = self.source_type
         if self.uri is not None:
@@ -4507,24 +5065,26 @@
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
-                temp_model = DatasetLabel()
+                temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Options') is not None:
             self.options = m.get('Options')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
         if m.get('Property') is not None:
             self.property = m.get('Property')
+        if m.get('ProviderType') is not None:
+            self.provider_type = m.get('ProviderType')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
         if m.get('SourceId') is not None:
             self.source_id = m.get('SourceId')
         if m.get('SourceType') is not None:
             self.source_type = m.get('SourceType')
         if m.get('Uri') is not None:
@@ -4581,15 +5141,14 @@
 
 
 class GetDatasetsStatisticsRequest(TeaModel):
     def __init__(
         self,
         workspace_id: str = None,
     ):
-        # WorkspaceId
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4610,17 +5169,15 @@
 
 class GetDatasetsStatisticsResponseBody(TeaModel):
     def __init__(
         self,
         count: int = None,
         request_id: str = None,
     ):
-        # Count
         self.count = count
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4717,19 +5274,16 @@
 class GetDefaultWorkspaceResponseBodyConditions(TeaModel):
     def __init__(
         self,
         code: int = None,
         message: str = None,
         type: str = None,
     ):
-        # 返回码，正常是200，其他都是错误
         self.code = code
-        # 消息
         self.message = message
-        # 类型
         self.type = type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4759,19 +5313,16 @@
 class GetDefaultWorkspaceResponseBodyOwner(TeaModel):
     def __init__(
         self,
         user_id: str = None,
         user_kp: str = None,
         user_name: str = None,
     ):
-        # 用户id
         self.user_id = user_id
-        # 用户kp
         self.user_kp = user_kp
-        # 用户名
         self.user_name = user_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4805,43 +5356,31 @@
         creator: str = None,
         description: str = None,
         display_name: str = None,
         env_types: List[str] = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         owner: GetDefaultWorkspaceResponseBodyOwner = None,
+        request_id: str = None,
         status: str = None,
         workspace_id: str = None,
         workspace_name: str = None,
-        request_id: str = None,
     ):
-        # 任务详情 创建默认工作空间会有多个任务依次进行，如果一个任务未开始，不会显示在任务详情里。
         self.conditions = conditions
-        # 创建人
         self.creator = creator
-        # 描述
         self.description = description
-        # 显示名称
         self.display_name = display_name
-        # 环境，用作判断简单模式还是标准模式，含义见
         self.env_types = env_types
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 修改 UTC 时间，日期格式 iso8601
         self.gmt_modified_time = gmt_modified_time
-        # 拥有者
         self.owner = owner
-        # 工作空间状态
+        self.request_id = request_id
         self.status = status
-        # 工作空间 ID
         self.workspace_id = workspace_id
-        # 项目空间名称， region 内唯一
         self.workspace_name = workspace_name
-        # Id of the request
-        self.request_id = request_id
 
     def validate(self):
         if self.conditions:
             for k in self.conditions:
                 if k:
                     k.validate()
         if self.owner:
@@ -4867,22 +5406,22 @@
             result['EnvTypes'] = self.env_types
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.owner is not None:
             result['Owner'] = self.owner.to_map()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
         if self.status is not None:
             result['Status'] = self.status
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         if self.workspace_name is not None:
             result['WorkspaceName'] = self.workspace_name
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.conditions = []
         if m.get('Conditions') is not None:
             for k in m.get('Conditions'):
@@ -4899,22 +5438,22 @@
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         if m.get('Owner') is not None:
             temp_model = GetDefaultWorkspaceResponseBodyOwner()
             self.owner = temp_model.from_map(m['Owner'])
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         if m.get('Status') is not None:
             self.status = m.get('Status')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         if m.get('WorkspaceName') is not None:
             self.workspace_name = m.get('WorkspaceName')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
         return self
 
 
 class GetDefaultWorkspaceResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -4959,15 +5498,14 @@
 
 
 class GetImageRequest(TeaModel):
     def __init__(
         self,
         verbose: bool = None,
     ):
-        # 是否显示非必要信息：Labels
         self.verbose = verbose
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -4988,17 +5526,15 @@
 
 class GetImageResponseBodyLabels(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # Key
         self.key = key
-        # Value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5027,41 +5563,30 @@
         accessibility: str = None,
         description: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         image_uri: str = None,
         labels: List[GetImageResponseBodyLabels] = None,
         name: str = None,
-        operator_create: str = None,
-        parent_operator_create: str = None,
-        workspace_id: str = None,
+        parent_user_id: str = None,
         request_id: str = None,
+        user_id: str = None,
+        workspace_id: str = None,
     ):
-        # 可见性
         self.accessibility = accessibility
-        # 描述
         self.description = description
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_modified_time = gmt_modified_time
-        # 镜像地址，包含版本号
         self.image_uri = image_uri
-        # 镜像标签
         self.labels = labels
-        # 镜像名称
         self.name = name
-        # 创建人
-        self.operator_create = operator_create
-        # 创建人父账户
-        self.parent_operator_create = parent_operator_create
-        # 工作空间id
-        self.workspace_id = workspace_id
-        # Id of the request
+        self.parent_user_id = parent_user_id
         self.request_id = request_id
+        self.user_id = user_id
+        self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
 
@@ -5083,22 +5608,22 @@
             result['ImageUri'] = self.image_uri
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         if self.name is not None:
             result['Name'] = self.name
-        if self.operator_create is not None:
-            result['OperatorCreate'] = self.operator_create
-        if self.parent_operator_create is not None:
-            result['ParentOperatorCreate'] = self.parent_operator_create
+        if self.parent_user_id is not None:
+            result['ParentUserId'] = self.parent_user_id
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        if self.user_id is not None:
+            result['UserId'] = self.user_id
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
             self.accessibility = m.get('Accessibility')
         if m.get('Description') is not None:
@@ -5112,22 +5637,22 @@
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = GetImageResponseBodyLabels()
                 self.labels.append(temp_model.from_map(k))
         if m.get('Name') is not None:
             self.name = m.get('Name')
-        if m.get('OperatorCreate') is not None:
-            self.operator_create = m.get('OperatorCreate')
-        if m.get('ParentOperatorCreate') is not None:
-            self.parent_operator_create = m.get('ParentOperatorCreate')
+        if m.get('ParentUserId') is not None:
+            self.parent_user_id = m.get('ParentUserId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        if m.get('UserId') is not None:
+            self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
         return self
 
 
 class GetImageResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -5172,15 +5697,14 @@
 
 
 class GetImagesStatisticsRequest(TeaModel):
     def __init__(
         self,
         workspace_id: str = None,
     ):
-        # 工作空间id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5201,40 +5725,38 @@
 
 class GetImagesStatisticsResponseBody(TeaModel):
     def __init__(
         self,
         count: int = None,
         request_id: str = None,
     ):
-        # 镜像总数
         self.count = count
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.count is not None:
             result['Count'] = self.count
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Count') is not None:
             self.count = m.get('Count')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class GetImagesStatisticsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -5279,15 +5801,14 @@
 
 
 class GetMemberRequest(TeaModel):
     def __init__(
         self,
         user_id: str = None,
     ):
-        # 用户id
         self.user_id = user_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5308,33 +5829,26 @@
 
 class GetMemberResponseBody(TeaModel):
     def __init__(
         self,
         display_name: str = None,
         gmt_create_time: str = None,
         member_id: str = None,
+        member_name: str = None,
+        request_id: str = None,
         roles: List[str] = None,
         user_id: str = None,
-        user_name: str = None,
-        request_id: str = None,
     ):
-        # 成员显示名
         self.display_name = display_name
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 成员 id
         self.member_id = member_id
-        # 角色列表
+        self.member_name = member_name
+        self.request_id = request_id
         self.roles = roles
-        # 用户 id
         self.user_id = user_id
-        # 云账号用户名
-        self.user_name = user_name
-        # Id of the request
-        self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
@@ -5343,40 +5857,40 @@
         result = dict()
         if self.display_name is not None:
             result['DisplayName'] = self.display_name
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.member_id is not None:
             result['MemberId'] = self.member_id
+        if self.member_name is not None:
+            result['MemberName'] = self.member_name
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
         if self.roles is not None:
             result['Roles'] = self.roles
         if self.user_id is not None:
             result['UserId'] = self.user_id
-        if self.user_name is not None:
-            result['UserName'] = self.user_name
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('DisplayName') is not None:
             self.display_name = m.get('DisplayName')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('MemberId') is not None:
             self.member_id = m.get('MemberId')
+        if m.get('MemberName') is not None:
+            self.member_name = m.get('MemberName')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         if m.get('Roles') is not None:
             self.roles = m.get('Roles')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
-        if m.get('UserName') is not None:
-            self.user_name = m.get('UserName')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
         return self
 
 
 class GetMemberResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -5420,49 +5934,47 @@
         return self
 
 
 class GetModelResponseBody(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
+        domain: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         labels: List[Label] = None,
         latest_version: ModelVersion = None,
         model_description: str = None,
+        model_doc: str = None,
         model_id: str = None,
         model_name: str = None,
+        origin: str = None,
         owner_id: str = None,
+        provider: str = None,
         request_id: str = None,
+        task: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
-        # 可见性
         self.accessibility = accessibility
-        # 创建时间
+        self.domain = domain
         self.gmt_create_time = gmt_create_time
-        # 最后更新时间
         self.gmt_modified_time = gmt_modified_time
-        # 模型的标签
         self.labels = labels
-        # 模型的最新版本
         self.latest_version = latest_version
-        # 模型描述
         self.model_description = model_description
-        # 模型ID
+        self.model_doc = model_doc
         self.model_id = model_id
-        # 模型名称
         self.model_name = model_name
-        # 云账号ID
+        self.origin = origin
         self.owner_id = owner_id
-        # Id of the request
+        self.provider = provider
         self.request_id = request_id
-        # 创建模型的用户ID
+        self.task = task
         self.user_id = user_id
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -5473,66 +5985,86 @@
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.accessibility is not None:
             result['Accessibility'] = self.accessibility
+        if self.domain is not None:
+            result['Domain'] = self.domain
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         if self.latest_version is not None:
             result['LatestVersion'] = self.latest_version.to_map()
         if self.model_description is not None:
             result['ModelDescription'] = self.model_description
+        if self.model_doc is not None:
+            result['ModelDoc'] = self.model_doc
         if self.model_id is not None:
             result['ModelId'] = self.model_id
         if self.model_name is not None:
             result['ModelName'] = self.model_name
+        if self.origin is not None:
+            result['Origin'] = self.origin
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
+        if self.provider is not None:
+            result['Provider'] = self.provider
         if self.request_id is not None:
             result['RequestId'] = self.request_id
+        if self.task is not None:
+            result['Task'] = self.task
         if self.user_id is not None:
             result['UserId'] = self.user_id
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
             self.accessibility = m.get('Accessibility')
+        if m.get('Domain') is not None:
+            self.domain = m.get('Domain')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = Label()
                 self.labels.append(temp_model.from_map(k))
         if m.get('LatestVersion') is not None:
             temp_model = ModelVersion()
             self.latest_version = temp_model.from_map(m['LatestVersion'])
         if m.get('ModelDescription') is not None:
             self.model_description = m.get('ModelDescription')
+        if m.get('ModelDoc') is not None:
+            self.model_doc = m.get('ModelDoc')
         if m.get('ModelId') is not None:
             self.model_id = m.get('ModelId')
         if m.get('ModelName') is not None:
             self.model_name = m.get('ModelName')
+        if m.get('Origin') is not None:
+            self.origin = m.get('Origin')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
+        if m.get('Provider') is not None:
+            self.provider = m.get('Provider')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
+        if m.get('Task') is not None:
+            self.task = m.get('Task')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
@@ -5579,67 +6111,64 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class GetModelVersionResponseBody(TeaModel):
     def __init__(
         self,
+        approval_status: str = None,
         format_type: str = None,
         framework_type: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         inference_spec: Dict[str, Any] = None,
         labels: List[Label] = None,
         options: str = None,
         owner_id: str = None,
         request_id: str = None,
+        source_id: str = None,
+        source_type: str = None,
+        training_spec: Dict[str, Any] = None,
         uri: str = None,
         user_id: str = None,
         version_description: str = None,
         version_name: str = None,
     ):
-        # 模型格式
+        self.approval_status = approval_status
         self.format_type = format_type
-        # 模型框架
         self.framework_type = framework_type
-        # 创建时间
         self.gmt_create_time = gmt_create_time
-        # 最后更新时间
         self.gmt_modified_time = gmt_modified_time
-        # 下游部署配置
         self.inference_spec = inference_spec
-        # 模型版本标签
         self.labels = labels
-        # 扩展字段
         self.options = options
-        # 云账号ID
         self.owner_id = owner_id
-        # 请求ID
         self.request_id = request_id
-        # 模型Uri
+        self.source_id = source_id
+        self.source_type = source_type
+        self.training_spec = training_spec
         self.uri = uri
-        # 创建者ID
         self.user_id = user_id
-        # 版本描述
         self.version_description = version_description
-        # 版本名
         self.version_name = version_name
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.approval_status is not None:
+            result['ApprovalStatus'] = self.approval_status
         if self.format_type is not None:
             result['FormatType'] = self.format_type
         if self.framework_type is not None:
             result['FrameworkType'] = self.framework_type
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
@@ -5652,26 +6181,34 @@
                 result['Labels'].append(k.to_map() if k else None)
         if self.options is not None:
             result['Options'] = self.options
         if self.owner_id is not None:
             result['OwnerId'] = self.owner_id
         if self.request_id is not None:
             result['RequestId'] = self.request_id
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
+        if self.source_type is not None:
+            result['SourceType'] = self.source_type
+        if self.training_spec is not None:
+            result['TrainingSpec'] = self.training_spec
         if self.uri is not None:
             result['Uri'] = self.uri
         if self.user_id is not None:
             result['UserId'] = self.user_id
         if self.version_description is not None:
             result['VersionDescription'] = self.version_description
         if self.version_name is not None:
             result['VersionName'] = self.version_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ApprovalStatus') is not None:
+            self.approval_status = m.get('ApprovalStatus')
         if m.get('FormatType') is not None:
             self.format_type = m.get('FormatType')
         if m.get('FrameworkType') is not None:
             self.framework_type = m.get('FrameworkType')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
@@ -5685,14 +6222,20 @@
                 self.labels.append(temp_model.from_map(k))
         if m.get('Options') is not None:
             self.options = m.get('Options')
         if m.get('OwnerId') is not None:
             self.owner_id = m.get('OwnerId')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
+        if m.get('SourceType') is not None:
+            self.source_type = m.get('SourceType')
+        if m.get('TrainingSpec') is not None:
+            self.training_spec = m.get('TrainingSpec')
         if m.get('Uri') is not None:
             self.uri = m.get('Uri')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('VersionDescription') is not None:
             self.version_description = m.get('VersionDescription')
         if m.get('VersionName') is not None:
@@ -5746,17 +6289,15 @@
 
 class GetPermissionRequest(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
         creator: str = None,
     ):
-        # 待鉴权实例的可见性 PUBLIC表示当前工作空间所有人都可以访问 PRIVATE表示只有Owner可以访问
         self.accessibility = accessibility
-        # 创建者
         self.creator = creator
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5781,17 +6322,15 @@
 
 class GetPermissionResponseBodyPermissionRules(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
         entity_access_type: str = None,
     ):
-        # 待鉴权实例的可见性 PUBLIC表示当前工作空间所有人都可以访问 PRIVATE表示只有Owner可以访问
         self.accessibility = accessibility
-        # 存取类型 CREATOR 代表能看自已创建的 OTHERS 代表可以看别人创建的 ALL代表所有
         self.entity_access_type = entity_access_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5817,18 +6356,16 @@
 class GetPermissionResponseBody(TeaModel):
     def __init__(
         self,
         permission_code: str = None,
         permission_rules: List[GetPermissionResponseBodyPermissionRules] = None,
         request_id: str = None,
     ):
-        # 权限
         self.permission_code = permission_code
         self.permission_rules = permission_rules
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         if self.permission_rules:
             for k in self.permission_rules:
                 if k:
                     k.validate()
@@ -5908,15 +6445,14 @@
 
 
 class GetRoleStatisticsRequest(TeaModel):
     def __init__(
         self,
         workspace_id: str = None,
     ):
-        # 工作空间 id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5937,17 +6473,15 @@
 
 class GetRoleStatisticsResponseBodyRoles(TeaModel):
     def __init__(
         self,
         member_size: int = None,
         role_name: str = None,
     ):
-        # 成员数量
         self.member_size = member_size
-        # 角色名
         self.role_name = role_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -5973,19 +6507,16 @@
 class GetRoleStatisticsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         roles: List[GetRoleStatisticsResponseBodyRoles] = None,
         total_count: int = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 角色信息统计
         self.roles = roles
-        # 总数
         self.total_count = total_count
 
     def validate(self):
         if self.roles:
             for k in self.roles:
                 if k:
                     k.validate()
@@ -6150,40 +6681,27 @@
         is_default: bool = None,
         owner: GetWorkspaceResponseBodyOwner = None,
         request_id: str = None,
         status: str = None,
         workspace_id: str = None,
         workspace_name: str = None,
     ):
-        # 管理员账户
         self.admin_names = admin_names
-        # 创建人
         self.creator = creator
-        # 描述
         self.description = description
-        # 显示名称
         self.display_name = display_name
-        # 环境，用作判断简单模式还是标准模式
         self.env_types = env_types
-        # 附加信息
         self.extra_infos = extra_infos
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 修改 UTC 时间，日期格式 iso8601
         self.gmt_modified_time = gmt_modified_time
-        # 是否为默认工作空间
         self.is_default = is_default
         self.owner = owner
-        # 请求 id
         self.request_id = request_id
-        # 工作空间状态
         self.status = status
-        # 工作空间 id
         self.workspace_id = workspace_id
-        # 项目空间名称， region 内唯一
         self.workspace_name = workspace_name
 
     def validate(self):
         if self.owner:
             self.owner.validate()
 
     def to_map(self):
@@ -6306,25 +6824,19 @@
         display_name: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
         sort_by: str = None,
         workspace_id: str = None,
     ):
-        # 代码源显示名称，支持模糊匹配
         self.display_name = display_name
-        # 排序顺序, 枚举值 desc 或者 asc
         self.order = order
-        # 取第几页的数据
         self.page_number = page_number
-        # 分页大小
         self.page_size = page_size
-        # 用于排序的字段名，可选字段名："DisplayName" "GmtCreateTime" "GmtModifyTime"
         self.sort_by = sort_by
-        # 工作空间ID
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6366,19 +6878,16 @@
 class ListCodeSourcesResponseBody(TeaModel):
     def __init__(
         self,
         code_sources: List[CodeSourceItem] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 代码源配置列表
         self.code_sources = code_sources
-        # 请求Id
         self.request_id = request_id
-        # 符合过滤条件的代码源配置的总数量
         self.total_count = total_count
 
     def validate(self):
         if self.code_sources:
             for k in self.code_sources:
                 if k:
                     k.validate()
@@ -6458,15 +6967,14 @@
 
 
 class ListConfigsRequest(TeaModel):
     def __init__(
         self,
         config_keys: str = None,
     ):
-        # 配置键
         self.config_keys = config_keys
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6487,17 +6995,15 @@
 
 class ListConfigsResponseBodyConfigs(TeaModel):
     def __init__(
         self,
         config_key: str = None,
         config_value: str = None,
     ):
-        # 配置键
         self.config_key = config_key
-        # 配置值
         self.config_value = config_value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6523,19 +7029,16 @@
 class ListConfigsResponseBody(TeaModel):
     def __init__(
         self,
         configs: List[ListConfigsResponseBodyConfigs] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 配置列表
         self.configs = configs
-        # 请求ID
         self.request_id = request_id
-        # 返回数量
         self.total_count = total_count
 
     def validate(self):
         if self.configs:
             for k in self.configs:
                 if k:
                     k.validate()
@@ -6615,35 +7118,38 @@
 
 
 class ListDatasetsRequest(TeaModel):
     def __init__(
         self,
         data_source_types: str = None,
         data_types: str = None,
+        label: str = None,
         label_keys: str = None,
         label_values: str = None,
         name: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
         properties: str = None,
+        source_id: str = None,
         source_types: str = None,
         workspace_id: str = None,
     ):
         self.data_source_types = data_source_types
         self.data_types = data_types
+        self.label = label
         self.label_keys = label_keys
         self.label_values = label_values
         self.name = name
         self.order = order
         self.page_number = page_number
         self.page_size = page_size
         self.properties = properties
+        self.source_id = source_id
         self.source_types = source_types
-        # Workspace Id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6651,54 +7157,62 @@
             return _map
 
         result = dict()
         if self.data_source_types is not None:
             result['DataSourceTypes'] = self.data_source_types
         if self.data_types is not None:
             result['DataTypes'] = self.data_types
+        if self.label is not None:
+            result['Label'] = self.label
         if self.label_keys is not None:
             result['LabelKeys'] = self.label_keys
         if self.label_values is not None:
             result['LabelValues'] = self.label_values
         if self.name is not None:
             result['Name'] = self.name
         if self.order is not None:
             result['Order'] = self.order
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
         if self.properties is not None:
             result['Properties'] = self.properties
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
         if self.source_types is not None:
             result['SourceTypes'] = self.source_types
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('DataSourceTypes') is not None:
             self.data_source_types = m.get('DataSourceTypes')
         if m.get('DataTypes') is not None:
             self.data_types = m.get('DataTypes')
+        if m.get('Label') is not None:
+            self.label = m.get('Label')
         if m.get('LabelKeys') is not None:
             self.label_keys = m.get('LabelKeys')
         if m.get('LabelValues') is not None:
             self.label_values = m.get('LabelValues')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Order') is not None:
             self.order = m.get('Order')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
         if m.get('Properties') is not None:
             self.properties = m.get('Properties')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
         if m.get('SourceTypes') is not None:
             self.source_types = m.get('SourceTypes')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
@@ -6706,15 +7220,14 @@
     def __init__(
         self,
         datasets: List[Dataset] = None,
         request_id: str = None,
         total_count: int = None,
     ):
         self.datasets = datasets
-        # Id of the request
         self.request_id = request_id
         self.total_count = total_count
 
     def validate(self):
         if self.datasets:
             for k in self.datasets:
                 if k:
@@ -6795,15 +7308,14 @@
 
 
 class ListFeaturesRequest(TeaModel):
     def __init__(
         self,
         names: str = None,
     ):
-        # 特性名称，以逗号分隔
         self.names = names
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6825,19 +7337,16 @@
 class ListFeaturesResponseBody(TeaModel):
     def __init__(
         self,
         features: List[str] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 特性列表
         self.features = features
-        # Id of the request
         self.request_id = request_id
-        # 特性总数
         self.total_count = total_count
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6910,17 +7419,15 @@
 
 class ListGlobalPermissionsResponseBodyPermissionsPermissionRules(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
         entity_access_type: str = None,
     ):
-        # 待鉴权实例的可见性 PUBLIC表示当前工作空间所有人都可以访问 PRIVATE表示只有Owner可以访问
         self.accessibility = accessibility
-        # 存取类型 CREATOR 代表能看自已创建的 OTHERS 代表可以看别人创建的 ALL代表所有
         self.entity_access_type = entity_access_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -6945,17 +7452,15 @@
 
 class ListGlobalPermissionsResponseBodyPermissions(TeaModel):
     def __init__(
         self,
         permission_code: str = None,
         permission_rules: List[ListGlobalPermissionsResponseBodyPermissionsPermissionRules] = None,
     ):
-        # PermissionCode
         self.permission_code = permission_code
-        # PermissionRules
         self.permission_rules = permission_rules
 
     def validate(self):
         if self.permission_rules:
             for k in self.permission_rules:
                 if k:
                     k.validate()
@@ -6988,17 +7493,15 @@
 
 class ListGlobalPermissionsResponseBody(TeaModel):
     def __init__(
         self,
         permissions: List[ListGlobalPermissionsResponseBodyPermissions] = None,
         request_id: str = None,
     ):
-        # Permissions
         self.permissions = permissions
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         if self.permissions:
             for k in self.permissions:
                 if k:
                     k.validate()
@@ -7010,26 +7513,26 @@
 
         result = dict()
         result['Permissions'] = []
         if self.permissions is not None:
             for k in self.permissions:
                 result['Permissions'].append(k.to_map() if k else None)
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.permissions = []
         if m.get('Permissions') is not None:
             for k in m.get('Permissions'):
                 temp_model = ListGlobalPermissionsResponseBodyPermissions()
                 self.permissions.append(temp_model.from_map(k))
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class ListGlobalPermissionsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -7078,23 +7581,18 @@
         self,
         image_id: str = None,
         label_filter: str = None,
         label_keys: str = None,
         region: str = None,
         workspace_id: str = None,
     ):
-        # 镜像id
         self.image_id = image_id
-        # image过滤条件，获取满足条件的image的所有label
         self.label_filter = label_filter
-        # 标签列表，以逗号分隔
         self.label_keys = label_keys
-        # 地域
         self.region = region
-        # 工作空间id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -7131,17 +7629,15 @@
 
 class ListImageLabelsResponseBodyLabels(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # 键
         self.key = key
-        # 值
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -7164,23 +7660,20 @@
         return self
 
 
 class ListImageLabelsResponseBody(TeaModel):
     def __init__(
         self,
         labels: List[ListImageLabelsResponseBodyLabels] = None,
-        total_count: int = None,
         request_id: str = None,
+        total_count: int = None,
     ):
-        # 镜像标签
         self.labels = labels
-        # 符合过滤条件的数量
-        self.total_count = total_count
-        # Id of the request
         self.request_id = request_id
+        self.total_count = total_count
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
 
@@ -7190,31 +7683,31 @@
             return _map
 
         result = dict()
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
         if self.total_count is not None:
             result['TotalCount'] = self.total_count
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = ListImageLabelsResponseBodyLabels()
                 self.labels.append(temp_model.from_map(k))
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         if m.get('TotalCount') is not None:
             self.total_count = m.get('TotalCount')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
         return self
 
 
 class ListImageLabelsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -7259,39 +7752,34 @@
 
 
 class ListImagesRequest(TeaModel):
     def __init__(
         self,
         labels: str = None,
         name: str = None,
-        operator_create: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
+        parent_user_id: str = None,
+        query: str = None,
         sort_by: str = None,
+        user_id: str = None,
         verbose: bool = None,
         workspace_id: str = None,
     ):
-        # 过滤值 以逗号分隔
         self.labels = labels
-        # 镜像名称，支持模糊搜索
         self.name = name
-        # 创建者
-        self.operator_create = operator_create
-        # 排序方向： ASC - 升序 DESC - 降序
         self.order = order
-        # 分页，从1开始，默认1
         self.page_number = page_number
-        # 页大小，默认20
         self.page_size = page_size
-        # 排序字段
+        self.parent_user_id = parent_user_id
+        self.query = query
         self.sort_by = sort_by
-        # 是否显示非必要信息：Labels
+        self.user_id = user_id
         self.verbose = verbose
-        # 工作空间id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -7299,62 +7787,68 @@
             return _map
 
         result = dict()
         if self.labels is not None:
             result['Labels'] = self.labels
         if self.name is not None:
             result['Name'] = self.name
-        if self.operator_create is not None:
-            result['OperatorCreate'] = self.operator_create
         if self.order is not None:
             result['Order'] = self.order
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
+        if self.parent_user_id is not None:
+            result['ParentUserId'] = self.parent_user_id
+        if self.query is not None:
+            result['Query'] = self.query
         if self.sort_by is not None:
             result['SortBy'] = self.sort_by
+        if self.user_id is not None:
+            result['UserId'] = self.user_id
         if self.verbose is not None:
             result['Verbose'] = self.verbose
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Labels') is not None:
             self.labels = m.get('Labels')
         if m.get('Name') is not None:
             self.name = m.get('Name')
-        if m.get('OperatorCreate') is not None:
-            self.operator_create = m.get('OperatorCreate')
         if m.get('Order') is not None:
             self.order = m.get('Order')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
+        if m.get('ParentUserId') is not None:
+            self.parent_user_id = m.get('ParentUserId')
+        if m.get('Query') is not None:
+            self.query = m.get('Query')
         if m.get('SortBy') is not None:
             self.sort_by = m.get('SortBy')
+        if m.get('UserId') is not None:
+            self.user_id = m.get('UserId')
         if m.get('Verbose') is not None:
             self.verbose = m.get('Verbose')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class ListImagesResponseBodyImagesLabels(TeaModel):
     def __init__(
         self,
         key: str = None,
         value: str = None,
     ):
-        # Key
         self.key = key
-        # Value
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -7384,39 +7878,28 @@
         description: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         image_id: str = None,
         image_uri: str = None,
         labels: List[ListImagesResponseBodyImagesLabels] = None,
         name: str = None,
-        operator_create: str = None,
-        parent_operator_create: str = None,
+        parent_user_id: str = None,
+        user_id: str = None,
         workspace_id: str = None,
     ):
-        # 可见性
         self.accessibility = accessibility
-        # 镜像描述
         self.description = description
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 修改时间
         self.gmt_modified_time = gmt_modified_time
-        # 镜像id
         self.image_id = image_id
-        # 镜像地址，包含版本号
         self.image_uri = image_uri
-        # 镜像标签，是个map
         self.labels = labels
-        # 镜像名称
         self.name = name
-        # 创建人
-        self.operator_create = operator_create
-        # 父创建人
-        self.parent_operator_create = parent_operator_create
-        # 工作空间id
+        self.parent_user_id = parent_user_id
+        self.user_id = user_id
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.labels:
             for k in self.labels:
                 if k:
                     k.validate()
@@ -7441,18 +7924,18 @@
             result['ImageUri'] = self.image_uri
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         if self.name is not None:
             result['Name'] = self.name
-        if self.operator_create is not None:
-            result['OperatorCreate'] = self.operator_create
-        if self.parent_operator_create is not None:
-            result['ParentOperatorCreate'] = self.parent_operator_create
+        if self.parent_user_id is not None:
+            result['ParentUserId'] = self.parent_user_id
+        if self.user_id is not None:
+            result['UserId'] = self.user_id
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
@@ -7470,36 +7953,33 @@
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = ListImagesResponseBodyImagesLabels()
                 self.labels.append(temp_model.from_map(k))
         if m.get('Name') is not None:
             self.name = m.get('Name')
-        if m.get('OperatorCreate') is not None:
-            self.operator_create = m.get('OperatorCreate')
-        if m.get('ParentOperatorCreate') is not None:
-            self.parent_operator_create = m.get('ParentOperatorCreate')
+        if m.get('ParentUserId') is not None:
+            self.parent_user_id = m.get('ParentUserId')
+        if m.get('UserId') is not None:
+            self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class ListImagesResponseBody(TeaModel):
     def __init__(
         self,
         images: List[ListImagesResponseBodyImages] = None,
-        total_count: int = None,
         request_id: str = None,
+        total_count: int = None,
     ):
-        # 镜像列表
         self.images = images
-        # 总数
-        self.total_count = total_count
-        # Id of the request
         self.request_id = request_id
+        self.total_count = total_count
 
     def validate(self):
         if self.images:
             for k in self.images:
                 if k:
                     k.validate()
 
@@ -7509,31 +7989,31 @@
             return _map
 
         result = dict()
         result['Images'] = []
         if self.images is not None:
             for k in self.images:
                 result['Images'].append(k.to_map() if k else None)
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
         if self.total_count is not None:
             result['TotalCount'] = self.total_count
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.images = []
         if m.get('Images') is not None:
             for k in m.get('Images'):
                 temp_model = ListImagesResponseBodyImages()
                 self.images.append(temp_model.from_map(k))
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         if m.get('TotalCount') is not None:
             self.total_count = m.get('TotalCount')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
         return self
 
 
 class ListImagesResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -7581,21 +8061,17 @@
     def __init__(
         self,
         member_name: str = None,
         page_number: int = None,
         page_size: int = None,
         roles: str = None,
     ):
-        # 成员名
         self.member_name = member_name
-        # 分页，从1开始，默认1
         self.page_number = page_number
-        # 页大小，默认20
         self.page_size = page_size
-        # Role 过滤列表，逗号分隔
         self.roles = roles
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -7628,30 +8104,24 @@
 
 class ListMembersResponseBodyMembers(TeaModel):
     def __init__(
         self,
         display_name: str = None,
         gmt_create_time: str = None,
         member_id: str = None,
+        member_name: str = None,
         roles: List[str] = None,
         user_id: str = None,
-        user_name: str = None,
     ):
-        # 成员显示名
         self.display_name = display_name
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 成员 id
         self.member_id = member_id
-        # 角色列表
+        self.member_name = member_name
         self.roles = roles
-        # 用户 id
         self.user_id = user_id
-        # 云账号用户名
-        self.user_name = user_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
@@ -7660,51 +8130,48 @@
         result = dict()
         if self.display_name is not None:
             result['DisplayName'] = self.display_name
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.member_id is not None:
             result['MemberId'] = self.member_id
+        if self.member_name is not None:
+            result['MemberName'] = self.member_name
         if self.roles is not None:
             result['Roles'] = self.roles
         if self.user_id is not None:
             result['UserId'] = self.user_id
-        if self.user_name is not None:
-            result['UserName'] = self.user_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('DisplayName') is not None:
             self.display_name = m.get('DisplayName')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('MemberId') is not None:
             self.member_id = m.get('MemberId')
+        if m.get('MemberName') is not None:
+            self.member_name = m.get('MemberName')
         if m.get('Roles') is not None:
             self.roles = m.get('Roles')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
-        if m.get('UserName') is not None:
-            self.user_name = m.get('UserName')
         return self
 
 
 class ListMembersResponseBody(TeaModel):
     def __init__(
         self,
         members: List[ListMembersResponseBodyMembers] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 成员列表
         self.members = members
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的数量
         self.total_count = total_count
 
     def validate(self):
         if self.members:
             for k in self.members:
                 if k:
                     k.validate()
@@ -7779,103 +8246,344 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = ListMembersResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class ListModelDomainsRequest(TeaModel):
+    def __init__(
+        self,
+        model_domain_ids: str = None,
+    ):
+        self.model_domain_ids = model_domain_ids
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_domain_ids is not None:
+            result['ModelDomainIds'] = self.model_domain_ids
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelDomainIds') is not None:
+            self.model_domain_ids = m.get('ModelDomainIds')
+        return self
+
+
+class ListModelDomainsResponseBodyModelDomainsModelTasks(TeaModel):
+    def __init__(
+        self,
+        model_domain_id: str = None,
+        model_task_id: str = None,
+        model_task_name: str = None,
+        order_number: int = None,
+        search_words: str = None,
+    ):
+        self.model_domain_id = model_domain_id
+        self.model_task_id = model_task_id
+        self.model_task_name = model_task_name
+        self.order_number = order_number
+        self.search_words = search_words
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_domain_id is not None:
+            result['ModelDomainId'] = self.model_domain_id
+        if self.model_task_id is not None:
+            result['ModelTaskId'] = self.model_task_id
+        if self.model_task_name is not None:
+            result['ModelTaskName'] = self.model_task_name
+        if self.order_number is not None:
+            result['OrderNumber'] = self.order_number
+        if self.search_words is not None:
+            result['SearchWords'] = self.search_words
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelDomainId') is not None:
+            self.model_domain_id = m.get('ModelDomainId')
+        if m.get('ModelTaskId') is not None:
+            self.model_task_id = m.get('ModelTaskId')
+        if m.get('ModelTaskName') is not None:
+            self.model_task_name = m.get('ModelTaskName')
+        if m.get('OrderNumber') is not None:
+            self.order_number = m.get('OrderNumber')
+        if m.get('SearchWords') is not None:
+            self.search_words = m.get('SearchWords')
+        return self
+
+
+class ListModelDomainsResponseBodyModelDomains(TeaModel):
+    def __init__(
+        self,
+        model_domain_id: str = None,
+        model_domain_name: str = None,
+        model_tasks: List[ListModelDomainsResponseBodyModelDomainsModelTasks] = None,
+        order_number: int = None,
+    ):
+        self.model_domain_id = model_domain_id
+        self.model_domain_name = model_domain_name
+        self.model_tasks = model_tasks
+        self.order_number = order_number
+
+    def validate(self):
+        if self.model_tasks:
+            for k in self.model_tasks:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_domain_id is not None:
+            result['ModelDomainId'] = self.model_domain_id
+        if self.model_domain_name is not None:
+            result['ModelDomainName'] = self.model_domain_name
+        result['ModelTasks'] = []
+        if self.model_tasks is not None:
+            for k in self.model_tasks:
+                result['ModelTasks'].append(k.to_map() if k else None)
+        if self.order_number is not None:
+            result['OrderNumber'] = self.order_number
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelDomainId') is not None:
+            self.model_domain_id = m.get('ModelDomainId')
+        if m.get('ModelDomainName') is not None:
+            self.model_domain_name = m.get('ModelDomainName')
+        self.model_tasks = []
+        if m.get('ModelTasks') is not None:
+            for k in m.get('ModelTasks'):
+                temp_model = ListModelDomainsResponseBodyModelDomainsModelTasks()
+                self.model_tasks.append(temp_model.from_map(k))
+        if m.get('OrderNumber') is not None:
+            self.order_number = m.get('OrderNumber')
+        return self
+
+
+class ListModelDomainsResponseBody(TeaModel):
+    def __init__(
+        self,
+        model_domains: List[ListModelDomainsResponseBodyModelDomains] = None,
+        request_id: str = None,
+        total_count: int = None,
+    ):
+        self.model_domains = model_domains
+        self.request_id = request_id
+        self.total_count = total_count
+
+    def validate(self):
+        if self.model_domains:
+            for k in self.model_domains:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        result['ModelDomains'] = []
+        if self.model_domains is not None:
+            for k in self.model_domains:
+                result['ModelDomains'].append(k.to_map() if k else None)
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        if self.total_count is not None:
+            result['TotalCount'] = self.total_count
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        self.model_domains = []
+        if m.get('ModelDomains') is not None:
+            for k in m.get('ModelDomains'):
+                temp_model = ListModelDomainsResponseBodyModelDomains()
+                self.model_domains.append(temp_model.from_map(k))
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        if m.get('TotalCount') is not None:
+            self.total_count = m.get('TotalCount')
+        return self
+
+
+class ListModelDomainsResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: ListModelDomainsResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = ListModelDomainsResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class ListModelVersionsRequest(TeaModel):
     def __init__(
         self,
+        approval_status: str = None,
         format_type: str = None,
         framework_type: str = None,
+        label: str = None,
+        label_string: str = None,
         labels: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
         sort_by: str = None,
-        versionl_name: str = None,
+        source_id: str = None,
+        source_type: str = None,
+        version_name: str = None,
     ):
-        # 模型格式类型
+        self.approval_status = approval_status
         self.format_type = format_type
-        # 模型框架
         self.framework_type = framework_type
-        # 标签
+        self.label = label
+        self.label_string = label_string
         self.labels = labels
-        # 顺序
         self.order = order
-        # 页数
         self.page_number = page_number
-        # 每页大小
         self.page_size = page_size
-        # 排序依据
         self.sort_by = sort_by
-        # 模型版本名称
-        self.versionl_name = versionl_name
+        self.source_id = source_id
+        self.source_type = source_type
+        self.version_name = version_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.approval_status is not None:
+            result['ApprovalStatus'] = self.approval_status
         if self.format_type is not None:
             result['FormatType'] = self.format_type
         if self.framework_type is not None:
             result['FrameworkType'] = self.framework_type
+        if self.label is not None:
+            result['Label'] = self.label
+        if self.label_string is not None:
+            result['LabelString'] = self.label_string
         if self.labels is not None:
             result['Labels'] = self.labels
         if self.order is not None:
             result['Order'] = self.order
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
         if self.sort_by is not None:
             result['SortBy'] = self.sort_by
-        if self.versionl_name is not None:
-            result['VersionlName'] = self.versionl_name
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
+        if self.source_type is not None:
+            result['SourceType'] = self.source_type
+        if self.version_name is not None:
+            result['VersionName'] = self.version_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ApprovalStatus') is not None:
+            self.approval_status = m.get('ApprovalStatus')
         if m.get('FormatType') is not None:
             self.format_type = m.get('FormatType')
         if m.get('FrameworkType') is not None:
             self.framework_type = m.get('FrameworkType')
+        if m.get('Label') is not None:
+            self.label = m.get('Label')
+        if m.get('LabelString') is not None:
+            self.label_string = m.get('LabelString')
         if m.get('Labels') is not None:
             self.labels = m.get('Labels')
         if m.get('Order') is not None:
             self.order = m.get('Order')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
         if m.get('SortBy') is not None:
             self.sort_by = m.get('SortBy')
-        if m.get('VersionlName') is not None:
-            self.versionl_name = m.get('VersionlName')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
+        if m.get('SourceType') is not None:
+            self.source_type = m.get('SourceType')
+        if m.get('VersionName') is not None:
+            self.version_name = m.get('VersionName')
         return self
 
 
 class ListModelVersionsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         total_count: int = None,
         versions: List[ModelVersion] = None,
     ):
-        # Id of the request
         self.request_id = request_id
-        # 总数
         self.total_count = total_count
-        # 模型版本列表
         self.versions = versions
 
     def validate(self):
         if self.versions:
             for k in self.versions:
                 if k:
                     k.validate()
@@ -7953,93 +8661,125 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class ListModelsRequest(TeaModel):
     def __init__(
         self,
+        domain: str = None,
+        label: str = None,
+        label_string: str = None,
         labels: str = None,
         model_name: str = None,
         order: str = None,
+        origin: str = None,
         page_number: int = None,
         page_size: int = None,
+        provider: str = None,
+        query: str = None,
         sort_by: str = None,
+        task: str = None,
         workspace_id: str = None,
     ):
-        # 标签
+        self.domain = domain
+        self.label = label
+        self.label_string = label_string
         self.labels = labels
-        # 模型名称
         self.model_name = model_name
-        # 顺序
         self.order = order
-        # 页数
+        self.origin = origin
         self.page_number = page_number
-        # 每页大小
         self.page_size = page_size
-        # 排序依据
+        self.provider = provider
+        self.query = query
         self.sort_by = sort_by
-        # 工作空间ID
+        self.task = task
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.domain is not None:
+            result['Domain'] = self.domain
+        if self.label is not None:
+            result['Label'] = self.label
+        if self.label_string is not None:
+            result['LabelString'] = self.label_string
         if self.labels is not None:
             result['Labels'] = self.labels
         if self.model_name is not None:
             result['ModelName'] = self.model_name
         if self.order is not None:
             result['Order'] = self.order
+        if self.origin is not None:
+            result['Origin'] = self.origin
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
+        if self.provider is not None:
+            result['Provider'] = self.provider
+        if self.query is not None:
+            result['Query'] = self.query
         if self.sort_by is not None:
             result['SortBy'] = self.sort_by
+        if self.task is not None:
+            result['Task'] = self.task
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('Domain') is not None:
+            self.domain = m.get('Domain')
+        if m.get('Label') is not None:
+            self.label = m.get('Label')
+        if m.get('LabelString') is not None:
+            self.label_string = m.get('LabelString')
         if m.get('Labels') is not None:
             self.labels = m.get('Labels')
         if m.get('ModelName') is not None:
             self.model_name = m.get('ModelName')
         if m.get('Order') is not None:
             self.order = m.get('Order')
+        if m.get('Origin') is not None:
+            self.origin = m.get('Origin')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
+        if m.get('Provider') is not None:
+            self.provider = m.get('Provider')
+        if m.get('Query') is not None:
+            self.query = m.get('Query')
         if m.get('SortBy') is not None:
             self.sort_by = m.get('SortBy')
+        if m.get('Task') is not None:
+            self.task = m.get('Task')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class ListModelsResponseBody(TeaModel):
     def __init__(
         self,
         models: List[Model] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 模型列表
         self.models = models
-        # Id of the request
         self.request_id = request_id
-        # 总数
         self.total_count = total_count
 
     def validate(self):
         if self.models:
             for k in self.models:
                 if k:
                     k.validate()
@@ -8114,40 +8854,237 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = ListModelsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class ListModuleConfigsRequest(TeaModel):
+    def __init__(
+        self,
+        module_codes: str = None,
+        region: str = None,
+    ):
+        self.module_codes = module_codes
+        self.region = region
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.module_codes is not None:
+            result['ModuleCodes'] = self.module_codes
+        if self.region is not None:
+            result['Region'] = self.region
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModuleCodes') is not None:
+            self.module_codes = m.get('ModuleCodes')
+        if m.get('Region') is not None:
+            self.region = m.get('Region')
+        return self
+
+
+class ListModuleConfigsResponseBodyModuleConfigsConfigs(TeaModel):
+    def __init__(
+        self,
+        key: str = None,
+        value: str = None,
+    ):
+        self.key = key
+        self.value = value
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.key is not None:
+            result['Key'] = self.key
+        if self.value is not None:
+            result['Value'] = self.value
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Key') is not None:
+            self.key = m.get('Key')
+        if m.get('Value') is not None:
+            self.value = m.get('Value')
+        return self
+
+
+class ListModuleConfigsResponseBodyModuleConfigs(TeaModel):
+    def __init__(
+        self,
+        configs: List[ListModuleConfigsResponseBodyModuleConfigsConfigs] = None,
+        module_code: str = None,
+        region: str = None,
+    ):
+        self.configs = configs
+        self.module_code = module_code
+        self.region = region
+
+    def validate(self):
+        if self.configs:
+            for k in self.configs:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        result['Configs'] = []
+        if self.configs is not None:
+            for k in self.configs:
+                result['Configs'].append(k.to_map() if k else None)
+        if self.module_code is not None:
+            result['ModuleCode'] = self.module_code
+        if self.region is not None:
+            result['Region'] = self.region
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        self.configs = []
+        if m.get('Configs') is not None:
+            for k in m.get('Configs'):
+                temp_model = ListModuleConfigsResponseBodyModuleConfigsConfigs()
+                self.configs.append(temp_model.from_map(k))
+        if m.get('ModuleCode') is not None:
+            self.module_code = m.get('ModuleCode')
+        if m.get('Region') is not None:
+            self.region = m.get('Region')
+        return self
+
+
+class ListModuleConfigsResponseBody(TeaModel):
+    def __init__(
+        self,
+        module_configs: List[ListModuleConfigsResponseBodyModuleConfigs] = None,
+        request_id: str = None,
+        total_count: int = None,
+    ):
+        self.module_configs = module_configs
+        self.request_id = request_id
+        self.total_count = total_count
+
+    def validate(self):
+        if self.module_configs:
+            for k in self.module_configs:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        result['ModuleConfigs'] = []
+        if self.module_configs is not None:
+            for k in self.module_configs:
+                result['ModuleConfigs'].append(k.to_map() if k else None)
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        if self.total_count is not None:
+            result['TotalCount'] = self.total_count
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        self.module_configs = []
+        if m.get('ModuleConfigs') is not None:
+            for k in m.get('ModuleConfigs'):
+                temp_model = ListModuleConfigsResponseBodyModuleConfigs()
+                self.module_configs.append(temp_model.from_map(k))
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        if m.get('TotalCount') is not None:
+            self.total_count = m.get('TotalCount')
+        return self
+
+
+class ListModuleConfigsResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: ListModuleConfigsResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = ListModuleConfigsResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class ListOperationLogsRequest(TeaModel):
     def __init__(
         self,
         entity_status: str = None,
         entity_types: str = None,
         operation_status: str = None,
         operations: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
         sort_by: str = None,
     ):
         self.entity_status = entity_status
-        # 以逗号分隔的日志类型，包含 Resource
         self.entity_types = entity_types
-        # 以逗号分隔的操作状态
         self.operation_status = operation_status
-        # 以逗号分隔的操作
         self.operations = operations
-        # 排序顺序， 顺序：ASC，倒序：DESC
         self.order = order
-        # 当前页，页码从1开始
         self.page_number = page_number
-        # 每页返回的输出数目
         self.page_size = page_size
-        # 排序字段
         self.sort_by = sort_by
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8201,27 +9138,20 @@
         entity_type: str = None,
         gmt_create_time: str = None,
         message: str = None,
         operation: str = None,
         operation_status: str = None,
         operator: str = None,
     ):
-        # 实体 id
         self.entity_id = entity_id
-        # 实体类型，目前支持Resource
         self.entity_type = entity_type
-        # 2021-01-30T12:51:33.028Z
         self.gmt_create_time = gmt_create_time
-        # 日志
         self.message = message
-        # 操作，目前支持Create, Update, SetDefault
         self.operation = operation
-        # 操作状态，支持 Processing、Succeeded、Failed
         self.operation_status = operation_status
-        # 操作人
         self.operator = operator
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8267,19 +9197,16 @@
 class ListOperationLogsResponseBody(TeaModel):
     def __init__(
         self,
         logs: List[ListOperationLogsResponseBodyLogs] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 输出日志列表
         self.logs = logs
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的日志数量
         self.total_count = total_count
 
     def validate(self):
         if self.logs:
             for k in self.logs:
                 if k:
                     k.validate()
@@ -8360,17 +9287,15 @@
 
 class ListPermissionsResponseBodyPermissionsPermissionRules(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
         entity_access_type: str = None,
     ):
-        # 待鉴权实例的可见性 PUBLIC表示当前工作空间所有人都可以访问 PRIVATE表示只有Owner可以访问
         self.accessibility = accessibility
-        # 存取类型 CREATOR 代表能看自已创建的 OTHERS 代表可以看别人创建的 ALL代表所有
         self.entity_access_type = entity_access_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8395,15 +9320,14 @@
 
 class ListPermissionsResponseBodyPermissions(TeaModel):
     def __init__(
         self,
         permission_code: str = None,
         permission_rules: List[ListPermissionsResponseBodyPermissionsPermissionRules] = None,
     ):
-        # 权限 code
         self.permission_code = permission_code
         self.permission_rules = permission_rules
 
     def validate(self):
         if self.permission_rules:
             for k in self.permission_rules:
                 if k:
@@ -8438,19 +9362,16 @@
 class ListPermissionsResponseBody(TeaModel):
     def __init__(
         self,
         permissions: List[ListPermissionsResponseBodyPermissions] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 权限列表
         self.permissions = permissions
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的数量
         self.total_count = total_count
 
     def validate(self):
         if self.permissions:
             for k in self.permissions:
                 if k:
                     k.validate()
@@ -8530,15 +9451,14 @@
 
 
 class ListProductAuthorizationsRequest(TeaModel):
     def __init__(
         self,
         ram_role_names: str = None,
     ):
-        # 逗号分隔的角色名 AliyunODPSPAIDefaultRole,AliyunPAIAccessingOSSRole,AliyunPAIDLCAccessingOSSRole,AliyunPAIDLCDefaultRole,AliyunPAIDSWDefaultRole
         self.ram_role_names = ram_role_names
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8562,23 +9482,18 @@
         self,
         authorization_url: str = None,
         is_authorized: bool = None,
         ram_role_arn: str = None,
         ram_role_name: str = None,
         ram_role_type: str = None,
     ):
-        # 快捷授权的url， 假如IsAuthorized为false时有效
         self.authorization_url = authorization_url
-        # 角色是否被授权
         self.is_authorized = is_authorized
-        # RoleArn
         self.ram_role_arn = ram_role_arn
-        # Role的名字
         self.ram_role_name = ram_role_name
-        # Role的类型
         self.ram_role_type = ram_role_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8616,19 +9531,16 @@
 class ListProductAuthorizationsResponseBody(TeaModel):
     def __init__(
         self,
         authorization_details: List[ListProductAuthorizationsResponseBodyAuthorizationDetails] = None,
         authorization_url: str = None,
         request_id: str = None,
     ):
-        # 角色列表
         self.authorization_details = authorization_details
-        # 授权链接
         self.authorization_url = authorization_url
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         if self.authorization_details:
             for k in self.authorization_details:
                 if k:
                     k.validate()
@@ -8642,28 +9554,28 @@
         result['AuthorizationDetails'] = []
         if self.authorization_details is not None:
             for k in self.authorization_details:
                 result['AuthorizationDetails'].append(k.to_map() if k else None)
         if self.authorization_url is not None:
             result['AuthorizationUrl'] = self.authorization_url
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         self.authorization_details = []
         if m.get('AuthorizationDetails') is not None:
             for k in m.get('AuthorizationDetails'):
                 temp_model = ListProductAuthorizationsResponseBodyAuthorizationDetails()
                 self.authorization_details.append(temp_model.from_map(k))
         if m.get('AuthorizationUrl') is not None:
             self.authorization_url = m.get('AuthorizationUrl')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class ListProductAuthorizationsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -8710,17 +9622,15 @@
 class ListProductsRequest(TeaModel):
     def __init__(
         self,
         product_codes: str = None,
         service_codes: str = None,
         verbose: bool = None,
     ):
-        # 逗号分割的商品 code
         self.product_codes = product_codes
-        # 逗号分割的服务 code
         self.service_codes = service_codes
         self.verbose = verbose
 
     def validate(self):
         pass
 
     def to_map(self):
@@ -8750,23 +9660,21 @@
 
 class ListProductsResponseBodyProducts(TeaModel):
     def __init__(
         self,
         has_permission_to_purchase: bool = None,
         is_purchased: bool = None,
         product_code: str = None,
+        product_instance_id: str = None,
         purchase_url: str = None,
     ):
-        # Whether user has permission to purchase
         self.has_permission_to_purchase = has_permission_to_purchase
-        # 是否已购买
         self.is_purchased = is_purchased
-        # 商品 code
         self.product_code = product_code
-        # 购买链接
+        self.product_instance_id = product_instance_id
         self.purchase_url = purchase_url
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8776,43 +9684,44 @@
         result = dict()
         if self.has_permission_to_purchase is not None:
             result['HasPermissionToPurchase'] = self.has_permission_to_purchase
         if self.is_purchased is not None:
             result['IsPurchased'] = self.is_purchased
         if self.product_code is not None:
             result['ProductCode'] = self.product_code
+        if self.product_instance_id is not None:
+            result['ProductInstanceId'] = self.product_instance_id
         if self.purchase_url is not None:
             result['PurchaseUrl'] = self.purchase_url
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('HasPermissionToPurchase') is not None:
             self.has_permission_to_purchase = m.get('HasPermissionToPurchase')
         if m.get('IsPurchased') is not None:
             self.is_purchased = m.get('IsPurchased')
         if m.get('ProductCode') is not None:
             self.product_code = m.get('ProductCode')
+        if m.get('ProductInstanceId') is not None:
+            self.product_instance_id = m.get('ProductInstanceId')
         if m.get('PurchaseUrl') is not None:
             self.purchase_url = m.get('PurchaseUrl')
         return self
 
 
 class ListProductsResponseBodyServices(TeaModel):
     def __init__(
         self,
         is_open: bool = None,
         open_url: str = None,
         service_code: str = None,
     ):
-        # 是否开通
         self.is_open = is_open
-        # 开通链接
         self.open_url = open_url
-        # 服务Code
         self.service_code = service_code
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8842,19 +9751,16 @@
 class ListProductsResponseBody(TeaModel):
     def __init__(
         self,
         products: List[ListProductsResponseBodyProducts] = None,
         request_id: str = None,
         services: List[ListProductsResponseBodyServices] = None,
     ):
-        # 产品列表
         self.products = products
-        # 请求 id
         self.request_id = request_id
-        # 服务列表
         self.services = services
 
     def validate(self):
         if self.products:
             for k in self.products:
                 if k:
                     k.validate()
@@ -8943,15 +9849,14 @@
 
 
 class ListQuotasRequest(TeaModel):
     def __init__(
         self,
         name: str = None,
     ):
-        # 名字，支持模糊搜索
         self.name = name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -8973,19 +9878,16 @@
 class ListQuotasResponseBodyQuotasSpecs(TeaModel):
     def __init__(
         self,
         name: str = None,
         type: str = None,
         value: str = None,
     ):
-        # 规格名
         self.name = name
-        # 类型，可为空
         self.type = type
-        # 规格描述
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -9011,46 +9913,44 @@
             self.value = m.get('Value')
         return self
 
 
 class ListQuotasResponseBodyQuotas(TeaModel):
     def __init__(
         self,
+        display_name: str = None,
         id: str = None,
         mode: str = None,
         name: str = None,
         product_code: str = None,
         quota_type: str = None,
         specs: List[ListQuotasResponseBodyQuotasSpecs] = None,
     ):
-        # quota的id
+        self.display_name = display_name
         self.id = id
-        # 模式  isolate 预付费  share 后付费  develop 开发模式
         self.mode = mode
-        # quota名字
         self.name = name
-        # 产品代码
         self.product_code = product_code
-        # 产品类型， 支持PAI，MaxCompute
         self.quota_type = quota_type
-        # 规格描述列表
         self.specs = specs
 
     def validate(self):
         if self.specs:
             for k in self.specs:
                 if k:
                     k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.id is not None:
             result['Id'] = self.id
         if self.mode is not None:
             result['Mode'] = self.mode
         if self.name is not None:
             result['Name'] = self.name
         if self.product_code is not None:
@@ -9061,14 +9961,16 @@
         if self.specs is not None:
             for k in self.specs:
                 result['Specs'].append(k.to_map() if k else None)
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('Id') is not None:
             self.id = m.get('Id')
         if m.get('Mode') is not None:
             self.mode = m.get('Mode')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('ProductCode') is not None:
@@ -9086,19 +9988,16 @@
 class ListQuotasResponseBody(TeaModel):
     def __init__(
         self,
         quotas: List[ListQuotasResponseBodyQuotas] = None,
         request_id: str = None,
         total_count: int = None,
     ):
-        # 配额列表
         self.quotas = quotas
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的数量
         self.total_count = total_count
 
     def validate(self):
         if self.quotas:
             for k in self.quotas:
                 if k:
                     k.validate()
@@ -9176,97 +10075,132 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class ListResourcesRequest(TeaModel):
     def __init__(
         self,
+        group_name: str = None,
         option: str = None,
         page_number: int = None,
         page_size: int = None,
         product_types: str = None,
-        resource_group_name: str = None,
         resource_name: str = None,
+        resource_types: str = None,
+        verbose: bool = None,
         workspace_id: str = None,
-        workspace_ids: str = None,
     ):
-        # 选项，目前支持 ListResourceByWorkspace    列举某个工作空间的资源 GetResource                       获取所有工作空间下的资源 GetResourceGroup               获取所有工作空间下的资源组 ListResourceSummaryByWorkspaces  列举一组工作空间的资源汇总
+        self.group_name = group_name
         self.option = option
-        # 分页，从1开始，默认1
         self.page_number = page_number
-        # 页大小，默认20
         self.page_size = page_size
-        # 逗号分隔的产品类型，可选值 MaxCompute，DLC
         self.product_types = product_types
-        # 资源的group名字
-        self.resource_group_name = resource_group_name
-        # 资源的名字
         self.resource_name = resource_name
-        # 工作空间 id
+        self.resource_types = resource_types
+        self.verbose = verbose
         self.workspace_id = workspace_id
-        # 工作空间id列表，以逗号分隔
-        self.workspace_ids = workspace_ids
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.group_name is not None:
+            result['GroupName'] = self.group_name
         if self.option is not None:
             result['Option'] = self.option
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
         if self.product_types is not None:
             result['ProductTypes'] = self.product_types
-        if self.resource_group_name is not None:
-            result['ResourceGroupName'] = self.resource_group_name
         if self.resource_name is not None:
             result['ResourceName'] = self.resource_name
+        if self.resource_types is not None:
+            result['ResourceTypes'] = self.resource_types
+        if self.verbose is not None:
+            result['Verbose'] = self.verbose
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
-        if self.workspace_ids is not None:
-            result['WorkspaceIds'] = self.workspace_ids
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('GroupName') is not None:
+            self.group_name = m.get('GroupName')
         if m.get('Option') is not None:
             self.option = m.get('Option')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
         if m.get('ProductTypes') is not None:
             self.product_types = m.get('ProductTypes')
-        if m.get('ResourceGroupName') is not None:
-            self.resource_group_name = m.get('ResourceGroupName')
         if m.get('ResourceName') is not None:
             self.resource_name = m.get('ResourceName')
+        if m.get('ResourceTypes') is not None:
+            self.resource_types = m.get('ResourceTypes')
+        if m.get('Verbose') is not None:
+            self.verbose = m.get('Verbose')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
-        if m.get('WorkspaceIds') is not None:
-            self.workspace_ids = m.get('WorkspaceIds')
+        return self
+
+
+class ListResourcesResponseBodyResourcesEncryption(TeaModel):
+    def __init__(
+        self,
+        algorithm: str = None,
+        enabled: bool = None,
+        key: str = None,
+    ):
+        self.algorithm = algorithm
+        self.enabled = enabled
+        self.key = key
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.algorithm is not None:
+            result['Algorithm'] = self.algorithm
+        if self.enabled is not None:
+            result['Enabled'] = self.enabled
+        if self.key is not None:
+            result['Key'] = self.key
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Algorithm') is not None:
+            self.algorithm = m.get('Algorithm')
+        if m.get('Enabled') is not None:
+            self.enabled = m.get('Enabled')
+        if m.get('Key') is not None:
+            self.key = m.get('Key')
         return self
 
 
 class ListResourcesResponseBodyResourcesQuotasSpecs(TeaModel):
     def __init__(
         self,
         name: str = None,
         value: str = None,
     ):
-        # 规格名字
         self.name = name
-        # 规格描述
         self.value = value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -9289,34 +10223,29 @@
         return self
 
 
 class ListResourcesResponseBodyResourcesQuotas(TeaModel):
     def __init__(
         self,
         card_type: str = None,
+        display_name: str = None,
         id: str = None,
         mode: str = None,
         name: str = None,
         product_code: str = None,
         quota_type: str = None,
         specs: List[ListResourcesResponseBodyResourcesQuotasSpecs] = None,
     ):
-        # 卡类型，支持cpu、gpu
         self.card_type = card_type
-        # 配额id
+        self.display_name = display_name
         self.id = id
-        # 模式 isolate 预付费 share 后付费 develop 开发模式
         self.mode = mode
-        # 配额名称
         self.name = name
-        # 商品 code
         self.product_code = product_code
-        # 产品类型， 支持PAI，MaxCompute
         self.quota_type = quota_type
-        # 规格描述列表
         self.specs = specs
 
     def validate(self):
         if self.specs:
             for k in self.specs:
                 if k:
                     k.validate()
@@ -9325,14 +10254,16 @@
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.card_type is not None:
             result['CardType'] = self.card_type
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.id is not None:
             result['Id'] = self.id
         if self.mode is not None:
             result['Mode'] = self.mode
         if self.name is not None:
             result['Name'] = self.name
         if self.product_code is not None:
@@ -9345,14 +10276,16 @@
                 result['Specs'].append(k.to_map() if k else None)
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('CardType') is not None:
             self.card_type = m.get('CardType')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('Id') is not None:
             self.id = m.get('Id')
         if m.get('Mode') is not None:
             self.mode = m.get('Mode')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('ProductCode') is not None:
@@ -9363,174 +10296,142 @@
         if m.get('Specs') is not None:
             for k in m.get('Specs'):
                 temp_model = ListResourcesResponseBodyResourcesQuotasSpecs()
                 self.specs.append(temp_model.from_map(k))
         return self
 
 
-class ListResourcesResponseBodyResourcesResourceSummary(TeaModel):
-    def __init__(
-        self,
-        count: int = None,
-        product_type: str = None,
-    ):
-        # 资源个数
-        self.count = count
-        # 资源类型
-        self.product_type = product_type
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.count is not None:
-            result['Count'] = self.count
-        if self.product_type is not None:
-            result['ProductType'] = self.product_type
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Count') is not None:
-            self.count = m.get('Count')
-        if m.get('ProductType') is not None:
-            self.product_type = m.get('ProductType')
-        return self
-
-
 class ListResourcesResponseBodyResources(TeaModel):
     def __init__(
         self,
+        encryption: ListResourcesResponseBodyResourcesEncryption = None,
         env_type: str = None,
+        executor: Dict[str, ResourcesExecutorValue] = None,
         gmt_create_time: str = None,
         group_name: str = None,
+        id: str = None,
         is_default: bool = None,
         name: str = None,
         product_type: str = None,
         quotas: List[ListResourcesResponseBodyResourcesQuotas] = None,
-        resource_summary: List[ListResourcesResponseBodyResourcesResourceSummary] = None,
+        resource_type: str = None,
         spec: Dict[str, Any] = None,
         workspace_id: str = None,
-        id: str = None,
     ):
-        # 环境， 支持dev（开发）、prod（生产）
+        self.encryption = encryption
         self.env_type = env_type
-        # 创建 UTC 时间，日期格式 iso8601
+        self.executor = executor
         self.gmt_create_time = gmt_create_time
-        # 分组名，主账户内唯一 一个 GroupName 下可能有一个 dev 资源和一个 prod 资源
         self.group_name = group_name
-        # 是否默认资源 每个类型都有一个默认的资源
+        self.id = id
         self.is_default = is_default
-        # 资源名 长度需要在3到27个字符 region内唯一
         self.name = name
-        # 产品类型， 支持PAI，MaxCompute
         self.product_type = product_type
         self.quotas = quotas
-        self.resource_summary = resource_summary
-        # 对于MaxCompute是个json，有如下key： Endpoint Project
+        self.resource_type = resource_type
         self.spec = spec
-        # 所属的工作空间 id
         self.workspace_id = workspace_id
-        # 资源 id
-        self.id = id
 
     def validate(self):
+        if self.encryption:
+            self.encryption.validate()
+        if self.executor:
+            for v in self.executor.values():
+                if v:
+                    v.validate()
         if self.quotas:
             for k in self.quotas:
                 if k:
                     k.validate()
-        if self.resource_summary:
-            for k in self.resource_summary:
-                if k:
-                    k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.encryption is not None:
+            result['Encryption'] = self.encryption.to_map()
         if self.env_type is not None:
             result['EnvType'] = self.env_type
+        result['Executor'] = {}
+        if self.executor is not None:
+            for k, v in self.executor.items():
+                result['Executor'][k] = v.to_map()
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.group_name is not None:
             result['GroupName'] = self.group_name
+        if self.id is not None:
+            result['Id'] = self.id
         if self.is_default is not None:
             result['IsDefault'] = self.is_default
         if self.name is not None:
             result['Name'] = self.name
         if self.product_type is not None:
             result['ProductType'] = self.product_type
         result['Quotas'] = []
         if self.quotas is not None:
             for k in self.quotas:
                 result['Quotas'].append(k.to_map() if k else None)
-        result['ResourceSummary'] = []
-        if self.resource_summary is not None:
-            for k in self.resource_summary:
-                result['ResourceSummary'].append(k.to_map() if k else None)
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         if self.spec is not None:
             result['Spec'] = self.spec
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
-        if self.id is not None:
-            result['id'] = self.id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('Encryption') is not None:
+            temp_model = ListResourcesResponseBodyResourcesEncryption()
+            self.encryption = temp_model.from_map(m['Encryption'])
         if m.get('EnvType') is not None:
             self.env_type = m.get('EnvType')
+        self.executor = {}
+        if m.get('Executor') is not None:
+            for k, v in m.get('Executor').items():
+                temp_model = ResourcesExecutorValue()
+                self.executor[k] = temp_model.from_map(v)
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GroupName') is not None:
             self.group_name = m.get('GroupName')
+        if m.get('Id') is not None:
+            self.id = m.get('Id')
         if m.get('IsDefault') is not None:
             self.is_default = m.get('IsDefault')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('ProductType') is not None:
             self.product_type = m.get('ProductType')
         self.quotas = []
         if m.get('Quotas') is not None:
             for k in m.get('Quotas'):
                 temp_model = ListResourcesResponseBodyResourcesQuotas()
                 self.quotas.append(temp_model.from_map(k))
-        self.resource_summary = []
-        if m.get('ResourceSummary') is not None:
-            for k in m.get('ResourceSummary'):
-                temp_model = ListResourcesResponseBodyResourcesResourceSummary()
-                self.resource_summary.append(temp_model.from_map(k))
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         if m.get('Spec') is not None:
             self.spec = m.get('Spec')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
-        if m.get('id') is not None:
-            self.id = m.get('id')
         return self
 
 
 class ListResourcesResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         resources: List[ListResourcesResponseBodyResources] = None,
         total_count: int = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 资源列表
         self.resources = resources
-        # 符合过滤条件的作业数量
         self.total_count = total_count
 
     def validate(self):
         if self.resources:
             for k in self.resources:
                 if k:
                     k.validate()
@@ -9614,23 +10515,18 @@
         self,
         account_types: str = None,
         page_number: int = None,
         page_size: int = None,
         user_ids: str = None,
         user_name: str = None,
     ):
-        # 账户类型列表，以逗号分隔
         self.account_types = account_types
-        # 分页，从1开始，默认1
         self.page_number = page_number
-        # 页大小，默认20
         self.page_size = page_size
-        # 用户 Id 列表，以逗号分隔
         self.user_ids = user_ids
-        # 用户名
         self.user_name = user_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -9668,19 +10564,16 @@
 class ListUsersResponseBodyUsers(TeaModel):
     def __init__(
         self,
         display_name: str = None,
         user_id: str = None,
         user_name: str = None,
     ):
-        # 用户显示名
         self.display_name = display_name
-        # 用户 id
         self.user_id = user_id
-        # 用户名
         self.user_name = user_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -9710,19 +10603,16 @@
 class ListUsersResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         total_count: int = None,
         users: List[ListUsersResponseBodyUsers] = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的用户数量
         self.total_count = total_count
-        # 用户列表
         self.users = users
 
     def validate(self):
         if self.users:
             for k in self.users:
                 if k:
                     k.validate()
@@ -9803,17 +10693,15 @@
 
 class ListWorkspaceUsersResponseBodyUsers(TeaModel):
     def __init__(
         self,
         user_id: str = None,
         user_name: str = None,
     ):
-        # 用户 id
         self.user_id = user_id
-        # 用户名
         self.user_name = user_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -9839,19 +10727,16 @@
 class ListWorkspaceUsersResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
         total_count: int = None,
         users: List[ListWorkspaceUsersResponseBodyUsers] = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 符合过滤条件的用户数量
         self.total_count = total_count
-        # 用户列表
         self.users = users
 
     def validate(self):
         if self.users:
             for k in self.users:
                 if k:
                     k.validate()
@@ -9941,35 +10826,24 @@
         page_size: int = None,
         sort_by: str = None,
         status: str = None,
         verbose: bool = None,
         workspace_ids: str = None,
         workspace_name: str = None,
     ):
-        # GetWorkspaceFields的Field字段
         self.fields = fields
-        # 逗号分割的模块列表，目前填入PAI
         self.module_list = module_list
-        # 逗号分隔的选项
         self.option = option
-        # 排序方向： ASC - 升序 DESC - 降序
         self.order = order
-        # 分页，从1开始，默认1
         self.page_number = page_number
-        # 页大小，默认20
         self.page_size = page_size
-        # 排序字段：CreateTime
         self.sort_by = sort_by
-        # 状态
         self.status = status
-        # 是否显示详细信息，默认true
         self.verbose = verbose
-        # 工作空间id列表
         self.workspace_ids = workspace_ids
-        # 工作空间名字
         self.workspace_name = workspace_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10039,35 +10913,24 @@
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         is_default: bool = None,
         status: str = None,
         workspace_id: str = None,
         workspace_name: str = None,
     ):
-        # 管理员名字
         self.admin_names = admin_names
-        # 创建人
         self.creator = creator
-        # 描述
         self.description = description
-        # 环境，用作判断简单模式还是标准模式
         self.env_types = env_types
-        # 附加信息
         self.extra_infos = extra_infos
-        # 创建 UTC 时间，日期格式 iso8601
         self.gmt_create_time = gmt_create_time
-        # 修改 UTC 时间，日期格式 iso8601
         self.gmt_modified_time = gmt_modified_time
-        # 是否为默认工作空间
         self.is_default = is_default
-        # 工作空间状态
         self.status = status
-        # 工作空间 id
         self.workspace_id = workspace_id
-        # 工作空间名字
         self.workspace_name = workspace_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10130,21 +10993,17 @@
     def __init__(
         self,
         request_id: str = None,
         resource_limits: Dict[str, Any] = None,
         total_count: int = None,
         workspaces: List[ListWorkspacesResponseBodyWorkspaces] = None,
     ):
-        # 请求 id
         self.request_id = request_id
-        # 资源限制
         self.resource_limits = resource_limits
-        # 符合过滤条件的作业数量
         self.total_count = total_count
-        # 工作空间列表
         self.workspaces = workspaces
 
     def validate(self):
         if self.workspaces:
             for k in self.workspaces:
                 if k:
                     k.validate()
@@ -10223,21 +11082,166 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = ListWorkspacesResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class MigrateDatasetsRequest(TeaModel):
+    def __init__(
+        self,
+        count: int = None,
+        dataset_id: str = None,
+        if_force: bool = None,
+        owner_id: str = None,
+        workspace_id: str = None,
+    ):
+        self.count = count
+        self.dataset_id = dataset_id
+        self.if_force = if_force
+        self.owner_id = owner_id
+        self.workspace_id = workspace_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.count is not None:
+            result['Count'] = self.count
+        if self.dataset_id is not None:
+            result['DatasetId'] = self.dataset_id
+        if self.if_force is not None:
+            result['IfForce'] = self.if_force
+        if self.owner_id is not None:
+            result['OwnerId'] = self.owner_id
+        if self.workspace_id is not None:
+            result['WorkspaceId'] = self.workspace_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Count') is not None:
+            self.count = m.get('Count')
+        if m.get('DatasetId') is not None:
+            self.dataset_id = m.get('DatasetId')
+        if m.get('IfForce') is not None:
+            self.if_force = m.get('IfForce')
+        if m.get('OwnerId') is not None:
+            self.owner_id = m.get('OwnerId')
+        if m.get('WorkspaceId') is not None:
+            self.workspace_id = m.get('WorkspaceId')
+        return self
+
+
+class MigrateDatasetsResponseBody(TeaModel):
+    def __init__(
+        self,
+        failed_count: int = None,
+        migrated_count: int = None,
+        request_id: str = None,
+        successful_count: int = None,
+        total_count: int = None,
+    ):
+        self.failed_count = failed_count
+        self.migrated_count = migrated_count
+        self.request_id = request_id
+        self.successful_count = successful_count
+        self.total_count = total_count
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.failed_count is not None:
+            result['FailedCount'] = self.failed_count
+        if self.migrated_count is not None:
+            result['MigratedCount'] = self.migrated_count
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        if self.successful_count is not None:
+            result['SuccessfulCount'] = self.successful_count
+        if self.total_count is not None:
+            result['TotalCount'] = self.total_count
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('FailedCount') is not None:
+            self.failed_count = m.get('FailedCount')
+        if m.get('MigratedCount') is not None:
+            self.migrated_count = m.get('MigratedCount')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        if m.get('SuccessfulCount') is not None:
+            self.successful_count = m.get('SuccessfulCount')
+        if m.get('TotalCount') is not None:
+            self.total_count = m.get('TotalCount')
+        return self
+
+
+class MigrateDatasetsResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: MigrateDatasetsResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = MigrateDatasetsResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class PublishCodeSourceResponseBody(TeaModel):
     def __init__(
         self,
         code_source_id: str = None,
         request_id: str = None,
     ):
-        # 被删除的代码源配置ID
         self.code_source_id = code_source_id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
@@ -10306,15 +11310,14 @@
 
 
 class PublishDatasetResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10379,40 +11382,38 @@
 
 class PublishImageResponseBody(TeaModel):
     def __init__(
         self,
         image_id: str = None,
         request_id: str = None,
     ):
-        # 镜像 id
         self.image_id = image_id
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.image_id is not None:
             result['ImageId'] = self.image_id
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('ImageId') is not None:
             self.image_id = m.get('ImageId')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class PublishImageResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -10457,34 +11458,33 @@
 
 
 class RemoveImageResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class RemoveImageResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -10529,34 +11529,33 @@
 
 
 class RemoveImageLabelsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.request_id is not None:
-            result['requestId'] = self.request_id
+            result['RequestId'] = self.request_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
         return self
 
 
 class RemoveImageLabelsResponse(TeaModel):
     def __init__(
         self,
         headers: Dict[str, str] = None,
@@ -10601,15 +11600,14 @@
 
 
 class RemoveMemberRoleResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10673,15 +11671,14 @@
 
 
 class RemoveWorkspaceQuotaResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10740,23 +11737,92 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = RemoveWorkspaceQuotaResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class SyncUsersResponseBody(TeaModel):
+    def __init__(
+        self,
+        request_id: str = None,
+    ):
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class SyncUsersResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: SyncUsersResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = SyncUsersResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class UpdateConfigsRequestConfigs(TeaModel):
     def __init__(
         self,
         config_key: str = None,
         config_value: str = None,
     ):
-        # 配置键
         self.config_key = config_key
-        # 配置值
         self.config_value = config_value
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10780,15 +11846,14 @@
 
 
 class UpdateConfigsRequest(TeaModel):
     def __init__(
         self,
         configs: List[UpdateConfigsRequestConfigs] = None,
     ):
-        # 配置列表
         self.configs = configs
 
     def validate(self):
         if self.configs:
             for k in self.configs:
                 if k:
                     k.validate()
@@ -10816,15 +11881,14 @@
 
 
 class UpdateConfigsResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10927,15 +11991,14 @@
 
 
 class UpdateDatasetResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -10997,45 +12060,43 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class UpdateDefaultWorkspaceRequest(TeaModel):
     def __init__(
         self,
-        default_workspace_id: str = None,
+        workspace_id: str = None,
     ):
-        # 显示名称
-        self.default_workspace_id = default_workspace_id
+        self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
-        if self.default_workspace_id is not None:
-            result['DefaultWorkspaceId'] = self.default_workspace_id
+        if self.workspace_id is not None:
+            result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        if m.get('DefaultWorkspaceId') is not None:
-            self.default_workspace_id = m.get('DefaultWorkspaceId')
+        if m.get('WorkspaceId') is not None:
+            self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class UpdateDefaultWorkspaceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -11098,58 +12159,78 @@
         return self
 
 
 class UpdateModelRequest(TeaModel):
     def __init__(
         self,
         accessibility: str = None,
+        domain: str = None,
         model_description: str = None,
+        model_doc: str = None,
         model_name: str = None,
+        origin: str = None,
+        task: str = None,
     ):
-        # 可见度
         self.accessibility = accessibility
-        # 模型描述
+        self.domain = domain
         self.model_description = model_description
-        # 模型名称
+        self.model_doc = model_doc
         self.model_name = model_name
+        self.origin = origin
+        self.task = task
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.accessibility is not None:
             result['Accessibility'] = self.accessibility
+        if self.domain is not None:
+            result['Domain'] = self.domain
         if self.model_description is not None:
             result['ModelDescription'] = self.model_description
+        if self.model_doc is not None:
+            result['ModelDoc'] = self.model_doc
         if self.model_name is not None:
             result['ModelName'] = self.model_name
+        if self.origin is not None:
+            result['Origin'] = self.origin
+        if self.task is not None:
+            result['Task'] = self.task
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Accessibility') is not None:
             self.accessibility = m.get('Accessibility')
+        if m.get('Domain') is not None:
+            self.domain = m.get('Domain')
         if m.get('ModelDescription') is not None:
             self.model_description = m.get('ModelDescription')
+        if m.get('ModelDoc') is not None:
+            self.model_doc = m.get('ModelDoc')
         if m.get('ModelName') is not None:
             self.model_name = m.get('ModelName')
+        if m.get('Origin') is not None:
+            self.origin = m.get('Origin')
+        if m.get('Task') is not None:
+            self.task = m.get('Task')
         return self
 
 
 class UpdateModelResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -11208,62 +12289,298 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = UpdateModelResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
+class UpdateModelDomainsRequestModelDomainsModelTasks(TeaModel):
+    def __init__(
+        self,
+        model_domain_id: str = None,
+        model_task_id: str = None,
+        model_task_name: str = None,
+        order_number: int = None,
+        search_words: str = None,
+    ):
+        self.model_domain_id = model_domain_id
+        self.model_task_id = model_task_id
+        self.model_task_name = model_task_name
+        self.order_number = order_number
+        self.search_words = search_words
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_domain_id is not None:
+            result['ModelDomainId'] = self.model_domain_id
+        if self.model_task_id is not None:
+            result['ModelTaskId'] = self.model_task_id
+        if self.model_task_name is not None:
+            result['ModelTaskName'] = self.model_task_name
+        if self.order_number is not None:
+            result['OrderNumber'] = self.order_number
+        if self.search_words is not None:
+            result['SearchWords'] = self.search_words
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelDomainId') is not None:
+            self.model_domain_id = m.get('ModelDomainId')
+        if m.get('ModelTaskId') is not None:
+            self.model_task_id = m.get('ModelTaskId')
+        if m.get('ModelTaskName') is not None:
+            self.model_task_name = m.get('ModelTaskName')
+        if m.get('OrderNumber') is not None:
+            self.order_number = m.get('OrderNumber')
+        if m.get('SearchWords') is not None:
+            self.search_words = m.get('SearchWords')
+        return self
+
+
+class UpdateModelDomainsRequestModelDomains(TeaModel):
+    def __init__(
+        self,
+        model_domain_id: str = None,
+        model_domain_name: str = None,
+        model_tasks: List[UpdateModelDomainsRequestModelDomainsModelTasks] = None,
+        order_number: int = None,
+    ):
+        self.model_domain_id = model_domain_id
+        self.model_domain_name = model_domain_name
+        self.model_tasks = model_tasks
+        self.order_number = order_number
+
+    def validate(self):
+        if self.model_tasks:
+            for k in self.model_tasks:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.model_domain_id is not None:
+            result['ModelDomainId'] = self.model_domain_id
+        if self.model_domain_name is not None:
+            result['ModelDomainName'] = self.model_domain_name
+        result['ModelTasks'] = []
+        if self.model_tasks is not None:
+            for k in self.model_tasks:
+                result['ModelTasks'].append(k.to_map() if k else None)
+        if self.order_number is not None:
+            result['OrderNumber'] = self.order_number
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('ModelDomainId') is not None:
+            self.model_domain_id = m.get('ModelDomainId')
+        if m.get('ModelDomainName') is not None:
+            self.model_domain_name = m.get('ModelDomainName')
+        self.model_tasks = []
+        if m.get('ModelTasks') is not None:
+            for k in m.get('ModelTasks'):
+                temp_model = UpdateModelDomainsRequestModelDomainsModelTasks()
+                self.model_tasks.append(temp_model.from_map(k))
+        if m.get('OrderNumber') is not None:
+            self.order_number = m.get('OrderNumber')
+        return self
+
+
+class UpdateModelDomainsRequest(TeaModel):
+    def __init__(
+        self,
+        model_domains: List[UpdateModelDomainsRequestModelDomains] = None,
+    ):
+        self.model_domains = model_domains
+
+    def validate(self):
+        if self.model_domains:
+            for k in self.model_domains:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        result['ModelDomains'] = []
+        if self.model_domains is not None:
+            for k in self.model_domains:
+                result['ModelDomains'].append(k.to_map() if k else None)
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        self.model_domains = []
+        if m.get('ModelDomains') is not None:
+            for k in m.get('ModelDomains'):
+                temp_model = UpdateModelDomainsRequestModelDomains()
+                self.model_domains.append(temp_model.from_map(k))
+        return self
+
+
+class UpdateModelDomainsResponseBody(TeaModel):
+    def __init__(
+        self,
+        request_id: str = None,
+    ):
+        self.request_id = request_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.request_id is not None:
+            result['RequestId'] = self.request_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('RequestId') is not None:
+            self.request_id = m.get('RequestId')
+        return self
+
+
+class UpdateModelDomainsResponse(TeaModel):
+    def __init__(
+        self,
+        headers: Dict[str, str] = None,
+        status_code: int = None,
+        body: UpdateModelDomainsResponseBody = None,
+    ):
+        self.headers = headers
+        self.status_code = status_code
+        self.body = body
+
+    def validate(self):
+        self.validate_required(self.headers, 'headers')
+        self.validate_required(self.status_code, 'status_code')
+        self.validate_required(self.body, 'body')
+        if self.body:
+            self.body.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.headers is not None:
+            result['headers'] = self.headers
+        if self.status_code is not None:
+            result['statusCode'] = self.status_code
+        if self.body is not None:
+            result['body'] = self.body.to_map()
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('headers') is not None:
+            self.headers = m.get('headers')
+        if m.get('statusCode') is not None:
+            self.status_code = m.get('statusCode')
+        if m.get('body') is not None:
+            temp_model = UpdateModelDomainsResponseBody()
+            self.body = temp_model.from_map(m['body'])
+        return self
+
+
 class UpdateModelVersionRequest(TeaModel):
     def __init__(
         self,
+        approval_status: str = None,
         inference_spec: Dict[str, Any] = None,
+        metrics: Dict[str, Any] = None,
         options: str = None,
+        source_id: str = None,
+        source_type: str = None,
+        training_spec: Dict[str, Any] = None,
         version_description: str = None,
     ):
-        # 描述下游的推理应用
+        self.approval_status = approval_status
         self.inference_spec = inference_spec
-        # 扩展字段。
+        self.metrics = metrics
         self.options = options
-        # 模型版本描述
+        self.source_id = source_id
+        self.source_type = source_type
+        self.training_spec = training_spec
         self.version_description = version_description
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.approval_status is not None:
+            result['ApprovalStatus'] = self.approval_status
         if self.inference_spec is not None:
             result['InferenceSpec'] = self.inference_spec
+        if self.metrics is not None:
+            result['Metrics'] = self.metrics
         if self.options is not None:
             result['Options'] = self.options
+        if self.source_id is not None:
+            result['SourceId'] = self.source_id
+        if self.source_type is not None:
+            result['SourceType'] = self.source_type
+        if self.training_spec is not None:
+            result['TrainingSpec'] = self.training_spec
         if self.version_description is not None:
             result['VersionDescription'] = self.version_description
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ApprovalStatus') is not None:
+            self.approval_status = m.get('ApprovalStatus')
         if m.get('InferenceSpec') is not None:
             self.inference_spec = m.get('InferenceSpec')
+        if m.get('Metrics') is not None:
+            self.metrics = m.get('Metrics')
         if m.get('Options') is not None:
             self.options = m.get('Options')
+        if m.get('SourceId') is not None:
+            self.source_id = m.get('SourceId')
+        if m.get('SourceType') is not None:
+            self.source_type = m.get('SourceType')
+        if m.get('TrainingSpec') is not None:
+            self.training_spec = m.get('TrainingSpec')
         if m.get('VersionDescription') is not None:
             self.version_description = m.get('VersionDescription')
         return self
 
 
 class UpdateModelVersionResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # Id of the request
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -11328,17 +12645,15 @@
 
 class UpdateWorkspaceRequest(TeaModel):
     def __init__(
         self,
         description: str = None,
         display_name: str = None,
     ):
-        # 描述
         self.description = description
-        # 显示名称
         self.display_name = display_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -11362,15 +12677,14 @@
 
 
 class UpdateWorkspaceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -11432,51 +12746,61 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class UpdateWorkspaceResourceRequest(TeaModel):
     def __init__(
         self,
+        group_name: str = None,
         is_default: bool = None,
         product_type: str = None,
+        resource_type: str = None,
     ):
-        # 是否默认资源实例，目前只能填 true，不支持填 false
+        self.group_name = group_name
         self.is_default = is_default
         self.product_type = product_type
+        self.resource_type = resource_type
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.group_name is not None:
+            result['GroupName'] = self.group_name
         if self.is_default is not None:
             result['IsDefault'] = self.is_default
         if self.product_type is not None:
             result['ProductType'] = self.product_type
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('GroupName') is not None:
+            self.group_name = m.get('GroupName')
         if m.get('IsDefault') is not None:
             self.is_default = m.get('IsDefault')
         if m.get('ProductType') is not None:
             self.product_type = m.get('ProductType')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         return self
 
 
 class UpdateWorkspaceResourceResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
-        # 请求 id
         self.request_id = request_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
```

### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

## pai/libs/alibabacloud_paistudio20220112/client.py

```diff
@@ -58,42 +58,28 @@
     ) -> str:
         if not UtilClient.empty(endpoint):
             return endpoint
         if not UtilClient.is_unset(endpoint_map) and not UtilClient.empty(endpoint_map.get(region_id)):
             return endpoint_map.get(region_id)
         return EndpointUtilClient.get_endpoint_rules(product_id, region_id, endpoint_rule, network, suffix)
 
-    def create_algorithm(
-        self,
-        request: pai_studio_20220112_models.CreateAlgorithmRequest,
-    ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.create_algorithm_with_options(request, headers, runtime)
-
-    async def create_algorithm_async(
-        self,
-        request: pai_studio_20220112_models.CreateAlgorithmRequest,
-    ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.create_algorithm_with_options_async(request, headers, runtime)
-
     def create_algorithm_with_options(
         self,
         request: pai_studio_20220112_models.CreateAlgorithmRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.algorithm_description):
             body['AlgorithmDescription'] = request.algorithm_description
         if not UtilClient.is_unset(request.algorithm_name):
             body['AlgorithmName'] = request.algorithm_name
+        if not UtilClient.is_unset(request.display_name):
+            body['DisplayName'] = request.display_name
         if not UtilClient.is_unset(request.workspace_id):
             body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -120,14 +106,16 @@
     ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.algorithm_description):
             body['AlgorithmDescription'] = request.algorithm_description
         if not UtilClient.is_unset(request.algorithm_name):
             body['AlgorithmName'] = request.algorithm_name
+        if not UtilClient.is_unset(request.display_name):
+            body['DisplayName'] = request.display_name
         if not UtilClient.is_unset(request.workspace_id):
             body['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -142,33 +130,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.CreateAlgorithmResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_algorithm_version(
+    def create_algorithm(
         self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.CreateAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.CreateAlgorithmVersionResponse:
+        request: pai_studio_20220112_models.CreateAlgorithmRequest,
+    ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_algorithm_version_with_options(algorithm_id, algorithm_version, request, headers, runtime)
+        return self.create_algorithm_with_options(request, headers, runtime)
 
-    async def create_algorithm_version_async(
+    async def create_algorithm_async(
         self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.CreateAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.CreateAlgorithmVersionResponse:
+        request: pai_studio_20220112_models.CreateAlgorithmRequest,
+    ) -> pai_studio_20220112_models.CreateAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_algorithm_version_with_options_async(algorithm_id, algorithm_version, request, headers, runtime)
+        return await self.create_algorithm_with_options_async(request, headers, runtime)
 
     def create_algorithm_version_with_options(
         self,
         algorithm_id: str,
         algorithm_version: str,
         tmp_req: pai_studio_20220112_models.CreateAlgorithmVersionRequest,
         headers: Dict[str, str],
@@ -234,42 +218,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.CreateAlgorithmVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_resource_group(
+    def create_algorithm_version(
         self,
-        request: pai_studio_20220112_models.CreateResourceGroupRequest,
-    ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+        request: pai_studio_20220112_models.CreateAlgorithmVersionRequest,
+    ) -> pai_studio_20220112_models.CreateAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_resource_group_with_options(request, headers, runtime)
+        return self.create_algorithm_version_with_options(algorithm_id, algorithm_version, request, headers, runtime)
 
-    async def create_resource_group_async(
+    async def create_algorithm_version_async(
         self,
-        request: pai_studio_20220112_models.CreateResourceGroupRequest,
-    ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+        request: pai_studio_20220112_models.CreateAlgorithmVersionRequest,
+    ) -> pai_studio_20220112_models.CreateAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_resource_group_with_options_async(request, headers, runtime)
+        return await self.create_algorithm_version_with_options_async(algorithm_id, algorithm_version, request, headers, runtime)
 
     def create_resource_group_with_options(
         self,
         request: pai_studio_20220112_models.CreateResourceGroupRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
         UtilClient.validate_model(request)
         body = {}
+        if not UtilClient.is_unset(request.computing_resource_provider):
+            body['ComputingResourceProvider'] = request.computing_resource_provider
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
+        if not UtilClient.is_unset(request.resource_type):
+            body['ResourceType'] = request.resource_type
         if not UtilClient.is_unset(request.user_vpc):
             body['UserVpc'] = request.user_vpc
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -292,18 +284,22 @@
         self,
         request: pai_studio_20220112_models.CreateResourceGroupRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
         UtilClient.validate_model(request)
         body = {}
+        if not UtilClient.is_unset(request.computing_resource_provider):
+            body['ComputingResourceProvider'] = request.computing_resource_provider
         if not UtilClient.is_unset(request.description):
             body['Description'] = request.description
         if not UtilClient.is_unset(request.name):
             body['Name'] = request.name
+        if not UtilClient.is_unset(request.resource_type):
+            body['ResourceType'] = request.resource_type
         if not UtilClient.is_unset(request.user_vpc):
             body['UserVpc'] = request.user_vpc
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
@@ -318,29 +314,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.CreateResourceGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def create_training_job(
+    def create_resource_group(
         self,
-        request: pai_studio_20220112_models.CreateTrainingJobRequest,
-    ) -> pai_studio_20220112_models.CreateTrainingJobResponse:
+        request: pai_studio_20220112_models.CreateResourceGroupRequest,
+    ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.create_training_job_with_options(request, headers, runtime)
+        return self.create_resource_group_with_options(request, headers, runtime)
 
-    async def create_training_job_async(
+    async def create_resource_group_async(
         self,
-        request: pai_studio_20220112_models.CreateTrainingJobRequest,
-    ) -> pai_studio_20220112_models.CreateTrainingJobResponse:
+        request: pai_studio_20220112_models.CreateResourceGroupRequest,
+    ) -> pai_studio_20220112_models.CreateResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.create_training_job_with_options_async(request, headers, runtime)
+        return await self.create_resource_group_with_options_async(request, headers, runtime)
 
     def create_training_job_with_options(
         self,
         request: pai_studio_20220112_models.CreateTrainingJobRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.CreateTrainingJobResponse:
@@ -362,14 +358,16 @@
             body['HyperParameters'] = request.hyper_parameters
         if not UtilClient.is_unset(request.input_channels):
             body['InputChannels'] = request.input_channels
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.output_channels):
             body['OutputChannels'] = request.output_channels
+        if not UtilClient.is_unset(request.role_arn):
+            body['RoleArn'] = request.role_arn
         if not UtilClient.is_unset(request.scheduler):
             body['Scheduler'] = request.scheduler
         if not UtilClient.is_unset(request.training_job_description):
             body['TrainingJobDescription'] = request.training_job_description
         if not UtilClient.is_unset(request.training_job_name):
             body['TrainingJobName'] = request.training_job_name
         if not UtilClient.is_unset(request.workspace_id):
@@ -418,14 +416,16 @@
             body['HyperParameters'] = request.hyper_parameters
         if not UtilClient.is_unset(request.input_channels):
             body['InputChannels'] = request.input_channels
         if not UtilClient.is_unset(request.labels):
             body['Labels'] = request.labels
         if not UtilClient.is_unset(request.output_channels):
             body['OutputChannels'] = request.output_channels
+        if not UtilClient.is_unset(request.role_arn):
+            body['RoleArn'] = request.role_arn
         if not UtilClient.is_unset(request.scheduler):
             body['Scheduler'] = request.scheduler
         if not UtilClient.is_unset(request.training_job_description):
             body['TrainingJobDescription'] = request.training_job_description
         if not UtilClient.is_unset(request.training_job_name):
             body['TrainingJobName'] = request.training_job_name
         if not UtilClient.is_unset(request.workspace_id):
@@ -446,165 +446,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.CreateTrainingJobResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_algorithm(
-        self,
-        algorithm_id: str,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.delete_algorithm_with_options(algorithm_id, headers, runtime)
-
-    async def delete_algorithm_async(
-        self,
-        algorithm_id: str,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.delete_algorithm_with_options_async(algorithm_id, headers, runtime)
-
-    def delete_algorithm_with_options(
-        self,
-        algorithm_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteAlgorithm',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteAlgorithmResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def delete_algorithm_with_options_async(
-        self,
-        algorithm_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteAlgorithm',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteAlgorithmResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def delete_algorithm_version(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmVersionResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.delete_algorithm_version_with_options(algorithm_id, algorithm_version, headers, runtime)
-
-    async def delete_algorithm_version_async(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmVersionResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.delete_algorithm_version_with_options_async(algorithm_id, algorithm_version, headers, runtime)
-
-    def delete_algorithm_version_with_options(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmVersionResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteAlgorithmVersion',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/versions/{OpenApiUtilClient.get_encode_param(algorithm_version)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteAlgorithmVersionResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def delete_algorithm_version_with_options_async(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteAlgorithmVersionResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteAlgorithmVersion',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/versions/{OpenApiUtilClient.get_encode_param(algorithm_version)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteAlgorithmVersionResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def delete_machine_group(
+    def create_training_job(
         self,
-        machine_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteMachineGroupResponse:
+        request: pai_studio_20220112_models.CreateTrainingJobRequest,
+    ) -> pai_studio_20220112_models.CreateTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_machine_group_with_options(machine_group_id, headers, runtime)
+        return self.create_training_job_with_options(request, headers, runtime)
 
-    async def delete_machine_group_async(
+    async def create_training_job_async(
         self,
-        machine_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteMachineGroupResponse:
+        request: pai_studio_20220112_models.CreateTrainingJobRequest,
+    ) -> pai_studio_20220112_models.CreateTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_machine_group_with_options_async(machine_group_id, headers, runtime)
+        return await self.create_training_job_with_options_async(request, headers, runtime)
 
     def delete_machine_group_with_options(
         self,
         machine_group_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.DeleteMachineGroupResponse:
@@ -648,29 +512,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.DeleteMachineGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_resource_group(
+    def delete_machine_group(
         self,
-        resource_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteResourceGroupResponse:
+        machine_group_id: str,
+    ) -> pai_studio_20220112_models.DeleteMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_resource_group_with_options(resource_group_id, headers, runtime)
+        return self.delete_machine_group_with_options(machine_group_id, headers, runtime)
 
-    async def delete_resource_group_async(
+    async def delete_machine_group_async(
         self,
-        resource_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteResourceGroupResponse:
+        machine_group_id: str,
+    ) -> pai_studio_20220112_models.DeleteMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_resource_group_with_options_async(resource_group_id, headers, runtime)
+        return await self.delete_machine_group_with_options_async(machine_group_id, headers, runtime)
 
     def delete_resource_group_with_options(
         self,
         resource_group_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.DeleteResourceGroupResponse:
@@ -714,31 +578,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.DeleteResourceGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_resource_group_machine_group(
+    def delete_resource_group(
         self,
-        machine_group_id: str,
         resource_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteResourceGroupMachineGroupResponse:
+    ) -> pai_studio_20220112_models.DeleteResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.delete_resource_group_machine_group_with_options(machine_group_id, resource_group_id, headers, runtime)
+        return self.delete_resource_group_with_options(resource_group_id, headers, runtime)
 
-    async def delete_resource_group_machine_group_async(
+    async def delete_resource_group_async(
         self,
-        machine_group_id: str,
         resource_group_id: str,
-    ) -> pai_studio_20220112_models.DeleteResourceGroupMachineGroupResponse:
+    ) -> pai_studio_20220112_models.DeleteResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.delete_resource_group_machine_group_with_options_async(machine_group_id, resource_group_id, headers, runtime)
+        return await self.delete_resource_group_with_options_async(resource_group_id, headers, runtime)
 
     def delete_resource_group_machine_group_with_options(
         self,
         machine_group_id: str,
         resource_group_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -784,175 +646,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.DeleteResourceGroupMachineGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def delete_training_job(
-        self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.delete_training_job_with_options(training_job_id, headers, runtime)
-
-    async def delete_training_job_async(
-        self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.delete_training_job_with_options_async(training_job_id, headers, runtime)
-
-    def delete_training_job_with_options(
-        self,
-        training_job_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteTrainingJob',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteTrainingJobResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def delete_training_job_with_options_async(
-        self,
-        training_job_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='DeleteTrainingJob',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteTrainingJobResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def delete_training_job_labels(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.DeleteTrainingJobLabelsRequest,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobLabelsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.delete_training_job_labels_with_options(training_job_id, request, headers, runtime)
-
-    async def delete_training_job_labels_async(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.DeleteTrainingJobLabelsRequest,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobLabelsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.delete_training_job_labels_with_options_async(training_job_id, request, headers, runtime)
-
-    def delete_training_job_labels_with_options(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.DeleteTrainingJobLabelsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobLabelsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.keys):
-            query['Keys'] = request.keys
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='DeleteTrainingJobLabels',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/labels',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteTrainingJobLabelsResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def delete_training_job_labels_with_options_async(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.DeleteTrainingJobLabelsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.DeleteTrainingJobLabelsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.keys):
-            query['Keys'] = request.keys
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='DeleteTrainingJobLabels',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/labels',
-            method='DELETE',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.DeleteTrainingJobLabelsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_algorithm(
+    def delete_resource_group_machine_group(
         self,
-        algorithm_id: str,
-    ) -> pai_studio_20220112_models.GetAlgorithmResponse:
+        machine_group_id: str,
+        resource_group_id: str,
+    ) -> pai_studio_20220112_models.DeleteResourceGroupMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_algorithm_with_options(algorithm_id, headers, runtime)
+        return self.delete_resource_group_machine_group_with_options(machine_group_id, resource_group_id, headers, runtime)
 
-    async def get_algorithm_async(
+    async def delete_resource_group_machine_group_async(
         self,
-        algorithm_id: str,
-    ) -> pai_studio_20220112_models.GetAlgorithmResponse:
+        machine_group_id: str,
+        resource_group_id: str,
+    ) -> pai_studio_20220112_models.DeleteResourceGroupMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_algorithm_with_options_async(algorithm_id, headers, runtime)
+        return await self.delete_resource_group_machine_group_with_options_async(machine_group_id, resource_group_id, headers, runtime)
 
     def get_algorithm_with_options(
         self,
         algorithm_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetAlgorithmResponse:
@@ -996,31 +714,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetAlgorithmResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_algorithm_version(
+    def get_algorithm(
         self,
         algorithm_id: str,
-        algorithm_version: str,
-    ) -> pai_studio_20220112_models.GetAlgorithmVersionResponse:
+    ) -> pai_studio_20220112_models.GetAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_algorithm_version_with_options(algorithm_id, algorithm_version, headers, runtime)
+        return self.get_algorithm_with_options(algorithm_id, headers, runtime)
 
-    async def get_algorithm_version_async(
+    async def get_algorithm_async(
         self,
         algorithm_id: str,
-        algorithm_version: str,
-    ) -> pai_studio_20220112_models.GetAlgorithmVersionResponse:
+    ) -> pai_studio_20220112_models.GetAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_algorithm_version_with_options_async(algorithm_id, algorithm_version, headers, runtime)
+        return await self.get_algorithm_with_options_async(algorithm_id, headers, runtime)
 
     def get_algorithm_version_with_options(
         self,
         algorithm_id: str,
         algorithm_version: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -1066,221 +782,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetAlgorithmVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_job_view_metrics(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetJobViewMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_job_view_metrics_with_options(resource_group_id, request, headers, runtime)
-
-    async def get_job_view_metrics_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetJobViewMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.get_job_view_metrics_with_options_async(resource_group_id, request, headers, runtime)
-
-    def get_job_view_metrics_with_options(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobViewMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetJobViewMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.sort_by):
-            query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetJobViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/jobmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetJobViewMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def get_job_view_metrics_with_options_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobViewMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetJobViewMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.sort_by):
-            query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetJobViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/jobmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetJobViewMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_jobs_statistics_by_resource_group(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobsStatisticsByResourceGroupRequest,
-    ) -> pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_jobs_statistics_by_resource_group_with_options(resource_group_id, request, headers, runtime)
-
-    async def get_jobs_statistics_by_resource_group_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobsStatisticsByResourceGroupRequest,
-    ) -> pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.get_jobs_statistics_by_resource_group_with_options_async(resource_group_id, request, headers, runtime)
-
-    def get_jobs_statistics_by_resource_group_with_options(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobsStatisticsByResourceGroupRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceID'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetJobsStatisticsByResourceGroup',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/statistics/jobs',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def get_jobs_statistics_by_resource_group_with_options_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetJobsStatisticsByResourceGroupRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceID'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetJobsStatisticsByResourceGroup',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/statistics/jobs',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetJobsStatisticsByResourceGroupResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_machine_group(
+    def get_algorithm_version(
         self,
-        machine_group_id: str,
-    ) -> pai_studio_20220112_models.GetMachineGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+    ) -> pai_studio_20220112_models.GetAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_machine_group_with_options(machine_group_id, headers, runtime)
+        return self.get_algorithm_version_with_options(algorithm_id, algorithm_version, headers, runtime)
 
-    async def get_machine_group_async(
+    async def get_algorithm_version_async(
         self,
-        machine_group_id: str,
-    ) -> pai_studio_20220112_models.GetMachineGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+    ) -> pai_studio_20220112_models.GetAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_machine_group_with_options_async(machine_group_id, headers, runtime)
+        return await self.get_algorithm_version_with_options_async(algorithm_id, algorithm_version, headers, runtime)
 
     def get_machine_group_with_options(
         self,
         machine_group_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetMachineGroupResponse:
@@ -1324,33 +850,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetMachineGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_node_metrics(
+    def get_machine_group(
         self,
-        resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetNodeMetricsRequest,
-    ) -> pai_studio_20220112_models.GetNodeMetricsResponse:
+        machine_group_id: str,
+    ) -> pai_studio_20220112_models.GetMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_node_metrics_with_options(resource_group_id, metric_type, request, headers, runtime)
+        return self.get_machine_group_with_options(machine_group_id, headers, runtime)
 
-    async def get_node_metrics_async(
+    async def get_machine_group_async(
         self,
-        resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetNodeMetricsRequest,
-    ) -> pai_studio_20220112_models.GetNodeMetricsResponse:
+        machine_group_id: str,
+    ) -> pai_studio_20220112_models.GetMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_node_metrics_with_options_async(resource_group_id, metric_type, request, headers, runtime)
+        return await self.get_machine_group_with_options_async(machine_group_id, headers, runtime)
 
     def get_node_metrics_with_options(
         self,
         resource_group_id: str,
         metric_type: str,
         request: pai_studio_20220112_models.GetNodeMetricsRequest,
         headers: Dict[str, str],
@@ -1424,244 +946,50 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetNodeMetricsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_node_view_metrics(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetNodeViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetNodeViewMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_node_view_metrics_with_options(resource_group_id, request, headers, runtime)
-
-    async def get_node_view_metrics_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetNodeViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetNodeViewMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.get_node_view_metrics_with_options_async(resource_group_id, request, headers, runtime)
-
-    def get_node_view_metrics_with_options(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetNodeViewMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetNodeViewMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.node_id):
-            query['NodeId'] = request.node_id
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetNodeViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/nodeviewmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetNodeViewMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def get_node_view_metrics_with_options_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetNodeViewMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetNodeViewMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.node_id):
-            query['NodeId'] = request.node_id
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetNodeViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/nodeviewmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetNodeViewMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_range_user_view_metrics(
+    def get_node_metrics(
         self,
         resource_group_id: str,
-        request: pai_studio_20220112_models.GetRangeUserViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetRangeUserViewMetricsResponse:
+        metric_type: str,
+        request: pai_studio_20220112_models.GetNodeMetricsRequest,
+    ) -> pai_studio_20220112_models.GetNodeMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_range_user_view_metrics_with_options(resource_group_id, request, headers, runtime)
+        return self.get_node_metrics_with_options(resource_group_id, metric_type, request, headers, runtime)
 
-    async def get_range_user_view_metrics_async(
+    async def get_node_metrics_async(
         self,
         resource_group_id: str,
-        request: pai_studio_20220112_models.GetRangeUserViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetRangeUserViewMetricsResponse:
+        metric_type: str,
+        request: pai_studio_20220112_models.GetNodeMetricsRequest,
+    ) -> pai_studio_20220112_models.GetNodeMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_range_user_view_metrics_with_options_async(resource_group_id, request, headers, runtime)
-
-    def get_range_user_view_metrics_with_options(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetRangeUserViewMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetRangeUserViewMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.order):
-            query['Order'] = request.order
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.sort_by):
-            query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.user_id):
-            query['UserId'] = request.user_id
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetRangeUserViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/rangeusermetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetRangeUserViewMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
+        return await self.get_node_metrics_with_options_async(resource_group_id, metric_type, request, headers, runtime)
 
-    async def get_range_user_view_metrics_with_options_async(
+    def get_resource_group_with_options(
         self,
         resource_group_id: str,
-        request: pai_studio_20220112_models.GetRangeUserViewMetricsRequest,
+        request: pai_studio_20220112_models.GetResourceGroupRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetRangeUserViewMetricsResponse:
+    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
         UtilClient.validate_model(request)
         query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.order):
-            query['Order'] = request.order
-        if not UtilClient.is_unset(request.page_number):
-            query['PageNumber'] = request.page_number
-        if not UtilClient.is_unset(request.page_size):
-            query['PageSize'] = request.page_size
-        if not UtilClient.is_unset(request.sort_by):
-            query['SortBy'] = request.sort_by
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.user_id):
-            query['UserId'] = request.user_id
-        if not UtilClient.is_unset(request.workspace_id):
-            query['WorkspaceId'] = request.workspace_id
+        if not UtilClient.is_unset(request.is_aiworkspace_data_enabled):
+            query['IsAIWorkspaceDataEnabled'] = request.is_aiworkspace_data_enabled
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
-            action='GetRangeUserViewMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/rangeusermetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetRangeUserViewMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_resource_group(
-        self,
-        resource_group_id: str,
-    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_resource_group_with_options(resource_group_id, headers, runtime)
-
-    async def get_resource_group_async(
-        self,
-        resource_group_id: str,
-    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.get_resource_group_with_options_async(resource_group_id, headers, runtime)
-
-    def get_resource_group_with_options(
-        self,
-        resource_group_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
             action='GetResourceGroup',
             version='2022-01-12',
             protocol='HTTPS',
             pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}',
             method='GET',
             auth_type='AK',
             style='ROA',
@@ -1672,19 +1000,25 @@
             pai_studio_20220112_models.GetResourceGroupResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def get_resource_group_with_options_async(
         self,
         resource_group_id: str,
+        request: pai_studio_20220112_models.GetResourceGroupRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetResourceGroupResponse:
+        UtilClient.validate_model(request)
+        query = {}
+        if not UtilClient.is_unset(request.is_aiworkspace_data_enabled):
+            query['IsAIWorkspaceDataEnabled'] = request.is_aiworkspace_data_enabled
         req = open_api_models.OpenApiRequest(
-            headers=headers
+            headers=headers,
+            query=OpenApiUtilClient.query(query)
         )
         params = open_api_models.Params(
             action='GetResourceGroup',
             version='2022-01-12',
             protocol='HTTPS',
             pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}',
             method='GET',
@@ -1694,31 +1028,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetResourceGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_resource_group_machine_group(
+    def get_resource_group(
         self,
-        machine_group_id: str,
         resource_group_id: str,
-    ) -> pai_studio_20220112_models.GetResourceGroupMachineGroupResponse:
+        request: pai_studio_20220112_models.GetResourceGroupRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_resource_group_machine_group_with_options(machine_group_id, resource_group_id, headers, runtime)
+        return self.get_resource_group_with_options(resource_group_id, request, headers, runtime)
 
-    async def get_resource_group_machine_group_async(
+    async def get_resource_group_async(
         self,
-        machine_group_id: str,
         resource_group_id: str,
-    ) -> pai_studio_20220112_models.GetResourceGroupMachineGroupResponse:
+        request: pai_studio_20220112_models.GetResourceGroupRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_resource_group_machine_group_with_options_async(machine_group_id, resource_group_id, headers, runtime)
+        return await self.get_resource_group_with_options_async(resource_group_id, request, headers, runtime)
 
     def get_resource_group_machine_group_with_options(
         self,
         machine_group_id: str,
         resource_group_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -1764,125 +1098,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetResourceGroupMachineGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_resource_group_metrics(
-        self,
-        resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetResourceGroupMetricsRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_resource_group_metrics_with_options(resource_group_id, metric_type, request, headers, runtime)
-
-    async def get_resource_group_metrics_async(
+    def get_resource_group_machine_group(
         self,
+        machine_group_id: str,
         resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetResourceGroupMetricsRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupMetricsResponse:
+    ) -> pai_studio_20220112_models.GetResourceGroupMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_resource_group_metrics_with_options_async(resource_group_id, metric_type, request, headers, runtime)
-
-    def get_resource_group_metrics_with_options(
-        self,
-        resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetResourceGroupMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetResourceGroupMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.gputype):
-            query['GPUType'] = request.gputype
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetResourceGroupMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/metrics/{OpenApiUtilClient.get_encode_param(metric_type)}',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetResourceGroupMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
+        return self.get_resource_group_machine_group_with_options(machine_group_id, resource_group_id, headers, runtime)
 
-    async def get_resource_group_metrics_with_options_async(
+    async def get_resource_group_machine_group_async(
         self,
+        machine_group_id: str,
         resource_group_id: str,
-        metric_type: str,
-        request: pai_studio_20220112_models.GetResourceGroupMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetResourceGroupMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.gputype):
-            query['GPUType'] = request.gputype
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetResourceGroupMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/resources/{OpenApiUtilClient.get_encode_param(resource_group_id)}/metrics/{OpenApiUtilClient.get_encode_param(metric_type)}',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetResourceGroupMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_resource_group_request(
-        self,
-        request: pai_studio_20220112_models.GetResourceGroupRequestRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupRequestResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_resource_group_request_with_options(request, headers, runtime)
-
-    async def get_resource_group_request_async(
-        self,
-        request: pai_studio_20220112_models.GetResourceGroupRequestRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupRequestResponse:
+    ) -> pai_studio_20220112_models.GetResourceGroupMachineGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_resource_group_request_with_options_async(request, headers, runtime)
+        return await self.get_resource_group_machine_group_with_options_async(machine_group_id, resource_group_id, headers, runtime)
 
     def get_resource_group_request_with_options(
         self,
         request: pai_studio_20220112_models.GetResourceGroupRequestRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetResourceGroupRequestResponse:
@@ -1940,29 +1180,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetResourceGroupRequestResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_resource_group_total(
+    def get_resource_group_request(
         self,
-        request: pai_studio_20220112_models.GetResourceGroupTotalRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupTotalResponse:
+        request: pai_studio_20220112_models.GetResourceGroupRequestRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupRequestResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_resource_group_total_with_options(request, headers, runtime)
+        return self.get_resource_group_request_with_options(request, headers, runtime)
 
-    async def get_resource_group_total_async(
+    async def get_resource_group_request_async(
         self,
-        request: pai_studio_20220112_models.GetResourceGroupTotalRequest,
-    ) -> pai_studio_20220112_models.GetResourceGroupTotalResponse:
+        request: pai_studio_20220112_models.GetResourceGroupRequestRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupRequestResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_resource_group_total_with_options_async(request, headers, runtime)
+        return await self.get_resource_group_request_with_options_async(request, headers, runtime)
 
     def get_resource_group_total_with_options(
         self,
         request: pai_studio_20220112_models.GetResourceGroupTotalRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetResourceGroupTotalResponse:
@@ -2016,29 +1256,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetResourceGroupTotalResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_training_job(
+    def get_resource_group_total(
         self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.GetTrainingJobResponse:
+        request: pai_studio_20220112_models.GetResourceGroupTotalRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupTotalResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.get_training_job_with_options(training_job_id, headers, runtime)
+        return self.get_resource_group_total_with_options(request, headers, runtime)
 
-    async def get_training_job_async(
+    async def get_resource_group_total_async(
         self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.GetTrainingJobResponse:
+        request: pai_studio_20220112_models.GetResourceGroupTotalRequest,
+    ) -> pai_studio_20220112_models.GetResourceGroupTotalResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_training_job_with_options_async(training_job_id, headers, runtime)
+        return await self.get_resource_group_total_with_options_async(request, headers, runtime)
 
     def get_training_job_with_options(
         self,
         training_job_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.GetTrainingJobResponse:
@@ -2082,111 +1322,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetTrainingJobResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def get_training_job_latest_metrics(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.GetTrainingJobLatestMetricsRequest,
-    ) -> pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_training_job_latest_metrics_with_options(training_job_id, request, headers, runtime)
-
-    async def get_training_job_latest_metrics_async(
+    def get_training_job(
         self,
         training_job_id: str,
-        request: pai_studio_20220112_models.GetTrainingJobLatestMetricsRequest,
-    ) -> pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse:
+    ) -> pai_studio_20220112_models.GetTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_training_job_latest_metrics_with_options_async(training_job_id, request, headers, runtime)
-
-    def get_training_job_latest_metrics_with_options(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.GetTrainingJobLatestMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.names):
-            query['Names'] = request.names
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetTrainingJobLatestMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/latestmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
+        return self.get_training_job_with_options(training_job_id, headers, runtime)
 
-    async def get_training_job_latest_metrics_with_options_async(
+    async def get_training_job_async(
         self,
         training_job_id: str,
-        request: pai_studio_20220112_models.GetTrainingJobLatestMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.names):
-            query['Names'] = request.names
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='GetTrainingJobLatestMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/latestmetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.GetTrainingJobLatestMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def get_user_view_metrics(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetUserViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetUserViewMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.get_user_view_metrics_with_options(resource_group_id, request, headers, runtime)
-
-    async def get_user_view_metrics_async(
-        self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.GetUserViewMetricsRequest,
-    ) -> pai_studio_20220112_models.GetUserViewMetricsResponse:
+    ) -> pai_studio_20220112_models.GetTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.get_user_view_metrics_with_options_async(resource_group_id, request, headers, runtime)
+        return await self.get_training_job_with_options_async(training_job_id, headers, runtime)
 
     def get_user_view_metrics_with_options(
         self,
         resource_group_id: str,
         request: pai_studio_20220112_models.GetUserViewMetricsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -2266,31 +1424,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.GetUserViewMetricsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_algorithm_versions(
+    def get_user_view_metrics(
         self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ListAlgorithmVersionsRequest,
-    ) -> pai_studio_20220112_models.ListAlgorithmVersionsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.GetUserViewMetricsRequest,
+    ) -> pai_studio_20220112_models.GetUserViewMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_algorithm_versions_with_options(algorithm_id, request, headers, runtime)
+        return self.get_user_view_metrics_with_options(resource_group_id, request, headers, runtime)
 
-    async def list_algorithm_versions_async(
+    async def get_user_view_metrics_async(
         self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ListAlgorithmVersionsRequest,
-    ) -> pai_studio_20220112_models.ListAlgorithmVersionsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.GetUserViewMetricsRequest,
+    ) -> pai_studio_20220112_models.GetUserViewMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_algorithm_versions_with_options_async(algorithm_id, request, headers, runtime)
+        return await self.get_user_view_metrics_with_options_async(resource_group_id, request, headers, runtime)
 
     def list_algorithm_versions_with_options(
         self,
         algorithm_id: str,
         request: pai_studio_20220112_models.ListAlgorithmVersionsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -2350,29 +1508,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListAlgorithmVersionsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_algorithms(
+    def list_algorithm_versions(
         self,
-        request: pai_studio_20220112_models.ListAlgorithmsRequest,
-    ) -> pai_studio_20220112_models.ListAlgorithmsResponse:
+        algorithm_id: str,
+        request: pai_studio_20220112_models.ListAlgorithmVersionsRequest,
+    ) -> pai_studio_20220112_models.ListAlgorithmVersionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_algorithms_with_options(request, headers, runtime)
+        return self.list_algorithm_versions_with_options(algorithm_id, request, headers, runtime)
 
-    async def list_algorithms_async(
+    async def list_algorithm_versions_async(
         self,
-        request: pai_studio_20220112_models.ListAlgorithmsRequest,
-    ) -> pai_studio_20220112_models.ListAlgorithmsResponse:
+        algorithm_id: str,
+        request: pai_studio_20220112_models.ListAlgorithmVersionsRequest,
+    ) -> pai_studio_20220112_models.ListAlgorithmVersionsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_algorithms_with_options_async(request, headers, runtime)
+        return await self.list_algorithm_versions_with_options_async(algorithm_id, request, headers, runtime)
 
     def list_algorithms_with_options(
         self,
         request: pai_studio_20220112_models.ListAlgorithmsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.ListAlgorithmsResponse:
@@ -2446,31 +1606,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListAlgorithmsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_resource_group_machine_groups(
+    def list_algorithms(
         self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.ListResourceGroupMachineGroupsRequest,
-    ) -> pai_studio_20220112_models.ListResourceGroupMachineGroupsResponse:
+        request: pai_studio_20220112_models.ListAlgorithmsRequest,
+    ) -> pai_studio_20220112_models.ListAlgorithmsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_resource_group_machine_groups_with_options(resource_group_id, request, headers, runtime)
+        return self.list_algorithms_with_options(request, headers, runtime)
 
-    async def list_resource_group_machine_groups_async(
+    async def list_algorithms_async(
         self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.ListResourceGroupMachineGroupsRequest,
-    ) -> pai_studio_20220112_models.ListResourceGroupMachineGroupsResponse:
+        request: pai_studio_20220112_models.ListAlgorithmsRequest,
+    ) -> pai_studio_20220112_models.ListAlgorithmsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_resource_group_machine_groups_with_options_async(resource_group_id, request, headers, runtime)
+        return await self.list_algorithms_with_options_async(request, headers, runtime)
 
     def list_resource_group_machine_groups_with_options(
         self,
         resource_group_id: str,
         request: pai_studio_20220112_models.ListResourceGroupMachineGroupsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -2566,46 +1724,52 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListResourceGroupMachineGroupsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_resource_groups(
+    def list_resource_group_machine_groups(
         self,
-        request: pai_studio_20220112_models.ListResourceGroupsRequest,
-    ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.ListResourceGroupMachineGroupsRequest,
+    ) -> pai_studio_20220112_models.ListResourceGroupMachineGroupsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_resource_groups_with_options(request, headers, runtime)
+        return self.list_resource_group_machine_groups_with_options(resource_group_id, request, headers, runtime)
 
-    async def list_resource_groups_async(
+    async def list_resource_group_machine_groups_async(
         self,
-        request: pai_studio_20220112_models.ListResourceGroupsRequest,
-    ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.ListResourceGroupMachineGroupsRequest,
+    ) -> pai_studio_20220112_models.ListResourceGroupMachineGroupsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_resource_groups_with_options_async(request, headers, runtime)
+        return await self.list_resource_group_machine_groups_with_options_async(resource_group_id, request, headers, runtime)
 
     def list_resource_groups_with_options(
         self,
         request: pai_studio_20220112_models.ListResourceGroupsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.computing_resource_provider):
+            query['ComputingResourceProvider'] = request.computing_resource_provider
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.resource_type):
+            query['ResourceType'] = request.resource_type
         if not UtilClient.is_unset(request.show_all):
             query['ShowAll'] = request.show_all
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
         if not UtilClient.is_unset(request.status):
             query['Status'] = request.status
         req = open_api_models.OpenApiRequest(
@@ -2632,22 +1796,26 @@
         self,
         request: pai_studio_20220112_models.ListResourceGroupsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
         UtilClient.validate_model(request)
         query = {}
+        if not UtilClient.is_unset(request.computing_resource_provider):
+            query['ComputingResourceProvider'] = request.computing_resource_provider
         if not UtilClient.is_unset(request.name):
             query['Name'] = request.name
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
+        if not UtilClient.is_unset(request.resource_type):
+            query['ResourceType'] = request.resource_type
         if not UtilClient.is_unset(request.show_all):
             query['ShowAll'] = request.show_all
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
         if not UtilClient.is_unset(request.status):
             query['Status'] = request.status
         req = open_api_models.OpenApiRequest(
@@ -2666,127 +1834,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListResourceGroupsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_training_job_instance_metrics(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobInstanceMetricsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.list_training_job_instance_metrics_with_options(training_job_id, request, headers, runtime)
-
-    async def list_training_job_instance_metrics_async(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobInstanceMetricsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.list_training_job_instance_metrics_with_options_async(training_job_id, request, headers, runtime)
-
-    def list_training_job_instance_metrics_with_options(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobInstanceMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.instance_id):
-            query['InstanceId'] = request.instance_id
-        if not UtilClient.is_unset(request.metric_type):
-            query['MetricType'] = request.metric_type
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ListTrainingJobInstanceMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/instancemetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def list_training_job_instance_metrics_with_options_async(
-        self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobInstanceMetricsRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.end_time):
-            query['EndTime'] = request.end_time
-        if not UtilClient.is_unset(request.instance_id):
-            query['InstanceId'] = request.instance_id
-        if not UtilClient.is_unset(request.metric_type):
-            query['MetricType'] = request.metric_type
-        if not UtilClient.is_unset(request.start_time):
-            query['StartTime'] = request.start_time
-        if not UtilClient.is_unset(request.time_step):
-            query['TimeStep'] = request.time_step
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ListTrainingJobInstanceMetrics',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/instancemetrics',
-            method='GET',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ListTrainingJobInstanceMetricsResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def list_training_job_logs(
+    def list_resource_groups(
         self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobLogsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobLogsResponse:
+        request: pai_studio_20220112_models.ListResourceGroupsRequest,
+    ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_training_job_logs_with_options(training_job_id, request, headers, runtime)
+        return self.list_resource_groups_with_options(request, headers, runtime)
 
-    async def list_training_job_logs_async(
+    async def list_resource_groups_async(
         self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobLogsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobLogsResponse:
+        request: pai_studio_20220112_models.ListResourceGroupsRequest,
+    ) -> pai_studio_20220112_models.ListResourceGroupsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_training_job_logs_with_options_async(training_job_id, request, headers, runtime)
+        return await self.list_resource_groups_with_options_async(request, headers, runtime)
 
     def list_training_job_logs_with_options(
         self,
         training_job_id: str,
         request: pai_studio_20220112_models.ListTrainingJobLogsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -2858,31 +1928,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListTrainingJobLogsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_training_job_metrics(
+    def list_training_job_logs(
         self,
         training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobMetricsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobMetricsResponse:
+        request: pai_studio_20220112_models.ListTrainingJobLogsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobLogsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_training_job_metrics_with_options(training_job_id, request, headers, runtime)
+        return self.list_training_job_logs_with_options(training_job_id, request, headers, runtime)
 
-    async def list_training_job_metrics_async(
+    async def list_training_job_logs_async(
         self,
         training_job_id: str,
-        request: pai_studio_20220112_models.ListTrainingJobMetricsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobMetricsResponse:
+        request: pai_studio_20220112_models.ListTrainingJobLogsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobLogsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_training_job_metrics_with_options_async(training_job_id, request, headers, runtime)
+        return await self.list_training_job_logs_with_options_async(training_job_id, request, headers, runtime)
 
     def list_training_job_metrics_with_options(
         self,
         training_job_id: str,
         request: pai_studio_20220112_models.ListTrainingJobMetricsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -2958,48 +2028,68 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListTrainingJobMetricsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def list_training_jobs(
+    def list_training_job_metrics(
         self,
-        request: pai_studio_20220112_models.ListTrainingJobsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
+        training_job_id: str,
+        request: pai_studio_20220112_models.ListTrainingJobMetricsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.list_training_jobs_with_options(request, headers, runtime)
+        return self.list_training_job_metrics_with_options(training_job_id, request, headers, runtime)
 
-    async def list_training_jobs_async(
+    async def list_training_job_metrics_async(
         self,
-        request: pai_studio_20220112_models.ListTrainingJobsRequest,
-    ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
+        training_job_id: str,
+        request: pai_studio_20220112_models.ListTrainingJobMetricsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobMetricsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.list_training_jobs_with_options_async(request, headers, runtime)
+        return await self.list_training_job_metrics_with_options_async(training_job_id, request, headers, runtime)
 
     def list_training_jobs_with_options(
         self,
-        request: pai_studio_20220112_models.ListTrainingJobsRequest,
+        tmp_req: pai_studio_20220112_models.ListTrainingJobsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
-        UtilClient.validate_model(request)
+        UtilClient.validate_model(tmp_req)
+        request = pai_studio_20220112_models.ListTrainingJobsShrinkRequest()
+        OpenApiUtilClient.convert(tmp_req, request)
+        if not UtilClient.is_unset(tmp_req.labels):
+            request.labels_shrink = OpenApiUtilClient.array_to_string_with_specified_style(tmp_req.labels, 'Labels', 'json')
         query = {}
+        if not UtilClient.is_unset(request.algorithm_name):
+            query['AlgorithmName'] = request.algorithm_name
+        if not UtilClient.is_unset(request.algorithm_provider):
+            query['AlgorithmProvider'] = request.algorithm_provider
+        if not UtilClient.is_unset(request.end_time):
+            query['EndTime'] = request.end_time
+        if not UtilClient.is_unset(request.is_temp_algo):
+            query['IsTempAlgo'] = request.is_temp_algo
+        if not UtilClient.is_unset(request.labels_shrink):
+            query['Labels'] = request.labels_shrink
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.start_time):
+            query['StartTime'] = request.start_time
         if not UtilClient.is_unset(request.status):
             query['Status'] = request.status
+        if not UtilClient.is_unset(request.training_job_id):
+            query['TrainingJobId'] = request.training_job_id
         if not UtilClient.is_unset(request.training_job_name):
             query['TrainingJobName'] = request.training_job_name
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -3018,30 +2108,48 @@
         return TeaCore.from_map(
             pai_studio_20220112_models.ListTrainingJobsResponse(),
             self.call_api(params, req, runtime)
         )
 
     async def list_training_jobs_with_options_async(
         self,
-        request: pai_studio_20220112_models.ListTrainingJobsRequest,
+        tmp_req: pai_studio_20220112_models.ListTrainingJobsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
-        UtilClient.validate_model(request)
+        UtilClient.validate_model(tmp_req)
+        request = pai_studio_20220112_models.ListTrainingJobsShrinkRequest()
+        OpenApiUtilClient.convert(tmp_req, request)
+        if not UtilClient.is_unset(tmp_req.labels):
+            request.labels_shrink = OpenApiUtilClient.array_to_string_with_specified_style(tmp_req.labels, 'Labels', 'json')
         query = {}
+        if not UtilClient.is_unset(request.algorithm_name):
+            query['AlgorithmName'] = request.algorithm_name
+        if not UtilClient.is_unset(request.algorithm_provider):
+            query['AlgorithmProvider'] = request.algorithm_provider
+        if not UtilClient.is_unset(request.end_time):
+            query['EndTime'] = request.end_time
+        if not UtilClient.is_unset(request.is_temp_algo):
+            query['IsTempAlgo'] = request.is_temp_algo
+        if not UtilClient.is_unset(request.labels_shrink):
+            query['Labels'] = request.labels_shrink
         if not UtilClient.is_unset(request.order):
             query['Order'] = request.order
         if not UtilClient.is_unset(request.page_number):
             query['PageNumber'] = request.page_number
         if not UtilClient.is_unset(request.page_size):
             query['PageSize'] = request.page_size
         if not UtilClient.is_unset(request.sort_by):
             query['SortBy'] = request.sort_by
+        if not UtilClient.is_unset(request.start_time):
+            query['StartTime'] = request.start_time
         if not UtilClient.is_unset(request.status):
             query['Status'] = request.status
+        if not UtilClient.is_unset(request.training_job_id):
+            query['TrainingJobId'] = request.training_job_id
         if not UtilClient.is_unset(request.training_job_name):
             query['TrainingJobName'] = request.training_job_name
         if not UtilClient.is_unset(request.workspace_id):
             query['WorkspaceId'] = request.workspace_id
         req = open_api_models.OpenApiRequest(
             headers=headers,
             query=OpenApiUtilClient.query(query)
@@ -3058,271 +2166,29 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.ListTrainingJobsResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def release_algorithm(
-        self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmRequest,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.release_algorithm_with_options(algorithm_id, request, headers, runtime)
-
-    async def release_algorithm_async(
-        self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmRequest,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.release_algorithm_with_options_async(algorithm_id, request, headers, runtime)
-
-    def release_algorithm_with_options(
-        self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.target_algorithm_name):
-            query['TargetAlgorithmName'] = request.target_algorithm_name
-        if not UtilClient.is_unset(request.update_if_exists):
-            query['UpdateIfExists'] = request.update_if_exists
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ReleaseAlgorithm',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/release',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ReleaseAlgorithmResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def release_algorithm_with_options_async(
-        self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.target_algorithm_name):
-            query['TargetAlgorithmName'] = request.target_algorithm_name
-        if not UtilClient.is_unset(request.update_if_exists):
-            query['UpdateIfExists'] = request.update_if_exists
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ReleaseAlgorithm',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/release',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ReleaseAlgorithmResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def release_algorithm_version(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmVersionResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.release_algorithm_version_with_options(algorithm_id, algorithm_version, request, headers, runtime)
-
-    async def release_algorithm_version_async(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmVersionResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.release_algorithm_version_with_options_async(algorithm_id, algorithm_version, request, headers, runtime)
-
-    def release_algorithm_version_with_options(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmVersionRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmVersionResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.target_algorithm_name):
-            query['TargetAlgorithmName'] = request.target_algorithm_name
-        if not UtilClient.is_unset(request.target_algorithm_version):
-            query['TargetAlgorithmVersion'] = request.target_algorithm_version
-        if not UtilClient.is_unset(request.update_if_exists):
-            query['UpdateIfExists'] = request.update_if_exists
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ReleaseAlgorithmVersion',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/versions/{OpenApiUtilClient.get_encode_param(algorithm_version)}/release',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ReleaseAlgorithmVersionResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def release_algorithm_version_with_options_async(
-        self,
-        algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.ReleaseAlgorithmVersionRequest,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.ReleaseAlgorithmVersionResponse:
-        UtilClient.validate_model(request)
-        query = {}
-        if not UtilClient.is_unset(request.target_algorithm_name):
-            query['TargetAlgorithmName'] = request.target_algorithm_name
-        if not UtilClient.is_unset(request.target_algorithm_version):
-            query['TargetAlgorithmVersion'] = request.target_algorithm_version
-        if not UtilClient.is_unset(request.update_if_exists):
-            query['UpdateIfExists'] = request.update_if_exists
-        req = open_api_models.OpenApiRequest(
-            headers=headers,
-            query=OpenApiUtilClient.query(query)
-        )
-        params = open_api_models.Params(
-            action='ReleaseAlgorithmVersion',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/algorithms/{OpenApiUtilClient.get_encode_param(algorithm_id)}/versions/{OpenApiUtilClient.get_encode_param(algorithm_version)}/release',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.ReleaseAlgorithmVersionResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def stop_arrears_training_job(
-        self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.StopArrearsTrainingJobResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return self.stop_arrears_training_job_with_options(training_job_id, headers, runtime)
-
-    async def stop_arrears_training_job_async(
-        self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.StopArrearsTrainingJobResponse:
-        runtime = util_models.RuntimeOptions()
-        headers = {}
-        return await self.stop_arrears_training_job_with_options_async(training_job_id, headers, runtime)
-
-    def stop_arrears_training_job_with_options(
-        self,
-        training_job_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.StopArrearsTrainingJobResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='StopArrearsTrainingJob',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/arrearage/stop',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.StopArrearsTrainingJobResponse(),
-            self.call_api(params, req, runtime)
-        )
-
-    async def stop_arrears_training_job_with_options_async(
-        self,
-        training_job_id: str,
-        headers: Dict[str, str],
-        runtime: util_models.RuntimeOptions,
-    ) -> pai_studio_20220112_models.StopArrearsTrainingJobResponse:
-        req = open_api_models.OpenApiRequest(
-            headers=headers
-        )
-        params = open_api_models.Params(
-            action='StopArrearsTrainingJob',
-            version='2022-01-12',
-            protocol='HTTPS',
-            pathname=f'/api/v1/trainingjobs/{OpenApiUtilClient.get_encode_param(training_job_id)}/arrearage/stop',
-            method='PUT',
-            auth_type='AK',
-            style='ROA',
-            req_body_type='json',
-            body_type='json'
-        )
-        return TeaCore.from_map(
-            pai_studio_20220112_models.StopArrearsTrainingJobResponse(),
-            await self.call_api_async(params, req, runtime)
-        )
-
-    def stop_training_job(
+    def list_training_jobs(
         self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.StopTrainingJobResponse:
+        request: pai_studio_20220112_models.ListTrainingJobsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.stop_training_job_with_options(training_job_id, headers, runtime)
+        return self.list_training_jobs_with_options(request, headers, runtime)
 
-    async def stop_training_job_async(
+    async def list_training_jobs_async(
         self,
-        training_job_id: str,
-    ) -> pai_studio_20220112_models.StopTrainingJobResponse:
+        request: pai_studio_20220112_models.ListTrainingJobsRequest,
+    ) -> pai_studio_20220112_models.ListTrainingJobsResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.stop_training_job_with_options_async(training_job_id, headers, runtime)
+        return await self.list_training_jobs_with_options_async(request, headers, runtime)
 
     def stop_training_job_with_options(
         self,
         training_job_id: str,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.StopTrainingJobResponse:
@@ -3366,43 +2232,43 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.StopTrainingJobResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_algorithm(
+    def stop_training_job(
         self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.UpdateAlgorithmRequest,
-    ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
+        training_job_id: str,
+    ) -> pai_studio_20220112_models.StopTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_algorithm_with_options(algorithm_id, request, headers, runtime)
+        return self.stop_training_job_with_options(training_job_id, headers, runtime)
 
-    async def update_algorithm_async(
+    async def stop_training_job_async(
         self,
-        algorithm_id: str,
-        request: pai_studio_20220112_models.UpdateAlgorithmRequest,
-    ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
+        training_job_id: str,
+    ) -> pai_studio_20220112_models.StopTrainingJobResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_algorithm_with_options_async(algorithm_id, request, headers, runtime)
+        return await self.stop_training_job_with_options_async(training_job_id, headers, runtime)
 
     def update_algorithm_with_options(
         self,
         algorithm_id: str,
         request: pai_studio_20220112_models.UpdateAlgorithmRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.algorithm_description):
             body['AlgorithmDescription'] = request.algorithm_description
+        if not UtilClient.is_unset(request.display_name):
+            body['DisplayName'] = request.display_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateAlgorithm',
             version='2022-01-12',
@@ -3426,14 +2292,16 @@
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
     ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
         UtilClient.validate_model(request)
         body = {}
         if not UtilClient.is_unset(request.algorithm_description):
             body['AlgorithmDescription'] = request.algorithm_description
+        if not UtilClient.is_unset(request.display_name):
+            body['DisplayName'] = request.display_name
         req = open_api_models.OpenApiRequest(
             headers=headers,
             body=OpenApiUtilClient.parse_to_map(body)
         )
         params = open_api_models.Params(
             action='UpdateAlgorithm',
             version='2022-01-12',
@@ -3446,33 +2314,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.UpdateAlgorithmResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_algorithm_version(
+    def update_algorithm(
         self,
         algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.UpdateAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.UpdateAlgorithmVersionResponse:
+        request: pai_studio_20220112_models.UpdateAlgorithmRequest,
+    ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_algorithm_version_with_options(algorithm_id, algorithm_version, request, headers, runtime)
+        return self.update_algorithm_with_options(algorithm_id, request, headers, runtime)
 
-    async def update_algorithm_version_async(
+    async def update_algorithm_async(
         self,
         algorithm_id: str,
-        algorithm_version: str,
-        request: pai_studio_20220112_models.UpdateAlgorithmVersionRequest,
-    ) -> pai_studio_20220112_models.UpdateAlgorithmVersionResponse:
+        request: pai_studio_20220112_models.UpdateAlgorithmRequest,
+    ) -> pai_studio_20220112_models.UpdateAlgorithmResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_algorithm_version_with_options_async(algorithm_id, algorithm_version, request, headers, runtime)
+        return await self.update_algorithm_with_options_async(algorithm_id, request, headers, runtime)
 
     def update_algorithm_version_with_options(
         self,
         algorithm_id: str,
         algorithm_version: str,
         tmp_req: pai_studio_20220112_models.UpdateAlgorithmVersionRequest,
         headers: Dict[str, str],
@@ -3538,31 +2404,33 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.UpdateAlgorithmVersionResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_resource_group(
+    def update_algorithm_version(
         self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.UpdateResourceGroupRequest,
-    ) -> pai_studio_20220112_models.UpdateResourceGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+        request: pai_studio_20220112_models.UpdateAlgorithmVersionRequest,
+    ) -> pai_studio_20220112_models.UpdateAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_resource_group_with_options(resource_group_id, request, headers, runtime)
+        return self.update_algorithm_version_with_options(algorithm_id, algorithm_version, request, headers, runtime)
 
-    async def update_resource_group_async(
+    async def update_algorithm_version_async(
         self,
-        resource_group_id: str,
-        request: pai_studio_20220112_models.UpdateResourceGroupRequest,
-    ) -> pai_studio_20220112_models.UpdateResourceGroupResponse:
+        algorithm_id: str,
+        algorithm_version: str,
+        request: pai_studio_20220112_models.UpdateAlgorithmVersionRequest,
+    ) -> pai_studio_20220112_models.UpdateAlgorithmVersionResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_resource_group_with_options_async(resource_group_id, request, headers, runtime)
+        return await self.update_algorithm_version_with_options_async(algorithm_id, algorithm_version, request, headers, runtime)
 
     def update_resource_group_with_options(
         self,
         resource_group_id: str,
         request: pai_studio_20220112_models.UpdateResourceGroupRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -3622,31 +2490,31 @@
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.UpdateResourceGroupResponse(),
             await self.call_api_async(params, req, runtime)
         )
 
-    def update_training_job_labels(
+    def update_resource_group(
         self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.UpdateTrainingJobLabelsRequest,
-    ) -> pai_studio_20220112_models.UpdateTrainingJobLabelsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.UpdateResourceGroupRequest,
+    ) -> pai_studio_20220112_models.UpdateResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return self.update_training_job_labels_with_options(training_job_id, request, headers, runtime)
+        return self.update_resource_group_with_options(resource_group_id, request, headers, runtime)
 
-    async def update_training_job_labels_async(
+    async def update_resource_group_async(
         self,
-        training_job_id: str,
-        request: pai_studio_20220112_models.UpdateTrainingJobLabelsRequest,
-    ) -> pai_studio_20220112_models.UpdateTrainingJobLabelsResponse:
+        resource_group_id: str,
+        request: pai_studio_20220112_models.UpdateResourceGroupRequest,
+    ) -> pai_studio_20220112_models.UpdateResourceGroupResponse:
         runtime = util_models.RuntimeOptions()
         headers = {}
-        return await self.update_training_job_labels_with_options_async(training_job_id, request, headers, runtime)
+        return await self.update_resource_group_with_options_async(resource_group_id, request, headers, runtime)
 
     def update_training_job_labels_with_options(
         self,
         training_job_id: str,
         request: pai_studio_20220112_models.UpdateTrainingJobLabelsRequest,
         headers: Dict[str, str],
         runtime: util_models.RuntimeOptions,
@@ -3701,7 +2569,25 @@
             req_body_type='json',
             body_type='json'
         )
         return TeaCore.from_map(
             pai_studio_20220112_models.UpdateTrainingJobLabelsResponse(),
             await self.call_api_async(params, req, runtime)
         )
+
+    def update_training_job_labels(
+        self,
+        training_job_id: str,
+        request: pai_studio_20220112_models.UpdateTrainingJobLabelsRequest,
+    ) -> pai_studio_20220112_models.UpdateTrainingJobLabelsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return self.update_training_job_labels_with_options(training_job_id, request, headers, runtime)
+
+    async def update_training_job_labels_async(
+        self,
+        training_job_id: str,
+        request: pai_studio_20220112_models.UpdateTrainingJobLabelsRequest,
+    ) -> pai_studio_20220112_models.UpdateTrainingJobLabelsResponse:
+        runtime = util_models.RuntimeOptions()
+        headers = {}
+        return await self.update_training_job_labels_with_options_async(training_job_id, request, headers, runtime)
```

## pai/libs/alibabacloud_paistudio20220112/models.py

```diff
@@ -1,46 +1,13 @@
 # -*- coding: utf-8 -*-
 # This file is auto-generated, don't edit it. Thanks.
 from Tea.model import TeaModel
 from typing import Dict, Any, List
 
 
-class AlgorithmSpecCodeDir(TeaModel):
-    def __init__(
-        self,
-        location_type: str = None,
-        location_value: Dict[str, Any] = None,
-    ):
-        self.location_type = location_type
-        self.location_value = location_value
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.location_type is not None:
-            result['LocationType'] = self.location_type
-        if self.location_value is not None:
-            result['LocationValue'] = self.location_value
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('LocationType') is not None:
-            self.location_type = m.get('LocationType')
-        if m.get('LocationValue') is not None:
-            self.location_value = m.get('LocationValue')
-        return self
-
-
 class AlgorithmSpecComputeResourcePolicy(TeaModel):
     def __init__(
         self,
         value: str = None,
         version: str = None,
     ):
         self.value = value
@@ -95,156 +62,252 @@
         m = m or dict()
         if m.get('Policy') is not None:
             temp_model = AlgorithmSpecComputeResourcePolicy()
             self.policy = temp_model.from_map(m['Policy'])
         return self
 
 
+class AlgorithmSpecCustomization(TeaModel):
+    def __init__(
+        self,
+        code_dir: bool = None,
+    ):
+        self.code_dir = code_dir
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.code_dir is not None:
+            result['CodeDir'] = self.code_dir
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('CodeDir') is not None:
+            self.code_dir = m.get('CodeDir')
+        return self
+
+
+class Location(TeaModel):
+    def __init__(
+        self,
+        location_type: str = None,
+        location_value: Dict[str, Any] = None,
+    ):
+        self.location_type = location_type
+        self.location_value = location_value
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.location_type is not None:
+            result['LocationType'] = self.location_type
+        if self.location_value is not None:
+            result['LocationValue'] = self.location_value
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('LocationType') is not None:
+            self.location_type = m.get('LocationType')
+        if m.get('LocationValue') is not None:
+            self.location_value = m.get('LocationValue')
+        return self
+
+
+class HyperParameterRange(TeaModel):
+    def __init__(
+        self,
+        enum: List[str] = None,
+        exclusive_maximum: bool = None,
+        exclusive_minimum: bool = None,
+        max_length: int = None,
+        maximum: str = None,
+        min_length: int = None,
+        minimum: str = None,
+        pattern: str = None,
+    ):
+        self.enum = enum
+        self.exclusive_maximum = exclusive_maximum
+        self.exclusive_minimum = exclusive_minimum
+        self.max_length = max_length
+        self.maximum = maximum
+        self.min_length = min_length
+        self.minimum = minimum
+        self.pattern = pattern
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.enum is not None:
+            result['Enum'] = self.enum
+        if self.exclusive_maximum is not None:
+            result['ExclusiveMaximum'] = self.exclusive_maximum
+        if self.exclusive_minimum is not None:
+            result['ExclusiveMinimum'] = self.exclusive_minimum
+        if self.max_length is not None:
+            result['MaxLength'] = self.max_length
+        if self.maximum is not None:
+            result['Maximum'] = self.maximum
+        if self.min_length is not None:
+            result['MinLength'] = self.min_length
+        if self.minimum is not None:
+            result['Minimum'] = self.minimum
+        if self.pattern is not None:
+            result['Pattern'] = self.pattern
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Enum') is not None:
+            self.enum = m.get('Enum')
+        if m.get('ExclusiveMaximum') is not None:
+            self.exclusive_maximum = m.get('ExclusiveMaximum')
+        if m.get('ExclusiveMinimum') is not None:
+            self.exclusive_minimum = m.get('ExclusiveMinimum')
+        if m.get('MaxLength') is not None:
+            self.max_length = m.get('MaxLength')
+        if m.get('Maximum') is not None:
+            self.maximum = m.get('Maximum')
+        if m.get('MinLength') is not None:
+            self.min_length = m.get('MinLength')
+        if m.get('Minimum') is not None:
+            self.minimum = m.get('Minimum')
+        if m.get('Pattern') is not None:
+            self.pattern = m.get('Pattern')
+        return self
+
+
 class HyperParameterDefinition(TeaModel):
     def __init__(
         self,
         default_value: str = None,
         description: str = None,
+        display_name: str = None,
         name: str = None,
+        range: HyperParameterRange = None,
         required: bool = None,
         type: str = None,
     ):
         self.default_value = default_value
         self.description = description
+        self.display_name = display_name
         self.name = name
+        self.range = range
         self.required = required
         self.type = type
 
     def validate(self):
-        pass
+        if self.range:
+            self.range.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.default_value is not None:
             result['DefaultValue'] = self.default_value
         if self.description is not None:
             result['Description'] = self.description
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.name is not None:
             result['Name'] = self.name
+        if self.range is not None:
+            result['Range'] = self.range.to_map()
         if self.required is not None:
             result['Required'] = self.required
         if self.type is not None:
             result['Type'] = self.type
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('DefaultValue') is not None:
             self.default_value = m.get('DefaultValue')
         if m.get('Description') is not None:
             self.description = m.get('Description')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('Name') is not None:
             self.name = m.get('Name')
+        if m.get('Range') is not None:
+            temp_model = HyperParameterRange()
+            self.range = temp_model.from_map(m['Range'])
         if m.get('Required') is not None:
             self.required = m.get('Required')
         if m.get('Type') is not None:
             self.type = m.get('Type')
         return self
 
 
-class ChannelProperty(TeaModel):
-    def __init__(
-        self,
-        name: str = None,
-        value: str = None,
-    ):
-        self.name = name
-        self.value = value
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.name is not None:
-            result['Name'] = self.name
-        if self.value is not None:
-            result['Value'] = self.value
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Name') is not None:
-            self.name = m.get('Name')
-        if m.get('Value') is not None:
-            self.value = m.get('Value')
-        return self
-
-
 class Channel(TeaModel):
     def __init__(
         self,
         description: str = None,
-        enable_oss_append: bool = None,
         name: str = None,
-        properties: List[ChannelProperty] = None,
+        properties: Dict[str, Any] = None,
         required: bool = None,
         supported_channel_types: List[str] = None,
     ):
         self.description = description
-        self.enable_oss_append = enable_oss_append
         self.name = name
         self.properties = properties
         self.required = required
         self.supported_channel_types = supported_channel_types
 
     def validate(self):
-        if self.properties:
-            for k in self.properties:
-                if k:
-                    k.validate()
+        pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.description is not None:
             result['Description'] = self.description
-        if self.enable_oss_append is not None:
-            result['EnableOssAppend'] = self.enable_oss_append
         if self.name is not None:
             result['Name'] = self.name
-        result['Properties'] = []
         if self.properties is not None:
-            for k in self.properties:
-                result['Properties'].append(k.to_map() if k else None)
+            result['Properties'] = self.properties
         if self.required is not None:
             result['Required'] = self.required
         if self.supported_channel_types is not None:
             result['SupportedChannelTypes'] = self.supported_channel_types
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('Description') is not None:
             self.description = m.get('Description')
-        if m.get('EnableOssAppend') is not None:
-            self.enable_oss_append = m.get('EnableOssAppend')
         if m.get('Name') is not None:
             self.name = m.get('Name')
-        self.properties = []
         if m.get('Properties') is not None:
-            for k in m.get('Properties'):
-                temp_model = ChannelProperty()
-                self.properties.append(temp_model.from_map(k))
+            self.properties = m.get('Properties')
         if m.get('Required') is not None:
             self.required = m.get('Required')
         if m.get('SupportedChannelTypes') is not None:
             self.supported_channel_types = m.get('SupportedChannelTypes')
         return self
 
 
@@ -283,46 +346,91 @@
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Regex') is not None:
             self.regex = m.get('Regex')
         return self
 
 
+class ConditionExpression(TeaModel):
+    def __init__(
+        self,
+        key: str = None,
+        operator: str = None,
+        values: List[str] = None,
+    ):
+        self.key = key
+        self.operator = operator
+        self.values = values
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.key is not None:
+            result['Key'] = self.key
+        if self.operator is not None:
+            result['Operator'] = self.operator
+        if self.values is not None:
+            result['Values'] = self.values
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Key') is not None:
+            self.key = m.get('Key')
+        if m.get('Operator') is not None:
+            self.operator = m.get('Operator')
+        if m.get('Values') is not None:
+            self.values = m.get('Values')
+        return self
+
+
 class AlgorithmSpec(TeaModel):
     def __init__(
         self,
-        code_dir: AlgorithmSpecCodeDir = None,
+        code_dir: Location = None,
         command: List[str] = None,
         compute_resource: AlgorithmSpecComputeResource = None,
+        customization: AlgorithmSpecCustomization = None,
         hyper_parameters: List[HyperParameterDefinition] = None,
         image: str = None,
         input_channels: List[Channel] = None,
         job_type: str = None,
         metric_definitions: List[MetricDefinition] = None,
         output_channels: List[Channel] = None,
+        resource_requirements: List[ConditionExpression] = None,
         supported_instance_types: List[str] = None,
         supports_distributed_training: bool = None,
     ):
         self.code_dir = code_dir
         self.command = command
         self.compute_resource = compute_resource
+        self.customization = customization
         self.hyper_parameters = hyper_parameters
         self.image = image
         self.input_channels = input_channels
         self.job_type = job_type
         self.metric_definitions = metric_definitions
         self.output_channels = output_channels
+        self.resource_requirements = resource_requirements
         self.supported_instance_types = supported_instance_types
         self.supports_distributed_training = supports_distributed_training
 
     def validate(self):
         if self.code_dir:
             self.code_dir.validate()
         if self.compute_resource:
             self.compute_resource.validate()
+        if self.customization:
+            self.customization.validate()
         if self.hyper_parameters:
             for k in self.hyper_parameters:
                 if k:
                     k.validate()
         if self.input_channels:
             for k in self.input_channels:
                 if k:
@@ -331,27 +439,33 @@
             for k in self.metric_definitions:
                 if k:
                     k.validate()
         if self.output_channels:
             for k in self.output_channels:
                 if k:
                     k.validate()
+        if self.resource_requirements:
+            for k in self.resource_requirements:
+                if k:
+                    k.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.code_dir is not None:
             result['CodeDir'] = self.code_dir.to_map()
         if self.command is not None:
             result['Command'] = self.command
         if self.compute_resource is not None:
             result['ComputeResource'] = self.compute_resource.to_map()
+        if self.customization is not None:
+            result['Customization'] = self.customization.to_map()
         result['HyperParameters'] = []
         if self.hyper_parameters is not None:
             for k in self.hyper_parameters:
                 result['HyperParameters'].append(k.to_map() if k else None)
         if self.image is not None:
             result['Image'] = self.image
         result['InputChannels'] = []
@@ -364,30 +478,37 @@
         if self.metric_definitions is not None:
             for k in self.metric_definitions:
                 result['MetricDefinitions'].append(k.to_map() if k else None)
         result['OutputChannels'] = []
         if self.output_channels is not None:
             for k in self.output_channels:
                 result['OutputChannels'].append(k.to_map() if k else None)
+        result['ResourceRequirements'] = []
+        if self.resource_requirements is not None:
+            for k in self.resource_requirements:
+                result['ResourceRequirements'].append(k.to_map() if k else None)
         if self.supported_instance_types is not None:
             result['SupportedInstanceTypes'] = self.supported_instance_types
         if self.supports_distributed_training is not None:
             result['SupportsDistributedTraining'] = self.supports_distributed_training
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('CodeDir') is not None:
-            temp_model = AlgorithmSpecCodeDir()
+            temp_model = Location()
             self.code_dir = temp_model.from_map(m['CodeDir'])
         if m.get('Command') is not None:
             self.command = m.get('Command')
         if m.get('ComputeResource') is not None:
             temp_model = AlgorithmSpecComputeResource()
             self.compute_resource = temp_model.from_map(m['ComputeResource'])
+        if m.get('Customization') is not None:
+            temp_model = AlgorithmSpecCustomization()
+            self.customization = temp_model.from_map(m['Customization'])
         self.hyper_parameters = []
         if m.get('HyperParameters') is not None:
             for k in m.get('HyperParameters'):
                 temp_model = HyperParameterDefinition()
                 self.hyper_parameters.append(temp_model.from_map(k))
         if m.get('Image') is not None:
             self.image = m.get('Image')
@@ -404,21 +525,181 @@
                 temp_model = MetricDefinition()
                 self.metric_definitions.append(temp_model.from_map(k))
         self.output_channels = []
         if m.get('OutputChannels') is not None:
             for k in m.get('OutputChannels'):
                 temp_model = Channel()
                 self.output_channels.append(temp_model.from_map(k))
+        self.resource_requirements = []
+        if m.get('ResourceRequirements') is not None:
+            for k in m.get('ResourceRequirements'):
+                temp_model = ConditionExpression()
+                self.resource_requirements.append(temp_model.from_map(k))
         if m.get('SupportedInstanceTypes') is not None:
             self.supported_instance_types = m.get('SupportedInstanceTypes')
         if m.get('SupportsDistributedTraining') is not None:
             self.supports_distributed_training = m.get('SupportsDistributedTraining')
         return self
 
 
+class ChannelProperty(TeaModel):
+    def __init__(
+        self,
+        name: str = None,
+        value: str = None,
+    ):
+        self.name = name
+        self.value = value
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.name is not None:
+            result['Name'] = self.name
+        if self.value is not None:
+            result['Value'] = self.value
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Name') is not None:
+            self.name = m.get('Name')
+        if m.get('Value') is not None:
+            self.value = m.get('Value')
+        return self
+
+
+class ComponentSpec(TeaModel):
+    def __init__(
+        self,
+        code_dir: Location = None,
+        command: str = None,
+        hyper_parameters: List[HyperParameterDefinition] = None,
+        image: str = None,
+        input_channels: List[Channel] = None,
+        job_type: str = None,
+        metric_definitions: List[MetricDefinition] = None,
+        output_channels: List[Channel] = None,
+        resource_requirements: List[ConditionExpression] = None,
+    ):
+        self.code_dir = code_dir
+        self.command = command
+        self.hyper_parameters = hyper_parameters
+        self.image = image
+        self.input_channels = input_channels
+        self.job_type = job_type
+        self.metric_definitions = metric_definitions
+        self.output_channels = output_channels
+        self.resource_requirements = resource_requirements
+
+    def validate(self):
+        if self.code_dir:
+            self.code_dir.validate()
+        if self.hyper_parameters:
+            for k in self.hyper_parameters:
+                if k:
+                    k.validate()
+        if self.input_channels:
+            for k in self.input_channels:
+                if k:
+                    k.validate()
+        if self.metric_definitions:
+            for k in self.metric_definitions:
+                if k:
+                    k.validate()
+        if self.output_channels:
+            for k in self.output_channels:
+                if k:
+                    k.validate()
+        if self.resource_requirements:
+            for k in self.resource_requirements:
+                if k:
+                    k.validate()
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.code_dir is not None:
+            result['CodeDir'] = self.code_dir.to_map()
+        if self.command is not None:
+            result['Command'] = self.command
+        result['HyperParameters'] = []
+        if self.hyper_parameters is not None:
+            for k in self.hyper_parameters:
+                result['HyperParameters'].append(k.to_map() if k else None)
+        if self.image is not None:
+            result['Image'] = self.image
+        result['InputChannels'] = []
+        if self.input_channels is not None:
+            for k in self.input_channels:
+                result['InputChannels'].append(k.to_map() if k else None)
+        if self.job_type is not None:
+            result['JobType'] = self.job_type
+        result['MetricDefinitions'] = []
+        if self.metric_definitions is not None:
+            for k in self.metric_definitions:
+                result['MetricDefinitions'].append(k.to_map() if k else None)
+        result['OutputChannels'] = []
+        if self.output_channels is not None:
+            for k in self.output_channels:
+                result['OutputChannels'].append(k.to_map() if k else None)
+        result['ResourceRequirements'] = []
+        if self.resource_requirements is not None:
+            for k in self.resource_requirements:
+                result['ResourceRequirements'].append(k.to_map() if k else None)
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('CodeDir') is not None:
+            temp_model = Location()
+            self.code_dir = temp_model.from_map(m['CodeDir'])
+        if m.get('Command') is not None:
+            self.command = m.get('Command')
+        self.hyper_parameters = []
+        if m.get('HyperParameters') is not None:
+            for k in m.get('HyperParameters'):
+                temp_model = HyperParameterDefinition()
+                self.hyper_parameters.append(temp_model.from_map(k))
+        if m.get('Image') is not None:
+            self.image = m.get('Image')
+        self.input_channels = []
+        if m.get('InputChannels') is not None:
+            for k in m.get('InputChannels'):
+                temp_model = Channel()
+                self.input_channels.append(temp_model.from_map(k))
+        if m.get('JobType') is not None:
+            self.job_type = m.get('JobType')
+        self.metric_definitions = []
+        if m.get('MetricDefinitions') is not None:
+            for k in m.get('MetricDefinitions'):
+                temp_model = MetricDefinition()
+                self.metric_definitions.append(temp_model.from_map(k))
+        self.output_channels = []
+        if m.get('OutputChannels') is not None:
+            for k in m.get('OutputChannels'):
+                temp_model = Channel()
+                self.output_channels.append(temp_model.from_map(k))
+        self.resource_requirements = []
+        if m.get('ResourceRequirements') is not None:
+            for k in m.get('ResourceRequirements'):
+                temp_model = ConditionExpression()
+                self.resource_requirements.append(temp_model.from_map(k))
+        return self
+
+
 class GPUInfo(TeaModel):
     def __init__(
         self,
         count: int = None,
         type: str = None,
     ):
         self.count = count
@@ -573,14 +854,47 @@
         if m.get('TotalMemory') is not None:
             self.total_memory = m.get('TotalMemory')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         return self
 
 
+class Label(TeaModel):
+    def __init__(
+        self,
+        key: str = None,
+        value: str = None,
+    ):
+        self.key = key
+        self.value = value
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.key is not None:
+            result['Key'] = self.key
+        if self.value is not None:
+            result['Value'] = self.value
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('Key') is not None:
+            self.key = m.get('Key')
+        if m.get('Value') is not None:
+            self.value = m.get('Value')
+        return self
+
+
 class MachineGroup(TeaModel):
     def __init__(
         self,
         creator_id: str = None,
         ecs_count: int = None,
         ecs_spec: str = None,
         gmt_created_time: str = None,
@@ -782,17 +1096,19 @@
         network_output_rate: str = None,
         node_id: str = None,
         node_status: str = None,
         node_type: str = None,
         request_cpu: int = None,
         request_gpu: int = None,
         request_memory: int = None,
+        task_id_map: Dict[str, Any] = None,
         total_cpu: int = None,
         total_gpu: int = None,
         total_memory: int = None,
+        total_tasks: int = None,
         user_ids: List[str] = None,
         user_number: str = None,
     ):
         self.cpuusage_rate = cpuusage_rate
         self.created_time = created_time
         self.disk_read_rate = disk_read_rate
         self.disk_write_rate = disk_write_rate
@@ -803,17 +1119,19 @@
         self.network_output_rate = network_output_rate
         self.node_id = node_id
         self.node_status = node_status
         self.node_type = node_type
         self.request_cpu = request_cpu
         self.request_gpu = request_gpu
         self.request_memory = request_memory
+        self.task_id_map = task_id_map
         self.total_cpu = total_cpu
         self.total_gpu = total_gpu
         self.total_memory = total_memory
+        self.total_tasks = total_tasks
         self.user_ids = user_ids
         self.user_number = user_number
 
     def validate(self):
         pass
 
     def to_map(self):
@@ -848,20 +1166,24 @@
             result['NodeType'] = self.node_type
         if self.request_cpu is not None:
             result['RequestCPU'] = self.request_cpu
         if self.request_gpu is not None:
             result['RequestGPU'] = self.request_gpu
         if self.request_memory is not None:
             result['RequestMemory'] = self.request_memory
+        if self.task_id_map is not None:
+            result['TaskIdMap'] = self.task_id_map
         if self.total_cpu is not None:
             result['TotalCPU'] = self.total_cpu
         if self.total_gpu is not None:
             result['TotalGPU'] = self.total_gpu
         if self.total_memory is not None:
             result['TotalMemory'] = self.total_memory
+        if self.total_tasks is not None:
+            result['TotalTasks'] = self.total_tasks
         if self.user_ids is not None:
             result['UserIDs'] = self.user_ids
         if self.user_number is not None:
             result['UserNumber'] = self.user_number
         return result
 
     def from_map(self, m: dict = None):
@@ -892,27 +1214,64 @@
             self.node_type = m.get('NodeType')
         if m.get('RequestCPU') is not None:
             self.request_cpu = m.get('RequestCPU')
         if m.get('RequestGPU') is not None:
             self.request_gpu = m.get('RequestGPU')
         if m.get('RequestMemory') is not None:
             self.request_memory = m.get('RequestMemory')
+        if m.get('TaskIdMap') is not None:
+            self.task_id_map = m.get('TaskIdMap')
         if m.get('TotalCPU') is not None:
             self.total_cpu = m.get('TotalCPU')
         if m.get('TotalGPU') is not None:
             self.total_gpu = m.get('TotalGPU')
         if m.get('TotalMemory') is not None:
             self.total_memory = m.get('TotalMemory')
+        if m.get('TotalTasks') is not None:
+            self.total_tasks = m.get('TotalTasks')
         if m.get('UserIDs') is not None:
             self.user_ids = m.get('UserIDs')
         if m.get('UserNumber') is not None:
             self.user_number = m.get('UserNumber')
         return self
 
 
+class Permission(TeaModel):
+    def __init__(
+        self,
+        is_enabled: bool = None,
+        resource_type: str = None,
+    ):
+        self.is_enabled = is_enabled
+        self.resource_type = resource_type
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.is_enabled is not None:
+            result['IsEnabled'] = self.is_enabled
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('IsEnabled') is not None:
+            self.is_enabled = m.get('IsEnabled')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
+        return self
+
+
 class UserVpc(TeaModel):
     def __init__(
         self,
         extended_cidrs: List[str] = None,
         role_arn: str = None,
         security_group_id: str = None,
         switch_id: str = None,
@@ -963,22 +1322,24 @@
 class ResourceGroup(TeaModel):
     def __init__(
         self,
         creator_id: str = None,
         gmt_created_time: str = None,
         gmt_modified_time: str = None,
         name: str = None,
+        node_count: int = None,
         resource_group_id: str = None,
         user_vpc: UserVpc = None,
         workspace_id: str = None,
     ):
         self.creator_id = creator_id
         self.gmt_created_time = gmt_created_time
         self.gmt_modified_time = gmt_modified_time
         self.name = name
+        self.node_count = node_count
         self.resource_group_id = resource_group_id
         self.user_vpc = user_vpc
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.user_vpc:
             self.user_vpc.validate()
@@ -993,14 +1354,16 @@
             result['CreatorID'] = self.creator_id
         if self.gmt_created_time is not None:
             result['GmtCreatedTime'] = self.gmt_created_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.name is not None:
             result['Name'] = self.name
+        if self.node_count is not None:
+            result['NodeCount'] = self.node_count
         if self.resource_group_id is not None:
             result['ResourceGroupID'] = self.resource_group_id
         if self.user_vpc is not None:
             result['UserVpc'] = self.user_vpc.to_map()
         if self.workspace_id is not None:
             result['WorkspaceID'] = self.workspace_id
         return result
@@ -1011,14 +1374,16 @@
             self.creator_id = m.get('CreatorID')
         if m.get('GmtCreatedTime') is not None:
             self.gmt_created_time = m.get('GmtCreatedTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         if m.get('Name') is not None:
             self.name = m.get('Name')
+        if m.get('NodeCount') is not None:
+            self.node_count = m.get('NodeCount')
         if m.get('ResourceGroupID') is not None:
             self.resource_group_id = m.get('ResourceGroupID')
         if m.get('UserVpc') is not None:
             temp_model = UserVpc()
             self.user_vpc = temp_model.from_map(m['UserVpc'])
         if m.get('WorkspaceID') is not None:
             self.workspace_id = m.get('WorkspaceID')
@@ -1232,18 +1597,20 @@
 
 
 class CreateAlgorithmRequest(TeaModel):
     def __init__(
         self,
         algorithm_description: str = None,
         algorithm_name: str = None,
+        display_name: str = None,
         workspace_id: str = None,
     ):
         self.algorithm_description = algorithm_description
         self.algorithm_name = algorithm_name
+        self.display_name = display_name
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
@@ -1251,24 +1618,28 @@
             return _map
 
         result = dict()
         if self.algorithm_description is not None:
             result['AlgorithmDescription'] = self.algorithm_description
         if self.algorithm_name is not None:
             result['AlgorithmName'] = self.algorithm_name
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('AlgorithmDescription') is not None:
             self.algorithm_description = m.get('AlgorithmDescription')
         if m.get('AlgorithmName') is not None:
             self.algorithm_name = m.get('AlgorithmName')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
 class CreateAlgorithmResponseBody(TeaModel):
     def __init__(
@@ -1479,46 +1850,58 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class CreateResourceGroupRequest(TeaModel):
     def __init__(
         self,
+        computing_resource_provider: str = None,
         description: str = None,
         name: str = None,
+        resource_type: str = None,
         user_vpc: UserVpc = None,
     ):
+        self.computing_resource_provider = computing_resource_provider
         self.description = description
         self.name = name
+        self.resource_type = resource_type
         self.user_vpc = user_vpc
 
     def validate(self):
         if self.user_vpc:
             self.user_vpc.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.computing_resource_provider is not None:
+            result['ComputingResourceProvider'] = self.computing_resource_provider
         if self.description is not None:
             result['Description'] = self.description
         if self.name is not None:
             result['Name'] = self.name
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         if self.user_vpc is not None:
             result['UserVpc'] = self.user_vpc.to_map()
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ComputingResourceProvider') is not None:
+            self.computing_resource_provider = m.get('ComputingResourceProvider')
         if m.get('Description') is not None:
             self.description = m.get('Description')
         if m.get('Name') is not None:
             self.name = m.get('Name')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         if m.get('UserVpc') is not None:
             temp_model = UserVpc()
             self.user_vpc = temp_model.from_map(m['UserVpc'])
         return self
 
 
 class CreateResourceGroupResponseBody(TeaModel):
@@ -1594,77 +1977,50 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateResourceGroupResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class CreateTrainingJobRequestCodeDir(TeaModel):
-    def __init__(
-        self,
-        location_type: str = None,
-        location_value: Dict[str, Any] = None,
-    ):
-        self.location_type = location_type
-        self.location_value = location_value
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.location_type is not None:
-            result['LocationType'] = self.location_type
-        if self.location_value is not None:
-            result['LocationValue'] = self.location_value
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('LocationType') is not None:
-            self.location_type = m.get('LocationType')
-        if m.get('LocationValue') is not None:
-            self.location_value = m.get('LocationValue')
-        return self
-
-
 class CreateTrainingJobRequestComputeResource(TeaModel):
     def __init__(
         self,
         ecs_count: int = None,
         ecs_spec: str = None,
+        resource_group_id: str = None,
     ):
         self.ecs_count = ecs_count
         self.ecs_spec = ecs_spec
+        self.resource_group_id = resource_group_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.ecs_count is not None:
             result['EcsCount'] = self.ecs_count
         if self.ecs_spec is not None:
             result['EcsSpec'] = self.ecs_spec
+        if self.resource_group_id is not None:
+            result['ResourceGroupId'] = self.resource_group_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('EcsCount') is not None:
             self.ecs_count = m.get('EcsCount')
         if m.get('EcsSpec') is not None:
             self.ecs_spec = m.get('EcsSpec')
+        if m.get('ResourceGroupId') is not None:
+            self.resource_group_id = m.get('ResourceGroupId')
         return self
 
 
 class CreateTrainingJobRequestHyperParameters(TeaModel):
     def __init__(
         self,
         name: str = None,
@@ -1838,20 +2194,21 @@
 class CreateTrainingJobRequest(TeaModel):
     def __init__(
         self,
         algorithm_name: str = None,
         algorithm_provider: str = None,
         algorithm_spec: AlgorithmSpec = None,
         algorithm_version: str = None,
-        code_dir: CreateTrainingJobRequestCodeDir = None,
+        code_dir: Location = None,
         compute_resource: CreateTrainingJobRequestComputeResource = None,
         hyper_parameters: List[CreateTrainingJobRequestHyperParameters] = None,
         input_channels: List[CreateTrainingJobRequestInputChannels] = None,
         labels: List[CreateTrainingJobRequestLabels] = None,
         output_channels: List[CreateTrainingJobRequestOutputChannels] = None,
+        role_arn: str = None,
         scheduler: CreateTrainingJobRequestScheduler = None,
         training_job_description: str = None,
         training_job_name: str = None,
         workspace_id: str = None,
     ):
         self.algorithm_name = algorithm_name
         self.algorithm_provider = algorithm_provider
@@ -1859,14 +2216,15 @@
         self.algorithm_version = algorithm_version
         self.code_dir = code_dir
         self.compute_resource = compute_resource
         self.hyper_parameters = hyper_parameters
         self.input_channels = input_channels
         self.labels = labels
         self.output_channels = output_channels
+        self.role_arn = role_arn
         self.scheduler = scheduler
         self.training_job_description = training_job_description
         self.training_job_name = training_job_name
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.algorithm_spec:
@@ -1924,14 +2282,16 @@
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         result['OutputChannels'] = []
         if self.output_channels is not None:
             for k in self.output_channels:
                 result['OutputChannels'].append(k.to_map() if k else None)
+        if self.role_arn is not None:
+            result['RoleArn'] = self.role_arn
         if self.scheduler is not None:
             result['Scheduler'] = self.scheduler.to_map()
         if self.training_job_description is not None:
             result['TrainingJobDescription'] = self.training_job_description
         if self.training_job_name is not None:
             result['TrainingJobName'] = self.training_job_name
         if self.workspace_id is not None:
@@ -1946,15 +2306,15 @@
             self.algorithm_provider = m.get('AlgorithmProvider')
         if m.get('AlgorithmSpec') is not None:
             temp_model = AlgorithmSpec()
             self.algorithm_spec = temp_model.from_map(m['AlgorithmSpec'])
         if m.get('AlgorithmVersion') is not None:
             self.algorithm_version = m.get('AlgorithmVersion')
         if m.get('CodeDir') is not None:
-            temp_model = CreateTrainingJobRequestCodeDir()
+            temp_model = Location()
             self.code_dir = temp_model.from_map(m['CodeDir'])
         if m.get('ComputeResource') is not None:
             temp_model = CreateTrainingJobRequestComputeResource()
             self.compute_resource = temp_model.from_map(m['ComputeResource'])
         self.hyper_parameters = []
         if m.get('HyperParameters') is not None:
             for k in m.get('HyperParameters'):
@@ -1971,14 +2331,16 @@
                 temp_model = CreateTrainingJobRequestLabels()
                 self.labels.append(temp_model.from_map(k))
         self.output_channels = []
         if m.get('OutputChannels') is not None:
             for k in m.get('OutputChannels'):
                 temp_model = CreateTrainingJobRequestOutputChannels()
                 self.output_channels.append(temp_model.from_map(k))
+        if m.get('RoleArn') is not None:
+            self.role_arn = m.get('RoleArn')
         if m.get('Scheduler') is not None:
             temp_model = CreateTrainingJobRequestScheduler()
             self.scheduler = temp_model.from_map(m['Scheduler'])
         if m.get('TrainingJobDescription') is not None:
             self.training_job_description = m.get('TrainingJobDescription')
         if m.get('TrainingJobName') is not None:
             self.training_job_name = m.get('TrainingJobName')
@@ -2060,156 +2422,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = CreateTrainingJobResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class DeleteAlgorithmResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-    ):
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
-        return self
-
-
-class DeleteAlgorithmResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: DeleteAlgorithmResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = DeleteAlgorithmResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class DeleteAlgorithmVersionResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-    ):
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class DeleteAlgorithmVersionResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: DeleteAlgorithmVersionResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = DeleteAlgorithmVersionResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class DeleteMachineGroupResponseBody(TeaModel):
     def __init__(
         self,
         machine_group_id: str = None,
         request_id: str = None,
     ):
         self.machine_group_id = machine_group_id
@@ -2433,201 +2653,34 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = DeleteResourceGroupMachineGroupResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class DeleteTrainingJobResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-    ):
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class DeleteTrainingJobResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: DeleteTrainingJobResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = DeleteTrainingJobResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class DeleteTrainingJobLabelsRequest(TeaModel):
-    def __init__(
-        self,
-        keys: str = None,
-    ):
-        self.keys = keys
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.keys is not None:
-            result['Keys'] = self.keys
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Keys') is not None:
-            self.keys = m.get('Keys')
-        return self
-
-
-class DeleteTrainingJobLabelsResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-    ):
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class DeleteTrainingJobLabelsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: DeleteTrainingJobLabelsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = DeleteTrainingJobLabelsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class GetAlgorithmResponseBody(TeaModel):
     def __init__(
         self,
         algorithm_description: str = None,
         algorithm_id: str = None,
         algorithm_name: str = None,
         algorithm_provider: str = None,
+        display_name: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         request_id: str = None,
         tenant_id: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
         self.algorithm_description = algorithm_description
         self.algorithm_id = algorithm_id
         self.algorithm_name = algorithm_name
         self.algorithm_provider = algorithm_provider
+        self.display_name = display_name
         self.gmt_create_time = gmt_create_time
         self.gmt_modified_time = gmt_modified_time
         self.request_id = request_id
         self.tenant_id = tenant_id
         self.user_id = user_id
         self.workspace_id = workspace_id
 
@@ -2644,14 +2697,16 @@
             result['AlgorithmDescription'] = self.algorithm_description
         if self.algorithm_id is not None:
             result['AlgorithmId'] = self.algorithm_id
         if self.algorithm_name is not None:
             result['AlgorithmName'] = self.algorithm_name
         if self.algorithm_provider is not None:
             result['AlgorithmProvider'] = self.algorithm_provider
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.request_id is not None:
             result['RequestId'] = self.request_id
         if self.tenant_id is not None:
@@ -2668,14 +2723,16 @@
             self.algorithm_description = m.get('AlgorithmDescription')
         if m.get('AlgorithmId') is not None:
             self.algorithm_id = m.get('AlgorithmId')
         if m.get('AlgorithmName') is not None:
             self.algorithm_name = m.get('AlgorithmName')
         if m.get('AlgorithmProvider') is not None:
             self.algorithm_provider = m.get('AlgorithmProvider')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
         if m.get('TenantId') is not None:
@@ -2848,293 +2905,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = GetAlgorithmVersionResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class GetJobViewMetricsRequest(TeaModel):
-    def __init__(
-        self,
-        end_time: str = None,
-        page_number: int = None,
-        page_size: int = None,
-        sort_by: str = None,
-        start_time: str = None,
-        time_step: str = None,
-        workspace_id: str = None,
-    ):
-        self.end_time = end_time
-        self.page_number = page_number
-        self.page_size = page_size
-        self.sort_by = sort_by
-        self.start_time = start_time
-        self.time_step = time_step
-        self.workspace_id = workspace_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.end_time is not None:
-            result['EndTime'] = self.end_time
-        if self.page_number is not None:
-            result['PageNumber'] = self.page_number
-        if self.page_size is not None:
-            result['PageSize'] = self.page_size
-        if self.sort_by is not None:
-            result['SortBy'] = self.sort_by
-        if self.start_time is not None:
-            result['StartTime'] = self.start_time
-        if self.time_step is not None:
-            result['TimeStep'] = self.time_step
-        if self.workspace_id is not None:
-            result['WorkspaceId'] = self.workspace_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('EndTime') is not None:
-            self.end_time = m.get('EndTime')
-        if m.get('PageNumber') is not None:
-            self.page_number = m.get('PageNumber')
-        if m.get('PageSize') is not None:
-            self.page_size = m.get('PageSize')
-        if m.get('SortBy') is not None:
-            self.sort_by = m.get('SortBy')
-        if m.get('StartTime') is not None:
-            self.start_time = m.get('StartTime')
-        if m.get('TimeStep') is not None:
-            self.time_step = m.get('TimeStep')
-        if m.get('WorkspaceId') is not None:
-            self.workspace_id = m.get('WorkspaceId')
-        return self
-
-
-class GetJobViewMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        job_metrics: List[JobViewMetric] = None,
-        request_id: str = None,
-        summary: JobViewMetric = None,
-        total: int = None,
-    ):
-        self.job_metrics = job_metrics
-        self.request_id = request_id
-        self.summary = summary
-        self.total = total
-
-    def validate(self):
-        if self.job_metrics:
-            for k in self.job_metrics:
-                if k:
-                    k.validate()
-        if self.summary:
-            self.summary.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        result['JobMetrics'] = []
-        if self.job_metrics is not None:
-            for k in self.job_metrics:
-                result['JobMetrics'].append(k.to_map() if k else None)
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        if self.summary is not None:
-            result['Summary'] = self.summary.to_map()
-        if self.total is not None:
-            result['Total'] = self.total
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        self.job_metrics = []
-        if m.get('JobMetrics') is not None:
-            for k in m.get('JobMetrics'):
-                temp_model = JobViewMetric()
-                self.job_metrics.append(temp_model.from_map(k))
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        if m.get('Summary') is not None:
-            temp_model = JobViewMetric()
-            self.summary = temp_model.from_map(m['Summary'])
-        if m.get('Total') is not None:
-            self.total = m.get('Total')
-        return self
-
-
-class GetJobViewMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetJobViewMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetJobViewMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class GetJobsStatisticsByResourceGroupRequest(TeaModel):
-    def __init__(
-        self,
-        end_time: str = None,
-        start_time: str = None,
-        workspace_id: str = None,
-    ):
-        self.end_time = end_time
-        self.start_time = start_time
-        self.workspace_id = workspace_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.end_time is not None:
-            result['EndTime'] = self.end_time
-        if self.start_time is not None:
-            result['StartTime'] = self.start_time
-        if self.workspace_id is not None:
-            result['WorkspaceID'] = self.workspace_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('EndTime') is not None:
-            self.end_time = m.get('EndTime')
-        if m.get('StartTime') is not None:
-            self.start_time = m.get('StartTime')
-        if m.get('WorkspaceID') is not None:
-            self.workspace_id = m.get('WorkspaceID')
-        return self
-
-
-class GetJobsStatisticsByResourceGroupResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-        statistics: Dict[str, Any] = None,
-    ):
-        self.request_id = request_id
-        self.statistics = statistics
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        if self.statistics is not None:
-            result['Statistics'] = self.statistics
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        if m.get('Statistics') is not None:
-            self.statistics = m.get('Statistics')
-        return self
-
-
-class GetJobsStatisticsByResourceGroupResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetJobsStatisticsByResourceGroupResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetJobsStatisticsByResourceGroupResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class GetMachineGroupResponseBody(TeaModel):
     def __init__(
         self,
         count: int = None,
         duration: str = None,
         ecs_type: str = None,
         gmt_created: str = None,
@@ -3424,376 +3202,128 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = GetNodeMetricsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class GetNodeViewMetricsRequest(TeaModel):
+class GetResourceGroupRequest(TeaModel):
     def __init__(
         self,
-        node_id: str = None,
-        page_number: int = None,
-        page_size: int = None,
-        time_step: str = None,
-        workspace_id: str = None,
+        is_aiworkspace_data_enabled: bool = None,
     ):
-        self.node_id = node_id
-        self.page_number = page_number
-        self.page_size = page_size
-        self.time_step = time_step
-        self.workspace_id = workspace_id
+        self.is_aiworkspace_data_enabled = is_aiworkspace_data_enabled
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
-        if self.node_id is not None:
-            result['NodeId'] = self.node_id
-        if self.page_number is not None:
-            result['PageNumber'] = self.page_number
-        if self.page_size is not None:
-            result['PageSize'] = self.page_size
-        if self.time_step is not None:
-            result['TimeStep'] = self.time_step
-        if self.workspace_id is not None:
-            result['WorkspaceId'] = self.workspace_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('NodeId') is not None:
-            self.node_id = m.get('NodeId')
-        if m.get('PageNumber') is not None:
-            self.page_number = m.get('PageNumber')
-        if m.get('PageSize') is not None:
-            self.page_size = m.get('PageSize')
-        if m.get('TimeStep') is not None:
-            self.time_step = m.get('TimeStep')
-        if m.get('WorkspaceId') is not None:
-            self.workspace_id = m.get('WorkspaceId')
-        return self
-
-
-class GetNodeViewMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        node_metrics: List[NodeViewMetric] = None,
-        total: int = None,
-    ):
-        self.node_metrics = node_metrics
-        self.total = total
-
-    def validate(self):
-        if self.node_metrics:
-            for k in self.node_metrics:
-                if k:
-                    k.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        result['NodeMetrics'] = []
-        if self.node_metrics is not None:
-            for k in self.node_metrics:
-                result['NodeMetrics'].append(k.to_map() if k else None)
-        if self.total is not None:
-            result['Total'] = self.total
+        if self.is_aiworkspace_data_enabled is not None:
+            result['IsAIWorkspaceDataEnabled'] = self.is_aiworkspace_data_enabled
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
-        self.node_metrics = []
-        if m.get('NodeMetrics') is not None:
-            for k in m.get('NodeMetrics'):
-                temp_model = NodeViewMetric()
-                self.node_metrics.append(temp_model.from_map(k))
-        if m.get('Total') is not None:
-            self.total = m.get('Total')
-        return self
-
-
-class GetNodeViewMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetNodeViewMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetNodeViewMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class GetRangeUserViewMetricsRequest(TeaModel):
-    def __init__(
-        self,
-        end_time: str = None,
-        order: str = None,
-        page_number: int = None,
-        page_size: int = None,
-        sort_by: str = None,
-        start_time: str = None,
-        user_id: str = None,
-        workspace_id: str = None,
-    ):
-        self.end_time = end_time
-        self.order = order
-        self.page_number = page_number
-        self.page_size = page_size
-        self.sort_by = sort_by
-        self.start_time = start_time
-        self.user_id = user_id
-        self.workspace_id = workspace_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.end_time is not None:
-            result['EndTime'] = self.end_time
-        if self.order is not None:
-            result['Order'] = self.order
-        if self.page_number is not None:
-            result['PageNumber'] = self.page_number
-        if self.page_size is not None:
-            result['PageSize'] = self.page_size
-        if self.sort_by is not None:
-            result['SortBy'] = self.sort_by
-        if self.start_time is not None:
-            result['StartTime'] = self.start_time
-        if self.user_id is not None:
-            result['UserId'] = self.user_id
-        if self.workspace_id is not None:
-            result['WorkspaceId'] = self.workspace_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('EndTime') is not None:
-            self.end_time = m.get('EndTime')
-        if m.get('Order') is not None:
-            self.order = m.get('Order')
-        if m.get('PageNumber') is not None:
-            self.page_number = m.get('PageNumber')
-        if m.get('PageSize') is not None:
-            self.page_size = m.get('PageSize')
-        if m.get('SortBy') is not None:
-            self.sort_by = m.get('SortBy')
-        if m.get('StartTime') is not None:
-            self.start_time = m.get('StartTime')
-        if m.get('UserId') is not None:
-            self.user_id = m.get('UserId')
-        if m.get('WorkspaceId') is not None:
-            self.workspace_id = m.get('WorkspaceId')
-        return self
-
-
-class GetRangeUserViewMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        summary: UserViewMetric = None,
-        user_metrics: List[UserViewMetric] = None,
-        request_id: str = None,
-    ):
-        self.summary = summary
-        self.user_metrics = user_metrics
-        self.request_id = request_id
-
-    def validate(self):
-        if self.summary:
-            self.summary.validate()
-        if self.user_metrics:
-            for k in self.user_metrics:
-                if k:
-                    k.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.summary is not None:
-            result['Summary'] = self.summary.to_map()
-        result['UserMetrics'] = []
-        if self.user_metrics is not None:
-            for k in self.user_metrics:
-                result['UserMetrics'].append(k.to_map() if k else None)
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Summary') is not None:
-            temp_model = UserViewMetric()
-            self.summary = temp_model.from_map(m['Summary'])
-        self.user_metrics = []
-        if m.get('UserMetrics') is not None:
-            for k in m.get('UserMetrics'):
-                temp_model = UserViewMetric()
-                self.user_metrics.append(temp_model.from_map(k))
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
-        return self
-
-
-class GetRangeUserViewMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetRangeUserViewMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetRangeUserViewMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
+        if m.get('IsAIWorkspaceDataEnabled') is not None:
+            self.is_aiworkspace_data_enabled = m.get('IsAIWorkspaceDataEnabled')
         return self
 
 
 class GetResourceGroupResponseBody(TeaModel):
     def __init__(
         self,
+        cluster_id: str = None,
+        computing_resource_provider: str = None,
         creator_id: str = None,
         gmt_created_time: str = None,
         gmt_modified_time: str = None,
         name: str = None,
         request_id: str = None,
+        resource_type: str = None,
         status: str = None,
+        support_rdma: bool = None,
         user_vpc: UserVpc = None,
         workspace_id: str = None,
     ):
+        self.cluster_id = cluster_id
+        self.computing_resource_provider = computing_resource_provider
         self.creator_id = creator_id
         self.gmt_created_time = gmt_created_time
         self.gmt_modified_time = gmt_modified_time
         self.name = name
         self.request_id = request_id
+        self.resource_type = resource_type
         self.status = status
+        self.support_rdma = support_rdma
         self.user_vpc = user_vpc
         self.workspace_id = workspace_id
 
     def validate(self):
         if self.user_vpc:
             self.user_vpc.validate()
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.cluster_id is not None:
+            result['ClusterID'] = self.cluster_id
+        if self.computing_resource_provider is not None:
+            result['ComputingResourceProvider'] = self.computing_resource_provider
         if self.creator_id is not None:
             result['CreatorID'] = self.creator_id
         if self.gmt_created_time is not None:
             result['GmtCreatedTime'] = self.gmt_created_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.name is not None:
             result['Name'] = self.name
         if self.request_id is not None:
             result['RequestId'] = self.request_id
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         if self.status is not None:
             result['Status'] = self.status
+        if self.support_rdma is not None:
+            result['SupportRDMA'] = self.support_rdma
         if self.user_vpc is not None:
             result['UserVpc'] = self.user_vpc.to_map()
         if self.workspace_id is not None:
             result['WorkspaceID'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ClusterID') is not None:
+            self.cluster_id = m.get('ClusterID')
+        if m.get('ComputingResourceProvider') is not None:
+            self.computing_resource_provider = m.get('ComputingResourceProvider')
         if m.get('CreatorID') is not None:
             self.creator_id = m.get('CreatorID')
         if m.get('GmtCreatedTime') is not None:
             self.gmt_created_time = m.get('GmtCreatedTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         if m.get('Status') is not None:
             self.status = m.get('Status')
+        if m.get('SupportRDMA') is not None:
+            self.support_rdma = m.get('SupportRDMA')
         if m.get('UserVpc') is not None:
             temp_model = UserVpc()
             self.user_vpc = temp_model.from_map(m['UserVpc'])
         if m.get('WorkspaceID') is not None:
             self.workspace_id = m.get('WorkspaceID')
         return self
 
@@ -4005,150 +3535,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = GetResourceGroupMachineGroupResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class GetResourceGroupMetricsRequest(TeaModel):
-    def __init__(
-        self,
-        end_time: str = None,
-        gputype: str = None,
-        start_time: str = None,
-        time_step: str = None,
-    ):
-        self.end_time = end_time
-        self.gputype = gputype
-        self.start_time = start_time
-        self.time_step = time_step
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.end_time is not None:
-            result['EndTime'] = self.end_time
-        if self.gputype is not None:
-            result['GPUType'] = self.gputype
-        if self.start_time is not None:
-            result['StartTime'] = self.start_time
-        if self.time_step is not None:
-            result['TimeStep'] = self.time_step
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('EndTime') is not None:
-            self.end_time = m.get('EndTime')
-        if m.get('GPUType') is not None:
-            self.gputype = m.get('GPUType')
-        if m.get('StartTime') is not None:
-            self.start_time = m.get('StartTime')
-        if m.get('TimeStep') is not None:
-            self.time_step = m.get('TimeStep')
-        return self
-
-
-class GetResourceGroupMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-        resource_group_id: str = None,
-        resource_group_metrics: List[ResourceGroupMetric] = None,
-    ):
-        self.request_id = request_id
-        self.resource_group_id = resource_group_id
-        self.resource_group_metrics = resource_group_metrics
-
-    def validate(self):
-        if self.resource_group_metrics:
-            for k in self.resource_group_metrics:
-                if k:
-                    k.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        if self.resource_group_id is not None:
-            result['ResourceGroupID'] = self.resource_group_id
-        result['ResourceGroupMetrics'] = []
-        if self.resource_group_metrics is not None:
-            for k in self.resource_group_metrics:
-                result['ResourceGroupMetrics'].append(k.to_map() if k else None)
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        if m.get('ResourceGroupID') is not None:
-            self.resource_group_id = m.get('ResourceGroupID')
-        self.resource_group_metrics = []
-        if m.get('ResourceGroupMetrics') is not None:
-            for k in m.get('ResourceGroupMetrics'):
-                temp_model = ResourceGroupMetric()
-                self.resource_group_metrics.append(temp_model.from_map(k))
-        return self
-
-
-class GetResourceGroupMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetResourceGroupMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetResourceGroupMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class GetResourceGroupRequestRequest(TeaModel):
     def __init__(
         self,
         pod_status: str = None,
         resource_group_id: str = None,
     ):
         self.pod_status = pod_status
@@ -4734,64 +4128,72 @@
 
 class GetTrainingJobResponseBody(TeaModel):
     def __init__(
         self,
         algorithm_id: str = None,
         algorithm_name: str = None,
         algorithm_provider: str = None,
+        algorithm_spec: AlgorithmSpec = None,
         algorithm_version: str = None,
         compute_resource: GetTrainingJobResponseBodyComputeResource = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         hyper_parameters: List[GetTrainingJobResponseBodyHyperParameters] = None,
         input_channels: List[GetTrainingJobResponseBodyInputChannels] = None,
         instances: List[GetTrainingJobResponseBodyInstances] = None,
+        is_temp_algo: bool = None,
         labels: List[GetTrainingJobResponseBodyLabels] = None,
         latest_metrics: List[GetTrainingJobResponseBodyLatestMetrics] = None,
         output_channels: List[GetTrainingJobResponseBodyOutputChannels] = None,
         reason_code: str = None,
         reason_message: str = None,
         request_id: str = None,
+        role_arn: str = None,
         scheduler: GetTrainingJobResponseBodyScheduler = None,
         status: str = None,
         status_transitions: List[GetTrainingJobResponseBodyStatusTransitions] = None,
         training_job_description: str = None,
         training_job_id: str = None,
         training_job_name: str = None,
         training_job_url: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
         self.algorithm_id = algorithm_id
         self.algorithm_name = algorithm_name
         self.algorithm_provider = algorithm_provider
+        self.algorithm_spec = algorithm_spec
         self.algorithm_version = algorithm_version
         self.compute_resource = compute_resource
         self.gmt_create_time = gmt_create_time
         self.gmt_modified_time = gmt_modified_time
         self.hyper_parameters = hyper_parameters
         self.input_channels = input_channels
         self.instances = instances
+        self.is_temp_algo = is_temp_algo
         self.labels = labels
         self.latest_metrics = latest_metrics
         self.output_channels = output_channels
         self.reason_code = reason_code
         self.reason_message = reason_message
         self.request_id = request_id
+        self.role_arn = role_arn
         self.scheduler = scheduler
         self.status = status
         self.status_transitions = status_transitions
         self.training_job_description = training_job_description
         self.training_job_id = training_job_id
         self.training_job_name = training_job_name
         self.training_job_url = training_job_url
         self.user_id = user_id
         self.workspace_id = workspace_id
 
     def validate(self):
+        if self.algorithm_spec:
+            self.algorithm_spec.validate()
         if self.compute_resource:
             self.compute_resource.validate()
         if self.hyper_parameters:
             for k in self.hyper_parameters:
                 if k:
                     k.validate()
         if self.input_channels:
@@ -4829,14 +4231,16 @@
         result = dict()
         if self.algorithm_id is not None:
             result['AlgorithmId'] = self.algorithm_id
         if self.algorithm_name is not None:
             result['AlgorithmName'] = self.algorithm_name
         if self.algorithm_provider is not None:
             result['AlgorithmProvider'] = self.algorithm_provider
+        if self.algorithm_spec is not None:
+            result['AlgorithmSpec'] = self.algorithm_spec.to_map()
         if self.algorithm_version is not None:
             result['AlgorithmVersion'] = self.algorithm_version
         if self.compute_resource is not None:
             result['ComputeResource'] = self.compute_resource.to_map()
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
@@ -4849,14 +4253,16 @@
         if self.input_channels is not None:
             for k in self.input_channels:
                 result['InputChannels'].append(k.to_map() if k else None)
         result['Instances'] = []
         if self.instances is not None:
             for k in self.instances:
                 result['Instances'].append(k.to_map() if k else None)
+        if self.is_temp_algo is not None:
+            result['IsTempAlgo'] = self.is_temp_algo
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         result['LatestMetrics'] = []
         if self.latest_metrics is not None:
             for k in self.latest_metrics:
@@ -4867,14 +4273,16 @@
                 result['OutputChannels'].append(k.to_map() if k else None)
         if self.reason_code is not None:
             result['ReasonCode'] = self.reason_code
         if self.reason_message is not None:
             result['ReasonMessage'] = self.reason_message
         if self.request_id is not None:
             result['RequestId'] = self.request_id
+        if self.role_arn is not None:
+            result['RoleArn'] = self.role_arn
         if self.scheduler is not None:
             result['Scheduler'] = self.scheduler.to_map()
         if self.status is not None:
             result['Status'] = self.status
         result['StatusTransitions'] = []
         if self.status_transitions is not None:
             for k in self.status_transitions:
@@ -4897,14 +4305,17 @@
         m = m or dict()
         if m.get('AlgorithmId') is not None:
             self.algorithm_id = m.get('AlgorithmId')
         if m.get('AlgorithmName') is not None:
             self.algorithm_name = m.get('AlgorithmName')
         if m.get('AlgorithmProvider') is not None:
             self.algorithm_provider = m.get('AlgorithmProvider')
+        if m.get('AlgorithmSpec') is not None:
+            temp_model = AlgorithmSpec()
+            self.algorithm_spec = temp_model.from_map(m['AlgorithmSpec'])
         if m.get('AlgorithmVersion') is not None:
             self.algorithm_version = m.get('AlgorithmVersion')
         if m.get('ComputeResource') is not None:
             temp_model = GetTrainingJobResponseBodyComputeResource()
             self.compute_resource = temp_model.from_map(m['ComputeResource'])
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
@@ -4921,14 +4332,16 @@
                 temp_model = GetTrainingJobResponseBodyInputChannels()
                 self.input_channels.append(temp_model.from_map(k))
         self.instances = []
         if m.get('Instances') is not None:
             for k in m.get('Instances'):
                 temp_model = GetTrainingJobResponseBodyInstances()
                 self.instances.append(temp_model.from_map(k))
+        if m.get('IsTempAlgo') is not None:
+            self.is_temp_algo = m.get('IsTempAlgo')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = GetTrainingJobResponseBodyLabels()
                 self.labels.append(temp_model.from_map(k))
         self.latest_metrics = []
         if m.get('LatestMetrics') is not None:
@@ -4942,14 +4355,16 @@
                 self.output_channels.append(temp_model.from_map(k))
         if m.get('ReasonCode') is not None:
             self.reason_code = m.get('ReasonCode')
         if m.get('ReasonMessage') is not None:
             self.reason_message = m.get('ReasonMessage')
         if m.get('RequestId') is not None:
             self.request_id = m.get('RequestId')
+        if m.get('RoleArn') is not None:
+            self.role_arn = m.get('RoleArn')
         if m.get('Scheduler') is not None:
             temp_model = GetTrainingJobResponseBodyScheduler()
             self.scheduler = temp_model.from_map(m['Scheduler'])
         if m.get('Status') is not None:
             self.status = m.get('Status')
         self.status_transitions = []
         if m.get('StatusTransitions') is not None:
@@ -5011,165 +4426,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = GetTrainingJobResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class GetTrainingJobLatestMetricsRequest(TeaModel):
-    def __init__(
-        self,
-        names: str = None,
-    ):
-        self.names = names
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.names is not None:
-            result['Names'] = self.names
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Names') is not None:
-            self.names = m.get('Names')
-        return self
-
-
-class GetTrainingJobLatestMetricsResponseBodyMetrics(TeaModel):
-    def __init__(
-        self,
-        name: str = None,
-        timestamp: str = None,
-        value: float = None,
-    ):
-        self.name = name
-        self.timestamp = timestamp
-        self.value = value
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.name is not None:
-            result['Name'] = self.name
-        if self.timestamp is not None:
-            result['Timestamp'] = self.timestamp
-        if self.value is not None:
-            result['Value'] = self.value
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Name') is not None:
-            self.name = m.get('Name')
-        if m.get('Timestamp') is not None:
-            self.timestamp = m.get('Timestamp')
-        if m.get('Value') is not None:
-            self.value = m.get('Value')
-        return self
-
-
-class GetTrainingJobLatestMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        metrics: List[GetTrainingJobLatestMetricsResponseBodyMetrics] = None,
-        request_id: str = None,
-    ):
-        self.metrics = metrics
-        self.request_id = request_id
-
-    def validate(self):
-        if self.metrics:
-            for k in self.metrics:
-                if k:
-                    k.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        result['Metrics'] = []
-        if self.metrics is not None:
-            for k in self.metrics:
-                result['Metrics'].append(k.to_map() if k else None)
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        self.metrics = []
-        if m.get('Metrics') is not None:
-            for k in m.get('Metrics'):
-                temp_model = GetTrainingJobLatestMetricsResponseBodyMetrics()
-                self.metrics.append(temp_model.from_map(k))
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class GetTrainingJobLatestMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: GetTrainingJobLatestMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = GetTrainingJobLatestMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class GetUserViewMetricsRequest(TeaModel):
     def __init__(
         self,
         order: str = None,
         page_number: str = None,
         page_size: str = None,
         sort_by: str = None,
@@ -5582,23 +4846,25 @@
 class ListAlgorithmsResponseBodyAlgorithms(TeaModel):
     def __init__(
         self,
         algorithm_description: str = None,
         algorithm_id: str = None,
         algorithm_name: str = None,
         algorithm_provider: str = None,
+        display_name: str = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         user_id: str = None,
         workspace_id: str = None,
     ):
         self.algorithm_description = algorithm_description
         self.algorithm_id = algorithm_id
         self.algorithm_name = algorithm_name
         self.algorithm_provider = algorithm_provider
+        self.display_name = display_name
         self.gmt_create_time = gmt_create_time
         self.gmt_modified_time = gmt_modified_time
         self.user_id = user_id
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
@@ -5613,14 +4879,16 @@
             result['AlgorithmDescription'] = self.algorithm_description
         if self.algorithm_id is not None:
             result['AlgorithmId'] = self.algorithm_id
         if self.algorithm_name is not None:
             result['AlgorithmName'] = self.algorithm_name
         if self.algorithm_provider is not None:
             result['AlgorithmProvider'] = self.algorithm_provider
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         if self.gmt_create_time is not None:
             result['GmtCreateTime'] = self.gmt_create_time
         if self.gmt_modified_time is not None:
             result['GmtModifiedTime'] = self.gmt_modified_time
         if self.user_id is not None:
             result['UserId'] = self.user_id
         if self.workspace_id is not None:
@@ -5633,14 +4901,16 @@
             self.algorithm_description = m.get('AlgorithmDescription')
         if m.get('AlgorithmId') is not None:
             self.algorithm_id = m.get('AlgorithmId')
         if m.get('AlgorithmName') is not None:
             self.algorithm_name = m.get('AlgorithmName')
         if m.get('AlgorithmProvider') is not None:
             self.algorithm_provider = m.get('AlgorithmProvider')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         if m.get('GmtCreateTime') is not None:
             self.gmt_create_time = m.get('GmtCreateTime')
         if m.get('GmtModifiedTime') is not None:
             self.gmt_modified_time = m.get('GmtModifiedTime')
         if m.get('UserId') is not None:
             self.user_id = m.get('UserId')
         if m.get('WorkspaceId') is not None:
@@ -5916,65 +5186,77 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class ListResourceGroupsRequest(TeaModel):
     def __init__(
         self,
+        computing_resource_provider: str = None,
         name: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
+        resource_type: str = None,
         show_all: bool = None,
         sort_by: str = None,
         status: str = None,
     ):
+        self.computing_resource_provider = computing_resource_provider
         self.name = name
         self.order = order
         self.page_number = page_number
         self.page_size = page_size
+        self.resource_type = resource_type
         self.show_all = show_all
         self.sort_by = sort_by
         self.status = status
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.computing_resource_provider is not None:
+            result['ComputingResourceProvider'] = self.computing_resource_provider
         if self.name is not None:
             result['Name'] = self.name
         if self.order is not None:
             result['Order'] = self.order
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
+        if self.resource_type is not None:
+            result['ResourceType'] = self.resource_type
         if self.show_all is not None:
             result['ShowAll'] = self.show_all
         if self.sort_by is not None:
             result['SortBy'] = self.sort_by
         if self.status is not None:
             result['Status'] = self.status
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('ComputingResourceProvider') is not None:
+            self.computing_resource_provider = m.get('ComputingResourceProvider')
         if m.get('Name') is not None:
             self.name = m.get('Name')
         if m.get('Order') is not None:
             self.order = m.get('Order')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
+        if m.get('ResourceType') is not None:
+            self.resource_type = m.get('ResourceType')
         if m.get('ShowAll') is not None:
             self.show_all = m.get('ShowAll')
         if m.get('SortBy') is not None:
             self.sort_by = m.get('SortBy')
         if m.get('Status') is not None:
             self.status = m.get('Status')
         return self
@@ -6067,183 +5349,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = ListResourceGroupsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class ListTrainingJobInstanceMetricsRequest(TeaModel):
-    def __init__(
-        self,
-        end_time: str = None,
-        instance_id: str = None,
-        metric_type: str = None,
-        start_time: str = None,
-        time_step: str = None,
-    ):
-        self.end_time = end_time
-        self.instance_id = instance_id
-        self.metric_type = metric_type
-        self.start_time = start_time
-        self.time_step = time_step
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.end_time is not None:
-            result['EndTime'] = self.end_time
-        if self.instance_id is not None:
-            result['InstanceId'] = self.instance_id
-        if self.metric_type is not None:
-            result['MetricType'] = self.metric_type
-        if self.start_time is not None:
-            result['StartTime'] = self.start_time
-        if self.time_step is not None:
-            result['TimeStep'] = self.time_step
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('EndTime') is not None:
-            self.end_time = m.get('EndTime')
-        if m.get('InstanceId') is not None:
-            self.instance_id = m.get('InstanceId')
-        if m.get('MetricType') is not None:
-            self.metric_type = m.get('MetricType')
-        if m.get('StartTime') is not None:
-            self.start_time = m.get('StartTime')
-        if m.get('TimeStep') is not None:
-            self.time_step = m.get('TimeStep')
-        return self
-
-
-class ListTrainingJobInstanceMetricsResponseBodyMetrics(TeaModel):
-    def __init__(
-        self,
-        timestamp: str = None,
-        value: float = None,
-    ):
-        self.timestamp = timestamp
-        self.value = value
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.timestamp is not None:
-            result['Timestamp'] = self.timestamp
-        if self.value is not None:
-            result['Value'] = self.value
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('Timestamp') is not None:
-            self.timestamp = m.get('Timestamp')
-        if m.get('Value') is not None:
-            self.value = m.get('Value')
-        return self
-
-
-class ListTrainingJobInstanceMetricsResponseBody(TeaModel):
-    def __init__(
-        self,
-        metrics: List[ListTrainingJobInstanceMetricsResponseBodyMetrics] = None,
-        request_id: str = None,
-    ):
-        self.metrics = metrics
-        self.request_id = request_id
-
-    def validate(self):
-        if self.metrics:
-            for k in self.metrics:
-                if k:
-                    k.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        result['Metrics'] = []
-        if self.metrics is not None:
-            for k in self.metrics:
-                result['Metrics'].append(k.to_map() if k else None)
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        self.metrics = []
-        if m.get('Metrics') is not None:
-            for k in m.get('Metrics'):
-                temp_model = ListTrainingJobInstanceMetricsResponseBodyMetrics()
-                self.metrics.append(temp_model.from_map(k))
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class ListTrainingJobInstanceMetricsResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: ListTrainingJobInstanceMetricsResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = ListTrainingJobInstanceMetricsResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class ListTrainingJobLogsRequest(TeaModel):
     def __init__(
         self,
         end_time: str = None,
         page_number: int = None,
         page_size: int = None,
         start_time: str = None,
@@ -6554,67 +5667,214 @@
             self.body = temp_model.from_map(m['body'])
         return self
 
 
 class ListTrainingJobsRequest(TeaModel):
     def __init__(
         self,
+        algorithm_name: str = None,
+        algorithm_provider: str = None,
+        end_time: str = None,
+        is_temp_algo: bool = None,
+        labels: Dict[str, Any] = None,
+        order: str = None,
+        page_number: int = None,
+        page_size: int = None,
+        sort_by: str = None,
+        start_time: str = None,
+        status: str = None,
+        training_job_id: str = None,
+        training_job_name: str = None,
+        workspace_id: str = None,
+    ):
+        self.algorithm_name = algorithm_name
+        self.algorithm_provider = algorithm_provider
+        self.end_time = end_time
+        self.is_temp_algo = is_temp_algo
+        self.labels = labels
+        self.order = order
+        self.page_number = page_number
+        self.page_size = page_size
+        self.sort_by = sort_by
+        self.start_time = start_time
+        self.status = status
+        self.training_job_id = training_job_id
+        self.training_job_name = training_job_name
+        self.workspace_id = workspace_id
+
+    def validate(self):
+        pass
+
+    def to_map(self):
+        _map = super().to_map()
+        if _map is not None:
+            return _map
+
+        result = dict()
+        if self.algorithm_name is not None:
+            result['AlgorithmName'] = self.algorithm_name
+        if self.algorithm_provider is not None:
+            result['AlgorithmProvider'] = self.algorithm_provider
+        if self.end_time is not None:
+            result['EndTime'] = self.end_time
+        if self.is_temp_algo is not None:
+            result['IsTempAlgo'] = self.is_temp_algo
+        if self.labels is not None:
+            result['Labels'] = self.labels
+        if self.order is not None:
+            result['Order'] = self.order
+        if self.page_number is not None:
+            result['PageNumber'] = self.page_number
+        if self.page_size is not None:
+            result['PageSize'] = self.page_size
+        if self.sort_by is not None:
+            result['SortBy'] = self.sort_by
+        if self.start_time is not None:
+            result['StartTime'] = self.start_time
+        if self.status is not None:
+            result['Status'] = self.status
+        if self.training_job_id is not None:
+            result['TrainingJobId'] = self.training_job_id
+        if self.training_job_name is not None:
+            result['TrainingJobName'] = self.training_job_name
+        if self.workspace_id is not None:
+            result['WorkspaceId'] = self.workspace_id
+        return result
+
+    def from_map(self, m: dict = None):
+        m = m or dict()
+        if m.get('AlgorithmName') is not None:
+            self.algorithm_name = m.get('AlgorithmName')
+        if m.get('AlgorithmProvider') is not None:
+            self.algorithm_provider = m.get('AlgorithmProvider')
+        if m.get('EndTime') is not None:
+            self.end_time = m.get('EndTime')
+        if m.get('IsTempAlgo') is not None:
+            self.is_temp_algo = m.get('IsTempAlgo')
+        if m.get('Labels') is not None:
+            self.labels = m.get('Labels')
+        if m.get('Order') is not None:
+            self.order = m.get('Order')
+        if m.get('PageNumber') is not None:
+            self.page_number = m.get('PageNumber')
+        if m.get('PageSize') is not None:
+            self.page_size = m.get('PageSize')
+        if m.get('SortBy') is not None:
+            self.sort_by = m.get('SortBy')
+        if m.get('StartTime') is not None:
+            self.start_time = m.get('StartTime')
+        if m.get('Status') is not None:
+            self.status = m.get('Status')
+        if m.get('TrainingJobId') is not None:
+            self.training_job_id = m.get('TrainingJobId')
+        if m.get('TrainingJobName') is not None:
+            self.training_job_name = m.get('TrainingJobName')
+        if m.get('WorkspaceId') is not None:
+            self.workspace_id = m.get('WorkspaceId')
+        return self
+
+
+class ListTrainingJobsShrinkRequest(TeaModel):
+    def __init__(
+        self,
+        algorithm_name: str = None,
+        algorithm_provider: str = None,
+        end_time: str = None,
+        is_temp_algo: bool = None,
+        labels_shrink: str = None,
         order: str = None,
         page_number: int = None,
         page_size: int = None,
         sort_by: str = None,
+        start_time: str = None,
         status: str = None,
+        training_job_id: str = None,
         training_job_name: str = None,
         workspace_id: str = None,
     ):
+        self.algorithm_name = algorithm_name
+        self.algorithm_provider = algorithm_provider
+        self.end_time = end_time
+        self.is_temp_algo = is_temp_algo
+        self.labels_shrink = labels_shrink
         self.order = order
         self.page_number = page_number
         self.page_size = page_size
         self.sort_by = sort_by
+        self.start_time = start_time
         self.status = status
+        self.training_job_id = training_job_id
         self.training_job_name = training_job_name
         self.workspace_id = workspace_id
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
+        if self.algorithm_name is not None:
+            result['AlgorithmName'] = self.algorithm_name
+        if self.algorithm_provider is not None:
+            result['AlgorithmProvider'] = self.algorithm_provider
+        if self.end_time is not None:
+            result['EndTime'] = self.end_time
+        if self.is_temp_algo is not None:
+            result['IsTempAlgo'] = self.is_temp_algo
+        if self.labels_shrink is not None:
+            result['Labels'] = self.labels_shrink
         if self.order is not None:
             result['Order'] = self.order
         if self.page_number is not None:
             result['PageNumber'] = self.page_number
         if self.page_size is not None:
             result['PageSize'] = self.page_size
         if self.sort_by is not None:
             result['SortBy'] = self.sort_by
+        if self.start_time is not None:
+            result['StartTime'] = self.start_time
         if self.status is not None:
             result['Status'] = self.status
+        if self.training_job_id is not None:
+            result['TrainingJobId'] = self.training_job_id
         if self.training_job_name is not None:
             result['TrainingJobName'] = self.training_job_name
         if self.workspace_id is not None:
             result['WorkspaceId'] = self.workspace_id
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
+        if m.get('AlgorithmName') is not None:
+            self.algorithm_name = m.get('AlgorithmName')
+        if m.get('AlgorithmProvider') is not None:
+            self.algorithm_provider = m.get('AlgorithmProvider')
+        if m.get('EndTime') is not None:
+            self.end_time = m.get('EndTime')
+        if m.get('IsTempAlgo') is not None:
+            self.is_temp_algo = m.get('IsTempAlgo')
+        if m.get('Labels') is not None:
+            self.labels_shrink = m.get('Labels')
         if m.get('Order') is not None:
             self.order = m.get('Order')
         if m.get('PageNumber') is not None:
             self.page_number = m.get('PageNumber')
         if m.get('PageSize') is not None:
             self.page_size = m.get('PageSize')
         if m.get('SortBy') is not None:
             self.sort_by = m.get('SortBy')
+        if m.get('StartTime') is not None:
+            self.start_time = m.get('StartTime')
         if m.get('Status') is not None:
             self.status = m.get('Status')
+        if m.get('TrainingJobId') is not None:
+            self.training_job_id = m.get('TrainingJobId')
         if m.get('TrainingJobName') is not None:
             self.training_job_name = m.get('TrainingJobName')
         if m.get('WorkspaceId') is not None:
             self.workspace_id = m.get('WorkspaceId')
         return self
 
 
@@ -6880,18 +6140,20 @@
         algorithm_provider: str = None,
         algorithm_version: str = None,
         compute_resource: ListTrainingJobsResponseBodyTrainingJobsComputeResource = None,
         gmt_create_time: str = None,
         gmt_modified_time: str = None,
         hyper_parameters: List[ListTrainingJobsResponseBodyTrainingJobsHyperParameters] = None,
         input_channels: List[ListTrainingJobsResponseBodyTrainingJobsInputChannels] = None,
+        is_temp_algo: bool = None,
         labels: List[ListTrainingJobsResponseBodyTrainingJobsLabels] = None,
         output_channels: List[ListTrainingJobsResponseBodyTrainingJobsOutputChannels] = None,
         reason_code: str = None,
         reason_message: str = None,
+        role_arn: str = None,
         scheduler: ListTrainingJobsResponseBodyTrainingJobsScheduler = None,
         status: str = None,
         status_transitions: List[ListTrainingJobsResponseBodyTrainingJobsStatusTransitions] = None,
         training_job_description: str = None,
         training_job_id: str = None,
         training_job_name: str = None,
         user_id: str = None,
@@ -6901,18 +6163,20 @@
         self.algorithm_provider = algorithm_provider
         self.algorithm_version = algorithm_version
         self.compute_resource = compute_resource
         self.gmt_create_time = gmt_create_time
         self.gmt_modified_time = gmt_modified_time
         self.hyper_parameters = hyper_parameters
         self.input_channels = input_channels
+        self.is_temp_algo = is_temp_algo
         self.labels = labels
         self.output_channels = output_channels
         self.reason_code = reason_code
         self.reason_message = reason_message
+        self.role_arn = role_arn
         self.scheduler = scheduler
         self.status = status
         self.status_transitions = status_transitions
         self.training_job_description = training_job_description
         self.training_job_id = training_job_id
         self.training_job_name = training_job_name
         self.user_id = user_id
@@ -6966,26 +6230,30 @@
         if self.hyper_parameters is not None:
             for k in self.hyper_parameters:
                 result['HyperParameters'].append(k.to_map() if k else None)
         result['InputChannels'] = []
         if self.input_channels is not None:
             for k in self.input_channels:
                 result['InputChannels'].append(k.to_map() if k else None)
+        if self.is_temp_algo is not None:
+            result['IsTempAlgo'] = self.is_temp_algo
         result['Labels'] = []
         if self.labels is not None:
             for k in self.labels:
                 result['Labels'].append(k.to_map() if k else None)
         result['OutputChannels'] = []
         if self.output_channels is not None:
             for k in self.output_channels:
                 result['OutputChannels'].append(k.to_map() if k else None)
         if self.reason_code is not None:
             result['ReasonCode'] = self.reason_code
         if self.reason_message is not None:
             result['ReasonMessage'] = self.reason_message
+        if self.role_arn is not None:
+            result['RoleArn'] = self.role_arn
         if self.scheduler is not None:
             result['Scheduler'] = self.scheduler.to_map()
         if self.status is not None:
             result['Status'] = self.status
         result['StatusTransitions'] = []
         if self.status_transitions is not None:
             for k in self.status_transitions:
@@ -7023,28 +6291,32 @@
                 temp_model = ListTrainingJobsResponseBodyTrainingJobsHyperParameters()
                 self.hyper_parameters.append(temp_model.from_map(k))
         self.input_channels = []
         if m.get('InputChannels') is not None:
             for k in m.get('InputChannels'):
                 temp_model = ListTrainingJobsResponseBodyTrainingJobsInputChannels()
                 self.input_channels.append(temp_model.from_map(k))
+        if m.get('IsTempAlgo') is not None:
+            self.is_temp_algo = m.get('IsTempAlgo')
         self.labels = []
         if m.get('Labels') is not None:
             for k in m.get('Labels'):
                 temp_model = ListTrainingJobsResponseBodyTrainingJobsLabels()
                 self.labels.append(temp_model.from_map(k))
         self.output_channels = []
         if m.get('OutputChannels') is not None:
             for k in m.get('OutputChannels'):
                 temp_model = ListTrainingJobsResponseBodyTrainingJobsOutputChannels()
                 self.output_channels.append(temp_model.from_map(k))
         if m.get('ReasonCode') is not None:
             self.reason_code = m.get('ReasonCode')
         if m.get('ReasonMessage') is not None:
             self.reason_message = m.get('ReasonMessage')
+        if m.get('RoleArn') is not None:
+            self.role_arn = m.get('RoleArn')
         if m.get('Scheduler') is not None:
             temp_model = ListTrainingJobsResponseBodyTrainingJobsScheduler()
             self.scheduler = temp_model.from_map(m['Scheduler'])
         if m.get('Status') is not None:
             self.status = m.get('Status')
         self.status_transitions = []
         if m.get('StatusTransitions') is not None:
@@ -7151,317 +6423,14 @@
             self.status_code = m.get('statusCode')
         if m.get('body') is not None:
             temp_model = ListTrainingJobsResponseBody()
             self.body = temp_model.from_map(m['body'])
         return self
 
 
-class ReleaseAlgorithmRequest(TeaModel):
-    def __init__(
-        self,
-        target_algorithm_name: str = None,
-        update_if_exists: bool = None,
-    ):
-        self.target_algorithm_name = target_algorithm_name
-        self.update_if_exists = update_if_exists
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.target_algorithm_name is not None:
-            result['TargetAlgorithmName'] = self.target_algorithm_name
-        if self.update_if_exists is not None:
-            result['UpdateIfExists'] = self.update_if_exists
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('TargetAlgorithmName') is not None:
-            self.target_algorithm_name = m.get('TargetAlgorithmName')
-        if m.get('UpdateIfExists') is not None:
-            self.update_if_exists = m.get('UpdateIfExists')
-        return self
-
-
-class ReleaseAlgorithmResponseBody(TeaModel):
-    def __init__(
-        self,
-        algorithm_id: str = None,
-        request_id: str = None,
-    ):
-        self.algorithm_id = algorithm_id
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.algorithm_id is not None:
-            result['AlgorithmId'] = self.algorithm_id
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('AlgorithmId') is not None:
-            self.algorithm_id = m.get('AlgorithmId')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
-        return self
-
-
-class ReleaseAlgorithmResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: ReleaseAlgorithmResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = ReleaseAlgorithmResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class ReleaseAlgorithmVersionRequest(TeaModel):
-    def __init__(
-        self,
-        target_algorithm_name: str = None,
-        target_algorithm_version: str = None,
-        update_if_exists: bool = None,
-    ):
-        self.target_algorithm_name = target_algorithm_name
-        self.target_algorithm_version = target_algorithm_version
-        self.update_if_exists = update_if_exists
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.target_algorithm_name is not None:
-            result['TargetAlgorithmName'] = self.target_algorithm_name
-        if self.target_algorithm_version is not None:
-            result['TargetAlgorithmVersion'] = self.target_algorithm_version
-        if self.update_if_exists is not None:
-            result['UpdateIfExists'] = self.update_if_exists
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('TargetAlgorithmName') is not None:
-            self.target_algorithm_name = m.get('TargetAlgorithmName')
-        if m.get('TargetAlgorithmVersion') is not None:
-            self.target_algorithm_version = m.get('TargetAlgorithmVersion')
-        if m.get('UpdateIfExists') is not None:
-            self.update_if_exists = m.get('UpdateIfExists')
-        return self
-
-
-class ReleaseAlgorithmVersionResponseBody(TeaModel):
-    def __init__(
-        self,
-        algorithm_id: str = None,
-        algorithm_version: str = None,
-        request_id: str = None,
-    ):
-        self.algorithm_id = algorithm_id
-        self.algorithm_version = algorithm_version
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.algorithm_id is not None:
-            result['AlgorithmId'] = self.algorithm_id
-        if self.algorithm_version is not None:
-            result['AlgorithmVersion'] = self.algorithm_version
-        if self.request_id is not None:
-            result['requestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('AlgorithmId') is not None:
-            self.algorithm_id = m.get('AlgorithmId')
-        if m.get('AlgorithmVersion') is not None:
-            self.algorithm_version = m.get('AlgorithmVersion')
-        if m.get('requestId') is not None:
-            self.request_id = m.get('requestId')
-        return self
-
-
-class ReleaseAlgorithmVersionResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: ReleaseAlgorithmVersionResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = ReleaseAlgorithmVersionResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
-class StopArrearsTrainingJobResponseBody(TeaModel):
-    def __init__(
-        self,
-        request_id: str = None,
-    ):
-        self.request_id = request_id
-
-    def validate(self):
-        pass
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.request_id is not None:
-            result['RequestId'] = self.request_id
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('RequestId') is not None:
-            self.request_id = m.get('RequestId')
-        return self
-
-
-class StopArrearsTrainingJobResponse(TeaModel):
-    def __init__(
-        self,
-        headers: Dict[str, str] = None,
-        status_code: int = None,
-        body: StopArrearsTrainingJobResponseBody = None,
-    ):
-        self.headers = headers
-        self.status_code = status_code
-        self.body = body
-
-    def validate(self):
-        self.validate_required(self.headers, 'headers')
-        self.validate_required(self.status_code, 'status_code')
-        self.validate_required(self.body, 'body')
-        if self.body:
-            self.body.validate()
-
-    def to_map(self):
-        _map = super().to_map()
-        if _map is not None:
-            return _map
-
-        result = dict()
-        if self.headers is not None:
-            result['headers'] = self.headers
-        if self.status_code is not None:
-            result['statusCode'] = self.status_code
-        if self.body is not None:
-            result['body'] = self.body.to_map()
-        return result
-
-    def from_map(self, m: dict = None):
-        m = m or dict()
-        if m.get('headers') is not None:
-            self.headers = m.get('headers')
-        if m.get('statusCode') is not None:
-            self.status_code = m.get('statusCode')
-        if m.get('body') is not None:
-            temp_model = StopArrearsTrainingJobResponseBody()
-            self.body = temp_model.from_map(m['body'])
-        return self
-
-
 class StopTrainingJobResponseBody(TeaModel):
     def __init__(
         self,
         request_id: str = None,
     ):
         self.request_id = request_id
 
@@ -7529,34 +6498,40 @@
         return self
 
 
 class UpdateAlgorithmRequest(TeaModel):
     def __init__(
         self,
         algorithm_description: str = None,
+        display_name: str = None,
     ):
         self.algorithm_description = algorithm_description
+        self.display_name = display_name
 
     def validate(self):
         pass
 
     def to_map(self):
         _map = super().to_map()
         if _map is not None:
             return _map
 
         result = dict()
         if self.algorithm_description is not None:
             result['AlgorithmDescription'] = self.algorithm_description
+        if self.display_name is not None:
+            result['DisplayName'] = self.display_name
         return result
 
     def from_map(self, m: dict = None):
         m = m or dict()
         if m.get('AlgorithmDescription') is not None:
             self.algorithm_description = m.get('AlgorithmDescription')
+        if m.get('DisplayName') is not None:
+            self.display_name = m.get('DisplayName')
         return self
 
 
 class UpdateAlgorithmResponseBody(TeaModel):
     def __init__(
         self,
         algorithm_id: str = None,
```

## pai/modelscope/estimator.py

```diff
@@ -29,14 +29,15 @@
 
     """
 
     def __init__(
         self,
         command: str,
         source_dir: Optional[str] = None,
+        git_config: Optional[Dict[str, str]] = None,
         image_uri: Optional[str] = None,
         modelscope_version: Optional[str] = None,
         hyperparameters: Optional[Dict[str, Any]] = None,
         base_job_name: Optional[str] = None,
         checkpoints_path: Optional[str] = None,
         output_path: Optional[str] = None,
         instance_type: str = "ecs.c6.xlarge",
@@ -50,14 +51,47 @@
             command (str): The command used to run the training job.
             source_dir (str, optional): The local source code directory used in the
                 training job. The directory will be packaged and uploaded to an OSS
                 bucket, then downloaded to the `/ml/usercode` directory in the training
                 job container. If there is a `requirements.txt` file in the source code
                 directory, the corresponding dependencies will be installed before the
                 training script runs.
+
+                If 'git_config' is provided, 'source_dir' should be a relative location
+                to a directory in the Git repo. With the following GitHub repo directory
+                structure:
+
+                .. code::
+
+                    |----- README.md
+                    |----- src
+                             |----- train.py
+                             |----- test.py
+
+                if you need 'src' directory as the source code directory, you can assign
+                source_dir='./src/'.
+            git_config (Dict[str, str]): Git configuration used to clone the repo.
+                Including ``repo``, ``branch``, ``commit``, ``username``, ``password``
+                and ``token``. The ``repo`` is required. All other fields are optional.
+                ``repo`` specifies the Git repository. If you don't provide ``branch``,
+                the default value 'master' is used. If you don't provide ``commit``, the
+                latest commit in the specified branch is used. ``username``, ``password``
+                and ``token`` are for authentication purpose.
+                For example, the following config:
+
+                .. code:: python
+
+                    git_config = {
+                        'repo': 'https://github.com/modelscope/modelscope.git',
+                        'branch': 'master',
+                        'commit': '9bfc4a9d83c4beaf8378d0a186261ffc1cd9f960'
+                    }
+
+                results in cloning the git repo specified in 'repo', then checking out
+                the 'master' branch, and checking out the specified commit.
             image_uri (str, optional): If specified, the estimator will use this image
                 in the training job, instead of selecting the appropriate PAI official
                 image based on modelscope_version. It can be an image provided by PAI
                 or a user customized image. To view the images provided by PAI, please
                 refer to the document:
                 https://help.aliyun.com/document_detail/202834.htm.
 
@@ -133,14 +167,15 @@
         self.image_uri = image_uri
         self.modelscope_version = modelscope_version
 
         super(ModelScopeEstimator, self).__init__(
             image_uri=self.image_uri,
             command=command,
             source_dir=source_dir,
+            git_config=git_config,
             hyperparameters=hyperparameters,
             base_job_name=base_job_name,
             checkpoints_path=checkpoints_path,
             output_path=output_path,
             instance_type=instance_type,
             instance_count=instance_count,
             session=session,
```

## pai/modelscope/model.py

```diff
@@ -52,14 +52,15 @@
     def __init__(
         self,
         model_data: Optional[str] = None,
         image_uri: Optional[str] = None,
         modelscope_version: Optional[str] = None,
         command: Optional[str] = None,
         source_dir: Optional[str] = None,
+        git_config: Optional[Dict[str, str]] = None,
         port: int = DEFAULT_SERVICE_PORT,
         environment_variables: Optional[Dict[str, str]] = None,
         requirements: Optional[List[str]] = None,
         requirements_path: Optional[str] = None,
         health_check: Optional[Dict[str, Any]] = None,
         session: Optional[Session] = None,
         **kwargs,
@@ -76,28 +77,63 @@
 
                 If ``modelscope_version`` is ``None``, then ``image_uri`` is required.
                 If also ``None``, then a ``ValueError`` will be raised.
             modelscope_version (str, optional): Modelscope version you want to use for
                 executing your model serving code. Defaults to ``None``. Required unless
                 ``image_uri`` is provided.
             command (str): The command used to launch the Model server.
-            source_dir (str, optional): Local path to the source code directory to be
-                uploaded and used for the model server.
+            source_dir (str, optional): A relative path or an absolute path to the source
+                code directory used to load model and launch the Model server, it will be
+                uploaded to the OSS bucket and mounted to the container. If there is a
+                ``requirements.txt`` file under the directory, it will be installed before
+                the prediction server started.
+
+                If 'git_config' is provided, 'source_dir' should be a relative location
+                to a directory in the Git repo. With the following GitHub repo directory
+                structure:
+
+                .. code::
+
+                    |----- README.md
+                    |----- src
+                                |----- train.py
+                                |----- test.py
+
+                if you need 'src' directory as the source code directory, you can assign
+                source_dir='./src/'.
+            git_config (Dict[str, str]): Git configuration used to clone the repo.
+                Including ``repo``, ``branch``, ``commit``, ``username``, ``password`` and
+                ``token``. The ``repo`` is required. All other fields are optional. ``repo``
+                specifies the Git repository. If you don't provide ``branch``, the default
+                value 'master' is used. If you don't provide ``commit``, the latest commit
+                in the specified branch is used. ``username``, ``password`` and ``token``
+                are for authentication purpose. For example, the following config:
+
+                .. code:: python
+
+                    git_config = {
+                        'repo': 'https://github.com/modelscope/modelscope.git',
+                        'branch': 'master',
+                        'commit': '9bfc4a9d83c4beaf8378d0a186261ffc1cd9f960'
+                    }
+
+                results in cloning the repo specified in 'repo', then checking out the
+                'master' branch, and checking out the specified commit.
             port (int, optional): Expose port of the server in container, the prediction
                 request will be forward to the port. The environment variable ``LISTENING_PORT``
                 in the container will be set to this value.
             environment_variables (Dict[str, str], optional): Dictionary of environment
                 variable key-value pairs to set on the running container.
             requirements (List[str], optional): A list of Python package dependency, it
                 will be installed before the serving container run.
             requirements_path (str, optional): A absolute path to the requirements.txt in
                 the container.
             health_check (Dict[str, Any], optional): The health check configuration. If it
                 not set, A TCP readiness probe will be used to check the health of the
-                HTTP server.
+                Model server.
             session (:class:`pai.session.Session`, optional): A pai session object
                 manages interactions with PAI REST API.
 
             **kwargs: Additional kwargs passed to the :class:`~pai.model.ModelBase` constructor.
 
         .. tip::
 
@@ -107,14 +143,15 @@
         self._validate_args(image_uri=image_uri, modelscope_version=modelscope_version)
 
         self.model_data = model_data
         self.image_uri = image_uri
         self.modelscope_version = modelscope_version
         self.command = command
         self.source_dir = source_dir
+        self.git_config = git_config
         self.port = port
         self.environment_variables = environment_variables
         self.requirements = requirements
         self.requirements_path = requirements_path
         self.health_check = health_check
         self.session = session
         inference_spec = dict()
@@ -133,16 +170,17 @@
                 "modelscope_version, and image_uri are both None. "
                 "Specify either modelscope_version or image_uri."
             )
 
     def serving_image_uri(self, instance_type: str) -> str:
         """Return the Docker image to use for serving.
 
-        The deploy() method, that does the model deployment, calls this method to
-        find the image to use for the inference service.
+        The :meth:`pai.modelscope.model.ModelScopeModel.deploy` method, that does the
+        model deployment, calls this method to find the image to use for the
+        inference service.
 
         Returns:
             str: The URI of the Docker image.
         """
         if self.image_uri:
             return self.image_uri
 
@@ -157,22 +195,23 @@
             framework_version=framework_version,
             accelerator_type=accelerator_type,
             image_scope=ImageScope.INFERENCE,
         ).image_uri
 
     def deploy(
         self,
-        service_name: Optional[str] = None,
+        service_name: str,
         instance_type: Optional[str] = None,
         instance_count: Optional[int] = 1,
         resource_config: Optional[Union[Dict[str, int], ResourceConfig]] = None,
         resource_id: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
         wait: bool = True,
         serializer: Optional["SerializerBase"] = None,
+        **kwargs,
     ):
         """Deploy an online prediction service.
 
         Args:
             service_name (str, optional): Name for the online prediction service. The name
                 must be unique in a region.
             instance_type (str, optional): Type of the machine instance, for example,
@@ -222,14 +261,15 @@
 
         self.image_uri = self.serving_image_uri(instance_type=instance_type)
         self.inference_spec = container_serving_spec(
             command=self.command,
             image_uri=self.image_uri,
             port=self.port,
             source_dir=self.source_dir,
+            git_config=self.git_config,
             environment_variables=self.environment_variables,
             requirements=self.requirements,
             requirements_path=self.requirements_path,
             health_check=self.health_check,
             session=self.session,
         )
         return super(ModelScopeModel, self).deploy(
```

## Comparing `alipai-0.4.0.post0.dist-info/LICENSE.txt` & `alipai-0.4.1.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `alipai-0.4.0.post0.dist-info/METADATA` & `alipai-0.4.1.dist-info/METADATA`

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: alipai
-Version: 0.4.0.post0
+Version: 0.4.1
 Summary: Alibaba Cloud PAI Python SDK
 Home-page: https://www.aliyun.com/product/bigdata/product/learn
 Author: Alibaba PAI team
 License: Apache License 2.0
 Keywords: ML Alibaba Cloud PAI Training Inference Pipeline
 Requires-Python: >=3.6
 Description-Content-Type: text/markdown
@@ -17,20 +17,21 @@
 Requires-Dist: pyodps (>=0.11.0)
 Requires-Dist: pyyaml (>=5.3.1)
 Requires-Dist: six (>=1.15.0)
 Requires-Dist: docker (>=4.4.0)
 Requires-Dist: marshmallow
 Requires-Dist: marshmallow-oneofschema (>=3.0.1)
 Requires-Dist: eas-prediction (>=0.20)
-Requires-Dist: alibabacloud-tea-util (<1.0.0,>=0.3.6)
+Requires-Dist: alibabacloud-tea-util (!=0.3.9,<1.0.0,>=0.3.6)
 Requires-Dist: alibabacloud-tea-openapi (<1.0.0,>=0.3.3)
 Requires-Dist: alibabacloud-openapi-util (<1.0.0,>=0.1.6)
 Requires-Dist: alibabacloud-endpoint-util (<1.0.0,>=0.0.3)
 Requires-Dist: pandas
 Requires-Dist: addict
 Requires-Dist: backoff (<2.0.0)
 Requires-Dist: semantic-version
 Requires-Dist: tqdm
 Requires-Dist: prompt-toolkit
 Requires-Dist: pyOpenSSL (>=23.0.0)
+Requires-Dist: aiohttp
 
 # Alibaba PAI Python SDK
```

## Comparing `alipai-0.4.0.post0.dist-info/RECORD` & `alipai-0.4.1.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,60 +1,61 @@
-pai/VERSION,sha256=aENW_x5PSaRvexYVlNmv7voyGbS8ldF3XrqI2u-Ah_g,12
+pai/VERSION,sha256=9iGEzuh4fy9pQcggQaVyXU7cmqKT6-Xb9mRAboLsH-E,6
 pai/__init__.py,sha256=8EbzTuHLzyuU4ZWOrLhK2p8fRJk7cWpSK9htMS4fLRA,290
-pai/estimator.py,sha256=GGXkzXnXhFt6m2w6HfRAuQlR41Vb-dNbRPm5q1zjvoo,37762
+pai/estimator.py,sha256=L6v4ZO3QfiJEwbLwS2qfZXvM60a4b-vjwRmJycnA2xI,40574
 pai/exception.py,sha256=xfvKD1e9fel4t3MXsOGx4Qsvc-IVvMxly74rXCQlLeE,489
 pai/image.py,sha256=EEqPdQ7wPZTAh8wE3N30dejyZd4korrqSI4UTrqtOU4,12163
-pai/model.py,sha256=6EJ_pYJ5E-O84DAJk9s1odffs0_ZS6xi2k0Y5Cf0szc,36719
-pai/predictor.py,sha256=nrTW-aVNjtnGogiVbH0SDQ9OO9_LDqaD4VzYrgkXjVM,24633
+pai/model.py,sha256=BrPX78RJZq8-l-Cn8XhK1TJp1E7_LzkVL2tMS87IKD0,40522
+pai/predictor.py,sha256=3-dnXqvq9nPDb5VGeDKmL7BRu9fFMQMuYDlPe_4jjDQ,46831
 pai/serializers.py,sha256=cegGv0BLwTrg3ubkEYRSGHq2xnBjaXNawKbSRInSFPk,20082
-pai/session.py,sha256=dgcP_mG72UdZbsAIW0JGUQnMK90BOE6o7BFLXY95mBM,14519
+pai/session.py,sha256=lveC30bset962AbW7Dbv62NvW-7az-UXydpzUGNby2o,14538
 pai/api/__init__.py,sha256=YV8TG1oW4YTohSL8XonH-ARm46SoGBV-wjOrW-wsi8I,39
 pai/api/algorithm.py,sha256=xS01gHJteqOHAg1CaJe6OHQGV24qAy9BTSCVVOAR6BE,4249
 pai/api/api_container.py,sha256=Fd9uJqOd1A0Mu1dtTTVlLzbpMkfryeSdSRGsU2ahFxk,7935
 pai/api/base.py,sha256=IllrMZIbqS1PyO50fg9p3CNirzPVRkTmm-eQ1qdDnSw,5439
-pai/api/client_factory.py,sha256=G191n_dNkPLLg3O9szZCo6ARqCR4l8IBaZAwLFRP0co,4016
+pai/api/client_factory.py,sha256=rn5jcgWYrZh4X7RXxFn2ampzW2XPxmtfF1Bp29EvsT8,4010
 pai/api/code_source.py,sha256=4DN-EDWwEvKazdy4ejSgugVEqMLDWUfgw9zAYdxIVfg,2945
 pai/api/dataset.py,sha256=pnooRnQ-N3Ln4DJ7RVU94PYb6T9UwpPJqBFijZj17_0,3755
 pai/api/entity_base.py,sha256=SJx-05R657MJSrEf7px0czLMdoyb4ao4Wfi95CcXXgk,1726
-pai/api/image.py,sha256=XlSozS8l4NaG_qFJOq5Er6vW1rS_oTQ5UQOzxoAIqGU,2498
+pai/api/image.py,sha256=7shc_4hZdGrxqxAjM-4KO9VwASdvk-MqZ-wlkLAxjyM,2665
 pai/api/job.py,sha256=eLLlTvyeK-LVbRK666djQUI2XC3PqK1sG6wN8JAPiGE,5232
 pai/api/model.py,sha256=mvEOGGMx8AE29QSLFsmAZoGY4xh1f9vc5Z3NmXWzB0E,6090
 pai/api/pipeline.py,sha256=_mvo8a3qkE9BI6B0AqeaZJ4VwZzEYe7AAtZlcZKQ_bk,3426
 pai/api/pipeline_run.py,sha256=UVKKt1AUF8mAvQHGqTtbLJ-ZYBRc_eOQ2CgQEoPF_Ec,5314
 pai/api/service.py,sha256=n6-R3IEWTg3YAzSoh82mv6NXQQbl-l3hAofjmzO9HgE,5421
 pai/api/training_job.py,sha256=koOYf8GuwNyH26Tvd4UgzNAayXLTZHGvIyi-CTBtdIs,5410
 pai/api/workspace.py,sha256=6CWRrbRQGHEn7Tzij3eDrpycHVQwUOqV3uwR9dXVEwg,8340
 pai/common/__init__.py,sha256=vwTRpeN4lv0dVtk__5azpaR9RH4H1tNSl_O_5_gpGME,67
-pai/common/consts.py,sha256=6qgxQJO2qIriCZspmMOTGrnsNVAVSJNE5e_xHmiV2Rs,1495
-pai/common/docker_utils.py,sha256=MKHx1iHZbIqEJTJ5UrkVbH5NE0QTEAfZ2v6yDdm4Bx4,4889
+pai/common/consts.py,sha256=oTBSJAoSsIhoAxepB_7rxUyJMqbd9TbDH2fJvGovuk0,1565
+pai/common/docker_utils.py,sha256=Lcw9h06vcgLUh-1vlZmxcM1CuHwyDFpFTnnCDaYphWg,6438
+pai/common/git_utils.py,sha256=k-q9Ef8vzhJnup3jSPgUj1BtvJx7INxBDGL0r89wtVo,12168
 pai/common/oss_utils.py,sha256=JLWcEKC9hJxkyKHul4YkQpAsjbcvZKQprKY6jByTkKY,14998
-pai/common/utils.py,sha256=guhWO8zEsPiOVkkxOuMub-N_-RlZ7UU-Qg-c1eMmaDg,2797
+pai/common/utils.py,sha256=VnnUExzq_7KBwK7cV40t_WZpaDLzW2AtZYLfyppX7D4,3406
 pai/common/yaml_utils.py,sha256=GAupYkXylpc0COo01X_bEQ_NTvUELwT_wWjIJ6SWoUM,710
 pai/huggingface/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pai/huggingface/estimator.py,sha256=O4R73rYA20UT0f77o40hneYszpsS9C-cuTMKFyg5JCA,8338
-pai/huggingface/model.py,sha256=furzlcNhVGeWWXs7GkBJW0mXJ76AWKNbSOvKR1vWvDM,10724
+pai/huggingface/estimator.py,sha256=OjY0LK5Y1ltNgUhjp97IabmjirSVIBSqsuv9iONbkmw,10037
+pai/huggingface/model.py,sha256=L_EHl1t1Vip83kMNFYZOxfnCS8Bki1JC8tya93RnSJk,12791
 pai/libs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pai/libs/alibabacloud_aiworkspace20210204/__init__.py,sha256=dHuoY6voK7np1A7oRzw1xyBy7CK9_KBAc4FCKW29uRQ,21
-pai/libs/alibabacloud_aiworkspace20210204/client.py,sha256=_b6ipUPyY2e34UjGWKIsGmcScEQTvtn78PPIDUMJNRA,241194
-pai/libs/alibabacloud_aiworkspace20210204/models.py,sha256=V3fWYFC-tVRJSem0d5i9yuKbjxLH1iiW0miM6FUjRQY,357327
+pai/libs/alibabacloud_aiworkspace20210204/__init__.py,sha256=eSyU24SgU3Uua45_Fv26TJ9RzfxBzBPCt7REcbfUSts,22
+pai/libs/alibabacloud_aiworkspace20210204/client.py,sha256=RqUMgEu7zo-pXPGrGhOJyV3ks5jVPjdNOKtUlP-PA0Q,278209
+pai/libs/alibabacloud_aiworkspace20210204/models.py,sha256=ObYQlVZxqboaU57UMG3Tbtcd1-SOB32aMy3E_sZzk8Y,400899
 pai/libs/alibabacloud_eas20210701/__init__.py,sha256=U8BEyItnCRffb5NQFYKwkJf1OI4ctsrASQHqqSyNC4k,21
 pai/libs/alibabacloud_eas20210701/client.py,sha256=eZ4YeSWhS1rPMI9o2nH1lt8RZIFHkWeOLcyOC74gjwk,188668
 pai/libs/alibabacloud_eas20210701/models.py,sha256=a_4GRIksK03ZrREBqw90Nu5dTyijXgidCb9dtF5QN5w,251200
 pai/libs/alibabacloud_pai_dlc20201203/__init__.py,sha256=dHuoY6voK7np1A7oRzw1xyBy7CK9_KBAc4FCKW29uRQ,21
 pai/libs/alibabacloud_pai_dlc20201203/client.py,sha256=JbPTnwSPLiCGIEqYkGeOgacQ_VObSVL5_SweGgQQ208,73033
 pai/libs/alibabacloud_pai_dlc20201203/models.py,sha256=jClhdR6jVrSP5N79svG97YLrgOZhSTng76cmFpYE3gQ,176083
 pai/libs/alibabacloud_paiflow20210202/__init__.py,sha256=dHuoY6voK7np1A7oRzw1xyBy7CK9_KBAc4FCKW29uRQ,21
 pai/libs/alibabacloud_paiflow20210202/client.py,sha256=6fNARjvxRXmDnvMx6tJno3EBCHkmTqu70b9fJt9XUlY,76356
 pai/libs/alibabacloud_paiflow20210202/models.py,sha256=Nb-ga4fLgx83ZX0MvqrSrZD-6tFrL9aPsOB2321g3Zo,116997
 pai/libs/alibabacloud_paistudio20220112/__init__.py,sha256=08DnIq8xe-WGgxH1S9FdvG-7s77q2vCT4JBAuMDZROo,22
-pai/libs/alibabacloud_paistudio20220112/client.py,sha256=r3f3-JOHuZa4K1OgsYG3KhVopASXt3mKq13HLRA5ZW4,151599
-pai/libs/alibabacloud_paistudio20220112/models.py,sha256=r4rZrAHRMbpM7L4mD7Oc1MywPGKi98gFatT9bMNP8VU,262318
+pai/libs/alibabacloud_paistudio20220112/client.py,sha256=JGfdaRkZ0q7-SBRSM6js9AwCXbrS4xNb8NIJwCW0qwY,107153
+pai/libs/alibabacloud_paistudio20220112/models.py,sha256=-ajbmwg906SqGCLr-RY4drqt3VpDzYrlgXUiMD2GNDg,236081
 pai/modelscope/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pai/modelscope/estimator.py,sha256=a30G3DHXfEnoEFFyUefg4OfNmIcOFBBtlJZFAPUsswk,8285
-pai/modelscope/model.py,sha256=bz90aUZhpWdi24PBwoM4XfCIcaCuwGkvl5bE2gA1zVg,10660
+pai/modelscope/estimator.py,sha256=gWy4jgLFGiBgW8fXdZrwjm9sv2JNJMbn2ltQF12Xulg,9985
+pai/modelscope/model.py,sha256=vkJPZHWywb07ZBuGi9N_0D1XfcMmfU_nhX2Vmm03coo,12704
 pai/pipeline/__init__.py,sha256=UPvgppQ80FlOSP0bhdNjlIwu4GotIYOcVtNYjrFZcNc,503
 pai/pipeline/artifact.py,sha256=BNBrJ7D-Mazy8nmjlQGLBmJ7f3h5g07_-ehzXiKpwF4,2463
 pai/pipeline/consts.py,sha256=PLEBK7ctL6tlELEOyBUPeb5g55uSCwWdIQDSr4RIg28,81
 pai/pipeline/core.py,sha256=IRmKUNMi_zwpUbThSf4_ZtjiRZxIw1LoWjCjXvlfQmI,13115
 pai/pipeline/run.py,sha256=DFD5ITljfP3m6RdFMSGQttVykcHepykFW0_6jxjjeAs,15710
 pai/pipeline/step.py,sha256=9OSh8iIEfe6VefrKedXbuBjnGIKWrYZ96vPEk3K4Hss,12848
 pai/pipeline/component/__init__.py,sha256=tMs-kbh4_m39wv12oUSOFqurW1RwEKVwNeQXdJFaTpo,128
@@ -70,12 +71,12 @@
 pai/schema/base.py,sha256=R7xg4mREKxPqKvYOasLXE77N1PQjKAIPLzL_bAtOkOs,2871
 pai/schema/training_job_schema.py,sha256=CEb2oq4lu5oubeQjY4zRTPTeAykb5ojCSGslzpmiHAQ,2857
 pai/toolkit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pai/toolkit/config.py,sha256=ZIXiLiqOqPMWYxw6xJMrddsNnHxgU0RjqlxzNc7MueM,16185
 pai/toolkit/helper/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pai/toolkit/helper/consts.py,sha256=KqU5jABCeIYct6ETGMnOW7-pcYoWOW8YKKtw5KwTANA,2559
 pai/toolkit/helper/utils.py,sha256=Mjku3RNnaYUX4ICa30ap1OKJDnRGJIA4umpQDrdp6K0,10835
-alipai-0.4.0.post0.dist-info/LICENSE.txt,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-alipai-0.4.0.post0.dist-info/METADATA,sha256=y46GFDKZBg415u3WH3kC3Pr_IPpnBHlez4ux5o0oB3U,1225
-alipai-0.4.0.post0.dist-info/WHEEL,sha256=Z-nyYpwrcSqxfdux5Mbn_DQ525iP7J2DG3JgGvOYyTQ,110
-alipai-0.4.0.post0.dist-info/top_level.txt,sha256=1jOjp5NlWBLogWe-8LLNotO51tqwsu2J38adsPBHuoc,4
-alipai-0.4.0.post0.dist-info/RECORD,,
+alipai-0.4.1.dist-info/LICENSE.txt,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+alipai-0.4.1.dist-info/METADATA,sha256=vM-2wTdEn5H9Wu6Byb8GKtqjj1ehxMXVAJ8odp6klfU,1250
+alipai-0.4.1.dist-info/WHEEL,sha256=Z-nyYpwrcSqxfdux5Mbn_DQ525iP7J2DG3JgGvOYyTQ,110
+alipai-0.4.1.dist-info/top_level.txt,sha256=1jOjp5NlWBLogWe-8LLNotO51tqwsu2J38adsPBHuoc,4
+alipai-0.4.1.dist-info/RECORD,,
```

