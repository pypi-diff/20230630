# Comparing `tmp/k1lib-1.4.1-py3-none-any.whl.zip` & `tmp/k1lib-1.4.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,86 +1,86 @@
-Zip file size: 2588692 bytes, number of entries: 84
+Zip file size: 2598491 bytes, number of entries: 84
 -rw-rw-r--  2.0 unx     1441 b- defN 23-May-26 17:16 k1lib/__init__.py
--rw-rw-r--  2.0 unx    83638 b- defN 23-Jun-12 14:45 k1lib/_baseClasses.py
--rw-rw-r--  2.0 unx    22816 b- defN 23-Jun-12 14:45 k1lib/_basics.py
--rw-rw-r--  2.0 unx     8208 b- defN 23-Jun-12 14:45 k1lib/_context.py
--rw-rw-r--  2.0 unx     4314 b- defN 23-Jun-12 14:45 k1lib/_higher.py
--rw-rw-r--  2.0 unx     3085 b- defN 23-Jun-12 14:45 k1lib/_k1a.py
--rw-rw-r--  2.0 unx    20567 b- defN 23-Jun-12 14:45 k1lib/_learner.py
--rw-rw-r--  2.0 unx    35159 b- defN 23-Jun-12 14:45 k1lib/_monkey.py
--rw-rw-r--  2.0 unx     5575 b- defN 23-Jun-12 14:45 k1lib/_perlin.py
--rw-rw-r--  2.0 unx    21263 b- defN 23-Jun-12 14:45 k1lib/eqn.py
--rw-rw-r--  2.0 unx    12310 b- defN 23-Jun-12 14:45 k1lib/fmt.py
--rw-rw-r--  2.0 unx    10890 b- defN 23-Jun-12 14:45 k1lib/graphEqn.py
--rw-rw-r--  2.0 unx     4996 b- defN 23-Jun-12 14:45 k1lib/imports.py
--rw-rw-r--  2.0 unx     4919 b- defN 23-Jun-12 14:45 k1lib/knn.py
--rw-rw-r--  2.0 unx     6449 b- defN 23-Jun-12 14:45 k1lib/p5.py
--rw-rw-r--  2.0 unx    14079 b- defN 23-Jun-12 14:45 k1lib/schedule.py
--rw-rw-r--  2.0 unx    29996 b- defN 23-Jun-12 14:45 k1lib/selector.py
--rw-rw-r--  2.0 unx    24144 b- defN 23-Jun-12 14:45 k1lib/viz.py
+-rw-rw-r--  2.0 unx    83638 b- defN 23-Jun-30 11:09 k1lib/_baseClasses.py
+-rw-rw-r--  2.0 unx    25511 b- defN 23-Jun-30 11:09 k1lib/_basics.py
+-rw-rw-r--  2.0 unx     8208 b- defN 23-Jun-30 11:09 k1lib/_context.py
+-rw-rw-r--  2.0 unx     4314 b- defN 23-Jun-30 11:09 k1lib/_higher.py
+-rw-rw-r--  2.0 unx     3085 b- defN 23-Jun-30 11:09 k1lib/_k1a.py
+-rw-rw-r--  2.0 unx    20567 b- defN 23-Jun-30 11:09 k1lib/_learner.py
+-rw-rw-r--  2.0 unx    36997 b- defN 23-Jun-30 11:09 k1lib/_monkey.py
+-rw-rw-r--  2.0 unx     5575 b- defN 23-Jun-30 11:09 k1lib/_perlin.py
+-rw-rw-r--  2.0 unx    21263 b- defN 23-Jun-30 11:09 k1lib/eqn.py
+-rw-rw-r--  2.0 unx    12310 b- defN 23-Jun-30 11:09 k1lib/fmt.py
+-rw-rw-r--  2.0 unx    10890 b- defN 23-Jun-30 11:09 k1lib/graphEqn.py
+-rw-rw-r--  2.0 unx     5174 b- defN 23-Jun-30 11:09 k1lib/imports.py
+-rw-rw-r--  2.0 unx     4919 b- defN 23-Jun-30 11:09 k1lib/knn.py
+-rw-rw-r--  2.0 unx     6449 b- defN 23-Jun-30 11:09 k1lib/p5.py
+-rw-rw-r--  2.0 unx    14079 b- defN 23-Jun-30 11:09 k1lib/schedule.py
+-rw-rw-r--  2.0 unx    29996 b- defN 23-Jun-30 11:09 k1lib/selector.py
+-rw-rw-r--  2.0 unx    27360 b- defN 23-Jun-30 11:09 k1lib/viz.py
 -rw-rw-r--  2.0 unx        0 b- defN 21-Aug-11 18:19 k1lib/_hidden/__init__.py
 -rw-rw-r--  2.0 unx       79 b- defN 21-Aug-11 18:19 k1lib/_hidden/hiddenFile.py
 -rw-rw-r--  2.0 unx      615 b- defN 21-Oct-24 23:32 k1lib/_mo/__init__.py
--rw-rw-r--  2.0 unx    24015 b- defN 23-Jun-12 14:45 k1lib/_mo/atom.py
--rw-rw-r--  2.0 unx    18173 b- defN 23-Jun-12 14:45 k1lib/_mo/parseM.py
--rw-rw-r--  2.0 unx     5631 b- defN 23-Jun-12 14:45 k1lib/_mo/substance.py
--rw-rw-r--  2.0 unx    15454 b- defN 23-Jun-12 14:45 k1lib/_mo/system.py
+-rw-rw-r--  2.0 unx    24015 b- defN 23-Jun-30 11:09 k1lib/_mo/atom.py
+-rw-rw-r--  2.0 unx    18173 b- defN 23-Jun-30 11:09 k1lib/_mo/parseM.py
+-rw-rw-r--  2.0 unx     5631 b- defN 23-Jun-30 11:09 k1lib/_mo/substance.py
+-rw-rw-r--  2.0 unx    15454 b- defN 23-Jun-30 11:09 k1lib/_mo/system.py
 -rw-rw-r--  2.0 unx      378 b- defN 21-Oct-30 05:51 k1lib/callbacks/__init__.py
--rw-rw-r--  2.0 unx    31963 b- defN 23-Jun-12 14:45 k1lib/callbacks/callbacks.py
--rw-rw-r--  2.0 unx     5455 b- defN 23-Jun-12 14:45 k1lib/callbacks/confusionMatrix.py
--rw-rw-r--  2.0 unx     2245 b- defN 23-Jun-12 14:45 k1lib/callbacks/core.py
--rw-rw-r--  2.0 unx    19517 b- defN 23-Jun-12 14:45 k1lib/callbacks/hookModule.py
--rw-rw-r--  2.0 unx     7488 b- defN 23-Jun-12 14:45 k1lib/callbacks/hookParam.py
--rw-rw-r--  2.0 unx     5728 b- defN 23-Jun-12 14:45 k1lib/callbacks/landscape.py
--rw-rw-r--  2.0 unx    14525 b- defN 23-Jun-12 14:45 k1lib/callbacks/limits.py
--rw-rw-r--  2.0 unx    10038 b- defN 23-Jun-12 14:45 k1lib/callbacks/loss_accuracy.py
--rw-rw-r--  2.0 unx     6002 b- defN 23-Jun-12 14:45 k1lib/callbacks/paramFinder.py
--rw-rw-r--  2.0 unx     5311 b- defN 23-Jun-12 14:45 k1lib/callbacks/profiler.py
--rw-rw-r--  2.0 unx     4242 b- defN 23-Jun-12 14:45 k1lib/callbacks/progress.py
--rw-rw-r--  2.0 unx     4370 b- defN 23-Jun-12 14:45 k1lib/callbacks/recorder.py
--rw-rw-r--  2.0 unx     8363 b- defN 23-Jun-12 14:45 k1lib/callbacks/shorts.py
+-rw-rw-r--  2.0 unx    31963 b- defN 23-Jun-30 11:09 k1lib/callbacks/callbacks.py
+-rw-rw-r--  2.0 unx     5455 b- defN 23-Jun-30 11:09 k1lib/callbacks/confusionMatrix.py
+-rw-rw-r--  2.0 unx     2245 b- defN 23-Jun-30 11:09 k1lib/callbacks/core.py
+-rw-rw-r--  2.0 unx    19517 b- defN 23-Jun-30 11:09 k1lib/callbacks/hookModule.py
+-rw-rw-r--  2.0 unx     7488 b- defN 23-Jun-30 11:09 k1lib/callbacks/hookParam.py
+-rw-rw-r--  2.0 unx     5728 b- defN 23-Jun-30 11:09 k1lib/callbacks/landscape.py
+-rw-rw-r--  2.0 unx    14525 b- defN 23-Jun-30 11:09 k1lib/callbacks/limits.py
+-rw-rw-r--  2.0 unx    10038 b- defN 23-Jun-30 11:09 k1lib/callbacks/loss_accuracy.py
+-rw-rw-r--  2.0 unx     6002 b- defN 23-Jun-30 11:09 k1lib/callbacks/paramFinder.py
+-rw-rw-r--  2.0 unx     5311 b- defN 23-Jun-30 11:09 k1lib/callbacks/profiler.py
+-rw-rw-r--  2.0 unx     4242 b- defN 23-Jun-30 11:09 k1lib/callbacks/progress.py
+-rw-rw-r--  2.0 unx     4370 b- defN 23-Jun-30 11:09 k1lib/callbacks/recorder.py
+-rw-rw-r--  2.0 unx     8363 b- defN 23-Jun-30 11:09 k1lib/callbacks/shorts.py
 -rw-rw-r--  2.0 unx       30 b- defN 21-Oct-27 12:39 k1lib/callbacks/lossFunctions/__init__.py
--rw-rw-r--  2.0 unx     3695 b- defN 23-Jun-12 14:45 k1lib/callbacks/lossFunctions/accuracy.py
--rw-rw-r--  2.0 unx     5968 b- defN 23-Jun-12 14:45 k1lib/callbacks/lossFunctions/shorts.py
+-rw-rw-r--  2.0 unx     3695 b- defN 23-Jun-30 11:09 k1lib/callbacks/lossFunctions/accuracy.py
+-rw-rw-r--  2.0 unx     5968 b- defN 23-Jun-30 11:09 k1lib/callbacks/lossFunctions/shorts.py
 -rw-rw-r--  2.0 unx       45 b- defN 21-Aug-11 18:19 k1lib/callbacks/profilers/__init__.py
--rw-rw-r--  2.0 unx     9311 b- defN 23-Jun-12 14:45 k1lib/callbacks/profilers/computation.py
--rw-rw-r--  2.0 unx     4069 b- defN 23-Jun-12 14:45 k1lib/callbacks/profilers/io.py
--rw-rw-r--  2.0 unx     7368 b- defN 23-Jun-12 14:45 k1lib/callbacks/profilers/memory.py
--rw-rw-r--  2.0 unx     6971 b- defN 23-Jun-12 14:45 k1lib/callbacks/profilers/time.py
--rw-rw-r--  2.0 unx      925 b- defN 22-Nov-16 09:22 k1lib/cli/__init__.py
--rw-rw-r--  2.0 unx    28678 b- defN 23-Jun-12 14:45 k1lib/cli/_applyCl.py
--rw-rw-r--  2.0 unx    13909 b- defN 23-Jun-12 14:45 k1lib/cli/bio.py
--rw-rw-r--  2.0 unx     5162 b- defN 23-Jun-12 14:45 k1lib/cli/cif.py
--rw-rw-r--  2.0 unx    32287 b- defN 23-Jun-12 14:45 k1lib/cli/conv.py
--rw-rw-r--  2.0 unx    43900 b- defN 23-Jun-12 14:45 k1lib/cli/filt.py
--rw-rw-r--  2.0 unx     8480 b- defN 23-Jun-12 14:45 k1lib/cli/gb.py
--rw-rw-r--  2.0 unx     8644 b- defN 23-Jun-12 14:45 k1lib/cli/grep.py
--rw-rw-r--  2.0 unx    35262 b- defN 23-Jun-12 14:45 k1lib/cli/init.py
--rw-rw-r--  2.0 unx    56176 b- defN 23-Jun-12 14:45 k1lib/cli/inp.py
--rw-rw-r--  2.0 unx     1127 b- defN 23-Jun-12 14:45 k1lib/cli/kcsv.py
--rw-rw-r--  2.0 unx     7467 b- defN 23-Jun-12 14:45 k1lib/cli/kxml.py
--rw-rw-r--  2.0 unx     2977 b- defN 23-Jun-12 14:45 k1lib/cli/mgi.py
--rw-rw-r--  2.0 unx    93036 b- defN 23-Jun-12 14:45 k1lib/cli/modifier.py
--rw-rw-r--  2.0 unx      735 b- defN 23-Jun-12 14:45 k1lib/cli/mol.py
--rw-rw-r--  2.0 unx     5822 b- defN 23-Jun-12 14:45 k1lib/cli/nb.py
--rw-rw-r--  2.0 unx     6311 b- defN 23-Jun-12 14:45 k1lib/cli/optimizations.py
--rw-rw-r--  2.0 unx    18482 b- defN 23-Jun-12 14:45 k1lib/cli/output.py
--rw-rw-r--  2.0 unx     3042 b- defN 23-Jun-12 14:45 k1lib/cli/sam.py
--rw-rw-r--  2.0 unx    68523 b- defN 23-Jun-12 14:45 k1lib/cli/structural.py
--rw-rw-r--  2.0 unx    15949 b- defN 23-Jun-12 14:45 k1lib/cli/trace.py
--rw-rw-r--  2.0 unx    41733 b- defN 23-Jun-12 14:45 k1lib/cli/typehint.py
--rw-rw-r--  2.0 unx    41886 b- defN 23-Jun-12 14:45 k1lib/cli/utils.py
+-rw-rw-r--  2.0 unx     9311 b- defN 23-Jun-30 11:09 k1lib/callbacks/profilers/computation.py
+-rw-rw-r--  2.0 unx     4069 b- defN 23-Jun-30 11:09 k1lib/callbacks/profilers/io.py
+-rw-rw-r--  2.0 unx     7368 b- defN 23-Jun-30 11:09 k1lib/callbacks/profilers/memory.py
+-rw-rw-r--  2.0 unx     6971 b- defN 23-Jun-30 11:09 k1lib/callbacks/profilers/time.py
+-rw-rw-r--  2.0 unx      926 b- defN 23-Jun-19 08:21 k1lib/cli/__init__.py
+-rw-rw-r--  2.0 unx    31282 b- defN 23-Jun-30 11:09 k1lib/cli/_applyCl.py
+-rw-rw-r--  2.0 unx    13909 b- defN 23-Jun-30 11:09 k1lib/cli/bio.py
+-rw-rw-r--  2.0 unx     5162 b- defN 23-Jun-30 11:09 k1lib/cli/cif.py
+-rw-rw-r--  2.0 unx    34729 b- defN 23-Jun-30 11:09 k1lib/cli/conv.py
+-rw-rw-r--  2.0 unx    47519 b- defN 23-Jun-30 11:09 k1lib/cli/filt.py
+-rw-rw-r--  2.0 unx     8480 b- defN 23-Jun-30 11:09 k1lib/cli/gb.py
+-rw-rw-r--  2.0 unx    12136 b- defN 23-Jun-30 11:09 k1lib/cli/grep.py
+-rw-rw-r--  2.0 unx    35262 b- defN 23-Jun-30 11:09 k1lib/cli/init.py
+-rw-rw-r--  2.0 unx    56332 b- defN 23-Jun-30 11:09 k1lib/cli/inp.py
+-rw-rw-r--  2.0 unx     1127 b- defN 23-Jun-30 11:09 k1lib/cli/kcsv.py
+-rw-rw-r--  2.0 unx     7467 b- defN 23-Jun-30 11:09 k1lib/cli/kxml.py
+-rw-rw-r--  2.0 unx     2977 b- defN 23-Jun-30 11:09 k1lib/cli/mgi.py
+-rw-rw-r--  2.0 unx   102579 b- defN 23-Jun-30 11:09 k1lib/cli/modifier.py
+-rw-rw-r--  2.0 unx      735 b- defN 23-Jun-30 11:09 k1lib/cli/mol.py
+-rw-rw-r--  2.0 unx     5822 b- defN 23-Jun-30 11:09 k1lib/cli/nb.py
+-rw-rw-r--  2.0 unx     6311 b- defN 23-Jun-30 11:09 k1lib/cli/optimizations.py
+-rw-rw-r--  2.0 unx    18482 b- defN 23-Jun-30 11:09 k1lib/cli/output.py
+-rw-rw-r--  2.0 unx     3042 b- defN 23-Jun-30 11:09 k1lib/cli/sam.py
+-rw-rw-r--  2.0 unx    68110 b- defN 23-Jun-30 11:09 k1lib/cli/structural.py
+-rw-rw-r--  2.0 unx    15949 b- defN 23-Jun-30 11:09 k1lib/cli/trace.py
+-rw-rw-r--  2.0 unx    41733 b- defN 23-Jun-30 11:09 k1lib/cli/typehint.py
+-rw-rw-r--  2.0 unx    49329 b- defN 23-Jun-30 11:09 k1lib/cli/utils.py
 -rw-rw-r--  2.0 unx       20 b- defN 23-Jan-19 22:00 k1lib/k1ui/__init__.py
--rw-rw-r--  2.0 unx    88699 b- defN 23-Jun-12 14:45 k1lib/k1ui/main.py
+-rw-rw-r--  2.0 unx    88758 b- defN 23-Jun-30 11:09 k1lib/k1ui/main.py
 -rw-rw-r--  2.0 unx       20 b- defN 22-Sep-16 01:12 k1lib/serve/__init__.py
--rw-rw-r--  2.0 unx    15412 b- defN 23-Jun-12 14:45 k1lib/serve/main.py
+-rw-rw-r--  2.0 unx    15412 b- defN 23-Jun-30 11:09 k1lib/serve/main.py
 -rw-rw-r--  2.0 unx      153 b- defN 23-May-05 16:00 k1lib/serve/suffix-dash.py
 -rw-rw-r--  2.0 unx      642 b- defN 23-Feb-13 19:00 k1lib/serve/suffix.py
--rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.4.1.data/data/k1lib/k1ui/256.model.state_dict.pth
--rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.4.1.data/data/k1lib/k1ui/mouseKey.pth
--rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.4.1.data/data/k1lib/serve/main.html
--rw-rw-r--  2.0 unx     1049 b- defN 23-Jun-12 14:45 k1lib-1.4.1.dist-info/LICENSE
--rw-rw-r--  2.0 unx     3888 b- defN 23-Jun-12 14:45 k1lib-1.4.1.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jun-12 14:45 k1lib-1.4.1.dist-info/WHEEL
--rw-rw-r--  2.0 unx        6 b- defN 23-Jun-12 14:45 k1lib-1.4.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6698 b- defN 23-Jun-12 14:45 k1lib-1.4.1.dist-info/RECORD
-84 files, 3977195 bytes uncompressed, 2578384 bytes compressed:  35.2%
+-rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.4.2.data/data/k1lib/k1ui/256.model.state_dict.pth
+-rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.4.2.data/data/k1lib/k1ui/mouseKey.pth
+-rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.4.2.data/data/k1lib/serve/main.html
+-rw-rw-r--  2.0 unx     1049 b- defN 23-Jun-30 11:19 k1lib-1.4.2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3888 b- defN 23-Jun-30 11:19 k1lib-1.4.2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-30 11:19 k1lib-1.4.2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        6 b- defN 23-Jun-30 11:19 k1lib-1.4.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6700 b- defN 23-Jun-30 11:19 k1lib-1.4.2.dist-info/RECORD
+84 files, 4014070 bytes uncompressed, 2588183 bytes compressed:  35.5%
```

## zipnote {}

```diff
@@ -222,32 +222,32 @@
 
 Filename: k1lib/serve/suffix-dash.py
 Comment: 
 
 Filename: k1lib/serve/suffix.py
 Comment: 
 
-Filename: k1lib-1.4.1.data/data/k1lib/k1ui/256.model.state_dict.pth
+Filename: k1lib-1.4.2.data/data/k1lib/k1ui/256.model.state_dict.pth
 Comment: 
 
-Filename: k1lib-1.4.1.data/data/k1lib/k1ui/mouseKey.pth
+Filename: k1lib-1.4.2.data/data/k1lib/k1ui/mouseKey.pth
 Comment: 
 
-Filename: k1lib-1.4.1.data/data/k1lib/serve/main.html
+Filename: k1lib-1.4.2.data/data/k1lib/serve/main.html
 Comment: 
 
-Filename: k1lib-1.4.1.dist-info/LICENSE
+Filename: k1lib-1.4.2.dist-info/LICENSE
 Comment: 
 
-Filename: k1lib-1.4.1.dist-info/METADATA
+Filename: k1lib-1.4.2.dist-info/METADATA
 Comment: 
 
-Filename: k1lib-1.4.1.dist-info/WHEEL
+Filename: k1lib-1.4.2.dist-info/WHEEL
 Comment: 
 
-Filename: k1lib-1.4.1.dist-info/top_level.txt
+Filename: k1lib-1.4.2.dist-info/top_level.txt
 Comment: 
 
-Filename: k1lib-1.4.1.dist-info/RECORD
+Filename: k1lib-1.4.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## k1lib/_basics.py

```diff
@@ -1,16 +1,16 @@
 # AUTOGENERATED FILE! PLEASE DON'T EDIT HERE. EDIT THE SOURCE NOTEBOOKS INSTEAD
-import logging, warnings, os, time, re, json, k1lib, importlib, urllib.parse, math, base64, dill
+import logging, warnings, os, time, re, json, k1lib, importlib, urllib.parse, math, base64, dill, inspect, threading, datetime
 import numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
 from typing import Any, List, Union, Tuple, Iterator, Dict
 from functools import partial
 try: import torch; hasTorch = True
 except: hasTorch = False
 __all__ = ["_docsUrl", "isNumeric",
-           "patch", "wrapMod", "wraps", "squeeze", "raiseEx",
+           "patch", "cron", "wrapMod", "wraps", "squeeze", "raiseEx",
            "numDigits", "limitLines",
            "limitChars", "showLog", "cleanDiv",
            "beep", "beepOnAvailable", "dontWrap",
            "debounce", "scaleSvg", "now", "pushNotification", "dep", "ticks", "digraph", "graph",
            "encode", "decode", "hash"]
 _docsUrl = "https://k1lib.com"
 def isNumeric(x) -> bool:                                                        # isNumeric
@@ -69,14 +69,59 @@
         if _docs is not None and not isinstance(_docs, str): _docs = _docs.__doc__ # patch
         _docs = _docs or function.__doc__ or _class.__doc__                      # patch
         _name = name or function.__qualname__.split(".")[-1]                     # patch
                                                                                  # patch
         _function = staticmethod(function) if static else function               # patch
         _function.__doc__ = _docs; setattr(_class, _name, _function); return _function # patch
     return inner                                                                 # patch
+def cron(f):                                                                     # cron
+    """Sets up a cron job in another thread, running the decorated
+function whenever ``f`` goes from False to True. Example::
+
+    @k1.cron(lambda minute: minute == 0)
+    def f1(): # runs every hour
+        ... # do some stuff
+
+    @k1.cron(lambda second: second % 5 == 0)
+    def f2(): # runs every 5 seconds
+        ... # do some stuff
+
+So, the first function will run every hour, and the second function will
+run every 5 seconds. Pretty straightforward. The timing function ``f`` can
+be as complicated as you want, but it can only accept the following parameters:
+
+- year
+- month: 1-12
+- day: 1-31
+- weekday: 0-6, 0 for Monday
+- hour: 0-23
+- minute: 0-59
+- second: 0-59"""                                                                # cron
+    def inner(func):                                                             # cron
+        args = list(inspect.signature(f).parameters.keys())                      # cron
+        s = {"year", "month", "day", "weekday", "hour", "minute", "second"}      # cron
+        for arg in args:                                                         # cron
+            if arg not in s: raise Exception(f"Unknown argument {arg}. Only (year, month, day, weekday, hour, minute, seconds) are allowed") # cron
+        def startLoop():                                                         # cron
+            last = False; this = last                                            # cron
+            while True:                                                          # cron
+                a = datetime.datetime.now()                                      # cron
+                now = {"year": a.year, "month": a.month, "day": a.day, "weekday": a.weekday(), "hour": a.hour, "minute": a.minute, "second": a.second} # cron
+                this = f(*[now[e] for e in args])                                # cron
+                if not last and this: func()                                     # cron
+                last = this; time.sleep(0.5)                                     # cron
+        threading.Thread(target=startLoop).start()                               # cron
+    return inner                                                                 # cron
+def cron(f):                                                                     # cron
+    """Sets up a cron job in another thread, activating whenever ``f`` goes from False to True.
+Example::
+
+
+"""                                                                              # cron
+    pass                                                                         # cron
 class wrapMod:                                                                   # wrapMod
     def __init__(self, m, moduleName=None):                                      # wrapMod
         """Wraps around a module, and only suggest symbols in __all__ list
 defined inside the module. Example::
 
     from . import randomModule
     randomModule = wrapMod(randomModule)
```

## k1lib/_monkey.py

```diff
@@ -531,7 +531,32 @@
     Progress: 100% | 100% | 100% | 100% | 100%
 
 :param n: number of progresses to keep track of
 :param title: title of the progress to show"""                                   # dummy
         rp = RayProgress.remote(n); startRayProgressThread(rp, title); yield rp  # dummy
         ray.get(rp.stop.remote()); time.sleep(0.1)                               # dummy
 except: pass                                                                     # dummy
+@k1lib.patch(np)                                                                 # dummy
+def gather(self, dim, index):                                                    # gather
+    """Gathers values along an axis specified by ``dim``.
+
+For a 3-D tensor the output is specified by::
+
+    out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0
+    out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1
+    out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2
+
+Not my code. All credits go to https://stackoverflow.com/questions/46868056/how-to-gather-elements-of-specific-indices-in-numpy
+
+:param dim: the axis along which to index
+:param index: A tensor of indices of elements to gather"""                       # gather
+    idx_xsection_shape = index.shape[:dim] + index.shape[dim + 1:]               # gather
+    self_xsection_shape = self.shape[:dim] + self.shape[dim + 1:]                # gather
+    if idx_xsection_shape != self_xsection_shape: raise ValueError("Except for dimension " + str(dim) + ", all dimensions of index and self should be the same size") # gather
+    if index.dtype != np.dtype('int_'): raise TypeError("The values of index must be integers") # gather
+    data_swaped = np.swapaxes(self, 0, dim); index_swaped = np.swapaxes(index, 0, dim) # gather
+    gathered = np.choose(index_swaped, data_swaped); return np.swapaxes(gathered, 0, dim) # gather
+try:                                                                             # gather
+    import forbiddenfruit                                                        # gather
+    def expand(self, sh): return np.broadcast_to(self, sh)                       # gather
+    forbiddenfruit.curse(np.ndarray, "expand", expand)                           # gather
+except: pass                                                                     # gather
```

## k1lib/imports.py

```diff
@@ -69,7 +69,9 @@
 except: pass                                                                     # dummy
 try: import plotly; import plotly.express as px                                  # dummy
 except: pass                                                                     # dummy
 try: import graphviz                                                             # dummy
 except: pass                                                                     # dummy
 try: import line_profiler; line_profiler.load_ipython_extension(IPython.get_ipython()) # dummy
 except: pass                                                                     # dummy
+try: import cython; cython.load_ipython_extension(IPython.get_ipython())         # dummy
+except: pass                                                                     # dummy
```

## k1lib/viz.py

```diff
@@ -169,60 +169,51 @@
                 if lx != None: _x = [lx] + _x; _y = [ly] + _y                    # plotSegments
                 plt.plot(_x, _y, colors[state]); lx = _x[-1]; ly = _y[-1]        # plotSegments
             _x = [x[count]]; _y = [y[count]]; state = states[count]              # plotSegments
         else: _x.append(x[count]); _y.append(y[count])                           # plotSegments
     if len(_x) > 0 and state >= 0:                                               # plotSegments
         if lx != None: _x = [lx] + _x; _y = [ly] + _y                            # plotSegments
         plt.plot(_x, _y, colors[state])                                          # plotSegments
-class Carousel:                                                                  # Carousel
-    _idx = k1lib.AutoIncrement.random()                                          # Carousel
-    def __init__(self, imgs=[]):                                                 # Carousel
-        """Creates a new Carousel. You can then add images and whatnot.
-Will even work even when you export the notebook as html. Example::
-
-    c = viz.Carousel()
-    x = np.linspace(-2, 2); plt.plot(x, x ** 2); plt.gcf() | toImg() | c
-    x = np.linspace(-1, 3); plt.plot(x, x ** 2); plt.gcf() | toImg() | c
-    "<h1>abc</h1><div>Some content</div>" | c # can add html
-    c # displays in notebook cell
-
-.. image:: images/carousel.png
-
-You can also pipe the content into it like this::
-
-    ["abc", "def"] | viz.Carousel()
-    ["abc", "def"] | aS(viz.Carousel) # also valid, but kinda outdated and unintuitive
-
-:param imgs: List of initial images. Can add more images later on by using :meth:`__ror__`
-"""                                                                              # Carousel
-        self.imgs:List[Tuple[str, str]] = [] # Tuple[format, base64 img]         # Carousel
-        self.defaultFormat = "jpeg"                                              # Carousel
-        for im in imgs: im | self                                                # Carousel
-    def __ror__(self, d):                                                        # Carousel
-        """Adds an image/html content to the collection"""                       # Carousel
-        if isinstance(d, str): self.imgs.append(k1lib.encode(f"{d}"))            # Carousel
-        elif hasPIL and isinstance(d, PIL.Image.Image):                          # Carousel
-            self.imgs.append(k1lib.encode(f"<img alt='' style='max-width: 100%' src='data:image/png;base64, {base64.b64encode(d | cli.toBytes()).decode()}' />")) # Carousel
-        else:                                                                    # Carousel
-            try:                                                                 # Carousel
-                for e in d: e | self                                             # Carousel
-            except Exception as e: warnings.warn("Tried to add html/image to Carousel but can't due to this error"); raise e # Carousel
-        return self                                                              # Carousel
-    def pop(self):                                                               # Carousel
-        """Pops last image"""                                                    # Carousel
-        return self.imgs.pop()                                                   # Carousel
-    def __getitem__(self, idx): return self.imgs[idx]                            # Carousel
-    def _repr_html_(self):                                                       # Carousel
-        idx = Carousel._idx()                                                    # Carousel
-        pre = f"k1c_{idx}"                                                       # Carousel
-        imgs = self.imgs | cli.op().replace("`", "\`").all() | cli.apply(lambda x: f"`{x}`") | cli.deref() # Carousel
-        n = len(imgs)                                                            # Carousel
-        if n > 0: contents = imgs | cli.apply(k1lib.decode) | cli.insertIdColumn() | ~cli.apply(lambda idx, html: f"<div id='{pre}_content{idx}'>{html}</div>") | cli.deref() | cli.join('\n') # Carousel
-        else: contents = "(no pages or images are found)"                        # Carousel
-        #imgs = [f"\"<img alt='' src='data:image/{fmt};base64, {img}' />\"" for fmt, img in self.imgs] # Carousel
+class _Carousel:                                                                 # _Carousel
+    _idx = k1lib.AutoIncrement.random()                                          # _Carousel
+    def __init__(self, imgs=[], searchMode:int=0):                               # _Carousel
+        self.imgs:List[Tuple[str, str]] = [] # Tuple[format, base64 img]         # _Carousel
+        self.defaultFormat = "jpeg"                                              # _Carousel
+        self.searchMode = searchMode                                             # _Carousel
+        self.titles = []; imgs | self                                            # _Carousel
+    def _process(self, e):                                                       # _Carousel
+        if isinstance(e, str): return f"{e}"                                     # _Carousel
+        elif hasPIL and isinstance(e, PIL.Image.Image):                          # _Carousel
+            return f"<img alt='' style='max-width: 100%' src='data:image/png;base64, {base64.b64encode(e | cli.toBytes()).decode()}' />" # _Carousel
+        else: raise Exception(f"Content is not a string nor a PIL image. Can't make a Carousel out of this unknown type: {type(e)}") # _Carousel
+    def __ror__(self, it):                                                       # _Carousel
+        """Adds an image/html content to the collection"""                       # _Carousel
+        searchMode = self.searchMode                                             # _Carousel
+        if searchMode == 0 or searchMode == 1:                                   # _Carousel
+            for e in it: self.imgs.append(k1lib.encode(self._process(e)))        # _Carousel
+        elif searchMode == 2:                                                    # _Carousel
+            for title, e in it:                                                  # _Carousel
+                if not isinstance(title, str): raise Exception("Title is not a string. Can't perform search") # _Carousel
+                self.imgs.append(k1lib.encode(title+self._process(e)))           # _Carousel
+                self.titles.append(k1lib.encode(title))                          # _Carousel
+        else: raise Exception(f"Invalid searchMode: {searchMode}")               # _Carousel
+        return self                                                              # _Carousel
+    def pop(self):                                                               # _Carousel
+        """Pops last image"""                                                    # _Carousel
+        return self.imgs.pop()                                                   # _Carousel
+    def __getitem__(self, idx): return self.imgs[idx]                            # _Carousel
+    def _repr_html_(self):                                                       # _Carousel
+        idx = _Carousel._idx(); pre = f"k1c_{idx}"; searchMode = self.searchMode # _Carousel
+        imgs = self.imgs | cli.apply(lambda x: f"`{x}`") | cli.deref(); n = len(imgs) # _Carousel
+        titles = self.titles | cli.apply(lambda x: f"`{x}`") | cli.deref()       # _Carousel
+        if searchMode > 0: searchBar = f"<input type='text' value='' id='{pre}_search' placeholder='Search in {'content' if searchMode == 1 else 'header'}' style='padding: 4px 4px'>" # _Carousel
+        else: searchBar = ""                                                     # _Carousel
+        if n > 0: contents = imgs | cli.apply(k1lib.decode) | cli.insertIdColumn() | ~cli.apply(lambda idx, html: f"<div id='{pre}_content{idx}'>{html}</div>") | cli.deref() | cli.join('\n') # _Carousel
+        else: contents = "(no pages or images are found)"                        # _Carousel
+        #imgs = [f"\"<img alt='' src='data:image/{fmt};base64, {img}' />\"" for fmt, img in self.imgs] # _Carousel
         html = f"""<!-- k1lib.Carousel -->
 <style>
     .{pre}_btn {{
         cursor: pointer;
         padding: 6px 12px;
         /*background: #9e9e9e;*/
         background-color: #eee;
@@ -236,48 +227,111 @@
     }}
     .{pre}_btn:hover {{
         box-shadow: box-shadow: 0 3px 10px rgb(0,0,0,0.6);
         background: #4caf50;
         color: #fff;
     }}
 </style>
+{searchBar}
 <div>
     <div style="display: flex; flex-direction: row; padding: 8px">
         <div id="{pre}_prevBtn" class="{pre}_btn">Prev</div>
         <div id="{pre}_nextBtn" class="{pre}_btn">Next</div>
     </div>
     <div id="{pre}_status" style="padding: 10px"></div>
 </div>
 <div id="{pre}_imgContainer">
     {contents}
 </div>
 <script>
-    {pre}_imgs = [{','.join(imgs)}];
-    {pre}_imgIdx = 0;
+    const {pre}_allImgs = [{','.join(imgs)}];
+    let {pre}_imgs = [...Array({pre}_allImgs.length).keys()]; // index of all available images. If searching for something then it will be a subset of allImgs
+    const {pre}_titles = [{','.join(titles)}];
+    {pre}_imgIdx = 0; // n-th element of pre_imgs, not of pre_allImgs
+    {pre}_searchMode = {searchMode};
+    function {pre}_show(i) {{ // i here is allImgs index, not of imgs
+        document.querySelector(`#{pre}_content${{i}}`).style.display = "block";
+    }}
+    function {pre}_hide(i) {{ // i here is allImgs index, not of imgs
+        document.querySelector(`#{pre}_content${{i}}`).style.display = "none";
+    }}
+    function {pre}_updatePageCount() {{
+        let n = {pre}_imgs.length;
+        if (n > 0) document.querySelector("#{pre}_status").innerHTML = "Page: " + ({pre}_imgIdx + 1) + "/" + n;
+        else document.querySelector("#{pre}_status").innerHTML = "Page: 0/0"
+    }}
     function {pre}_display() {{
-        //document.querySelector("#{pre}_imgContainer").innerHTML = window.atob({pre}_imgs[{pre}_imgIdx]);
-        for (let i = 0; i < {n}; i++) {{
-            document.querySelector(`#{pre}_content${{i}}`).style.display = "none";
-        }}
-        document.querySelector(`#{pre}_content${{{pre}_imgIdx}}`).style.display = "block";
-        document.querySelector("#{pre}_status").innerHTML = "Page: " + ({pre}_imgIdx + 1) + "/" + {pre}_imgs.length;
+        let n = {pre}_imgs.length;
+        for (let i = 0; i < {n}; i++) {pre}_hide(i);
+        if (n > 0) {pre}_show({pre}_imgs[{pre}_imgIdx]);
+        {pre}_updatePageCount();
     }};
     document.querySelector("#{pre}_prevBtn").onclick = () => {{
         {pre}_imgIdx -= 1;
         {pre}_imgIdx = Math.max({pre}_imgIdx, 0);
         {pre}_display();
     }};
     document.querySelector("#{pre}_nextBtn").onclick = () => {{
         {pre}_imgIdx += 1;
         {pre}_imgIdx = Math.min({pre}_imgIdx, {pre}_imgs.length - 1);
         {pre}_display();
     }};
+    if ({pre}_searchMode > 0) {{
+        {pre}_searchInp = document.querySelector("#{pre}_search");
+        {pre}_searchInp.oninput = (value) => {{
+            const val = {pre}_searchInp.value;
+            {pre}_imgs = ({pre}_searchMode === 1 ? {pre}_allImgs : {pre}_titles).map((e, i) => [window.atob(e).includes(val), i]).filter(e => e[0]).map(e => e[1]);
+            {pre}_imgIdx = 0;; {pre}_display();
+        }}
+    }}
     {pre}_display();
-</script>"""                                                                     # Carousel
-        return html                                                              # Carousel
+</script>"""                                                                     # _Carousel
+        return html                                                              # _Carousel
+def Carousel(imgs=None, searchMode=0):                                           # Carousel
+    """Creates a new Carousel. You can then add images and whatnot.
+Will even work even when you export the notebook as html. Example::
+
+    c = viz.Carousel()
+    x = np.linspace(-2, 2); plt.plot(x, x ** 2); im1 = plt.gcf() | toImg()
+    x = np.linspace(-1, 3); plt.plot(x, x ** 2); im2 - plt.gcf() | toImg()
+    im3 = "<h1>abc</h1><div>Some content</div>" # can add html
+    viz.Carousel([im1, im2, im3]) # displays in notebook cell
+    [im1, im2, im3] | viz.Carousel() # also displays in notebook cell
+
+.. image:: images/carousel.png
+
+You can also pipe the content into it like this::
+
+    ["abc", "def"] | viz.Carousel()
+    ["abc", "def"] | aS(viz.Carousel) # also valid, but kinda outdated and unintuitive
+
+There's also a builtin search functionality that works like this::
+
+    [
+        "<h1>abc</h1><div>Some content 1</div>",
+        "<h1>def</h1><div>Some other content 2</div>",
+        "<h1>ghi</h1><div>Another content 3</div>",
+    ] | Carousel(searchMode=1)
+
+    [
+        ["<h1>abc</h1>", "<div>Some content 1</div>"],
+        ["<h1>def</h1>", "<div>Some other content 2</div>"],
+        ["<h1>ghi</h1>", "<div>Another content 3</div>"],
+    ] | Carousel(searchMode=2)
+
+The first mode will search for some text inside the html content. The second mode
+will search inside the title only, that means it's expecting to receive Iterator[title, html/img]
+
+:param imgs: List of initial images. Can add more images later on by using :meth:`__ror__`
+:param searchMode: 0 for no search, accepts Iterator[html/img],
+    1 for search content, accepts Iterator[html/img],
+    2 for search title, accepts Iterator[title, html/img]
+"""                                                                              # Carousel
+    if imgs is None: return cli.aS(_Carousel, searchMode)                        # Carousel
+    else: return _Carousel(imgs, searchMode)                                     # Carousel
 class Toggle(cli.BaseCli):                                                       # Toggle
     _idx = k1lib.AutoIncrement.random()                                          # Toggle
     def __init__(self):                                                          # Toggle
         """Button to toggle whether the content is displayed or
 not. Useful if the html content is very big in size. Example::
 
     x = np.linspace(-2, 2); plt.plot(x, x ** 2)
```

## k1lib/cli/__init__.py

```diff
@@ -20,15 +20,15 @@
 from .bio import *
 from .mol import *
 from . import mgi;  mgi  = _wrapMod(mgi)
 from . import cif;  #cif  = _wrapMod(cif)
 
 # file formats
 from . import kxml; kxml = _wrapMod(kxml)
-from . import kcsv; kcsv = _wrapMod(kcsv)
+from . import kcsv; #kcsv = _wrapMod(kcsv)
 from . import sam;  sam  = _wrapMod(sam)
 from . import gb;   gb   = _wrapMod(gb)
 from . import nb;   nb   = _wrapMod(nb)
 
 from .optimizations import *
 from .trace import * # has to be last, to wait for others to load up
```

## k1lib/cli/_applyCl.py

```diff
@@ -110,21 +110,21 @@
     return a | lookup(idx2FileName, 2) | deref()                                 # traj2
 # def moveFile(fileName:str, sourceNodeId:str, destNodeId:str, timeout=60): # old, slow, corrupted version # traj2
 #     """Moves file from the current node to the destination node. Usually executed on other nodes than the driver node""" # traj2
 #     fn = os.path.expanduser(fileName); dirname = os.path.dirname(fn)           # traj2
 #     applyCl.cmd(f"mkdir -p {dirname}", nodeIds=[destNodeId]); applyCl.cmd(f"rm -f {fn}", nodeIds=[destNodeId]) # traj2
 #     for chunk in cat(fn, False, True): [destNodeId] | applyCl.aS(lambda: chunk >> file(fn), timeout=timeout) | deref() # traj2
 #     None | cmd(f"rm {fn}") | deref(); return "ok1"                             # traj2
-def moveFile(fn:str, sourceN:str, destN:str, timeout=60): # runs on dest node    # moveFile
+def moveFile(fn:str, sourceN:str, destN:str, timeout=None): # runs on dest node  # moveFile
     fn = os.path.expanduser(fn); dirname = os.path.dirname(fn)                   # moveFile
     applyCl.cmd(f"mkdir -p {dirname}; rm -f {fn}", nodeIds=[destN]);             # moveFile
-    windows = [sourceN] | applyCl.aS(lambda: range(os.path.getsize(fn)) | batched(settings.cli.cat.chunkSize, True) | apply("[x.start, x.stop]") | deref(), num_cpus=0.2, timeout=60) | cut(1) | item() | deref() # moveFile
-    for chunk in [[sourceN]*len(windows), windows] | transpose() | ~applyCl(lambda sB,eB: cat(fn, False, sB=sB, eB=eB), pre=True, prefetch=20, num_cpus=0.2, timeout=60) | cut(1): chunk >> file(fn) # moveFile
+    windows = [sourceN] | applyCl.aS(lambda: range(os.path.getsize(fn)) | batched(settings.cli.cat.chunkSize, True) | apply("[x.start, x.stop]") | deref(), num_cpus=0.2, timeout=timeout) | cut(1) | item() | deref() # moveFile
+    for chunk in [[sourceN]*len(windows), windows] | transpose() | ~applyCl(lambda sB,eB: cat(fn, False, sB=sB, eB=eB), pre=True, prefetch=20, num_cpus=0.2, timeout=timeout) | cut(1): chunk >> file(fn) # moveFile
     applyCl.cmd(f"rm {fn}", nodeIds=[sourceN])                                   # moveFile
-def moveFF(ff:str, sourceN:str, destN:str, timeout=60): # runs on dest node      # moveFF
+def moveFF(ff:str, sourceN:str, destN:str, timeout=None): # runs on dest node    # moveFF
     """Moves file or folder from the current node to the destination node"""     # moveFF
     ff = os.path.expanduser(ff); isfile = [sourceN] | applyCl.aS(lambda: os.path.isfile(ff)) | cut(1) | item() # moveFF
     if isfile: return moveFile(ff, sourceN, destN, timeout)                      # moveFF
     [sourceN] | applyCl.aS(lambda: ff | getFilesInFolder | deref(), timeout=timeout) | cut(1) | item() | apply(aS(moveFile, sourceN, destN, timeout)) | deref() # moveFF
     applyCl.cmd(f"rm -rf {ff}", nodeIds=[sourceN])                               # moveFF
 def moveAll(tr, bs=5, timeout=None):                                             # moveAll
     groups = tr | groupBy(1) | deref() # grouping by destination                 # moveAll
@@ -200,54 +200,69 @@
     nodeIds = applyCl.nodeIds(); nodeId_cpu = loadTestGuard(False).items() | deref(); nodeId2Cpu = nodeId_cpu | toDict() # spreadOut
     sizes = nAs | applyCl.aS(lambda: os.path.getsize(fn) if os.path.exists(fn) else 0) | deref(); totalSize = sizes | cut(1) | toSum() # spreadOut
     ns = [*nAs, *nBs]; totalCpu = ns | lookup(nodeId2Cpu) | toSum(); bytePerCpu = totalSize/totalCpu; wsB = nBs | lookup(nodeId2Cpu) | deref() # spreadOut
     # prepares segments and metadata, List[nodeId, [sB, eB]], where sB and eB are the ranges of nAs that they're willing to share # spreadOut
     sizePost = sizes | ~apply(lambda idx, size: [idx, nodeId2Cpu[idx]/totalCpu*totalSize/size]) | deref() # size fraction to retain # spreadOut
     invalidNodes = sizePost | ~filt(lambda x: 0 <= x <= 1, 1) | cut(0) | deref() # spreadOut
     if len(invalidNodes) > 0: raise Exception(f"Unsupported configuration! These nodes have too little data to share: {invalidNodes}. This couldn't have happen using applyCl alone. Data is not corrupted, but you'll have to combine data from all files into 1 and spread them back out again.") # spreadOut
-    inter = sizePost | ~apply(lambda idx, x: [idx, [x, 1-x]]) | applyCl(lambda ws: fn | splitSeek(ws=ws) | rS | ~head(1), pre=True) | deref() | filt(~aS(lambda x,y: y-x>0), 1) | deref() # filter at the end to eliminate files that don't want to share anything (x == y) # spreadOut
+    inter = sizePost | ~apply(lambda idx, x: [idx, [x, 1-x]]) | applyCl(lambda ws: fn | splitSeek(ws=ws) | rS | ~head(1), pre=True, timeout=None) | deref() | filt(~aS(lambda x,y: y-x>0), 1) | deref() # filter at the end to eliminate files that don't want to share anything (x == y) # spreadOut
     # actually transferring data to new nodes                                    # spreadOut
     meta = inter | apply(~aS(range) | splitW(*wsB) | ranges2Seeks | apply(lambda x: splitSeek.backward(fn, x)) | deref() | rS | window(2) | deref() | apply(wrapList()) | insertColumn(nBs), 1) | ungroup(False) | groupBy(1, True) | deref() # spreadOut
     with ray.progress(len(meta), "Transferring data to new nodes") as rp:        # spreadOut
         meta | insertIdColumn(True) | applyTh(~aS(lambda idx, nB, nse: a_transfer(fn, nse, nB, rpF=aS(lambda p: ray.get(rp.update.remote(idx, p))))), timeout=24*3600) | deref() # spreadOut
     # truncates the files in nAs nodes                                           # spreadOut
     inter | ~apply(lambda idx,se: [idx,se[0]]) | applyCl(lambda sB: open(fn, 'a').truncate(sB), pre=True, timeout=None) | deref() # spreadOut
 def balanceFile(fn:str, nAs:List[str]=None, nBs:List[str]=None, rS=None):        # balanceFile
     fn = os.path.expanduser(fn); rS = rS or refineSeek(); rS.injectFn(fn); loadTestGuard() # balanceFile
     if nAs is None: nAs = None | applyCl.aS(lambda: os.path.exists(fn)) | filt(op(), 1) | cut(0) | deref() # balanceFile
     if nBs is None: nBs = applyCl.nodeIds()                                      # balanceFile
     decommission(fn, *nAs | inSet(nBs).split() | reverse(), rS)                  # balanceFile
     spreadOut(fn, *nBs | inSet(nAs).split(), rS)                                 # balanceFile
-def diskScan1(base:str) -> List[str]: # like ls(), but returns files and folders that appear at least on 2 nodes # diskScan1
+def diskScan1(base:str) -> List[str]: # like ls(), but returns files and folders that appear at least on 2 nodes. No recursion # diskScan1
     isdir, base = base.split("\ue000")                                           # diskScan1
     if not isdir: return []                                                      # diskScan1
     return None | applyCl.aS(lambda: base | (tryout([]) | ls() | apply(os.path.isdir) & iden() | transpose() | ~apply(lambda x,y: f"{x*1}\ue000{y}")) | deref(), timeout=60) | cut(1) | joinStreams() | count() | filt(op()>1, 0) | cut(1) | deref() # diskScan1
 def diskScan2(base:str) -> Tuple[List[str], List[str]]: # returns list of distributed folders and list of distributed files # diskScan2
-    dFolders = []; folders, files = diskScan1(base) | op().split("\ue000").all() | toInt(0) | filt(op(), 0).split() | (join("\ue000")).all(2) | deref() # diskScan2
+    dFolders = []; folders, files = diskScan1(base) | op().split("\ue000").all() | toInt(0) | filt(op(), 0).split() | (join("\ue000")).all(2) | deref() # first explore this directory # diskScan2
     # print("2--", folders, files, base)                                         # diskScan2
-    for folder in folders:                                                       # diskScan2
+    for folder in folders: # then recursively explore inside directories         # diskScan2
         fol, fil = diskScan2(folder); dFolders.extend(fol); files.extend(fil)    # diskScan2
         if len(fol) + len(fil) == 0: dFolders.append(folder) # no shared contents, must be a distributed folder # diskScan2
         else: files.extend(fil)                                                  # diskScan2
     # print("3--", [dFolders, files], base)                                      # diskScan2
     return [dFolders, files]                                                     # diskScan2
-def diskScan3(base:str): base = os.path.expanduser(base); return diskScan2(f"1\ue000{base}") | op().split("\ue000")[1].all(2) | deref() # diskScan3
 def getFolderSize2(folder:str):                                                  # getFolderSize2
     folder = os.path.expanduser(folder)                                          # getFolderSize2
     return None | cmd(f"du -s {folder}") | table() | cut(0) | item() | aS(int) | op()*1024 # getFolderSize2
+def diskScan3(base:str, accurate=False):                                         # diskScan3
+    base = os.path.expanduser(base); folders, files = diskScan2(f"1\ue000{base}") | op().split("\ue000")[1].all(2) | apply(set) | apply(list) | aS(list) # getting rid of all file/folder flags # diskScan3
+    getFZ = getFolderSize if accurate else getFolderSize2                        # diskScan3
+    folders = [folders, None | applyCl.aS(lambda: folders | apply(lambda x: getFZ(x)           if os.path.exists(x) else 0) | deref(), timeout=300) | cut(1) | transpose()] | transpose() | deref() # diskScan3
+    files   = [files,   None | applyCl.aS(lambda: files   | apply(lambda x: os.path.getsize(x) if os.path.exists(x) else 0) | deref(), timeout=300) | cut(1) | transpose()] | transpose() | deref() # diskScan3
+    # this section below tries to squeeze out replicatedFolders from a bunch of replicatedFiles. The exact mechanism involved may seem like magic to you, but it seems to work # diskScan3
+    balancedFolders = folders; replicatedFiles, balancedFiles = files | filt(filt("x") | aS(set) | shape(0) | (op() == 1), 1).split() | deref() # diskScan3
+    f1 = iden() & apply(os.path.dirname) | joinStreams() | aS(set)               # diskScan3
+    excludedFolders = balancedFolders | cut(0) | serial(*[f1]*100) | aS(set)     # diskScan3
+    f = iden() & apply(os.path.dirname) | joinStreams() | ~inSet(excludedFolders); elims = []; i = 0 # diskScan3
+    a = replicatedFiles | cut(0) | apply(os.path.dirname) | serial(*[f]*30) | aS(set) | sort(None, False) | aS(list) # diskScan3
+    while i < len(a): # trying to eliminate child directories, so that replicatedFolders work recursively. Doing this weird index loop so that time complexity is O(n*log(n)) instead of O(n^2) # diskScan3
+        j = i+1                                                                  # diskScan3
+        while j < len(a) and a[j].startswith(a[i]): elims.append(a[j]); j += 1   # diskScan3
+        i = j                                                                    # diskScan3
+    candidates = a | ~inSet(elims) | deref() # replicatedFolder candidates. Has to reverify that total folder size is the same before declaring it a replicated folder. Yes, this is not the same as each individual files are the same, and I can imagine an edge case that will trip this up, but it's so damn rare and I'm so lazy that I'm sticking with this version # diskScan3
+    replicatedFolders = [candidates, None | applyCl.aS(lambda: candidates | apply(lambda x: getFolderSize(x) if os.path.exists(x) else 0) | deref()) | cut(1) | transpose()] | transpose() | apply(filt("x") | aS(set) | shape(0) | aS("x == 1"), 1) | filt("x", 1) | cut(0) | deref() # diskScan3
+    replicatedFiles = replicatedFiles | ~filt(lambda fn: replicatedFolders | filt(lambda folder: fn.startswith(f"{folder}/")) | shape(0), 0) | deref() # diskScan3
+    replicatedFolders = [replicatedFolders, None | applyCl.aS(lambda: replicatedFolders | apply(lambda x: getFZ(x) if os.path.exists(x) else 0) | deref()) | cut(1) | transpose()] | transpose() | deref() # diskScan3
+    return balancedFolders, replicatedFolders, balancedFiles, replicatedFiles    # diskScan3
 def diskScan4(base:str, sortSize=True, accurate=False): # fully featured data    # diskScan4
-    folders, files = diskScan3(base)                                             # diskScan4
-    getFZ = getFolderSize if accurate else getFolderSize2                        # diskScan4
-    folders = [folders, None | applyCl.aS(lambda: folders | apply(lambda x: getFZ(x) if os.path.exists(x) else 0) | deref(), timeout=300) | cut(1) | transpose()] | transpose() | deref() # diskScan4
-    files   = [files,   None | applyCl.aS(lambda: files   | apply(lambda x: os.path.getsize(x) if os.path.exists(x) else 0) | deref(), timeout=300) | cut(1) | transpose()] | transpose() | deref() # diskScan4
-    post = apply(~sortF(toSum(), 1)) if sortSize else iden()                     # diskScan4
-    return [folders, files] | wrapList() + filt(filt(op() > 0) | count() | shape(0) | (op() == 1), 1).split() | joinStreams() | apply(unique(0)) | post | deref() # diskScan4
-def diskScan5(base:str, sortSize=True, accurate=False): # displays it in a nice format # diskScan5
-    d4 = diskScan4(base, sortSize, accurate); lens = d4 | apply(len) | deref(); nodeNames = None | applyCl.aS(lambda: os.cpu_count()) | apply(op()[:5], 0) | apply('f"{x} thr"', 1) | join(", ").all() | deref(); nodeNames # diskScan5
+    return diskScan3(base, accurate) | (apply(~sortF(toSum(), 1)) if sortSize else iden()) | deref() # diskScan4
+def diskScan5(base:str, sortSize=True, accurate=False, f=iden()): # displays it in a nice format # diskScan5
+    d4 = diskScan4(base, sortSize, accurate) | f; lens = d4 | apply(len) | deref(); nodeNames = None | applyCl.aS(lambda: os.cpu_count()) | apply(op()[:5], 0) | apply('f"{x} thr"', 1) | join(", ").all() | deref(); nodeNames # diskScan5
     d5 = d4 | apply(~apply(lambda path, sizes: [path, sizes | toSum() | aS(fmt.size), sizes | apply(fmt.size)]) | insert(["-"*40, "-"*10, ["-"*12]*len(nodeNames)]) | insert(["", "", nodeNames])) | deref(); d5 # diskScan5
     ws = d5 | shape(0).all() | deref()                                           # diskScan5
     d6 = d5 | joinStreams() | cut(0, 1) & (cut(2) | pretty() | wrapList().all()) | transpose() | joinStreams().all() | splitW(*ws) | insert(["Path", "Total size", "Size on each node (node id and thread count)"]).all() | joinStreams() | pretty() | splitW(*ws | apply(op()+1)) | deref() # diskScan5
     explainers = ["\nA distributed folder is a folder that has many files and folders inside, but their names\nare all different from each other. It's managed by applyCl.balanceFolder()", # diskScan5
-                  "\nA replicated file is a file that has been copied to multiple nodes. Size of all file\ncopies should be the same. It's managed by applyCl.replicateFile()", # diskScan5
-                  "\nA distributed file is a file that has been split into multiple pieces and sent to other\nnodes. It's managed by applyCl.balanceFile()"] # diskScan5
-    arr = [d6, ["Distributed folders", "Replicated files", "Distributed files"] | (aS(lambda x: [["-"*60, x, "-"*60] | join(" ")])).all()] | transpose() | permute(1, 0) | (joinStreams() | join("\n")).all() | wrapList() | insert(explainers, False) | transpose() | join("\n").all() | deref() # diskScan5
+                  "\nA replicated folder is a folder that has been copied to multiple nodes. Size of all folder\ncopies should be the same. It's managed by applyCl.replicateFolder()", # diskScan5
+                  "\nA distributed file is a file that has been split into multiple pieces and sent to other\nnodes. It's managed by applyCl.balanceFile()", # diskScan5
+                  "\nA replicated file is a file that has been copied to multiple nodes. Size of all file\ncopies should be the same. It's managed by applyCl.replicateFile()",] # diskScan5
+    arr = [d6, ["Distributed folders", "Replicated folders", "Distributed files", "Replicated files"] | (aS(lambda x: [["="*60, x, "="*60] | join(" ")])).all()] | transpose() | permute(1, 0) | (joinStreams() | join("\n")).all() | wrapList() | insert(explainers, False) | transpose() | join("\n").all() | deref() # diskScan5
     [arr, lens] | transpose() | filt(op(), 1) | cut(0) | join("\n"*2) | wrapList() | stdout() # diskScan5
```

## k1lib/cli/conv.py

```diff
@@ -15,20 +15,20 @@
 __all__ = ["toTensor", "toRange", "toList",
            "toSum", "toProd", "toAvg", "toMean", "toMax", "toMin", "toPIL", "toImg",
            "toRgb", "toRgba", "toGray", "toDict",
            "toFloat", "toInt", "toBytes", "toHtml", "toAscii", "toHash"]
 import re, k1lib, math, os, numpy as np, io, base64, unicodedata
 from k1lib.cli.init import BaseCli, T, yieldT; import k1lib.cli as cli
 from k1lib.cli.typehint import *; import matplotlib as mpl; import matplotlib.pyplot as plt
-from collections import deque; from typing import Iterator, Any, List, Set, Tuple, Dict, Callable, Union
+from collections import deque, defaultdict; from typing import Iterator, Any, List, Set, Tuple, Dict, Callable, Union
 settings = k1lib.settings.cli
 try: import PIL; hasPIL = True
 except: hasPIL = False
 try: import torch; hasTorch = True
-except: torch = k1lib.Object().withAutoDeclare(lambda: type("RandomClass", (object, ), {})); hasTorch = False
+except: torch = k1lib.dep("torch"); hasTorch = False
 try: import rdkit; hasRdkit = True
 except: hasRdkit = False
 try: import graphviz; hasGraphviz = True
 except: hasGraphviz = False
 try: import plotly; import plotly.express as px; hasPlotly = True
 except: hasPlotly = False
 class toTensor(BaseCli):                                                         # toTensor
@@ -95,40 +95,52 @@
     def __init__(self):                                                          # toSum
         """Calculates the sum of list of numbers. Can pipe in :class:`torch.Tensor` or :class:`numpy.ndarray`.
 Example::
 
     # returns 45
     range(10) | toSum()"""                                                       # toSum
         super().__init__()                                                       # toSum
+    def _all_array_opt(self, it, level):                                         # toSum
+        bm = np if isinstance(it, np.ndarray) else (torch if hasTorch and isinstance(it, torch.Tensor) else None) # toSum
+        return NotImplemented if bm is None else bm.sum(it, tuple(range(level, len(it.shape)))) # toSum
     def _typehint(self, inp): return genericTypeHint(inp)                        # toSum
     def __ror__(self, it:Iterator[float]):                                       # toSum
         if isinstance(it, settings.arrayTypes): return it.sum()                  # toSum
         return sum(it)                                                           # toSum
 class toProd(BaseCli):                                                           # toProd
     def __init__(self):                                                          # toProd
         """Calculates the product of a list of numbers. Can pipe in :class:`torch.Tensor` or :class:`numpy.ndarray`.
 Example::
 
     # returns 362880
     range(1,10) | toProd()"""                                                    # toProd
         super().__init__()                                                       # toProd
+    def _all_array_opt(self, it, level):                                         # toProd
+        if isinstance(it, np.ndarray): return np.prod(it, tuple(range(level, len(it.shape)))) # toProd
+        elif hasTorch and isinstance(it, torch.Tensor):                          # toProd
+            for i in range(level, len(it.shape)): it = torch.prod(it, level)     # toProd
+            return it                                                            # toProd
+        return NotImplemented                                                    # toProd
     def _typehint(self, inp): return genericTypeHint(inp)                        # toProd
     def __ror__(self, it):                                                       # toProd
         if isinstance(it, settings.arrayTypes): return it.prod()                 # toProd
         else: return math.prod(it)                                               # toProd
 class toAvg(BaseCli):                                                            # toAvg
     def __init__(self):                                                          # toAvg
         """Calculates average of list of numbers. Can pipe in :class:`torch.Tensor` or :class:`numpy.ndarray`.
 Example::
 
     # returns 4.5
     range(10) | toAvg()
     # returns nan
     [] | toAvg()"""                                                              # toAvg
         super().__init__()                                                       # toAvg
+    def _all_array_opt(self, it, level):                                         # toAvg
+        bm = np if isinstance(it, np.ndarray) else (torch if hasTorch and isinstance(it, torch.Tensor) else None) # toAvg
+        return NotImplemented if bm is None else bm.mean(it, tuple(range(level, len(it.shape)))) # toAvg
     def _typehint(self, inp):                                                    # toAvg
         i = None                                                                 # toAvg
         if isinstance(inp, tListIterSet): i = inp.child                          # toAvg
         if isinstance(inp, tCollection): i = inp.children[0]                     # toAvg
         if isinstance(inp, tArrayTypes): i = inp.child                           # toAvg
         if i is not None: return float if i == int else i                        # toAvg
         return tAny()                                                            # toAvg
@@ -144,25 +156,37 @@
     def __init__(self):                                                          # toMax
         """Calculates the max of a bunch of numbers. Can pipe in :class:`torch.Tensor` or :class:`numpy.ndarray`.
 Example::
 
     # returns 6
     [2, 5, 6, 1, 2] | toMax()"""                                                 # toMax
         super().__init__()                                                       # toMax
+    def _all_array_opt(self, it, level):                                         # toMax
+        if isinstance(it, np.ndarray): return np.max(it, tuple(range(level, len(it.shape)))) # toMax
+        elif hasTorch and isinstance(it, torch.Tensor):                          # toMax
+            for i in range(level, len(it.shape)): it = torch.max(it, level)[0]   # toMax
+            return it                                                            # toMax
+        return NotImplemented                                                    # toMax
     def __ror__(self, it:Iterator[float]) -> float:                              # toMax
         if isinstance(it, settings.arrayTypes): return it.max()                  # toMax
         return max(it)                                                           # toMax
 class toMin(BaseCli):                                                            # toMin
     def __init__(self):                                                          # toMin
         """Calculates the min of a bunch of numbers. Can pipe in :class:`torch.Tensor` or :class:`numpy.ndarray`.
 Example::
 
     # returns 1
     [2, 5, 6, 1, 2] | toMin()"""                                                 # toMin
         super().__init__()                                                       # toMin
+    def _all_array_opt(self, it, level):                                         # toMin
+        if isinstance(it, np.ndarray): return np.min(it, tuple(range(level, len(it.shape)))) # toMin
+        elif hasTorch and isinstance(it, torch.Tensor):                          # toMin
+            for i in range(level, len(it.shape)): it = torch.min(it, level)[0]   # toMin
+            return it                                                            # toMin
+        return NotImplemented                                                    # toMin
     def __ror__(self, it:Iterator[float]) -> float:                              # toMin
         if isinstance(it, settings.arrayTypes): return it.min()                  # toMin
         return min(it)                                                           # toMin
 settings.add("font", None, "default font file. Best to use .ttf files, used by toPIL()") # toMin
 settings.add("chem", k1lib.Settings().add("imgSize", 200, "default image size used in toPIL() when drawing rdkit molecules"), "chemistry-related settings") # toMin
 def cropToContentNp(ogIm, pad=10):                                               # cropToContentNp
     dim = len(ogIm.shape); im = ogIm                                             # cropToContentNp
@@ -277,15 +301,15 @@
     "a.png" | toPIL() | toGray()"""                                              # toGray
         import PIL; self.PIL = PIL                                               # toGray
     def _typehint(self, inp): return inp                                         # toGray
     def __ror__(self, i):                                                        # toGray
         if i.getbands() == ("L"): return i                                       # toGray
         return self.PIL.ImageOps.grayscale(i)                                    # toGray
 class toDict(BaseCli):                                                           # toDict
-    def __init__(self, rows=True):                                               # toDict
+    def __init__(self, rows=True, f=None):                                       # toDict
         """Converts 2 Iterators, 1 key, 1 value into a dictionary.
 Example::
 
     # returns {1: 3, 2: 4}
     [[1, 3], [2, 4]] | toDict()
     # returns {1: 3, 2: 4}
     [[1, 2], [3, 4]] | toDict(False)
@@ -314,23 +338,26 @@
      'transcript_type': '"lncRNA"',
      'transcript_name': '"DDX11L2-202"',
      'level': '2',
      'transcript_support_level': '"1"',
      'tag': '"Ensembl_canonical"',
      'havana_transcript': '"OTTHUMT00000362751.1"'}
 
-:params rows: if True, reads input in row by row, else reads
-    in list of columns"""                                                        # toDict
+:param rows: if True, reads input in row by row, else reads
+    in list of columns
+:param f: if specified, return a defaultdict that uses this function as its generator""" # toDict
         self.rows = rows                                                         # toDict
+        if f is not None: self.f = lambda d: defaultdict(f, d)                   # toDict
+        else: self.f = lambda x: x                                               # toDict
     def __ror__(self, it:Tuple[Iterator[T], Iterator[T]]) -> dict:               # toDict
-        r = self.rows                                                            # toDict
+        r = self.rows; f = self.f                                                # toDict
         if r:                                                                    # toDict
             if isinstance(r, str): return it | cli.apply(cli.aS(lambda x: x.split(" ")) | cli.head(1).split() | cli.item() + cli.join(" ")) | toDict() # toDict
-            return {_k:_v for _k, _v in it}                                      # toDict
-        return {_k:_v for _k, _v in zip(*it)}                                    # toDict
+            return f({_k:_v for _k, _v in it})                                   # toDict
+        return f({_k:_v for _k, _v in zip(*it)})                                 # toDict
 def _toop(toOp, c, force, defaultValue):                                         # _toop
     return cli.apply(toOp, c) | (cli.apply(lambda x: x or defaultValue, c) if force else cli.filt(cli.op() != None, c)) # _toop
 def _toFloat(e) -> Union[float, None]:                                           # _toFloat
     try: return float(e)                                                         # _toFloat
     except: return None                                                          # _toFloat
 class toFloat(BaseCli):                                                          # toFloat
     def __init__(self, *columns, mode=2):                                        # toFloat
```

## k1lib/cli/filt.py

```diff
@@ -11,15 +11,15 @@
 except: hasTorch = False
 __all__ = ["filt", "filter_", "inSet", "contains", "empty",
            "isNumeric", "instanceOf",
            "head", "tail", "cut", "rows",
            "intersection", "union", "unique", "breakIf", "mask", "tryout", "resume"]
 settings = k1lib.settings.cli
 class filt(BaseCli):                                                             # filt
-    def __init__(self, predicate:Callable[[Any], bool], column:int=None, catchErrors:bool=False): # filt
+    def __init__(self, predicate:Callable[[Any], bool], column:Union[int, List[int]]=None, catchErrors:bool=False): # filt
         """Filters out elements.
 Examples::
 
     # returns [2, 6], grabbing all the even elements
     [2, 3, 5, 6] | filt(lambda x: x%2 == 0) | deref()
     # returns [3, 5], grabbing all the odd elements
     [2, 3, 5, 6] | ~filt(lambda x: x%2 == 0) | deref()
@@ -50,42 +50,53 @@
 If you need more extensive filtering capabilities involving text, check out :class:`~k1lib.cli.grep.grep`
 
 If "filt" is too hard to remember, this cli also has an alias :class:`filter_`
 that kinda mimics Python's ``filter()``.
 
 :param predicate: function that returns True or False
 :param column: if not specified, then filters elements of the input
-    array, else filters the specific column only
+    array, else filters the specific column only (or columns, just
+    like in :class:`~k1lib.cli.modifier.apply`)
 :param catchErrors: whether to catch errors in the function or not (reject
     elements that raise errors). Runs slower if enabled though"""                # filt
         fs = [predicate]; super().__init__(fs)                                   # filt
-        if column and column < 0: raise Exception(f"Filtering using a function on a negative-indexed column ({column}) is not supported") # filt
+        if column:                                                               # filt
+            ex = Exception(f"Filtering using a function on a negative-indexed column ({column}) is not supported") # filt
+            if isinstance(column, int):                                          # filt
+                if column < 0: raise ex                                          # filt
+            else:                                                                # filt
+                column = list(column)                                            # filt
+                if len([c for c in column if c < 0]): raise ex                   # filt
         f = fs[0]; _fP = fastF(f); self.column = column                          # filt
         if catchErrors:                                                          # filt
             def g(x):                                                            # filt
                 try: return _fP(x)                                               # filt
                 except: return False                                             # filt
             self.predicate = g                                                   # filt
         else: self.predicate = _fP                                               # filt
     def __ror__(self, it:Iterator[Any]) -> Iterator[Any]:                        # filt
         p = self.predicate; c = self.column                                      # filt
         if c is None:                                                            # filt
             if isinstance(it, settings.arrayTypes):                              # filt
                 try: return it[p(it)]                                            # filt
                 except Exception as e: print(e)                                  # filt
             return (l for l in it if p(l))                                       # filt
-        else:                                                                    # filt
+        elif isinstance(c, int):                                                 # filt
             if isinstance(it, settings.arrayTypes):                              # filt
                 try: return it[p(it[:,c])]                                       # filt
                 except: pass                                                     # filt
             def gen():                                                           # filt
                 for es in it:                                                    # filt
                     es = list(es)                                                # filt
                     if c < len(es) and p(es[c]): yield es                        # filt
             return gen()                                                         # filt
+        else: # list of ints                                                     # filt
+            ops = []                                                             # filt
+            for c_ in c: ops.append(filt(self.predicate, c_, False))             # filt
+            return it | cli.serial(*ops)                                         # filt
     def __invert__(self):                                                        # filt
         """Negate the condition"""                                               # filt
         def f(s):                                                                # filt
             if isinstance(s, settings.arrayTypes):                               # filt
                 res = self.predicate(s) # can cause an exception, but that's ok, as that's the signal telling the code in __ror__ to not pass in array types # filt
                 if isinstance(res, settings.arrayTypes): return ~res             # filt
             return not self.predicate(s)                                         # filt
@@ -201,47 +212,70 @@
     range(20) | head(0.25) | deref() # returns [0, 1, 2, 3, 4], or the first 25% of samples
 
 Also works well and fast with :class:`numpy.ndarray`, :class:`torch.Tensor`
 and other sliceable types::
 
     # returns (10,)
     np.linspace(1, 3) | head(10) | shape()"""                                    # head
-        super().__init__(); self.n = n; self.inverted = False                    # head
+        super().__init__(); self.n = n; self.inverted = False; self._sliceable = None # head
     def _all_array_opt(self, it, level):                                         # head
         n = self.n; inverted = self.inverted                                     # head
         if n is not None and round(n) != n: n = int(it.shape[level]*n) # fractional head # head
-        sl = tuple([slice(None)]*level); return it[(*sl, slice(n))] if inverted else it[(*sl, slice(None, n))] # head
+        sl = tuple([slice(None)]*level); return it[(*sl, slice(n, None))] if inverted else it[(*sl, slice(None, n))] # head
     def _typehint(self, inp):                                                    # head
         if isinstance(inp, tListIter): return inp                                # head
         if isinstance(inp, tArrayTypes): return inp                              # head
         if inp == str: return str                                                # head
         return tIter(tAny())                                                     # head
     def __ror__(self, it:Iterator[Any]) -> Iterator[Any]:                        # head
         n = self.n; inverted = self.inverted                                     # head
         if n is not None and round(n) != n: # fractional head                    # head
             if not sliceable(it): it = list(it)                                  # head
             i = int(len(it)*n)                                                   # head
             return it[i:] if inverted else it[:i]                                # head
         if inverted and n is None: return [] # special case                      # head
-        if sliceable(it): return it[n:] if inverted else it[:n]                  # head
+        _sliceable = self._sliceable # all of this to cache sliceable value, because it takes a lot of time to determine whether it's sliceable or not # head
+        if _sliceable is None: self._sliceable = _sliceable = sliceable(it)      # head
+        if _sliceable: return it[n:] if inverted else it[:n]                     # head
         else: return _head(self.n, self.inverted, it)                            # head
     def __invert__(self):                                                        # head
         h = head(self.n); h.inverted = not self.inverted                         # head
         return h                                                                 # head
     def split(self):                                                             # head
         """Splits the list up into a head and tail sections.
 Example::
 
     # returns [[0, 1, 2, 3], [4, 5, 6, 7, 8, 9]]
     range(10) | head(4).split() | deref()
 
 This only splits it into 2 parts. If you want to split it up
 into many more parts with specified checkpoints, check out
 :class:`~k1lib.cli.structural.splitC`."""                                        # head
-        return self & ~self                                                      # head
+        # return self & ~self # old version                                      # head
+        return headSplit(self.n, self.inverted)                                  # head
+class headSplit(BaseCli):                                                        # headSplit
+    def __init__(self, n, inverted):                                             # headSplit
+        self.n = n; self.inverted = inverted                                     # headSplit
+        self.fixup = n is None or isinstance(n, float) or n < 0                  # headSplit
+        self.sliceable = None                                                    # headSplit
+    def _all_array_opt(self, it, level):                                         # headSplit
+        n = self.n; inverted = self.inverted                                     # headSplit
+        if n is not None and round(n) != n: n = int(it.shape[level]*n) # fractional head # headSplit
+        sl = tuple([slice(None)]*level); b = it[(*sl, slice(n, None))]; a = it[(*sl, slice(None, n))] # headSplit
+        return [b, a] if inverted else [a, b]                                    # headSplit
+    def __ror__(self, it):                                                       # headSplit
+        sliceable_ = self.sliceable; n = self.n                                  # headSplit
+        if sliceable_ is None: self.sliceable = sliceable_ = sliceable(it)       # headSplit
+        it = it if sliceable_ else list(it)                                      # headSplit
+        if self.fixup: # needs to fix n to a more definite value. Just to make it faster # headSplit
+            l = len(it)                                                          # headSplit
+            if n is None: return it, []                                          # headSplit
+            if isinstance(n, float): n = int(l*n) # fractional head              # headSplit
+            n = (n+l)%l                                                          # headSplit
+        return it[:n], it[n:]                                                    # headSplit
 def tail(n:int=10):                                                              # tail
     """Basically an inverted :class:`head`.
 Examples::
 
     range(10) | tail(3) | deref() # returns [7, 8, 9]"""                         # tail
     return ~head(-n)                                                             # tail
 class lazyList:                                                                  # lazyList
@@ -514,23 +548,25 @@
         """Wraps every cli operation after this in a try-catch block, returning ``result``
 if the operation fails. Example::
 
     # returns 9
     3 | (tryout("failed") | op()**2)
     # returns "failed", instead of raising an exception
     "3" | (tryout("failed") | op()**2)
-    # returns "unsupported operand type(s) for ** or pow(): 'str' and 'int'"
+    # special mode: returns "unsupported operand type(s) for ** or pow(): 'str' and 'int'"
     "3" | (tryout(str) | op()**2)
+    # special mode: returns "3", the input of the tryout() block
+    "3" | (tryout(input) | op()**2)
 
 By default, this ``tryout()`` object will gobble up all clis behind it and wrap
 them inside a try-catch block. This might be undesirable, so you can stop it early::
 
     # returns "failed"
     3 | (tryout("failed") | op()**2 | aS(str) | op()**2)
-    # raises an exception, because it does not errors after `tryout.end`
+    # raises an exception, because it errors out after the tryout()-captured operations
     3 | (tryout("failed") | op()**2) | aS(str) | op()**2
 
 In the first example, :class:`tryout` will catch any errors happening within ``op()``,
 ``aS(str)`` or the second ``op()**2``. In the second example, :class:`tryout` will only
 catch errors happening within the first ``op()**2``.
 
 .. admonition:: Array mode
@@ -598,42 +634,44 @@
         range(10) | (~tryout(retries=0) | apply(f)) | deref()
         counter = 0 # line below returns [0, 1, 4, 9, 16, 25, None, 49, 64, 81]
         range(10) | (~tryout(retries=1) | apply(f)) | deref()
         counter = 0 # line below returns [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
         range(10) | (~tryout(retries=2) | apply(f)) | deref()
 
 :param result: result to return if there is an exception. If passed in the class
-    `str`, then will return the exception's string instead
+    `str`, then will return the exception's string instead. If passed in the
+    function `input`, then will return the input instead
 :param retries: how many time to retry before giving up?"""                      # tryout
         super().__init__(capture=True); self.result = result; self.inverted = False; self.retries = retries # tryout
     def __ror__(self, it):                                                       # tryout
         retries = self.retries                                                   # tryout
+        result = self.result                                                     # tryout
         if len(self.capturedClis) == 0: raise Exception("tryout() currently does not wrap around any other cli. You may need to change `data | tryout() | cli1() | cli2()` into `data | (tryout() | cli1() | cli2())`") # tryout
-        if not self.inverted:                                                    # tryout
+        if not self.inverted: # single mode                                      # tryout
             while True:                                                          # tryout
                 try: return it | self.capturedSerial                             # tryout
                 except Exception as e:                                           # tryout
-                    if retries <= 0: return str(e) if self.result is str else self.result # tryout
+                    if retries <= 0: return str(e) if result is str else (it if result is input else result) # tryout
                     retries -= 1                                                 # tryout
-        else:                                                                    # tryout
+        else: # array mode                                                       # tryout
             def gen(it):                                                         # tryout
-                patience = retries; savedInputs = k1lib.Wrapper(deque())         # tryout
+                patience = retries; savedInputs = k1lib.Wrapper(deque()); ogInp = None # tryout
                 def interceptIt(it):                                             # tryout
                     for e in it: savedInputs().append(e); yield e                # tryout
                 it = iter(it); ogIt = it; it = interceptIt(it); outIt = it | self.capturedSerial # tryout
                 while True:                                                      # tryout
                     try: e = next(outIt); yield e; savedInputs().popleft(); patience = retries # tryout
                     except StopIteration: break                                  # tryout
                     except Exception as e:                                       # tryout
-                        if patience <= 0: savedInputs().popleft(); patience = retries # tryout
+                        if patience <= 0: ogInp = savedInputs().popleft(); patience = retries # ran out of patience, so gonna just return the canned result instead # tryout
                         else: patience -= 1                                      # tryout
                         # restart the loop                                       # tryout
                         it = interceptIt([list(savedInputs()), ogIt] | cli.joinStreams()) # tryout
                         savedInputs.value = deque(); outIt = it | self.capturedSerial # tryout
-                        if patience == retries: yield str(e) if self.result is str else self.result # tryout
+                        if patience == retries: yield str(e) if result is str else (ogInp if result is input else result) # just resetted # tryout
             return gen(it)                                                       # tryout
     def __invert__(self): self.inverted = not self.inverted; return self         # tryout
 def resume(fn):                                                                  # resume
     """Resumes a long-running operation. I usually have code that
 looks like this::
 
     def f(x): pass # long running, expensive calculation
```

## k1lib/cli/grep.py

```diff
@@ -1,15 +1,17 @@
 # AUTOGENERATED FILE! PLEASE DON'T EDIT HERE. EDIT THE SOURCE NOTEBOOKS INSTEAD
 __all__ = ["grep", "grepTemplate"]
 import re, k1lib
 from k1lib.cli.init import BaseCli; import k1lib.cli as cli
 from collections import deque; from typing import Iterator, Union, Callable, Any
-inf = float("inf")
+def extGuard(cond, s=""):                                                        # extGuard
+    if cond: Exception(f"Can't use extract mode. {s}")                           # extGuard
+inf = float("inf")                                                               # extGuard
 class grep(BaseCli):                                                             # grep
-    def __init__(self, pattern:Union[str, Callable[[Any], bool]], before:int=0, after:int=0, N:int=float("inf"), sep:bool=False, col:int=None): # grep
+    def __init__(self, pattern:Union[str, Callable[[Any], bool]], before:int=0, after:int=0, N:int=float("inf"), sep:bool=False, col:int=None, extract:str=None): # grep
         """Find lines that has the specified pattern.
 Example::
 
     # returns ['d', 'd']
     "abcde12d34" | grep("d") | deref()
     # returns ['c', 'd', '2', 'd'], 2 sections of ['c', 'd'] and ['2', 'd']
     "abcde12d34" | grep("d", 1) | deref()
@@ -46,26 +48,59 @@
 
 Also, there's a `whole tutorial <../tutorials/cli.html>`_ devoted to just this cli
 
 Also also, if each element in the input iterator is not a string/bytes, and
 you're searching using regex, then it will get its representation and searches
 in it.
 
+.. admonition:: Extract mode
+
+    Sometimes, you want to extract a subsection of a matched string, like extracting
+    links in a html file, then you can do something like this::
+
+        # returns ['a.io', 'b.com', 'c.net']
+        ["href='a.io'", "href='b.com'", "href='c.net'"] | grep("href='(?P<g>.*)'", extract="g") | deref()
+        # returns [['a.io', 3], ['b.com', 4], ['c.net', 5]]
+        [["href='a.io'", 3], ["href='b.com'", 4], ["href='c.net'", 5]] | grep("href='(?P<g>.*)'", extract="g", col=0) | deref()
+
+    Essentially, you're defining the group with name "g" to be any string within a quote block
+    following "href", and then it will just extract out the group that you want. Because the
+    purpose of this mode is to extract matched objects, a few of the arguments don't really make
+    sense and thus are disabled, like "before", "after", "sep", "N"
+
+Regex quick cheatsheet:
+
+- `\\d`: digit (\\D for inverse)
+- `^`: begin of string ($ for end of string)
+- `\\w`: unicode word (\\W for inverse)
+- `(?!...)`: matches if the inside does not match
+- `(?P<name>...)`: matches as group "name"
+- `A|B`: matches A or B
+- `[aml]`: set of characters "a", "m" and "k"
+- `a{3,5}`: matches character "a" 3 to 5 times ("aaa", "aaaa" and "aaaaa")
+- `a*`: matches "a" 0 or more times (`a*?` matches "a" 0 or more times non-greedy)
+
 :param pattern: regex pattern to search for in a line
 :param before: lines before the hit. Outputs independent lines
 :param after: lines after the hit. Outputs independent lines
 :param N: max sections to output
 :param sep: whether to separate out the sections as lists
 :param col: searches for pattern in a specific column"""                         # grep
         super().__init__()                                                       # grep
         if isinstance(pattern, str):                                             # grep
             self._f = re.compile(pattern).search; self.mode = 0 # make func quickly accessible # grep
         else: self._f = cli.op.solidify(pattern); self.mode = 1 # mode for either regex or normal funcs # grep
         self.before = before; self.after = after; self.col = col; self.N = N; self.sep = sep # grep
-        self.tillPattern = None; self.tillAfter = None; self._tillF = lambda x: False # grep
+        self.tillPattern = None; self.tillAfter = None; self._tillF = lambda x: False; self.extract = extract # grep
+        if extract:                                                              # grep
+            extGuard(before, "`before` has to be zero")                          # grep
+            extGuard(after, "`after` has to be zero")                            # grep
+            extGuard(sep, "`sep` has to be False")                               # grep
+            extGuard(col is not None, "`col` has to be None. Cut out the column if you want") # grep
+            extGuard(N < inf, "`N` has to be infinite. Just use head() if you want to limit the number of results") # grep
     def till(self, pattern:Union[str, Callable[[Any], bool]]=None):              # grep
         """Greps until some other pattern appear. Inclusive, so you might want to
 trim the last line. Example::
 
     # returns ['5', '6', '7', '8'], includes last item
     range(10) | join("") | grep("5").till("8") | deref()
     # returns ['d', 'e', 'd', '3', '4']
@@ -74,14 +109,15 @@
     "abcde12d34" | grep("d", N=1).till("e") | deref()
 
 If initial pattern and till pattern are the same, then you don't have use this method at
 all. Instead, do something like this::
 
     # returns ['1', '2', '3']
     "0123145" | grep("1", after=1e9, N=1) | deref()"""                           # grep
+        if self.extract: extGuard(True, "Can't use .till() in extract mode as it makes no sense") # grep
         if pattern is None: self._tillF = self._f                                # grep
         elif isinstance(pattern, str): self._tillF = re.compile(pattern).search  # grep
         else: self._tillF = cli.op.solidify(pattern)                             # grep
         self.tillAfter = self.after; self.after = inf; return self               # grep
     def __ror__(self, it:Iterator[str]) -> Iterator[str]:                        # grep
         self.sectionIdx = 0; col = self.col; _f = self._f; _tillF = self._tillF  # grep
         if self.sep:                                                             # grep
@@ -89,14 +125,26 @@
             s = self._clone(); s.sep = False                                     # grep
             for line in (it | s):                                                # grep
                 if s.sectionIdx > idx: # outputs whatever remaining              # grep
                     if len(elems) > 0: yield list(elems)                         # grep
                     idx = s.sectionIdx; elems = []                               # grep
                 elems.append(line)                                               # grep
             yield list(elems); return                                            # grep
+        if self.extract:                                                         # grep
+            group = self.extract                                                 # grep
+            if col is None:                                                      # grep
+                for line in it:                                                  # grep
+                    res = _f(line)                                               # grep
+                    if res: yield res.group(group)                               # grep
+            else:                                                                # grep
+                for line in it:                                                  # grep
+                    line = list(line); res = _f(line[col])                       # grep
+                    if res: line[col] = res.group(group); yield line             # grep
+                                                                                 # grep
+            return                                                               # grep
         queue = deque([], self.before); counter = 0 # remaining lines after to display # grep
         cRO = k1lib.RunOnce(); cRO.done()                                        # grep
         for line in it:                                                          # grep
             if col != None: line = list(line); elem = line[col]                  # grep
             else: elem = line                                                    # grep
             if self.mode == 0 and not isinstance(elem, (str, bytes)): elem = f"{elem}" # grep
             if _f(elem): # new section                                           # grep
@@ -112,14 +160,15 @@
                 counter -= 1                                                     # grep
     def __invert__(self):                                                        # grep
         """Flips the pattern, just like how :class:`~k1lib.cli.filt.filt`
 works. Example::
 
     # returns ['a', 'b', 'c', 'e', '1', '2', '3', '4']
     "abcde12d34" | ~grep("d") | deref()"""                                       # grep
+        if self.extract: extGuard(True, "Can't invert search condition in extract mode as it makes no sense") # grep
         f = self._f; self._f = lambda s: not f(s); return self                   # grep
     def _clone(self):                                                            # grep
         answer = grep(self._f, self.before, self.after, self.N, self.sep, self.col) # grep
         answer._tillF = self._tillF; answer.tillAfter = self.tillAfter; return answer # grep
 class grepTemplate(BaseCli):                                                     # grepTemplate
     def __init__(self, pattern:str, template:str):                               # grepTemplate
         """Searches over all lines, pick out the match, and expands
```

## k1lib/cli/inp.py

```diff
@@ -107,19 +107,20 @@
                 if i >= self.retries: raise Exception(f"Can't get size of remote file: {e}") # RemoteFile
     def __len__(self):                                                           # RemoteFile
         if self.size is None: self.size = self._getSize()                        # RemoteFile
         return self.size                                                         # RemoteFile
     def __repr__(self): return f"<RemoteFile url={self.url} size={k1lib.fmt.size(len(self))}>" # RemoteFile
 @contextmanager                                                                  # RemoteFile
 def openFile(fn, text, noPartialConfirm=False): # can be actual file or url      # openFile
+    if not isinstance(fn, str): yield fn; return # file handle case, just return itself # openFile
     if os.path.exists(fn):                                                       # openFile
         if text:                                                                 # openFile
-            with open(fn, "r") as f: yield f                                     # openFile
+            with open(fn, "r", settings.cat.chunkSize) as f: yield f             # openFile
         else:                                                                    # openFile
-            with open(fn, "rb") as f: yield f                                    # openFile
+            with open(fn, "rb", settings.cat.chunkSize) as f: yield f            # openFile
     elif validators.url(fn) is True:                                             # openFile
         yield RemoteFile(fn, False, noPartialConfirm=noPartialConfirm)           # openFile
     else: raise FileNotFoundError(f"The file {fn} doesn't seem to exist and/or it's not a valid url") # openFile
 def _catGenText(fn, sB, eB): # fn for "file name"                                # _catGenText
     try:                                                                         # _catGenText
         if sB == 0 and eB == -1: # fast path without bounds (90-160 MB/s expected) # _catGenText
             with openFile(fn, True) as f:                                        # _catGenText
@@ -149,18 +150,18 @@
     with openFile(fn, False) as f: return f.seek(0, os.SEEK_END)                 # fileLength
 def wrap(fn, b): return b if b >= 0 else b + fileLength(fn) + 1                  # wrap
 class _cat(BaseCli):                                                             # _cat
     def __init__(self, text, chunks, sB, eB): self.text = text; self.chunks = chunks; self.sB = sB; self.eB = eB # _cat
     def _typehint(self, ignored=None):                                           # _cat
         if self.text: return tIter(str) if self.chunks else tList(str)           # _cat
         else: return tIter(bytes) if self.chunks else bytes                      # _cat
-    def __ror__(self, fn:str) -> Union[Iterator[str], bytes]:                    # _cat
-        text = self.text; chunks = self.chunks; sB = self.sB; eB = self.eB; fn = os.path.expanduser(fn) # _cat
-        if text and chunks and k1lib._settings.packages.k1a and os.path.exists(fn): # _cat
-            return k1lib._k1a.k1a.StrIterCat(fn, sB, eB)                         # _cat
+    def __ror__(self, fn:Union[str, "fileHandle"]) -> Union[Iterator[str], bytes]: # _cat
+        text = self.text; chunks = self.chunks; sB = self.sB; eB = self.eB; fn = os.path.expanduser(fn) if isinstance(fn, str) else fn # _cat
+        if text and chunks and k1lib._settings.packages.k1a and isinstance(fn, str) and os.path.exists(fn): # _cat
+            return k1lib._k1a.k1a.StrIterCat(fn, sB, eB) # accelerated C version # _cat
         if chunks: return _catGenText(fn, sB, eB) if text else _catGenBin(fn, sB, eB) # _cat
         sB = wrap(fn, sB); eB = wrap(fn, eB)                                     # _cat
         if text:                                                                 # _cat
             with openFile(fn, True) as f: f.seek(sB); return f.read(eB-sB).splitlines() # _cat
         else:                                                                    # _cat
             with openFile(fn, False) as f: f.seek(sB); return f.read(eB-sB)      # _cat
 class Profile(BaseCli):                                                          # Profile
```

## k1lib/cli/kcsv.py

```diff
@@ -10,11 +10,11 @@
 import csv, os
 __all__ = ["cat"]
 class _cat(BaseCli):                                                             # _cat
     def __ror__(self, file):                                                     # _cat
         file = os.path.expanduser(file)                                          # _cat
         with open(file) as f:                                                    # _cat
             yield from csv.reader(f)                                             # _cat
-def cat(file:str=None) -> cli.Table[str]:                                        # cat
+def cat(file:str=None):                                                          # cat
     """Opens a csv file, and turns them into nice row elements"""                # cat
     if file is None: return _cat()                                               # cat
     return file | _cat()                                                         # cat
```

## k1lib/cli/modifier.py

```diff
@@ -8,15 +8,15 @@
            "integrate"]
 from typing import Callable, Iterator, Any, Union, List, Tuple
 from k1lib.cli.init import patchDefaultDelim, BaseCli, fastF
 import k1lib.cli as cli, numpy as np, threading, gc; import k1lib
 from collections import deque
 from functools import partial, update_wrapper, lru_cache
 from k1lib.cli.typehint import *
-import dill, pickle, k1lib, warnings, atexit, signal, time, os, random
+import dill, pickle, k1lib, warnings, atexit, signal, time, os, random, sys
 try: import torch; import torch.multiprocessing as mp; hasTorch = True
 except: import multiprocessing as mp; hasTorch = False
 ray = k1lib.dep("ray")
 settings = k1lib.settings.cli
 class applyS(BaseCli):                                                           # applyS
     def __init__(self, f:Callable[[Any], Any], *args, **kwargs):                 # applyS
         """Like :class:`apply`, but much simpler, just operating on the entire input
@@ -142,42 +142,43 @@
     def _arrayTypeF(self): # returns None or the function                        # apply
         if self.__arrayTypeF == 0: return None                                   # apply
         if self.__arrayTypeF is None:                                            # apply
             arrs = []; last = self # figure out the depth                        # apply
             while isinstance(last, apply) and last.normal: arrs.append(last); last = last.f # apply
             depth = len(arrs)                                                    # apply
             if depth == 0: self.__arrayTypeF = 0; return None                    # apply
-            if isinstance(last, cli.serial):                                     # apply
-                self.__arrayTypeF = cli.serial(*[(e if isinstance(e, BaseCli) else aS(e)).all(depth) for e in last.clis]); return self.__arrayTypeF # breaks up the serial # apply
+            if isinstance(last, cli.serial): self.__arrayTypeF = cli.serial(*[(e if isinstance(e, BaseCli) else aS(e)).all(depth) for e in last.clis]); return self.__arrayTypeF # breaks up the serial # apply
             else: self.__arrayTypeF = aS(lambda it: last._all_array_opt(it, depth)); return self.__arrayTypeF # actually call accelerate function on each individual operation # apply
         return self.__arrayTypeF                                                 # apply
     def _typehint(self, inp):                                                    # apply
         if self.column is None:                                                  # apply
             if isinstance(inp, tListIterSet):                                    # apply
                 try: return tIter(self.f._typehint(inp.child))                   # apply
                 except: return tIter(tAny())                                     # apply
         return super()._typehint(inp)                                            # apply
     def _copy(self): return apply(self.f, self.column, self.cache, **self.kwargs) # ~apply() case handled automatically # apply
     def __ror__(self, it:Iterator[str]):                                         # apply
         c = self.column; f = self._fC; kwargs = self.kwargs                      # apply
         if c is None:                                                            # apply
             if self.normal and isinstance(it, settings.arrayTypes):              # apply
-                af = self._arrayTypeF                                            # apply
-                if af is not None:                                               # apply
+                af = self._arrayTypeF # this whole section is for unwrapping (A.all(2) | B).all(3) into A.all(5) | B.all(3), and each A and B will have their own _all_array_opt() functions that can handle array types insanely fast # apply
+                if af is not None: # there're lots of code here, but it doesn't impact perf cause it's done once for each array object # apply
                     try:                                                         # apply
                         ans = af(it)                                             # apply
                         if ans is not NotImplemented: return ans                 # apply
                     except Exception as e: self.__arrayTypeF = 0                 # apply
             return (f(line, **kwargs) for line in it)                            # apply
+        elif isinstance(c, int):                                                 # apply
+            def gen(it):                                                         # apply
+                for row in it: row = list(row); row[c] = f(row[c]); yield row    # apply
+            return gen(it) # return ([(e if i != c else f(e, **kwargs)) for i, e in enumerate(row)] for row in it) # old version # apply
         else:                                                                    # apply
-            if isinstance(c, int): return ([(e if i != c else f(e, **kwargs)) for i, e in enumerate(row)] for row in it) # apply
-            else:                                                                # apply
-                ops = []                                                         # apply
-                for c_ in c: a = self._copy(); a.column = c_; ops.append(a)      # apply
-                return it | cli.serial(*ops)                                     # apply
+            ops = []                                                             # apply
+            for c_ in c: a = self._copy(); a.column = c_; ops.append(a)          # apply
+            return it | cli.serial(*ops)                                         # apply
     def __invert__(self):                                                        # apply
         """Same mechanism as in :class:`applyS`, it expands the
 arguments out. Just for convenience really. Example::
 
     # returns [10, 12, 14, 16, 18]
     [range(5), range(10, 15)] | transpose() | ~apply(lambda x, y: x+y) | deref()""" # apply
         return apply(lambda x: self.f(*x, **self.kwargs), self.column, self.cache) # apply
@@ -407,16 +408,17 @@
     return {k:exportSe(v) for k,v in se.__dict__.items() if not k.startswith("_")} # exportSe
 def movePropsSe(obj, se):                                                        # movePropsSe
     d = se.__dict__; keys = [e for e in d.keys() if not e.startswith("_")]       # movePropsSe
     for key in keys:                                                             # movePropsSe
         if key not in obj: continue                                              # movePropsSe
         if isinstance(d[key], k1lib.Settings): movePropsSe(obj[key], d[key])     # movePropsSe
         else: d[key] = obj[key]                                                  # movePropsSe
+_applyCl_soCache = set() # dynamic library (.so) that has been installed across all nodes, so don't have to reimport # movePropsSe
 class applyCl(BaseCli):                                                          # applyCl
-    def __init__(self, f, prefetch=None, timeout=60, bs=1, rss:Union[dict, str]={}, pre:bool=False, num_cpus=1, resolve=True, **kwargs): # applyCl
+    def __init__(self, f, prefetch=None, timeout=60, bs=1, rss:Union[dict, str]={}, pre:bool=False, num_cpus=1, memory=None, resolve=True, **kwargs): # applyCl
         """Like :class:`apply`, but execute a function over the input iterator
 in multiple processes on multiple nodes inside of a cluster (hence "cl"). So, just a more
 powerful version of :class:`applyMp`, assuming you have a cluster to run it on.
 Example::
 
     # returns [3, 2]
     ["abc", "de"] | applyCl(len) | deref()
@@ -489,14 +491,69 @@
     bytes and count up those bytes. Finally in step D, the results are grouped together and the
     sizes summed.
 
     So yeah, it's pretty nice that we did all of that in a relatively short amount of code.
     The data is distributed too (reading multiple files from multiple nodes), so we're truly
     not bottlenecked by anything.
 
+.. admonition:: Cython
+
+    Even with running everything distributedly like this, you might run into speed issues.
+    Then, you'll essentially have 2 options. First is to write (pleasant) Cython code, or
+    second is to write (unpleasant) C/C++ Python extensions. If you were to choose the C/C++
+    option, then here's the flow:
+
+    - Develop Python C extension, export everything as a shared library (a single .so file)
+    - Execute ``applyCl.installSo("library.so")`` to install the library to all nodes
+    - Use functions provided by your library normally, like ``import yourlibrary; range(10) | applyCl(yourlibrary.afunction) | deref()``
+
+    But applyCl can deal with cython functions directly in your notebook. Here's the flow:
+
+    - Annotate a code cell with the magic "%%cython", write Cython code as usual
+    - Just use that function normally
+
+    Let's see an example::
+
+        # ---------- code cell 1 ----------
+        from k1lib.imports import *      # cython ipython extension is automatically loaded
+        # ---------- code cell 2 ----------
+        %%cython
+        from k1lib.cli import ls         # demonstrating that you can use all of the existing tools and libraries as usual
+        cdef g(a:int): return f"{a} 123" # demonstrating that you can refactor out to other functions
+        def f (a:int): return [g(a), ls(".")]
+        # ---------- code cell 3 ----------
+        range(10) | applyCl(f) | deref()
+
+    You only have to install Cython on the current node and not the other nodes. Also note
+    that currently, this only supports you passing in Cython-compiled functions directly into
+    ``applyCl()`` or ``applyCl.aS()``. You can't pass a normal Python function that uses a
+    Cython function like this::
+
+        # ---------- code cell 1 ----------
+        from k1lib.imports import *
+        # ---------- code cell 2 ----------
+        %%cython
+        from k1lib.cli import ls          # note: have to reimport here because all the symbols inside this code block is independent from the rest of the notebook
+        cpdef g(a:int): return f"{a} 123"
+        # ---------- code cell 3 ----------
+        def f (a:int): return [g(a), ls(".")]
+        range(10) | applyCl(f) | deref() # this throws an import error, as the compiled code won't be installed on the remote nodes
+
+    This behavior can potentially be fixed in the future, but I'm lazy and it's not a hard
+    thing to follow the rules. The dynamic library will be installed in the working directory.
+    You can delete them after a coding session to free up some space, but they're likely to be
+    tiny, so you don't really have to worry about it.
+
+    Also, like everything else in parallel programming, please benchmark absolutely everything
+    because it might even be slower using Cython if internally you're allocating space for
+    large data structures constantly, compared to cli tool's lazy execution model. For operations
+    that work on giant files, I actually find it very difficult to gain any appreciable speedups
+    using Cython, as cli tools are already pretty optimized, so best task for this is probably
+    long-running, complex mathematical modelling, and not generic text manipulation.
+
 .. warning::
 
     Just like with any other parallel processing model, there are some quirks that
     can happen behind the scenes that aren't quite what you expected, as this is
     incredibly tricky. Dig into Ray's serialization page (https://docs.ray.io/en/latest/ray-core/objects/serialization.html)
     or their whitepapers (https://docs.ray.io/en/latest/ray-contribute/whitepaper.html)
     to get a feel for how it all works underneath. The notable quirks that you might need to think about is:
@@ -509,48 +566,59 @@
     jobs, and will only schedule more if results are actually being used.
 :param timeout: seconds to wait for job before raising an error
 :param bs: if specified, groups ``bs`` number of transforms into 1 job to be more
     efficient.
 :param rss: resources required for the task. Can be {"custom_resource1": 2} or "custom_resource1" as a shortcut
 :param pre: "preserve", same convention as :meth:`applyCl.aS`. If True, then allow passing
     through node ids as the first column to shedule jobs on those specific nodes only
-:param orPatch: whether to automatically patch __or__ function so that cli tools can
-    work with numpy arrays on that remote worker
 :param num_cpus: how many cpu does each task take?
+:param memory: how much memory to give to the task in bytes?
 :param resolve: whether to resolve the outputs or not. Set this to False to not move
     memory to the requesting node and cache the big data structure on the remote node
 :param kwargs: extra arguments to be passed to the function. ``args`` not
     included as there're a couple of options you can pass for this cli."""       # applyCl
         super().__init__(fs=[f]); _fC = fastF(f); self.ogF = f; self.pre = pre   # applyCl
+        isCythonFunc = "cython" in f.__module__                                  # applyCl
+        if isCythonFunc: applyCl.installSo(sys.modules[f.__module__].__file__)   # applyCl
         self.rss = rss = {rss: 1} if isinstance(rss, str) else rss               # applyCl
         cwd = os.getcwd(); se = exportSe(k1lib.settings)                         # applyCl
         def remoteF(e):                                                          # applyCl
             import k1lib; movePropsSe(se, k1lib.settings) # do this to sync current settings with the remote worker nodes # applyCl
             if k1lib.settings.startup.or_patch.numpy: k1lib.cli.init.patchNumpy() # applyCl
             if k1lib.settings.startup.or_patch.dict: k1lib.cli.init.patchDict()  # applyCl
             if k1lib.settings.startup.or_patch.pandas: k1lib.cli.init.patchPandas() # applyCl
             import os; os.makedirs(cwd, exist_ok = True); os.chdir(cwd)          # applyCl
             return _fC(e, **kwargs)                                              # applyCl
-        self.remoteF = remoteF; self.f = ray.remote(resources=rss, num_cpus=num_cpus)(remoteF) # applyCl
+        self.remoteF = remoteF; self.f = ray.remote(resources=rss, num_cpus=num_cpus, **({"memory": memory} if memory else {}))(remoteF) # applyCl
         self.prefetch = prefetch or int(1e9)                                     # applyCl
         self.timeout = timeout; self.bs = bs                                     # applyCl
-        self._copyCtx = lambda: [f, [prefetch, timeout, bs, rss, pre, orPatch, num_cpus, resolve], kwargs] # applyCl
+        self._copyCtx = lambda: [f, [prefetch, timeout, bs, rss, pre, num_cpus, memory, resolve], kwargs] # applyCl
         def preprocessF(f, e): # return future (if pre=False), or [nodeId, future] (if pre=True) # applyCl
             if pre: nodeId, e = e; return [nodeId, specificNode(f, nodeId).remote(e)] # applyCl
             else: return f.remote(e)                                             # applyCl
         @ray.remote                                                              # applyCl
         def resolveFRemote(o): return 1                                          # applyCl
         def resolveF(e):                                                         # applyCl
             if resolve:                                                          # applyCl
                 if pre: return [e[0], ray.get(e[1], timeout=timeout)]            # applyCl
                 else: return ray.get(e, timeout=timeout)                         # applyCl
             else: # don't resolve to this node, but still block execution until that object is resolvable # applyCl
                 f = specificNode(resolveFRemote, e[0]) if pre else resolveFRemote # if node ids are available (pre=True), then resolves to that specific node only, else do generic resolve # applyCl
                 ray.get(f.remote(e[1] if pre else e), timeout=timeout); return e # applyCl
         self.preprocessF = preprocessF; self.resolveF = resolveF                 # applyCl
+    @staticmethod                                                                # applyCl
+    def installSo(fn:str, force:bool=False):                                     # applyCl
+        """Installs dynamic library (.so file) to all nodes.
+
+:param fn: file name of the shared library
+:param force: force reinstall even if the library is already on the remote node""" # applyCl
+        basename = os.path.basename(fn)                                          # applyCl
+        if not force and basename in _applyCl_soCache: return                    # applyCl
+        print("Installing dynamic library to all nodes... ", end=""); _applyCl_soCache.add(basename); contents = cli.cat(fn, False) # applyCl
+        None | applyCl.aS(lambda: contents | cli.file(basename)) | cli.ignore(); print("Done") # applyCl
     def __ror__(self, it):                                                       # applyCl
         f = self.f; timeout = self.timeout; bs = self.bs; ogF = self.ogF; preprocessF = self.preprocessF; resolveF = self.resolveF # applyCl
         if bs > 1: return it | cli.batched(bs, True) | applyCl(lambda x: x | apply(ogF) | cli.aS(list), self.prefetch, timeout) | cli.joinStreams() # applyCl
         def gen(it):                                                             # applyCl
             futures = deque(); it = iter(it)                                     # applyCl
             for i, e in zip(range(self.prefetch), it): futures.append(preprocessF(f, e)) # applyCl
             for e in it: yield resolveF(futures.popleft()); futures.append(preprocessF(f, e)) # applyCl
@@ -651,23 +719,32 @@
 
 Internally, this will read chunks of 100kB of the specified file and dump it
 incrementally to all other nodes, which has implications on performance. To
 increase or decrease it, check out :class:`~k1lib.cli.inp.cat`. This also means
 you can replicate arbitrarily large files around as long as you have the disk
 space for it, while ram size doesn't really matter
 
+Please note that this operation is not symmetric. Unlike :meth:`balanceFile` and
+:meth:`balanceFolder`, in which they can be invoke on any node and it'll roughly
+do the same thing (rebalances everything out), this operation can do totally
+different things depending on which node you run it on. Let's say the file exists
+on nodes A and B, but not on nodes C and D. If you run this function on either
+node A or B, it will replicate the file to C and D. However, if you run this
+function on node C or D, it will instead throw an error since the file doesn't
+exist.
+
 :param fn: file name"""                                                          # applyCl
         fn = os.path.expanduser(fn); dirname = os.path.dirname(fn)               # applyCl
+        # checking if there's an existing file already. If there is, then don't try to copy data to that node # applyCl
         if nodeIds is None: canSize = os.path.getsize(fn); nodeIds = None | applyCl.aS(lambda: os.path.getsize(fn) if os.path.exists(fn) else 0) | cli.filt(cli.op() != canSize, 1) | cli.cut(0) | cli.deref() # applyCl
         nodeIds = nodeIds | cli.wrapList().all() | cli.deref()                   # applyCl
-        nodeIds | cli.insert(None, False).all() | applyCl(lambda _: None | cli.cmd(f"mkdir -p {dirname}; rm {fn}") | cli.deref(), pre=True) | cli.deref() # applyCl
-        for chunk in cli.cat(fn, text=False, chunks=True):                       # applyCl
-            nodeIds | cli.insert(chunk, False).all() | applyCl(lambda chunk: chunk >> cli.file(fn) | cli.deref(), pre=True) | cli.deref() # applyCl
+        nodeIds | cli.insert(None, False).all() | applyCl(lambda _: None | cli.cmd(f"mkdir -p {dirname}; rm -rf {fn}") | cli.deref(), pre=True) | cli.deref() # applyCl
+        for chunk in cli.cat(fn, text=False, chunks=True): nodeIds | cli.insert(chunk, False).all() | applyCl(lambda chunk: chunk >> cli.file(fn) | cli.deref(), pre=True) | cli.deref() # applyCl
     @staticmethod                                                                # applyCl
-    def balanceFile(fn:str, nAs:List[str]=None, nBs:List[str]=None, rS=None):    # applyCl
+    def balanceFile(fn:str, nAs:List[str]=None, nBs:List[str]=None, rS=None, chunkSize:int=100_000_000): # applyCl
         """Splits a specified file in node nAs and dumps other parts
 to nodes nBs. Example::
 
     applyCl.balanceFile("~/cron.log")
 
 This will split the big files up into multiple segments (1 for each node). Then
 for each segment, it will read through it chunk by chunk into memory, and then
@@ -743,22 +820,23 @@
 :param fn: file name
 :param nAs: node ids that currently stores the file. If not specified, try to detect
     what nodes the file exists in
 :param nBs: node ids that will store the file after balancing everything out. If not
     specified, will take all available nodes
 :param rS: :class:`~k1lib.cli.inp.refineSeek` instance, if you need more fine-grained
     control over section boundaries so as to not make everything corrupted
+:param chunkSize: see :meth:`balanceFolder`
 """                                                                              # applyCl
         from k1lib.cli._applyCl import balanceFile                               # applyCl
-        balanceFile(fn, nAs, nBs, rS)                                            # applyCl
+        with settings.cat.context(chunkSize=chunkSize): balanceFile(fn, nAs, nBs, rS) # applyCl
     @staticmethod                                                                # applyCl
-    def decommissionFile(fn, nAs:List[str], rS=None):                            # applyCl
+    def decommissionFile(fn, nAs:List[str], rS=None, chunkSize:int=100_000_000): # applyCl
         """Convenience function for :meth:`balanceFile`. See docs over there.""" # applyCl
         from k1lib.cli._applyCl import balanceFile                               # applyCl
-        balanceFile(fn, None, applyCl.nodeIds() | ~cli.inSet(nAs) | cli.deref(), rS) # applyCl
+        with settings.cat.context(chunkSize=chunkSize): balanceFile(fn, None, applyCl.nodeIds() | ~cli.inSet(nAs) | cli.deref(), rS) # applyCl
     @staticmethod                                                                # applyCl
     def cat(fn:str=None, f:Callable=None, nodeIds=None, timeout:float=60, pre:bool=False, multiplier:int=1, includeId:bool=False, resolve:bool=True): # applyCl
         """Reads a file distributedly, does some operation on them, collects and
 returns all of the data together. Example::
 
     fn = "~/repos/labs/k1lib/k1lib/cli/test/applyCl.cat.data"
     ("0123456789"*5 + "\\n") * 1000 | file(fn)
@@ -831,25 +909,33 @@
                 nodeId, fn = nodeId_fn; seeks = [nodeId] | applyCl.aS(lambda: fn | cli.splitSeek(round(os.path.getsize(fn)/settings.cat.chunkSize+1))) | cli.cut(1) | cli.item() | cli.deref() # applyCl
                 inter = seeks | cli.window(2) | apply(cli.wrapList() | cli.insert(nodeId)) | cli.deref() # applyCl
                 return inter | ~applyCl(lambda sB, eB: cli.cat(fn,sB=sB,eB=eB) | cli.deref(), pre=True) | cli.cut(1) | cli.joinStreams() # applyCl
                 # return [nodeId_fn] | applyCl(cat() | deref(), pre=True) | cut(1) | item() # direct, no chunking method # applyCl
             if fn is None: return aS(inner) # [nodeId, fn] | applyCl.cat()       # applyCl
             if isinstance(fn, str): return aS(lambda nodeId: inner([nodeId, fn])) # nodeId | applyCl.cat() # applyCl
             else: return inner(fn) # applyCl.cat([nodeId, fn])                   # applyCl
-        postprocess = cli.insertIdColumn(True, False) | ~apply(lambda x,y,z: [x,[*y,z]]) # applyCl
         nodeIds = nodeIds or (applyCl.nodeIds() | applyCl.aS(lambda: os.path.exists(fn)) | cli.filt(cli.op(), 1) | cli.cut(0) | cli.deref()) # applyCl
-        checkpoints = nodeIds | applyCl.aS(lambda: fn | cli.splitSeek(int(applyCl.meta()["Resources"]["CPU"]*multiplier)) | cli.window(2) | cli.deref()) | cli.ungroup() | postprocess | cli.deref() # applyCl
-        postprocess = cli.iden() if pre else cli.cut(1)                          # applyCl
-        a = checkpoints | applyCl(~aS(lambda x,y,idx: cli.cat(fn, sB=x, eB=y) | ((cli.wrapList() | cli.insert(idx)) if includeId else cli.iden()) | f), pre=True, timeout=timeout, num_cpus=1, resolve=resolve) # applyCl
-        return a | postprocess                                                   # applyCl
+        checkpoints = nodeIds | applyCl.aS(lambda: fn | cli.splitSeek(int(applyCl.meta()["Resources"]["CPU"]*multiplier)) | cli.window(2) | cli.deref()) | cli.ungroup() | cli.insertIdColumn(True, False) | ~apply(lambda x,y,z: [x,[*y,z]]) | cli.deref() # applyCl
+        return checkpoints | applyCl(~aS(lambda x,y,idx: cli.cat(fn, sB=x, eB=y) | ((cli.wrapList() | cli.insert(idx)) if includeId else cli.iden()) | f), pre=True, timeout=timeout, num_cpus=1, resolve=resolve) | (cli.iden() if pre else cli.cut(1)) # applyCl
     @staticmethod                                                                # applyCl
-    def balanceFolder(folder:str, maxSteps:int=None, audit:bool=False, bs:int=5): # applyCl
+    def replicateFolder(folder:str, nodeIds=None):                               # applyCl
+        """Replicates a specific folder in the current node to all the other nodes.
+Example::
+
+    applyCl.replicateFolder("~/ssd2/data/owl")
+
+This just list out all files recursively in the specified folder, then replicate each file using :meth:`replicateFile`""" # applyCl
+        applyCl.getFilesInFolder(folder) | applyCl(lambda fn: applyCl.replicateFile(fn, nodeIds), num_cpus=0.1) | cli.deref() # applyCl
+    @staticmethod                                                                # applyCl
+    def balanceFolder(folder:str, maxSteps:int=None, audit:bool=False, bs:int=5, chunkSize:int=100_000_000): # applyCl
         """Balances all files within a folder across all nodes.
 Example::
 
+    # make the chunk size huge so that transfers become faster
+    settings.cli.cat.chunkSize = 100_000_000
     base = "~/repos/labs/k1lib/k1lib/cli/test/applyCl.balance"
     # deletes old structures and making test folder
     applyCl.cmd(f"rm -r {base}"); applyCl.cmd(f"mkdir -p {base}")
     # creates 20 files of different sizes and dump it in the base folder of the current node
     torch.linspace(1e4, 1e5, 20).int() | apply(lambda x: "x"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f"{base}/{idx}.txt")) | deref();
     # transfers files between nodes such that the total folder size is proportional to the number of cpus across nodes
     applyCl.balanceFolder(base)
@@ -865,46 +951,58 @@
 
 So imagine that you just downloaded 1000 files to a single node on a specific folder,
 but you need to analyze all of them in a distributed manner. What you can do is to
 move some files to other nodes and then do your analysis. If you want to download
 more files, just dump it to any node (or download distributed across all nodes),
 then rebalance the folders and do your analysis.
 
+Also, internally, it splits files into multiple chunks, transfer the chunks to other
+nodes and append to the correct files. It uses :meth:`~k1lib.cli.inp.cat` to split up
+the file, which has settings under ``settings.cli.cat``. By default, the chunk size is
+100k bytes, which I think is the sweet spot because :meth:`~k1lib.cli.inp.cat` also
+supports remote file accessed from the internet and sometimes the library is used for
+systems with very few memory. But for this use case where you already have the insane
+hardware for this, 100kB is extremely small and will slow transfer rates to a crawl,
+so in this function, it will be temporarily be set to the parameter ``ChunkSize``, which
+is 100MB by default.
+
 :param folder: folder to rebalance all of the files
 :param maxSteps: what's the maximum number of file transfers? By default has no limit, so that files are transferred until
 :param audit: if True, don't actually move files around and just return what files are going to be moved where
 :param bs: batch size for transporting this many files at once. Increase to make it faster, but with the
     penalty of the progress bar not updating as frequently
+:param chunkSize: file chunk size to split up and send to other nodes
 """                                                                              # applyCl
         from k1lib.cli._applyCl import balanceFolder                             # applyCl
-        return balanceFolder(folder, audit, maxSteps, bs=bs)                     # applyCl
-    def decommissionFolder(folder:str, nAs:List[str], maxSteps:int=10000, audit:bool=False, timeout:float=3600, bs:int=5): # applyCl
+        with settings.cat.context(chunkSize=chunkSize): return balanceFolder(folder, audit, maxSteps, bs=bs) # applyCl
+    def decommissionFolder(folder:str, nAs:List[str], maxSteps:int=10000, audit:bool=False, timeout:float=3600, bs:int=5, chunkSize:int=100_000_000): # applyCl
         """Like :meth:`decommissionFile`, but works for distributed folders instead.
 
 :param nAs: list of node ids to migrate files away from
 :param maxSteps: limits the total number of optimization steps. Normally don't have to specify,
     but just here in case it runs for too long trying to optimize the folder structure
 :param audit: if True, just returns the file movements it's planning to do
 :param bs: batch size for transporting this many files at once. Increase to make it faster, but with the
     penalty of the progress bar not updating as frequently
+:param chunkSize: see :meth:`balanceFolder`
 """                                                                              # applyCl
         from k1lib.cli._applyCl import decommissionFolder                        # applyCl
-        return decommissionFolder(folder, nAs, audit=audit, maxSteps=maxSteps, timeout=timeout, bs=bs) # applyCl
+        with settings.cat.context(chunkSize=chunkSize): return decommissionFolder(folder, nAs, audit=audit, maxSteps=maxSteps, timeout=timeout, bs=bs) # applyCl
     @staticmethod                                                                # applyCl
     def pruneFolder(folder):                                                     # applyCl
         """Removes empty directories recursively from a root folder."""          # applyCl
         def inner(folder):                                                       # applyCl
             folder = os.path.expanduser(folder)                                  # applyCl
             dirs, files = folder | ls() | filt(os.path.isdir).split() | deref()  # applyCl
             if len(files) > 0: return                                            # applyCl
             dirs | apply(pruneFolder) | ignore()                                 # applyCl
             if folder | ls() | shape(0) == 0: None | cmd(f"rm -rf {folder}") | ignore() # applyCl
         None | applyCl.aS(lambda: inner(folder)) | deref()                       # applyCl
     @staticmethod                                                                # applyCl
-    def diskScan(folder:str, raw=False, accurate=True):                          # applyCl
+    def diskScan(folder:str, raw=False, accurate=True, f=None):                  # applyCl
         """Scans for files and folders in the specified folder for potential
 distributed files and folders. A distributed file is a file that exists on more
 than 1 node. A distributed folder is a folder that that exists on more than 1
 node and does not have any shared children. Example::
 
     applyCl.diskScan("~/ssd2")
     applyCl.diskScan("~/ssd2", True)
@@ -931,18 +1029,19 @@
 (like "~/.bashrc", for example), these might be mistaken as a distributed file.
 Make sure to only scan folders that you store data in, or else it'll take a long time to return.
 
 :param folder: the folder to scan through
 :param raw: whether to return raw data or display it out nicely
 :param accurate: if True, returns size when you read all files into RAM. If False
     returns size occupied by the entire file/folder (will be larger because files
-    are arranged into different blocks in the underlying disk)"""                # applyCl
+    are arranged into different blocks in the underlying disk)
+:param f: optional post process function applied after getting the raw results, if ``raw=False``""" # applyCl
         from k1lib.cli._applyCl import diskScan4, diskScan5                      # applyCl
         if raw: return diskScan4(folder, accurate=accurate)                      # applyCl
-        else: return diskScan5(folder, accurate=accurate)                        # applyCl
+        else: return diskScan5(folder, accurate=accurate, f=(f or cli.iden()))   # applyCl
     @staticmethod                                                                # applyCl
     def balancedNodeIds():                                                       # applyCl
         """Returns a stream of node ids that's balanced based on cpu count/performance.
 Example::
 
     # returns list of 10 node ids: ["abc...", "def...", "abc...", ...]
     applyCl.balancedNodeIds() | head() | deref()
@@ -1102,16 +1201,35 @@
 
 :param column: if None, sort rows based on themselves and not an element
 :param numeric: whether to convert column to float
 :param reverse: False for smaller to bigger, True for bigger to smaller. Use
     :meth:`__invert__` to quickly reverse the order instead of using this param""" # sort
         self.column = column; self.reverse = reverse; self.numeric = numeric     # sort
         self.filterF = (lambda x: float(x)) if numeric else (lambda x: x)        # sort
+    def _all_array_opt(self, it, level):                                         # sort
+        c = self.column; reverse = self.reverse; p = [slice(None, None, None)]*level; p1 = (*p, slice(None, None, None)) # sort
+        if c is None and len(it.shape)-level != 1: raise Exception(f"Expected sort(None) to take in 1-d array, but the array has shape {it.shape[level:]}") # sort
+        if c is not None and len(it.shape)-level != 2: raise Exception(f"Expected sort(None) to take in 2-d array, but the array has shape {it.shape[level:]}") # sort
+        bm = np if isinstance(it, np.ndarray) else (torch if (hasTorch and isinstance(it, torch.Tensor)) else None) # sort
+        if bm is not None:                                                       # sort
+            try:                                                                 # sort
+                if c is None: b = bm.argsort(it);   b = bm.flip(b, (level,)) if reverse else b; return bm.gather(it, level, b) # sort
+                else: b = bm.argsort(it[(*p1, c)]); b = bm.flip(b, (level,)) if reverse else b; return bm.gather(it, level, b[(*p1, None)].expand(it.shape)) # sort
+            except Exception as e:                                               # sort
+                print(e)                                                         # sort
+        return NotImplemented                                                    # sort
     def __ror__(self, it:Iterator[str]):                                         # sort
-        c = self.column                                                          # sort
+        c = self.column; reverse = self.reverse; bm = None                       # sort
+        if isinstance(it, settings.arrayTypes):                                  # sort
+            if c is None and len(it.shape) != 1: raise Exception(f"Expected sort(None) to take in a 1-d array, but the array has shape {it.shape}") # sort
+            if c is not None and len(it.shape) != 2: raise Exception(f"Expected sort(col) to take in a 2-d array, but the array has shape {it.shape}") # sort
+            bm = np if isinstance(it, np.ndarray) else (torch if (hasTorch and isinstance(it, torch.Tensor)) else None) # sort
+            if bm:                                                               # sort
+                if c is None: ans = it[bm.argsort(it)]; return bm.flip(ans, (0,)) if reverse else ans # sort
+                else: ans = it[bm.argsort(it[:,c])]; return bm.flip(ans, (0,)) if reverse else ans # sort
         if c is None:                                                            # sort
             return it | cli.wrapList() | cli.transpose() | sort(0, self.numeric, self.reverse) | cli.op()[0].all() # sort
         f = self.filterF                                                         # sort
         rows = (it | cli.isNumeric(c) if self.numeric else it) | cli.apply(list) # sort
         def sortF(row):                                                          # sort
             if len(row) > c: return f(row[c])                                    # sort
             return float("inf")                                                  # sort
@@ -1169,31 +1287,41 @@
     # returns something like this: [1, 0, 2, 3, 5, 4, 6, 8, 7, 9]. You can clearly see the batches
     range(10) | randomize(3) | deref()
     # returns something like this: [7, 0, 5, 2, 4, 9, 6, 3, 1, 8]
     range(10) | randomize(float("inf")) | deref()
     # same as above
     range(10) | randomize(None) | deref()
     # returns True, as the seed is the same
-    range(10) | randomize(seed=4) | deref() == range(10) | randomize(seed=4) | deref()""" # randomize
-        self.bs = bs if bs != None else float("inf"); self.seed = seed; self._initGenn() # randomize
-    def _initGenn(self):                                                         # randomize
-        if hasTorch:                                                             # randomize
-            gen = torch.Generator().manual_seed(random.Random(self.seed).getrandbits(63)) # randomize
-            self.genn = lambda n: torch.randperm(n, generator=gen)               # randomize
-        else: self.genn = np.random.permutation                                  # randomize
-    def __getstate__(self):                                                      # randomize
-        genn = self.genn; self.genn = None; return self.__dict__                 # randomize
-    def __setstate__(self, d): self.__dict__.update(d); self._initGenn()         # randomize
+    range(10) | randomize(seed=4) | deref() == range(10) | randomize(seed=4) | deref()
+
+Note that if ``seed=True``, then it will randomize all input
+iterators the same way and independently of each other. Meaning::
+
+    r = randomize(seed=42)
+    range(10) | r | deref() #      returns [6, 9, 1, 2, 0, 8, 3, 5, 4, 7]
+    range(10) | r | deref() # also returns [6, 9, 1, 2, 0, 8, 3, 5, 4, 7]
+
+This may or may not be desireable, but I think it's desirable.
+
+:param bs: batch size
+:param seed: if specified, will always randomize the input iterator in the same way""" # randomize
+        self.bs = bs if bs != None else float("inf"); self.seed = seed           # randomize
+        if seed is not None and not hasTorch: raise Exception("Seeded randomize() depends on PyTorch. Please install it first") # randomize
+    def _newGenn(self):                                                          # randomize
+        if self.seed is None: return np.random.permutation                       # randomize
+        gen = torch.Generator().manual_seed(random.Random(self.seed).getrandbits(63)) # randomize
+        return lambda n: torch.randperm(n, generator=gen)                        # randomize
     def __ror__(self, it:Iterator[Any]) -> Iterator[Any]:                        # randomize
         bs = self.bs                                                             # randomize
         if isinstance(it, settings.arrayTypes):                                  # randomize
-            if bs is None or len(it) <= bs: return it if len(it) == 1 else it[self.genn(len(it))] # randomize
+            if bs is None or len(it) <= bs: return it if len(it) == 1 else it[self._newGenn()(len(it))] # randomize
         def gen():                                                               # randomize
+            genn = self._newGenn()                                               # randomize
             for batch in it | cli.batched(bs, True):                             # randomize
-                batch = list(batch); perms = self.genn(len(batch))               # randomize
+                batch = list(batch); perms = genn(len(batch))                    # randomize
                 for idx in perms: yield batch[idx]                               # randomize
         return gen()                                                             # randomize
 class StaggeredStream:                                                           # StaggeredStream
     def __init__(self, stream:Iterator[Any], every:int):                         # StaggeredStream
         """Not intended to be instantiated by the end user. Use :class:`stagger`
 instead."""                                                                      # StaggeredStream
         self.stream = stream; self.every = every                                 # StaggeredStream
```

## k1lib/cli/structural.py

```diff
@@ -432,22 +432,23 @@
 Also, if input is a :class:`range`, then to save time, a bunch of other
 ranges will be returned, instead of a bunch of lists, for performance::
 
     # returns [range(0, 3), range(3, 6), range(6, 9)]
     range(11) | batched(3) | toList()
 """                                                                              # batched
         super().__init__(); self.bs = bs; self.includeLast = includeLast         # batched
+    def _all_array_opt(self, it, level):                                         # batched
+        if self.includeLast: return NotImplemented                               # batched
+        bs = self.bs; a = [slice(None, None, None)]*level; n = it.shape[level] // bs; it = it[(*a, slice(None, n*bs))] # batched
+        return it.reshape(*it.shape[:level], n, bs, *it.shape[level+1:])         # batched
     def __ror__(self, it):                                                       # batched
         bs = self.bs; includeLast = self.includeLast                             # batched
-        if bs == float("inf"):                                                   # batched
-            if includeLast: return [it]                                          # batched
-            return []                                                            # batched
-        if not includeLast and isinstance(it, k1lib.settings.cli.arrayTypes):    # batched
-            n = it.shape[0] // bs; it = it[:n*bs]                                # batched
-            return it.reshape(n, bs, *it.shape[1:])                              # batched
+        if bs == float("inf"): return [it] if includeLast else []                # batched
+        if isinstance(it, k1lib.settings.cli.arrayTypes):                        # batched
+            if (not includeLast) or (it.shape[0]%bs == 0): n = it.shape[0] // bs; it = it[:n*bs]; return it.reshape(n, bs, *it.shape[1:]) # batched
         if isinstance(it, range): return _batchRange(it, bs, includeLast)        # batched
         try: it[0]; len(it); return _batchSliceable(it, bs, includeLast)         # batched
         except: return _batch(it, bs, includeLast)                               # batched
 nothing = object()                                                               # batched
 class window(BaseCli):                                                           # window
     def __init__(self, n, newList=False, pad=nothing):                           # window
         """Slides window of size n forward and yields the windows.
@@ -480,17 +481,15 @@
         self.pad = pad; self.padBool = pad is not nothing # why do this? Cause in applyMp, "nothing" takes on multiple identities # window
     def __ror__(self, it):                                                       # window
         n = self.n; pad = self.pad; q = deque([], n); listF = self.listF         # window
         for e in it:                                                             # window
             q.append(e)                                                          # window
             if len(q) == n: yield listF(q); q.popleft()                          # window
         if self.padBool:                                                         # window
-            for i in range(n-1):                                                 # window
-                q.append(pad)                                                    # window
-                yield listF(q); q.popleft()                                      # window
+            for i in range(n-1): q.append(pad); yield listF(q); q.popleft()      # window
 class groupBy(BaseCli):                                                          # groupBy
     def __init__(self, column:int, separate:bool=False, removeCol:bool=None):    # groupBy
         """Groups table by some column.
 Example::
 
     a = [[2.3, 5],
          [3.4, 2],
@@ -544,33 +543,29 @@
 :param separate: whether to separate out the column to sort of form a dict or not. See example
 :param removeCol: whether to remove the grouped-by column. Defaults to True if
     ``separate=True``, and False if ``separate=False``"""                        # groupBy
         self.column = column; self.separate = separate                           # groupBy
         if removeCol is None: removeCol = separate # if separate, then remove cols, else don't do it # groupBy
         self.removeCol = removeCol                                               # groupBy
     def __ror__(self, it):                                                       # groupBy
-        it = it | cli.deref(2); c = self.column; separate = self.separate; removeCol = self.removeCol # groupBy
-        it = it | cli.sort(c, False); sentinel = object()                        # groupBy
-        it = iter(it); a = [next(it, sentinel)]                                  # groupBy
+        it = [list(e) for e in it]; c = self.column; separate = self.separate; removeCol = self.removeCol # groupBy
+        it = it | cli.sort(c, False); sentinel = object(); it = iter(it); a = [next(it, sentinel)] # groupBy
         if a[0] is sentinel: return                                              # groupBy
         v = a[0][c]                                                              # groupBy
         try:                                                                     # groupBy
             while True:                                                          # groupBy
                 e = next(it)                                                     # groupBy
                 if e[c] == v: a.append(e)                                        # groupBy
                 else:                                                            # groupBy
                     if removeCol: a = a | ~cli.cut(c)                            # groupBy
-                    if separate: yield [v, a]                                    # groupBy
-                    else: yield a                                                # groupBy
-                    a = [e]; v = a[0][c]                                         # groupBy
+                    yield [v, a] if separate else a; a = [e]; v = a[0][c]        # groupBy
         except StopIteration:                                                    # groupBy
             if len(a) > 0:                                                       # groupBy
                 if removeCol: a = a | ~cli.cut(c)                                # groupBy
-                if separate: yield [v, a]                                        # groupBy
-                else: yield a                                                    # groupBy
+                yield [v, a] if separate else a                                  # groupBy
 class ungroup(BaseCli):                                                          # ungroup
     def __init__(self, single=True, begin=True, insertCol:bool=True):            # ungroup
         """Ungroups things that were grouped using a specific mode of
 :class:`groupBy`. Particularly useful to transform some complex data
 structure into a flat dataframe so that you can plug into pandas. Example::
 
     # returns [[3, 1.2], [3, 3.4], [5, 6], [5, 8], [5, 11]]
@@ -595,16 +590,15 @@
 Example::
 
     # returns [['a', 1, 2], ['b', 3, 4]]
     [[1, 2], [3, 4]] | insertColumn(["a", "b"]) | deref()
     # returns [[1, 2, 'a'], [3, 4, 'b']]
     [[1, 2], [3, 4]] | insertColumn(["a", "b"], begin=False) | deref()"""        # insertColumn
         self.column = column; self.begin = begin; self.fill = fill               # insertColumn
-    def __ror__(self, it):                                                       # insertColumn
-        return it | transpose(fill=self.fill) | insert(self.column, begin=self.begin) | transpose(fill=self.fill) # insertColumn
+    def __ror__(self, it): return it | transpose(fill=self.fill) | insert(self.column, begin=self.begin) | transpose(fill=self.fill) # insertColumn
 def insertIdColumn(table=False, begin=True):                                     # insertIdColumn
     """Inserts an id column at the beginning (or end).
 Example::
 
     # returns [[0, 'a', 2], [1, 'b', 4]]
     [["a", 2], ["b", 4]] | insertIdColumn(True) | deref()
     # returns [[0, 'a'], [1, 'b']]
```

## k1lib/cli/utils.py

```diff
@@ -12,15 +12,15 @@
 try: import PIL; hasPIL = True
 except: hasPIL = False
 try: plt = k1lib.dep("matplotlib.pyplot")
 except: pass
 __all__ = ["size", "shape", "item", "rItem", "iden", "join", "wrapList",
            "equals", "reverse", "ignore", "rateLimit", "timeLimit", "tab", "indent",
            "clipboard", "deref", "bindec", "smooth", "disassemble",
-           "tree", "lookup", "dictFields", "backup", "sketch"]
+           "tree", "lookup", "dictFields", "backup", "sketch", "syncStepper"]
 settings = k1lib.settings.cli
 def exploreSize(it):                                                             # exploreSize
     """Returns first element and length of array. Returns [first item, length]""" # exploreSize
     if isinstance(it, str): return None, len(it)                                 # exploreSize
     try: return it[0], len(it)                                                   # exploreSize
     except: pass                                                                 # exploreSize
     sentinel = object(); it = iter(it)                                           # exploreSize
@@ -120,18 +120,18 @@
 class rItem(BaseCli):                                                            # rItem
     def __init__(self, idx:int):                                                 # rItem
         """Combines ``rows(idx) | item()``, as this is a pretty common pattern.
 Example::
 
     iter(range(10)) | rItem(4) # returns 4
 """                                                                              # rItem
-        self.idx = idx                                                           # rItem
+        self.idx = idx; self.arrayTypes = (*settings.arrayTypes, list, tuple)    # rItem
     def _all_array_opt(self, it, level:int): return it[(*[slice(None, None, None) for i in range(level)], self.idx)] # rItem
     def __ror__(self, it):                                                       # rItem
-        if isinstance(it, settings.arrayTypes): return it[self.idx]              # rItem
+        if isinstance(it, self.arrayTypes): return it[self.idx]                  # rItem
         for i, e in zip(range(self.idx+1), it): pass                             # rItem
         return e                                                                 # rItem
 class iden(BaseCli):                                                             # iden
     def __init__(self):                                                          # iden
         """Yields whatever the input is. Useful for multiple streams.
 Example::
 
@@ -370,18 +370,17 @@
     def __ror__(self, it:Iterator[Any]) -> List[Any]:                            # deref
         if self.depth >= self.maxDepth: return it                                # deref
         elif isinstance(it, np.number): return it.item()                         # deref
         elif isinstance(it, atomic.deref): return it                             # deref
         elif isinstance(it, self.arrayType):                                     # deref
             if self.igT: return it                                               # deref
             if len(it.shape) == 0: return it.item()                              # deref
-        elif isinstance(it, dict):                                               # deref
-            self.depth += 1; _d = {k: self.__ror__(v) for k, v in it.items()}; self.depth -= 1; return _d # deref
-        elif isinstance(it, tuple):                                              # deref
-            self.depth += 1; _t = tuple(self.__ror__(k) for k in it); self.depth -= 1; return _t # deref
+        elif isinstance(it, dict):  self.depth += 1; _d = {k:   self.__ror__(v) for k, v in it.items()}; self.depth -= 1; return _d # deref
+        elif isinstance(it, tuple): self.depth += 1; _t = tuple(self.__ror__(k) for k    in it);         self.depth -= 1; return _t # deref
+        elif isinstance(it, set):   self.depth += 1; _s = set  (self.__ror__(k) for k    in it);         self.depth -= 1; return _s # deref
         try: iter(it)                                                            # deref
         except: return it                                                        # deref
         self.depth += 1; answer = []                                             # deref
         for e in it:                                                             # deref
             if e is cli.yieldT: return answer                                    # deref
             answer.append(self.__ror__(e))                                       # deref
         self.depth -= 1; return answer                                           # deref
@@ -555,15 +554,15 @@
     def restore():                                                               # backup
         def inner(it):                                                           # backup
             it = os.path.expanduser(it)                                          # backup
             None | cli.cmd(f"rm -rf '{it}'") | cli.ignore()                      # backup
             None | cli.cmd(f"cp -r '{it}.backup' '{it}'") | cli.ignore()         # backup
         return cli.aS(inner)                                                     # backup
 class sketch(BaseCli):                                                           # sketch
-    def __init__(self, transforms:List[callable]=[], titles:List[str]=None, im:bool=False): # sketch
+    def __init__(self, transforms:List[callable]=[], titles:List[str]=None, im:bool=False, ncols:int=None): # sketch
         """Convenience tool to plot multiple matplotlib plots at the same
 time, while still keeping everything short and in 1 line. For this example,
 we're trying to plot x^1, x^2, ..., x^8 on 2 separate plots, one left one
 right. The left will have x^1 till x^4, the right will have x^5 to x^8.
 
 How you would do this normally::
 
@@ -598,20 +597,124 @@
 
 Is it worth the extra confusion? Afterall, it just saves you 2-3 lines of
 code. To me, it is worth it, because you can quickly change styles (add
 a grid, make y axis log)
 
 :param transforms: transform functions to be run when drawing every plot. ``plt`` (aka ``matplotlib.pyplot``) will be passed in
 :param titles: if specified, use these titles for each plot. Kinda hacky I have to admit
-:param im: if True, returns a PIL image and closes the sketch, else return nothing but still have the sketch open""" # sketch
+:param im: if True, returns a PIL image and closes the sketch, else return nothing but still have the sketch open
+:param ncols: if specified, will sketch with this number of columns"""           # sketch
         super().__init__(capture=True); self.titles = titles; self.im = im       # sketch
-        self.transforms = [cli.fastF(t) for t in transforms]                     # sketch
+        self.transforms = [cli.fastF(t) for t in transforms]; self.ncols = ncols # sketch
     def __ror__(self, it):                                                       # sketch
         it = list(it); n = len(it); s = self.capturedSerial; transforms = self.transforms # sketch
-        ncols = math.ceil(n**0.5); nrows = math.ceil(n/ncols)                    # sketch
+        ncols = self.ncols or math.ceil(n**0.5); nrows = math.ceil(n/ncols)      # sketch
         fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*4))       # sketch
         if axes | cli.shape() | cli.shape(0) > 1: axes = axes.flatten()          # sketch
-        for ax, e, title in zip(axes, it, self.titles or ("" | cli.repeat())):   # sketch
-            plt.sca(ax); e | s | cli.deref(); plt.title(title)                   # sketch
+        for i, [ax, e, title] in enumerate(zip(axes, it, self.titles or ("" | cli.repeat()))): # sketch
+            plt.sca(ax); e | s | cli.deref()                                     # sketch
+            if title: plt.title(title)                                           # sketch
             for trans in transforms: trans(plt)                                  # sketch
-        plt.tight_layout()                                                       # sketch
+        axes[i+1:] | cli.op().remove().all() | cli.deref(); plt.tight_layout()   # sketch
         if self.im: return plt.gcf() | cli.toImg()                               # sketch
+import numbers, sys; from collections import deque                               # sketch
+class syncStepper(BaseCli):                                                      # syncStepper
+    def __init__(self, col=0, sort=False):                                       # syncStepper
+        """Steps forward all streams at a time, yielding same results from min to max.
+That's a bit vague, so let's see an example::
+
+    a = [["a", 1], ["b", 7 ], ["c", 4], ["e", 6]]
+    b = [["b", 5], ["c", 1 ], ["d", 3], ["f", 5]]
+    c = [["a", 2], ["c", -4], ["d", 9], ["e", 4]]
+
+    [a, b, c] | syncStepper() | deref() # sync-step by the 1st column
+    [a, b, c] | syncStepper(1, True) | deref() # sync-step by the 2nd column. Have to sort it explicitly
+
+The first line returns this::
+
+    [[['a', 1], None, ['a', 2]],
+     [['b', 7], ['b', 5], None],
+     [['c', 4], ['c', 1], ['c', -4]],
+     [None, ['d', 3], ['d', 9]],
+     [['e', 6], None, ['e', 4]],
+     [None, ['f', 5], None]]
+
+The second line returns this::
+
+    [[None, None, ['c', -4]],
+     [['a', 1], ['c', 1], None],
+     [None, None, ['a', 2]],
+     [None, ['d', 3], None],
+     [['c', 4], None, ['e', 4]],
+     [None, ['b', 5], None],
+     [['e', 6], None, None],
+     [['b', 7], None, None],
+     [None, None, ['d', 9]]]
+
+``col`` can be None, but it's quite a strange use case::
+
+    [['a', 'b', 'c', 'e'], ['b', 'c', 'd', 'f'], ['a', 'c', 'd', 'e']] | syncStepper(None) | deref()
+
+It returns this::
+
+    [[['a'], None, ['a']],
+     [['b'], ['b'], None],
+     [['c'], ['c'], ['c']],
+     [None, ['d'], ['d']],
+     [['e'], None, ['e']],
+     [None, ['f'], None]]
+
+As you can see, for each line, it kinda yields elements with the same column. If
+that element doesn't exist, it'll just put None there. This expects the input
+streams are sorted at the column of interest. If they are not, specify ``sort=True``.
+
+It has roughly the same vibe as :class:`~k1lib.cli.structural.groupBy`, in that
+it groups everything by a specific column. The main difference here is that you
+can sync-step them line-by-line, loading very little into memory, so you can run
+this on giant datasets and not have to worry about running out of memory.
+
+With k streams each having n elements, you should expect memory complexity to be
+O(k), and the time complexity to be O(n*k^2/2). That k^2 term is kinda worrying,
+but in most use cases, k is small and so k^2 can be treated as a constant
+
+:param col: column where it should compare values and merge them together. Can be None, but that would be quite a weird use case
+:param sort: whether to sort the streams or not. This cli requires it, but it's
+    not turned on by default because it's an intensive operation"""              # syncStepper
+        if col is None: self.col = 0; self.colPreprocess = cli.wrapList().all()  # syncStepper
+        else: self.col = col; self.colPreprocess = cli.iden()                    # syncStepper
+        self.bank = deque(); self.sentinel = object(); self._sort = sort         # syncStepper
+    def _append(self, stIdx1, val1, elem1): # append to bank in the correct position # syncStepper
+        i = 0; val2 = self.minObj                                                # syncStepper
+        for i, [stIdx2, val2, elem2] in enumerate(self.bank):                    # syncStepper
+            if val1 <= val2: break                                               # syncStepper
+        if val1 <= val2: self.bank.insert(i, [stIdx1, val1, elem1])              # syncStepper
+        else: self.bank.append([stIdx1, val1, elem1])                            # syncStepper
+    def _yieldNext(self): # yield the next set of values                         # syncStepper
+        n = len(self.sts); res = [None]*n; last = None; hasInit = False; changed = False; bank = self.bank; sentinel = self.sentinel # syncStepper
+        for i, [stIdx, val, elem] in enumerate(bank):                            # syncStepper
+            if not hasInit and elem is sentinel: return res, changed             # syncStepper
+            if last == val or not hasInit: changed = True; res[stIdx] = elem     # syncStepper
+            elif hasInit: break                                                  # syncStepper
+            hasInit = True; last = val                                           # syncStepper
+        while bank[0][1] == last: # popping the values off                       # syncStepper
+            stIdx, val1, elem1 = bank.popleft(); val2, elem2 = next(self.sts[stIdx]) # syncStepper
+            if val1 > val2: raise Exception(f"Stream {stIdx} has not been sorted yet! Please sort all streams before passing it into syncStepper") # syncStepper
+            self._append(stIdx, val2, elem2)                                     # syncStepper
+        return res, changed                                                      # syncStepper
+    def __ror__(self, sts): # sts = "streams"                                    # syncStepper
+        col = self.col                                                           # syncStepper
+        # --------------------- All of this is just to figure out the type of the column dynamically. So painful --------------------- # syncStepper
+        samples, sts = sts | self.colPreprocess.all() | cli.apply(cli.peek()) | cli.transpose() | cli.cut(col) + cli.iden() | cli.apply(list) # syncStepper
+        if len([e for e in sts if e != []]) == 0: return # no elements to yield at all! # syncStepper
+        n_nums = sum([1 if isinstance(e, numbers.Number) else 0 for e in samples]) # syncStepper
+        n_strs = sum([1 if isinstance(e, str) else 0 for e in samples]); n = len(samples) # syncStepper
+        if n_nums*(n-n_nums) + n_strs*(n-n_strs) > 0: raise Exception("The requested column in some of the streams is not purely of numeric or string type, a requirement of syncStepper(). Please fix your data structure and try again.") # syncStepper
+        if n_nums + n_strs == 0: raise Exception("The requested column in some of the streams is not of numeric or string type, so can't compare them to sync-step them") # syncStepper
+        # n = 3; n_strs = 1                                                      # syncStepper
+        text = n_strs > 0; self.minObj = "" if text else float("-inf"); self.maxObj = chr(sys.maxunicode) if text else float("inf"); senObj = [self.maxObj, self.sentinel] # syncStepper
+        # --------------------- And here's the meat of the cli --------------------- # syncStepper
+        sts = sts | (cli.sort(col, not text).all() if self._sort else cli.iden()) | cli.apply(lambda st: [st | cli.apply(lambda elem: [elem[col], elem]), senObj | cli.repeat()] | cli.joinStreams()) | cli.aS(list) # syncStepper
+        sts | cli.apply(next) | cli.insertIdColumn() | ~cli.apply(lambda idx,e: self._append(idx, *e)) | cli.ignore(); self.sts = sts # syncStepper
+        while True:                                                              # syncStepper
+            res, changed = self._yieldNext()                                     # syncStepper
+            if not changed: break                                                # syncStepper
+            yield res                                                            # syncStepper
```

## k1lib/k1ui/main.py

```diff
@@ -3,19 +3,20 @@
 aims to record and manipulate the screen, keyboard and mouse. The interface to
 that project on its own is clunky, and this module is the Python interface to
 ease its use.
 
 Not quite developed yet tho, because I'm lazy."""
 import k1lib, numpy as np, asyncio, time, inspect, json, threading, dill, math, base64, os, random, warnings
 k1 = k1lib; cli = k1.cli; from k1lib.cli import *; knn = k1.knn; Cbs = k1.Cbs; viz = k1.viz; websockets = k1.dep("websockets")
-nn = k1.dep("torch.nn"); optim = k1.dep("torch.optim"); tf = k1.dep("torchvision.transforms")
-PIL = k1.dep("PIL"); k1.dep("graphviz"); requests = k1.dep("requests")
+nn = k1.dep("torch.nn"); optim = k1.dep("torch.optim")
+PIL = k1.dep("PIL"); k1.dep("graphviz"); requests = k1.dep("requests"); tf = k1.dep("torchvision.transforms")
 try: import torch; hasTorch = True
 except: torch = k1.dep("torch"); hasTorch = False
-
+try: import torchvision; hasTv = True
+except: hasTv = False
 from typing import Callable, List, Iterator, Tuple, Union, Dict; from collections import defaultdict, deque; from functools import lru_cache
 import matplotlib as mpl; import matplotlib.pyplot as plt
 __all__ = ["get", "WsSession", "selectArea", "record", "execute", "Recording",
            "Track", "CharTrack", "WordTrack", "ContourTrack", "ClickTrack", "WheelTrack", "StreamTrack",
            "distNet", "TrainScreen"]
 k1lib.settings.add("k1ui", k1.Settings().add("server", k1.Settings().add("http", "http://localhost:9511", "normal http server").add("ws", "ws://localhost:9512", "websocket server"), "server urls"), "docs related to k1ui java library");
 settings = k1lib.settings.k1ui
@@ -802,15 +803,15 @@
         else: count = 0; lastE = e; lastRow = row; yielded = False               # discardTransients
         if count > countThres-2 and not yielded: yielded = True; yield lastRow   # discardTransients
         elif regular: yield None                                                 # discardTransients
 class Buffer:                                                                    # Buffer
     def __init__(self): self.l = deque()                                         # Buffer
     def append(self, x): self.l.append(x)                                        # Buffer
     def __next__(self): return self.l.popleft()                                  # Buffer
-if hasTorch:                                                                     # Buffer
+if hasTorch and hasTv:                                                           # Buffer
     np2Tensor = toImg() | aS(tf.Resize([192, 192])) | toTensor()                 # Buffer
     class MLP(nn.Module):                                                        # Buffer
         def __init__(self, nClasses, **kwargs):                                  # Buffer
             super().__init__(); self.l1 = knn.LinBlock(50, nClasses); self.l2 = nn.Linear(nClasses, nClasses) # Buffer
         def forward(self, xb): return xb | self.l1 | self.l2                     # Buffer
 whatever = object()                                                              # Buffer
 class TrainScreen:                                                               # TrainScreen
```

## Comparing `k1lib-1.4.1.data/data/k1lib/k1ui/256.model.state_dict.pth` & `k1lib-1.4.2.data/data/k1lib/k1ui/256.model.state_dict.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.4.1.data/data/k1lib/k1ui/mouseKey.pth` & `k1lib-1.4.2.data/data/k1lib/k1ui/mouseKey.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.4.1.data/data/k1lib/serve/main.html` & `k1lib-1.4.2.data/data/k1lib/serve/main.html`

 * *Files identical despite different names*

## Comparing `k1lib-1.4.1.dist-info/LICENSE` & `k1lib-1.4.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `k1lib-1.4.1.dist-info/METADATA` & `k1lib-1.4.2.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: k1lib
-Version: 1.4.1
+Version: 1.4.2
 Summary: Some nice ML overhaul
 Home-page: https://k1lib.com
 Author: Quang Ho
 Author-email: 157239q@gmail.com
 License: MIT
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `k1lib-1.4.1.dist-info/RECORD` & `k1lib-1.4.2.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 k1lib/__init__.py,sha256=tHszZf_A_U-Pq3S5ag6Q6xVDZiRLA6VRxRkikl6BwRA,1441
 k1lib/_baseClasses.py,sha256=gOaGVvrSocdqpNDek5SA1v46M9fOLKlDyhCROKQr7ic,83638
-k1lib/_basics.py,sha256=5kk7fZlVkFkkDQcLU8DYI5wTc2iNXRL2SvPMTUY8JpY,22816
+k1lib/_basics.py,sha256=50kzCvgLDmOLMPVJlebe7kgf2akhedJP-nWMdpP11Fg,25511
 k1lib/_context.py,sha256=ha8FkjmOGksqGZJLBJSSGc0M1IbtCzr9APisESRstko,8208
 k1lib/_higher.py,sha256=x7uvroUijQ8dqTv0skfeaMFF9MF7Q4ncwEBjUtpw89s,4314
 k1lib/_k1a.py,sha256=LhrmrTWh7aTasRfbKB3wIseaIMcpnthMAyw5TX87plU,3085
 k1lib/_learner.py,sha256=40dDzOe2vmoVmuhoMZ3opBQll9mmXIWJlX6pG-HXLSI,20567
-k1lib/_monkey.py,sha256=fRu1heiJAjhpAq1ck4CWnz39rfGgxWYAx_Iq6dfKgAM,35159
+k1lib/_monkey.py,sha256=8VaiBcQrkwGnLFHbmB4hVTwtYQlj18fPgeYYVsk9JBo,36997
 k1lib/_perlin.py,sha256=euxCMyKrPqxwdz-A82oTXS62CtYOfNclSy6pJLOlJIY,5575
 k1lib/eqn.py,sha256=vKannnIMmySYTzrY2Ub6bBHIyTRFgL0vmcA7EKfPQTI,21263
 k1lib/fmt.py,sha256=vgou7uBZplkrtpFpbP726r0xw-LY1p2VmFrgFtxLY0E,12310
 k1lib/graphEqn.py,sha256=1uCNm-h0sWOczFJxNM4Kx-mXXgOGS_KV_mxCqIXH0cE,10890
-k1lib/imports.py,sha256=UJwri5nMcMYXLGSRQQYznOreeE3FFd22wTvus1SnPrQ,4996
+k1lib/imports.py,sha256=1bqXKG1v6JiJzHhF-xFtGg9Cc0zjvlOcOfMBVqkqvLc,5174
 k1lib/knn.py,sha256=Rmjom56xuRJUs5h5sCeLK10HdFUPqtm6YkN539NPSt4,4919
 k1lib/p5.py,sha256=h8HeMpWBzuhus5z11dRALoomt9x-dK3swH-xndpClTI,6449
 k1lib/schedule.py,sha256=lfGMUshb_LQ5MO4t18NyvpSEydpb8vg62A3Sq8SnVD0,14079
 k1lib/selector.py,sha256=rSM5JQ5hQyPAE5Wuo9ZLeoTzITTCUnJbb1xNUQAwW5A,29996
-k1lib/viz.py,sha256=Q31TTQUXeWBm2dZWMXREAs4WeXMx3JiJN8aF8JJ9cuU,24144
+k1lib/viz.py,sha256=I0zOze8gZN3hU0LRRzFCzhwaTW6mfGzTSOI0xN_c8QE,27360
 k1lib/_hidden/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 k1lib/_hidden/hiddenFile.py,sha256=v05pb9A7xcuzIJ0zLt4rTp6mZ4zP6QFkn9UN4qmC9G4,79
 k1lib/_mo/__init__.py,sha256=1cn6kpsev735HU4hNTRzOiHgU0bwyxIJoNhOxzLRto4,615
 k1lib/_mo/atom.py,sha256=coEnbybqoZqnWoRwu8u8L76ch9i6g4sOY2dg4NHl8us,24015
 k1lib/_mo/parseM.py,sha256=RGOGUu5Pnq5m7mTAom8-fGPbWnDWBKz3ooSg9PKKJH4,18173
 k1lib/_mo/substance.py,sha256=QVa0ls0RbpIWp9VYZvu7bybfmDECC04VPHVOb4w4iwk,5631
 k1lib/_mo/system.py,sha256=HV-XJgzxOSSfhQLVE3p-84P6YLv2FiYrM3R_MOlEpfY,15454
@@ -41,44 +41,44 @@
 k1lib/callbacks/lossFunctions/accuracy.py,sha256=Z1wa5WL78SKWWIAd3KiduS6NEiCaILG7LBha5EMlvmM,3695
 k1lib/callbacks/lossFunctions/shorts.py,sha256=TB9OAkCSlBsegZ4l9xYPj4CjTuVVI7jqYtSxWpOD8BI,5968
 k1lib/callbacks/profilers/__init__.py,sha256=Gp5IvLRABYAg1J0ilTT2v72gfDbyTvUUHUEpvlSo1Lc,45
 k1lib/callbacks/profilers/computation.py,sha256=blkJNDzOoKKPo_CJ1FxkjOMNNRgujkiwEJtf-Rb73n8,9311
 k1lib/callbacks/profilers/io.py,sha256=C7z75XupTFSfNLUuIJ3HhGm_th5wRMPoAXzE4AqhNgM,4069
 k1lib/callbacks/profilers/memory.py,sha256=OGktEUoiSwAvDEU-G4zdelVRK_VKg_PtTPIUzy2wGCM,7368
 k1lib/callbacks/profilers/time.py,sha256=SKPp2Lly14UGjpb9WJOuMCTWrCmHhIjCeGD0lwZS4i0,6971
-k1lib/cli/__init__.py,sha256=hF0ODhL20OSM9o1j68VhcIVflibgSpPuqeyYlsh8oow,925
-k1lib/cli/_applyCl.py,sha256=Gwm1PYlMrF1YEzSjOrJ0QUrEYGIzffOh5MEfHTU5nnA,28678
+k1lib/cli/__init__.py,sha256=Jpvy5usyoI_ke7YCd6rp41v0ei5MSdURFD7m2JnDyXc,926
+k1lib/cli/_applyCl.py,sha256=6DNZFIPQnf1VsaD8eQBJzS-Ea83Wgpmon4Iv2WEwIPA,31282
 k1lib/cli/bio.py,sha256=V5QHg1nkpynk3_6VqYcvKWOx4UV42IWwhNanB-zThmc,13909
 k1lib/cli/cif.py,sha256=Wi0Zeqq6NJBF31FOKGvvQfHXi-M4ufkZIChxNi39890,5162
-k1lib/cli/conv.py,sha256=FsCXAOdpqcUiOkKBqe7RSh4LZ-L87qS9KC3VQ2NAmDs,32287
-k1lib/cli/filt.py,sha256=aUS7yCvbTxz3fpnly36smFaESdI_OOxUvUQkim7cjQU,43900
+k1lib/cli/conv.py,sha256=WiXww9Ma8LMlT1rNFjFrQ4LSFZYFa2aDRYUG7XuiOLo,34729
+k1lib/cli/filt.py,sha256=KimM23X0zwrKCiupwO_jUJdaiB5sgScnXUynBVCkbWA,47519
 k1lib/cli/gb.py,sha256=EhxJ7TlxSLYptSPTuLsI8dfGIAhSpKFfDN_sBfnHX0s,8480
-k1lib/cli/grep.py,sha256=SBs1cxTi3XVeoo4ONpCsj40V5fIzk_pQBRbjpXO_2Ww,8644
+k1lib/cli/grep.py,sha256=sX-IQrAt_4EaVmEJGzCGhcaozI5j1b-6JflH1IPX-gw,12136
 k1lib/cli/init.py,sha256=EMNnoD7iH-ltNO9eZ8zP7l28YEBa_ugrrnDmtSgXu7g,35262
-k1lib/cli/inp.py,sha256=Nw-3zPv3sUVXtt8mhfen5nme4sPPXEKsGyrWd4LO_WI,56176
-k1lib/cli/kcsv.py,sha256=kG2QfwYIyJtc9GuBkT1M2xXup5JCdgpLuS0FlU3_1bY,1127
+k1lib/cli/inp.py,sha256=hNIAdim0E4PZowBwf-DMozkfopN84rXWEmeTboX33Rk,56332
+k1lib/cli/kcsv.py,sha256=VSrFDzobRk14Wh5Os_wVoShi01s4L5gby-jnfSlV3qU,1127
 k1lib/cli/kxml.py,sha256=Tzb05JUMOfBl3WqJM9k3_v_ubDNrG8yOUYHrnBTeDqA,7467
 k1lib/cli/mgi.py,sha256=Dl_vITAfu3TNQMqekYEbEzhSP3jX1JFjD4KFkxqXBeg,2977
-k1lib/cli/modifier.py,sha256=dXkYUrCqd7DGDvpp08fKImIM9nsDovx3AqrW2CggkFU,93036
+k1lib/cli/modifier.py,sha256=qlc2wL-8Fz7sErATpeNX0sOI-Kpkbuq109WvjuDibtM,102579
 k1lib/cli/mol.py,sha256=3ABsuHkhTdgjLN6cB2LR0ibyMtiDBvb4K4TxvdvtHrk,735
 k1lib/cli/nb.py,sha256=YhU330fzzCygYZ6RZEyRqsHMLaOE4fr2cSWDh0rt9ck,5822
 k1lib/cli/optimizations.py,sha256=h_2083cbf03E9hYb8oQfcms8mhilpPRqCCLCegV9-OQ,6311
 k1lib/cli/output.py,sha256=2swTdYKgtdQjaRMOI_JJP7zoMbSn-RDAZw5sA0ehNJU,18482
 k1lib/cli/sam.py,sha256=RH28RaWyYDffWoV3UJbRrCuAI1msr-n95KTkLlMcNTk,3042
-k1lib/cli/structural.py,sha256=Fkd55G5-ntsgg3CH_U-PenMoZ8Y3-W9bOmF6XPQiCVM,68523
+k1lib/cli/structural.py,sha256=rVzghxjszH24-t_fioA_zduDHHhAOXdIdk1-vXy4J20,68110
 k1lib/cli/trace.py,sha256=rXLnzHL-CwcNWgAmPTbsojDMS4NYpwLhJIUA37eyLAM,15949
 k1lib/cli/typehint.py,sha256=ect5O4Pq4zsV0_FSO4Ys5rUr07IVNn1fdj7BOJwHcZI,41733
-k1lib/cli/utils.py,sha256=DDx3W38MWxgOkNVP8fFQmsXCpY7Hc2-M4wW76G8kkJA,41886
+k1lib/cli/utils.py,sha256=2uIjdzbVZH6sMBhKgKYz3XFWaWxg5DlAG-iGeoXuWrA,49329
 k1lib/k1ui/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
-k1lib/k1ui/main.py,sha256=xUzw_8UeUxxYt_SNhiyl4s0ll2RtVP5vg7GwdP2VceA,88699
+k1lib/k1ui/main.py,sha256=gsDNGtjIRFAZrCdBfOX7QfnwEg2duavpshpjq5Bhk_I,88758
 k1lib/serve/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/serve/main.py,sha256=7hO_xhmOCLFRMjdry7MeUSB04EeaAwPqoCiiSwJMwcA,15412
 k1lib/serve/suffix-dash.py,sha256=HMNJvB4d-PTHXDRDQTdYUKtzgirJ0LVnqqAkXxO0B4w,153
 k1lib/serve/suffix.py,sha256=UH3ITN6O2vzoha2f6v4bcQG3_Boav7VA7EC8wf8r9f8,642
-k1lib-1.4.1.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
-k1lib-1.4.1.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
-k1lib-1.4.1.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
-k1lib-1.4.1.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
-k1lib-1.4.1.dist-info/METADATA,sha256=xLiwRWiuwBooFDgs_Azz3HJJI3uOXOi1S0TMhZpOj6U,3888
-k1lib-1.4.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-k1lib-1.4.1.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
-k1lib-1.4.1.dist-info/RECORD,,
+k1lib-1.4.2.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
+k1lib-1.4.2.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
+k1lib-1.4.2.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
+k1lib-1.4.2.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
+k1lib-1.4.2.dist-info/METADATA,sha256=ntp4sxL0xuoFhyXQLU3q9KPgiuYtp3Kac3VoRkKs3Bs,3888
+k1lib-1.4.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+k1lib-1.4.2.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
+k1lib-1.4.2.dist-info/RECORD,,
```

